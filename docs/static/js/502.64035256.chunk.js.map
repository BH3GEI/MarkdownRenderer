{"version":3,"file":"static/js/502.64035256.chunk.js","mappings":"gKAiBIA,GAAgBC,EAAG,cAAcC,EAAAA,GAInCC,WAAAA,GACEC,MAAM,CAAC,OAAQ,YACjB,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,oBAAmBA,GAQhCK,EAAa,CACfC,OAAQ,CACNC,cAA8BH,EAAAA,EAAAA,KAAO,IAAM,IAAIL,GAAoB,gBACnES,gBAAgCJ,EAAAA,EAAAA,KAAO,IAAM,IAAIK,EAAAA,IAAwB,oBAG7E,SAASC,IAA8C,IAA3BC,EAAOC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGG,EAAAA,GACpC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,IAA8BP,GAC9BQ,EAAAA,IAEIC,GAAOH,EAAAA,EAAAA,KACXI,EAAAA,EAAAA,IAAwB,CAAEL,WAC1BM,EAAAA,GACAjB,GAGF,OADAW,EAAOO,gBAAgBC,SAASJ,GACzB,CAAEJ,SAAQI,OACnB,EACAhB,EAAAA,EAAAA,IAAOM,EAAoB,qB,8DC7BvBe,GAAezB,EAAG,cAAcC,EAAAA,GAIlCC,WAAAA,GACEC,MAAM,CAAC,MAAO,YAChB,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,mBAAkBA,GAQ/B0B,GAAiBC,EAAG,cAAcC,EAAAA,GAIpCC,kBAAAA,CAAmBC,EAAMC,EAAOC,GAC9B,GAAkB,sBAAdF,EAAKG,KAGT,OAAOF,EAAMG,QAAQ,KAAM,IAAIC,MACjC,IAPE/B,EAAAA,EAAAA,IAAMuB,EAAO,qBAAoBA,GAWjCS,EAAY,CACd9B,OAAQ,CACNC,cAA8BH,EAAAA,EAAAA,KAAO,IAAM,IAAIqB,GAAmB,gBAClEjB,gBAAgCJ,EAAAA,EAAAA,KAAO,IAAM,IAAIsB,GAAqB,oBAG1E,SAASW,IAA6C,IAA3B1B,EAAOC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGG,EAAAA,GACnC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,IAA8BP,GAC9BQ,EAAAA,IAEImB,GAAMrB,EAAAA,EAAAA,KACVI,EAAAA,EAAAA,IAAwB,CAAEL,WAC1BuB,EAAAA,GACAH,GAGF,OADApB,EAAOO,gBAAgBC,SAASc,GACzB,CAAEtB,SAAQsB,MACnB,EACAlC,EAAAA,EAAAA,IAAOiC,EAAmB,oB,4DC1CtBG,GAAkBxC,EAAG,cAAcC,EAAAA,GAIrCC,WAAAA,GACEC,MAAM,CAAC,eACT,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,sBAAqBA,GAQlCyC,EAAe,CACjBnC,OAAQ,CACNC,cAA8BH,EAAAA,EAAAA,KAAO,IAAM,IAAIoC,GAAsB,gBACrEhC,gBAAgCJ,EAAAA,EAAAA,KAAO,IAAM,IAAIK,EAAAA,IAAwB,oBAG7E,SAASiC,IAAgD,IAA3B/B,EAAOC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGG,EAAAA,GACtC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,IAA8BP,GAC9BQ,EAAAA,IAEIwB,GAAS1B,EAAAA,EAAAA,KACbI,EAAAA,EAAAA,IAAwB,CAAEL,WAC1B4B,EAAAA,GACAH,GAGF,OADAzB,EAAOO,gBAAgBC,SAASmB,GACzB,CAAE3B,SAAQ2B,SACnB,EACAvC,EAAAA,EAAAA,IAAOsC,EAAsB,uB,8DC7BzBG,GAAwB7C,EAAG,cAAcC,EAAAA,GAI3CC,WAAAA,GACEC,MAAM,CAAC,gBACT,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,4BAA2BA,GAQxC8C,GAA0BnB,EAAG,cAAcC,EAAAA,GAI7CC,kBAAAA,CAAmBC,EAAMC,EAAOC,GAC9B,MAAkB,cAAdF,EAAKG,KACAF,EAAMG,QAAQ,QAAS,IAAIC,OACX,mBAAdL,EAAKG,KACPF,EAAMG,QAAQ,SAAU,IACR,eAAdJ,EAAKG,KACPF,EAAMG,QAAQ,SAAU,IAAIC,YAD9B,CAIT,IAXE/B,EAAAA,EAAAA,IAAMuB,EAAO,8BAA6BA,GAe1CoB,EAAqB,CACvBzC,OAAQ,CACNC,cAA8BH,EAAAA,EAAAA,KAAO,IAAM,IAAIyC,GAA4B,gBAC3ErC,gBAAgCJ,EAAAA,EAAAA,KAAO,IAAM,IAAI0C,GAA8B,oBAGnF,SAASE,IAAsD,IAA3BrC,EAAOC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGG,EAAAA,GAC5C,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,IAA8BP,GAC9BQ,EAAAA,IAEI8B,GAAehC,EAAAA,EAAAA,KACnBI,EAAAA,EAAAA,IAAwB,CAAEL,WAC1BkC,EAAAA,GACAH,GAGF,OADA/B,EAAOO,gBAAgBC,SAASyB,GACzB,CAAEjC,SAAQiC,eACnB,EACA7C,EAAAA,EAAAA,IAAO4C,EAA4B,6B,4DC9C/BG,GAAoBnD,EAAG,cAAcC,EAAAA,GAIvCC,WAAAA,GACEC,MAAM,CAAC,YACT,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,wBAAuBA,GAQpCoD,EAAiB,CACnB9C,OAAQ,CACNC,cAA8BH,EAAAA,EAAAA,KAAO,IAAM,IAAI+C,GAAwB,gBACvE3C,gBAAgCJ,EAAAA,EAAAA,KAAO,IAAM,IAAIK,EAAAA,IAAwB,oBAG7E,SAAS4C,IAAkD,IAA3B1C,EAAOC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGG,EAAAA,GACxC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,IAA8BP,GAC9BQ,EAAAA,IAEImC,GAAWrC,EAAAA,EAAAA,KACfI,EAAAA,EAAAA,IAAwB,CAAEL,WAC1BuC,EAAAA,GACAH,GAGF,OADApC,EAAOO,gBAAgBC,SAAS8B,GACzB,CAAEtC,SAAQsC,WACnB,EACAlD,EAAAA,EAAAA,IAAOiD,EAAwB,yB,4IC9C3BG,EAAYC,OAAOC,eACnBtD,EAASA,CAACuD,EAAQC,IAAUJ,EAAUG,EAAQ,OAAQ,CAAEC,QAAOC,cAAc,IASjFzD,GAHA,SAAwB0D,GACtB,OAAOC,EAAWC,WAAWF,EAFZ,eAGnB,GACuB,kBACvB,IAAIG,EAAS,SAIb7D,GAHA,SAAkB0D,GAChB,OAAOC,EAAWC,WAAWF,EAAMG,EACrC,GACiB,YACjB,IAEIC,EAAS,SAIb9D,GAHA,SAAkB0D,GAChB,OAAOC,EAAWC,WAAWF,EAAMI,EACrC,GACiB,YAKjB9D,GAHA,SAAkB0D,GAChB,OAAOC,EAAWC,WAAWF,EAFlB,SAGb,GACiB,YACjB,IAAIR,EAAW,WAIflD,GAHA,SAAoB0D,GAClB,OAAOC,EAAWC,WAAWF,EAAMR,EACrC,GACmB,cAKnBlD,GAHA,SAAgB0D,GACd,OAAOC,EAAWC,WAAWF,EAFpB,OAGX,GACe,UACf,IAAIK,EAAQ,QAIZ/D,GAHA,SAAiB0D,GACf,OAAOC,EAAWC,WAAWF,EAAMK,EACrC,GACgB,WAKhB/D,GAHA,SAAkB0D,GAChB,OAAOC,EAAWC,WAAWF,EAFlB,SAGb,GACiB,YAKjB1D,GAHA,SAAuB0D,GACrB,OAAOC,EAAWC,WAAWF,EAFb,cAGlB,GACsB,iBAKtB1D,GAHA,SAAe0D,GACb,OAAOC,EAAWC,WAAWF,EAFrB,MAGV,GACc,SAKd1D,GAHA,SAAsB0D,GACpB,OAAOC,EAAWC,WAAWF,EAFd,aAGjB,GACqB,gBACrB,IAoPIM,EAEAC,EAEAC,EAEAC,EAEAC,EA3PAC,GAAoBzE,EAAG,cAAc0E,EAAAA,GAIvCC,WAAAA,GACE,MAAO,CAAC,eAAgB,SAAU,WAAY,gBAAiB,SAAU,SAAU,YAAa,OAAQ,WAAY,QAAS,OAAQ,WAAY,QAAS,SAAU,cAAe,MAAO,aAAc,UAAW,YACrN,CACAC,gBAAAA,CAAiBC,EAASC,GACxB,OAAQD,GACN,KAAKZ,EACL,IA1DS,WA2DT,IA1Dc,gBA2Dd,KAAKC,EACL,KAAKC,EACH,OAAOY,KAAKC,UAzEJ,YAyEyBF,GAEnC,IAjBU,YAkBR,OAAOC,KAAKC,UAAU1B,EAAUwB,GAElC,QACE,OAAO,EAGb,CACAG,gBAAAA,CAAiBC,GACf,MAAMC,EAAc,GAAHC,OAAMF,EAAQG,UAAUC,MAAK,KAAAF,OAAIF,EAAQK,UAGtD,MAAM,IAAIC,MAAM,GAADJ,OAAID,EAAW,iCAGpC,CACAM,eAAAA,CAAgBC,GACd,OAAQA,GACN,IAAK,eACH,MAAO,CACLzD,KAAM,eACN0D,WAAY,CACV,CAAE1D,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,QAAS2D,aAAc,IAC/B,CAAE3D,KAAM,SAAU2D,aAAc,IAChC,CAAE3D,KAAM,YAAa2D,aAAc,IACnC,CAAE3D,KAAM,WAAY2D,aAAc,IAClC,CAAE3D,KAAM,WAId,IAAK,SACH,MAAO,CACLA,KAAM,SACN0D,WAAY,CACV,CAAE1D,KAAM,QACR,CAAEA,KAAM,WAId,IAAK,WACH,MAAO,CACLA,KAAM,WACN0D,WAAY,CACV,CAAE1D,KAAM,YAId,IAAK,gBACH,MAAO,CACLA,KAAM,gBACN0D,WAAY,CACV,CAAE1D,KAAM,MACR,CAAEA,KAAM,UACR,CAAEA,KAAM,OAAQ2D,aAAc,MAIpC,IAAK,SACH,MAAO,CACL3D,KAAM,SACN0D,WAAY,CACV,CAAE1D,KAAM,MACR,CAAEA,KAAM,WACR,CAAEA,KAAM,OAAQ2D,aAAc,IAC9B,CAAE3D,KAAM,UAId,IAAK,SACH,MAAO,CACLA,KAAM,SACN0D,WAAY,CACV,CAAE1D,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,WAId,IAAK,OACH,MAAO,CACLA,KAAM,OACN0D,WAAY,CACV,CAAE1D,KAAM,UACR,CAAEA,KAAM,WAAY2D,cAAc,GAClC,CAAE3D,KAAM,SACR,CAAEA,KAAM,UAAW2D,cAAc,GACjC,CAAE3D,KAAM,UACR,CAAEA,KAAM,WAAY2D,cAAc,GAClC,CAAE3D,KAAM,SACR,CAAEA,KAAM,UAAW2D,cAAc,GACjC,CAAE3D,KAAM,WAId,IAAK,WACH,MAAO,CACLA,KAAM,WACN0D,WAAY,CACV,CAAE1D,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,aAAc2D,aAAc,IACpC,CAAE3D,KAAM,WAId,IAAK,QACH,MAAO,CACLA,KAAM,QACN0D,WAAY,CACV,CAAE1D,KAAM,QACR,CAAEA,KAAM,MACR,CAAEA,KAAM,MACR,CAAEA,KAAM,WAId,IAAK,OACH,MAAO,CACLA,KAAM,OACN0D,WAAY,CACV,CAAE1D,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,WAId,IAAK,WACH,MAAO,CACLA,KAAM,WACN0D,WAAY,CACV,CAAE1D,KAAM,MACR,CAAEA,KAAM,QAId,IAAK,QACH,MAAO,CACLA,KAAM,QACN0D,WAAY,CACV,CAAE1D,KAAM,UACR,CAAEA,KAAM,MACR,CAAEA,KAAM,OAAQ2D,aAAc,IAC9B,CAAE3D,KAAM,UAId,IAAK,SACH,MAAO,CACLA,KAAM,SACN0D,WAAY,CACV,CAAE1D,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,SAAU2D,aAAc,IAChC,CAAE3D,KAAM,WAId,IAAK,cACH,MAAO,CACLA,KAAM,cACN0D,WAAY,CACV,CAAE1D,KAAM,OACR,CAAEA,KAAM,SACR,CAAEA,KAAM,WAId,IAAK,MACH,MAAO,CACLA,KAAM,MACN0D,WAAY,CACV,CAAE1D,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,WAAY2D,aAAc,IAClC,CAAE3D,KAAM,WAAY2D,cAAc,GAClC,CAAE3D,KAAM,WAId,IAAK,aACH,MAAO,CACLA,KAAM,aACN0D,WAAY,CACV,CAAE1D,KAAM,SACR,CAAEA,KAAM,WAId,IAAK,UACH,MAAO,CACLA,KAAM,UACN0D,WAAY,CACV,CAAE1D,KAAM,QACR,CAAEA,KAAM,YACR,CAAEA,KAAM,MACR,CAAEA,KAAM,MACR,CAAEA,KAAM,WAId,IAAK,YACH,MAAO,CACLA,KAAM,YACN0D,WAAY,CACV,CAAE1D,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,OACR,CAAEA,KAAM,aAAc2D,aAAc,IACpC,CAAE3D,KAAM,WAId,QACE,MAAO,CACLA,KAAMyD,EACNC,WAAY,IAIpB,GA3OEvF,EAAMJ,EAAO,wBAAuBA,GA6OpC+D,EAAa,IAAIU,EAKjBoB,EAA8BzF,GAAO,SAAA0F,EAAA,OAAuB,QAAvBA,EAAM1B,SAAiB,IAAA0B,EAAAA,EAAK1B,GAAoB2B,EAAAA,EAAAA,IAAoB,wlHAAwlH,GAAG,eAEpsHC,EAAgC5F,GAAO,SAAA6F,EAAA,OAAyB,QAAzBA,EAAM5B,SAAmB,IAAA4B,EAAAA,EAAK5B,GAAsB0B,EAAAA,EAAAA,IAAoB,+hKAA4hK,GAAG,iBAE9oKG,EAA6B9F,GAAO,SAAA+F,EAAA,OAAsB,QAAtBA,EAAM7B,SAAgB,IAAA6B,EAAAA,EAAK7B,GAAmByB,EAAAA,EAAAA,IAAoB,g+JAAg+J,GAAG,cAEzkKK,EAAsChG,GAAO,SAAAiG,EAAA,OAA+B,QAA/BA,EAAM9B,SAAyB,IAAA8B,EAAAA,EAAK9B,GAA4BwB,EAAAA,EAAAA,IAAoB,y5VAAy5V,GAAG,uBAE7hWO,EAAkClG,GAAO,SAAAmG,EAAA,OAA2B,QAA3BA,EAAM/B,SAAqB,IAAA+B,EAAAA,EAAK/B,GAAwBuB,EAAAA,EAAAA,IAAoB,itUAA8sU,GAAG,mBAGt0US,EAAuB,CACzBC,WAAY,OACZC,eAAgB,CAAC,OAAQ,YACzBC,iBAAiB,GAEfC,EAAyB,CAC3BH,WAAY,SACZC,eAAgB,CAAC,OAAQ,YACzBC,iBAAiB,GAEfE,EAAsB,CACxBJ,WAAY,MACZC,eAAgB,CAAC,OAAQ,YACzBC,iBAAiB,GAEfG,EAA+B,CACjCL,WAAY,eACZC,eAAgB,CAAC,OAAQ,YACzBC,iBAAiB,GAEfI,EAA2B,CAC7BN,WAAY,WACZC,eAAgB,CAAC,OAAQ,YACzBC,iBAAiB,GAEfxF,EAA+B,CACjC6F,cAA+B5G,GAAO,IAAM,IAAIqE,GAAwB,kBAEtEnD,EAAsB,CACxB2F,QAAyB7G,GAAO,IAAMyF,KAAe,WACrDqB,iBAAkC9G,GAAO,IAAMoG,GAAsB,oBACrElG,OAAQ,CAAC,GAEPsC,EAAwB,CAC1BqE,QAAyB7G,GAAO,IAAM4F,KAAiB,WACvDkB,iBAAkC9G,GAAO,IAAMwG,GAAwB,oBACvEtG,OAAQ,CAAC,GAEPiC,EAAqB,CACvB0E,QAAyB7G,GAAO,IAAM8F,KAAc,WACpDgB,iBAAkC9G,GAAO,IAAMyG,GAAqB,oBACpEvG,OAAQ,CAAC,GAEP4C,EAA8B,CAChC+D,QAAyB7G,GAAO,IAAMgG,KAAuB,WAC7Dc,iBAAkC9G,GAAO,IAAM0G,GAA8B,oBAC7ExG,OAAQ,CAAC,GAEPiD,EAA0B,CAC5B0D,QAAyB7G,GAAO,IAAMkG,KAAmB,WACzDY,iBAAkC9G,GAAO,IAAM2G,GAA0B,oBACzEzG,OAAQ,CAAC,GAYP6G,EAAe,CACjBC,UAN4B,6CAO5BC,UAN4B,4BAO5BC,MANe,yBAQb1F,GAA6BD,EAAG,cAAc4F,EAAAA,GAIhDC,YAAAA,CAAa1F,EAAMC,EAAO0F,GACxB,IAAI7D,EAAQmB,KAAK2C,mBAAmB5F,EAAMC,EAAO0F,GAIjD,YAHc,IAAV7D,IACFA,EAAQmB,KAAKlD,mBAAmBC,EAAMC,EAAO0F,SAEjC,IAAV7D,EACKzD,MAAMqH,aAAa1F,EAAMC,EAAO0F,GAElC7D,CACT,CACA8D,kBAAAA,CAAmB5F,EAAMC,EAAOC,GAC9B,MAAM2F,EAAQR,EAAarF,EAAKG,MAChC,QAAc,IAAV0F,EACF,OAEF,MAAMC,EAAQD,EAAME,KAAK9F,GACzB,OAAc,OAAV6F,OAGa,IAAbA,EAAM,GACDA,EAAM,GAAGzF,OAAOD,QAAQ,cAAe,UAE/B,IAAb0F,EAAM,GACDA,EAAM,GAAG1F,QAAQ,SAAU,IAAIA,QAAQ,SAAU,IAAIA,QAAQ,cAAe,KAAKA,QAAQ,eAAgB,WADlH,OANA,CAUF,GA5BE9B,EAAMuB,EAAO,iCAAgCA,GA8B7ClB,GAEAL,EAFoB0H,EAAG,cAAclG,EAIvCC,kBAAAA,CAAmBkG,EAAOC,EAAQhG,GAElC,GAJe,wBAAuB8F,GASpC7H,GAA2BgI,EAAG,cAAcC,EAAAA,GAI9ChI,WAAAA,CAAYiI,GACVhI,QACA4E,KAAKoD,SAAW,IAAIC,IAAID,EAC1B,CACAE,kBAAAA,CAAmBC,EAAOC,EAAgBC,GACxC,MAAMC,EAAatI,MAAMkI,mBAAmBC,EAAOC,EAAgBC,GAMnE,OALAC,EAAWC,SAASC,IACd5D,KAAKoD,SAASS,IAAID,EAAU1G,YAA+B,IAAtB0G,EAAUE,UACjDF,EAAUE,QAAU,IAAIC,OAAOH,EAAUE,QAAQE,WAAa,sBAChE,IAEKN,CACT,GAdErI,EAAM6H,EAAO,+BAA8BA,GAkB3C7H,EAFkB4I,EAAG,cAAc/I,IAEtB,qB,2FCzYbgJ,EAAU,CAAC,EACXC,EAAe,CACjBC,MAAsB/I,EAAAA,EAAAA,KAAOgJ,UAC3B,MAAQ1I,mBAAoB2I,SAA8B,8BACpD/I,EAAS+I,IAAsBjI,KAAKd,OAAOgJ,cACjDL,EAAQE,KAAO7I,CAAM,GACpB,QACHiJ,QAAwBnJ,EAAAA,EAAAA,KAAOgJ,UAC7B,MAAQ1G,qBAAsB8G,SAAgC,8BACxDlJ,EAASkJ,IAAwB7G,OAAOrC,OAAOgJ,cACrDL,EAAQM,OAASjJ,CAAM,GACtB,UACHmJ,KAAqBrJ,EAAAA,EAAAA,KAAOgJ,UAC1B,MAAQ/G,kBAAmBqH,SAA6B,8BAClDpJ,EAASoJ,IAAqBpH,IAAIhC,OAAOgJ,cAC/CL,EAAQQ,IAAMnJ,CAAM,GACnB,OACHqJ,cAA8BvJ,EAAAA,EAAAA,KAAOgJ,UACnC,MAAQpG,2BAA4B4G,SAAsC,6BACpEtJ,EAASsJ,IAA8B3G,aAAa3C,OAAOgJ,cACjEL,EAAQU,aAAerJ,CAAM,GAC5B,gBACHuJ,UAA0BzJ,EAAAA,EAAAA,KAAOgJ,UAC/B,MAAQ/F,uBAAwByG,SAAkC,8BAC5DxJ,EAASwJ,IAA0BxG,SAAShD,OAAOgJ,cACzDL,EAAQY,SAAWvJ,CAAM,GACxB,aAEL8I,eAAeW,EAAMC,EAAaC,GAChC,MAAMC,EAAchB,EAAac,GACjC,IAAKE,EACH,MAAM,IAAI1E,MAAM,yBAADJ,OAA0B4E,IAEtCf,EAAQe,UACLE,IAER,MACMC,EADSlB,EAAQe,GACDD,MAAME,GAC5B,GAAIE,EAAOC,YAAYvJ,OAAS,GAAKsJ,EAAOE,aAAaxJ,OAAS,EAChE,MAAM,IAAIyJ,EAAkBH,GAE9B,OAAOA,EAAOvG,KAChB,EACAxD,EAAAA,EAAAA,IAAO2J,EAAO,SACd,IAAIO,GAAiBtK,EAAG,cAAcwF,MACpCtF,WAAAA,CAAYiK,GACV,MAAMC,EAAcD,EAAOC,YAAYG,KAAKC,GAAQA,EAAIC,UAASC,KAAK,MAChEL,EAAeF,EAAOE,aAAaE,KAAKC,GAAQA,EAAIC,UAASC,KAAK,MACxEvK,MAAM,mBAADiF,OAAoBgF,EAAW,KAAAhF,OAAIiF,IACxCtF,KAAKoF,OAASA,CAChB,IAEE/J,EAAAA,EAAAA,IAAMJ,EAAO,qBAAoBA,E,iBChF/B,SAAU2K,EAAUC,GACtB,MAAsB,kBAARA,GAA4B,OAARA,GAAkD,kBAA1BA,EAAgBtF,KAC9E,CAkCM,SAAUuF,EAAYD,GACxB,MAAsB,kBAARA,GAA4B,OAARA,GAAuD,kBAA/BA,EAAkBE,QAChF,CAwDM,SAAUC,EAAeH,GAC3B,MAAsB,kBAARA,GAA4B,OAARA,GAC3BD,EAAWC,EAAqBvF,YAChCwF,EAAaD,EAAqBI,YACO,kBAAjCJ,EAAqBH,OACxC,C,wFAmBM,MAAgB/F,EAAtBxE,WAAAA,GAEc,KAAA+K,SAAgE,CAAC,EACjE,KAAAC,YAAoD,CAAC,CA6CnE,CAtCIlH,UAAAA,CAAWmH,EAAezF,GACtB,OAAOiF,EAAUQ,IAASpG,KAAKC,UAAUmG,EAAK7F,MAAOI,EACzD,CAEAV,SAAAA,CAAUH,EAAiBC,GACvB,GAAID,IAAYC,EACZ,OAAO,EAEX,IAAIsG,EAASrG,KAAKkG,SAASpG,GACtBuG,IACDA,EAASrG,KAAKkG,SAASpG,GAAW,CAAC,GAEvC,MAAMwG,EAAWD,EAAOtG,GACxB,QAAiBhE,IAAbuK,EACA,OAAOA,EACJ,CACH,MAAMlB,EAASpF,KAAKH,iBAAiBC,EAASC,GAE9C,OADAsG,EAAOtG,GAAaqF,EACbA,C,CAEf,CAEAmB,cAAAA,CAAe5F,GACX,MAAM2F,EAAWtG,KAAKmG,YAAYxF,GAClC,GAAI2F,EACA,OAAOA,EACJ,CACH,MAAME,EAAWxG,KAAKJ,cAChB6G,EAAkB,GACxB,IAAK,MAAMC,KAAmBF,EACtBxG,KAAKC,UAAUyG,EAAiB/F,IAChC8F,EAAME,KAAKD,GAInB,OADA1G,KAAKmG,YAAYxF,GAAQ8F,EAClBA,C,CAEf,EA8DE,SAAUG,EAAmBR,GAC/B,MAAuB,kBAATA,GAA8B,OAATA,GAAiBS,MAAMC,QAASV,EAA0BW,QACjG,CASM,SAAUC,EAAcZ,GAC1B,MAAuB,kBAATA,GAA8B,OAATA,GAA4D,kBAAnCA,EAAqBxC,SACrF,CAMM,SAAUqD,EAAcb,GAC1B,OAAOQ,EAAmBR,IAAmD,kBAAlCA,EAAqBc,QACpE,CCjBM,MAAOC,EAIThM,WAAAA,CAAYiM,EAAkBC,GAC1BrH,KAAKoH,QAAUA,EACfpH,KAAKqH,OAASA,CAClB,CAEAC,QAAAA,GACI,MAAMA,EAAW,CACbC,MAAOvH,KAAKoH,UACZI,KAAMA,IAAMxH,KAAKqH,OAAOC,EAASC,OACjC,CAACE,OAAOH,UAAW,IAAMA,GAE7B,OAAOA,CACX,CAEA,CAACG,OAAOH,YACJ,OAAOtH,KAAKsH,UAChB,CAEAI,OAAAA,GACI,MAAMJ,EAAWtH,KAAKsH,WACtB,OAAOK,QAAQL,EAASE,OAAOI,KACnC,CAEAC,KAAAA,GACI,MAAMP,EAAWtH,KAAKsH,WACtB,IAAIO,EAAQ,EACRL,EAAOF,EAASE,OACpB,MAAQA,EAAKI,MACTC,IACAL,EAAOF,EAASE,OAEpB,OAAOK,CACX,CAEAC,OAAAA,GACI,MAAM1C,EAAc,GACdkC,EAAWtH,KAAKsH,WACtB,IAAIE,EACJ,GACIA,EAAOF,EAASE,YACGzL,IAAfyL,EAAK3I,OACLuG,EAAOuB,KAAKa,EAAK3I,cAEf2I,EAAKI,MACf,OAAOxC,CACX,CAEA2C,KAAAA,GACI,OAAO,IAAI1E,IAAIrD,KACnB,CAEAgI,KAAAA,CAAoBC,EAAqBC,GACrC,MAAMC,EAAcnI,KAAKwF,KAAI4C,GAAmB,CAC5CH,EAAQA,EAAMG,GAAWA,EACzBF,EAAUA,EAAQE,GAAWA,KAEjC,OAAO,IAAIC,IAAIF,EACnB,CAEAnE,QAAAA,GACI,OAAOhE,KAAK2F,MAChB,CAEAtF,MAAAA,CAAWiI,GACP,MAAMhB,EAAWgB,EAAMb,OAAOH,YAC9B,OAAO,IAAIH,GACP,KAAM,CAAGoB,MAAOvI,KAAKoH,UAAWoB,WAAW,MAC3CjB,IACI,IAAInC,EACJ,IAAKmC,EAAMiB,UAAW,CAClB,GAEI,GADApD,EAASpF,KAAKqH,OAAOE,EAAMgB,QACtBnD,EAAOwC,KACR,OAAOxC,SAELA,EAAOwC,MACjBL,EAAMiB,WAAY,C,CAEtB,GAEI,GADApD,EAASkC,EAASE,QACbpC,EAAOwC,KACR,OAAOxC,SAELA,EAAOwC,MACjB,OAAOa,CAAW,GAG9B,CAEA9C,IAAAA,GAAoB,IAAf+C,EAAS7M,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,IACb,MAAMyL,EAAWtH,KAAKsH,WACtB,IACIlC,EADAvG,EAAQ,GAER8J,GAAe,EACnB,GACIvD,EAASkC,EAASE,OACbpC,EAAOwC,OACJe,IACA9J,GAAS6J,GAEb7J,GAASmF,EAASoB,EAAOvG,QAE7B8J,GAAe,SACTvD,EAAOwC,MACjB,OAAO/I,CACX,CAEA+J,OAAAA,CAAQC,GAA+B,IAAbC,EAASjN,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EAClC,MAAMyL,EAAWtH,KAAKsH,WACtB,IAAIyB,EAAQ,EACRvB,EAAOF,EAASE,OACpB,MAAQA,EAAKI,MAAM,CACf,GAAImB,GAASD,GAAatB,EAAK3I,QAAUgK,EACrC,OAAOE,EAEXvB,EAAOF,EAASE,OAChBuB,G,CAEJ,OAAQ,CACZ,CAeAC,KAAAA,CAAMC,GACF,MAAM3B,EAAWtH,KAAKsH,WACtB,IAAIE,EAAOF,EAASE,OACpB,MAAQA,EAAKI,MAAM,CACf,IAAKqB,EAAUzB,EAAK3I,OAChB,OAAO,EAEX2I,EAAOF,EAASE,M,CAEpB,OAAO,CACX,CAEA0B,IAAAA,CAAKD,GACD,MAAM3B,EAAWtH,KAAKsH,WACtB,IAAIE,EAAOF,EAASE,OACpB,MAAQA,EAAKI,MAAM,CACf,GAAIqB,EAAUzB,EAAK3I,OACf,OAAO,EAEX2I,EAAOF,EAASE,M,CAEpB,OAAO,CACX,CAEA7D,OAAAA,CAAQwF,GACJ,MAAM7B,EAAWtH,KAAKsH,WACtB,IAAIyB,EAAQ,EACRvB,EAAOF,EAASE,OACpB,MAAQA,EAAKI,MACTuB,EAAW3B,EAAK3I,MAAOkK,GACvBvB,EAAOF,EAASE,OAChBuB,GAER,CAEAvD,GAAAA,CAAO2D,GACH,OAAO,IAAIhC,EACPnH,KAAKoH,SACJG,IACG,MAAM,KAAEK,EAAI,MAAE/I,GAAUmB,KAAKqH,OAAOE,GACpC,OAAIK,EACOa,EAEA,CAAEb,MAAM,EAAO/I,MAAOsK,EAAWtK,G,GAIxD,CAKAuK,MAAAA,CAAOH,GACH,OAAO,IAAI9B,EACPnH,KAAKoH,SACLG,IACI,IAAInC,EACJ,GAEI,GADAA,EAASpF,KAAKqH,OAAOE,IAChBnC,EAAOwC,MAAQqB,EAAU7D,EAAOvG,OACjC,OAAOuG,SAELA,EAAOwC,MACjB,OAAOa,CAAW,GAG9B,CAEAY,WAAAA,GACI,OAAOrJ,KAAKoJ,QAAOE,QAAWvN,IAANuN,GAAyB,OAANA,GAC/C,CAIAC,MAAAA,CAAUJ,EAA0DK,GAChE,MAAMlC,EAAWtH,KAAKsH,WACtB,IAAImC,EAAmCD,EACnChC,EAAOF,EAASE,OACpB,MAAQA,EAAKI,MAEL6B,OADkB1N,IAAlB0N,EACgBjC,EAAK3I,MAELsK,EAAWM,EAAejC,EAAK3I,OAEnD2I,EAAOF,EAASE,OAEpB,OAAOiC,CACX,CAIAC,WAAAA,CAAeP,EAA0DK,GACrE,OAAOxJ,KAAK2J,gBAAgB3J,KAAKsH,WAAY6B,EAAYK,EAC7D,CAEUG,eAAAA,CAAmBrC,EAAuB6B,EAA0DK,GAC1G,MAAMhC,EAAOF,EAASE,OACtB,GAAIA,EAAKI,KACL,OAAO4B,EAEX,MAAMC,EAAgBzJ,KAAK2J,gBAAgBrC,EAAU6B,EAAYK,GACjE,YAAsBzN,IAAlB0N,EACOjC,EAAK3I,MAETsK,EAAWM,EAAejC,EAAK3I,MAC1C,CAIA+K,IAAAA,CAAKX,GACD,MAAM3B,EAAWtH,KAAKsH,WACtB,IAAIE,EAAOF,EAASE,OACpB,MAAQA,EAAKI,MAAM,CACf,GAAIqB,EAAUzB,EAAK3I,OACf,OAAO2I,EAAK3I,MAEhB2I,EAAOF,EAASE,M,CAGxB,CAEAqC,SAAAA,CAAUZ,GACN,MAAM3B,EAAWtH,KAAKsH,WACtB,IAAIyB,EAAQ,EACRvB,EAAOF,EAASE,OACpB,MAAQA,EAAKI,MAAM,CACf,GAAIqB,EAAUzB,EAAK3I,OACf,OAAOkK,EAEXvB,EAAOF,EAASE,OAChBuB,G,CAEJ,OAAQ,CACZ,CAEAe,QAAAA,CAASjB,GACL,MAAMvB,EAAWtH,KAAKsH,WACtB,IAAIE,EAAOF,EAASE,OACpB,MAAQA,EAAKI,MAAM,CACf,GAAIJ,EAAK3I,QAAUgK,EACf,OAAO,EAEXrB,EAAOF,EAASE,M,CAEpB,OAAO,CACX,CAEAuC,OAAAA,CAAWZ,GAEP,OAAO,IAAIhC,GACP,KAAM,CAAGnH,KAAMA,KAAKoH,cACnBG,IACG,EAAG,CACC,GAAIA,EAAMD,SAAU,CAChB,MAAME,EAAOD,EAAMD,SAASE,OAC5B,IAAIA,EAAKI,KAGL,OAAOJ,EAFPD,EAAMD,cAAWvL,C,CAKzB,MAAM,KAAE6L,EAAI,MAAE/I,GAAUmB,KAAKqH,OAAOE,EAAMvH,MAC1C,IAAK4H,EAAM,CACP,MAAMoC,EAASb,EAAWtK,GAC1B,IAAIoL,EAAWD,GAGX,MAAO,CAAEpC,MAAM,EAAO/I,MAAOmL,GAF7BzC,EAAMD,SAAW0C,EAAOvC,OAAOH,W,QAKlCC,EAAMD,UACf,OAAOmB,CAAW,GAG9B,CAEAyB,IAAAA,CAA2BC,GAIvB,QAHcpO,IAAVoO,IACAA,EAAQ,GAERA,GAAS,EACT,OAAOnK,KAEX,MAAMoK,EAASD,EAAQ,EAAInK,KAAKkK,KAAKC,EAAQ,GAAoCnK,KAEjF,OAAO,IAAImH,GACP,KAAM,CAAGnH,KAAMoK,EAAOhD,cACrBG,IACG,EAAG,CACC,GAAIA,EAAMD,SAAU,CAChB,MAAME,EAAOD,EAAMD,SAASE,OAC5B,IAAIA,EAAKI,KAGL,OAAOJ,EAFPD,EAAMD,cAAWvL,C,CAKzB,MAAM,KAAE6L,EAAI,MAAE/I,GAAUuL,EAAO/C,OAAOE,EAAMvH,MAC5C,IAAK4H,EAAM,CACP,IAAIqC,EAAWpL,GAGX,MAAO,CAAE+I,MAAM,EAAO/I,MAAOA,GAF7B0I,EAAMD,SAAWzI,EAAM4I,OAAOH,W,QAKjCC,EAAMD,UACf,OAAOmB,CAAW,GAG9B,CAEA4B,IAAAA,GACI,MACMjF,EADWpF,KAAKsH,WACEE,OACxB,IAAIpC,EAAOwC,KAGX,OAAOxC,EAAOvG,KAClB,CAEAyL,IAAAA,GAAkB,IAAbC,EAAS1O,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EACb,OAAO,IAAIsL,GACP,KACI,MAAMI,EAAQvH,KAAKoH,UACnB,IAAK,IAAIoD,EAAI,EAAGA,EAAID,EAAWC,IAAK,CAEhC,GADaxK,KAAKqH,OAAOE,GAChBK,KACL,OAAOL,C,CAGf,OAAOA,CAAK,GAEhBvH,KAAKqH,OAEb,CAEAoD,KAAAA,CAAMC,GACF,OAAO,IAAIvD,GACP,KAAM,CAAGwD,KAAM,EAAGpD,MAAOvH,KAAKoH,cAC9BG,IACIA,EAAMoD,OACFpD,EAAMoD,KAAOD,EACNjC,EAEJzI,KAAKqH,OAAOE,EAAMA,SAGrC,CAEAqD,QAAAA,CAAkBC,GACd,MAAMC,EAAM,IAAIzH,IAChB,OAAOrD,KAAKoJ,QAAOE,IACf,MAAMzK,EAAQgM,EAAKA,EAAGvB,GAAKA,EAC3B,OAAIwB,EAAIjH,IAAIhF,KAGRiM,EAAIC,IAAIlM,IACD,E,GAGnB,CAEAmM,OAAAA,CAAiB1C,EAAoB2C,GACjC,MAAMC,EAAc,IAAI7H,IACxB,IAAK,MAAMtE,KAAQuJ,EAAO,CACtB,MAAMzJ,EAAQoM,EAAMA,EAAIlM,GAAQA,EAChCmM,EAAYH,IAAIlM,E,CAEpB,OAAOmB,KAAKoJ,QAAOE,IACf,MAAM6B,EAASF,EAAMA,EAAI3B,GAAKA,EAC9B,OAAQ4B,EAAYrH,IAAIsH,EAAO,GAEvC,EAGJ,SAASnH,EAASjF,GACd,MAAoB,kBAATA,EACAA,EAES,qBAATA,EACA,YAG2B,oBAA1BA,EAAaiF,SAEbjF,EAAaiF,WAElBtF,OAAO0M,UAAUpH,SAASqH,KAAKtM,EAC1C,CAEA,SAASkL,EAAcpE,GACnB,QAASA,GAAwD,oBAAzCA,EAAoB4B,OAAOH,SACvD,CAMO,MAAMgE,EAA4B,IAAInE,GAA2B,KAAe,IAAE,IAAMsB,IAKlFA,EAA+C/J,OAAO6M,OAAO,CAAE3D,MAAM,EAAM/I,WAAO9C,IAKzF,SAAUqO,IAA2D,QAAAoB,EAAA3P,UAAAC,OAA9C2P,EAA8C,IAAA5E,MAAA2E,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAA9CD,EAA8CC,GAAA7P,UAAA6P,GACvE,GAA2B,IAAvBD,EAAY3P,OAAc,CAC1B,MAAM6P,EAAaF,EAAY,GAC/B,GAAIE,aAAsBxE,EACtB,OAAOwE,EAEX,GAAI1B,EAAW0B,GACX,OAAO,IAAIxE,GACP,IAAMwE,EAAWlE,OAAOH,cACvBA,GAAaA,EAASE,SAG/B,GAAiC,kBAAtBmE,EAAW7P,OAClB,OAAO,IAAIqL,GACP,KAAM,CAAG4B,MAAO,MACfxB,GACOA,EAAMwB,MAAQ4C,EAAW7P,OAClB,CAAE8L,MAAM,EAAO/I,MAAO8M,EAAWpE,EAAMwB,UAEvCN,G,CAM3B,OAAIgD,EAAY3P,OAAS,EAEd,IAAIqL,GACP,KAAM,CAAGyE,UAAW,EAAGC,SAAU,MAChCtE,IACG,EAAG,CACC,GAAIA,EAAMD,SAAU,CAChB,MAAME,EAAOD,EAAMD,SAASE,OAC5B,IAAKA,EAAKI,KACN,OAAOJ,EAEXD,EAAMD,cAAWvL,C,CAErB,GAAIwL,EAAMuE,MAAO,CACb,GAAIvE,EAAMsE,SAAWtE,EAAMuE,MAAMhQ,OAC7B,MAAO,CAAE8L,MAAM,EAAO/I,MAAO0I,EAAMuE,MAAMvE,EAAMsE,aAEnDtE,EAAMuE,WAAQ/P,EACdwL,EAAMsE,SAAW,C,CAErB,GAAItE,EAAMqE,UAAYH,EAAY3P,OAAQ,CACtC,MAAM6P,EAAaF,EAAYlE,EAAMqE,aACjC3B,EAAW0B,GACXpE,EAAMD,SAAWqE,EAAWlE,OAAOH,YAC5BqE,GAA2C,kBAAtBA,EAAW7P,SACvCyL,EAAMuE,MAAQH,E,QAGjBpE,EAAMD,UAAYC,EAAMuE,OAASvE,EAAMqE,UAAYH,EAAY3P,QACxE,OAAO2M,CAAW,IAIvB6C,CACX,CAyBM,MAAOS,UACD5E,EAGRhM,WAAAA,CAAY6Q,EAASC,EAAoCxI,GACrDrI,OACI,KAAM,CACF8Q,WAAkB,OAAPzI,QAAO,IAAPA,OAAO,EAAPA,EAAS0I,aAAc,CAAC,CAACH,GAAMvE,OAAOH,aAAe,CAAC2E,EAASD,GAAMvE,OAAOH,aACvF8E,QAAQ,MAEZ7E,IAKI,IAJIA,EAAM6E,SACN7E,EAAM2E,UAAUG,MAChB9E,EAAM6E,QAAS,GAEZ7E,EAAM2E,UAAUpQ,OAAS,GAAG,CAC/B,MACM0L,EADWD,EAAM2E,UAAU3E,EAAM2E,UAAUpQ,OAAS,GACpC0L,OACtB,IAAIA,EAAKI,KAIL,OADAL,EAAM2E,UAAUvF,KAAKsF,EAASzE,EAAK3I,OAAO4I,OAAOH,aAC1CE,EAHPD,EAAM2E,UAAUG,K,CAMxB,OAAO5D,CAAW,GAG9B,CAESnB,QAAAA,GACL,MAAMA,EAAW,CACbC,MAAOvH,KAAKoH,UACZI,KAAMA,IAAMxH,KAAKqH,OAAOC,EAASC,OACjC+E,MAAOA,KACHhF,EAASC,MAAM6E,QAAS,CAAI,EAEhC,CAAC3E,OAAOH,UAAW,IAAMA,GAE7B,OAAOA,CACX,EAME,IAAWiF,ECtvBLC,EA5DN,SAAUC,EAAUrG,GACtB,OAAO,IAAI2F,EAAe3F,GAAMgC,GACxBxB,EAAmBwB,GACZA,EAAQrB,QAER,IAEZ,CAAEoF,aAAa,GACtB,CAsBM,SAAUO,EAAaC,GAGzB,MAAO,CACHC,MAAO,CACHC,UAAWF,EAAMG,YAAe,EAChCC,KAAMJ,EAAMK,UAAa,GAE7BC,IAAK,CACDJ,UAAWF,EAAMO,UACjBH,KAAMJ,EAAMQ,QAAW,GAGnC,CAIM,SAAUC,EAAkBhH,GAC9B,IAAKA,EACD,OAEJ,MAAM,OAAEiH,EAAM,IAAEJ,EAAG,MAAEK,GAAUlH,EAC/B,MAAO,CACHkH,QACAD,SACAJ,MACAnR,OAAQmR,EAAMI,EAEtB,CA2BM,SAAUE,EAAQD,EAAcE,GAClC,MAAMC,EAlBJ,SAAuBH,EAAcE,GACvC,GAAIF,EAAML,IAAIF,KAAOS,EAAGZ,MAAMG,MAASO,EAAML,IAAIF,OAASS,EAAGZ,MAAMG,MAAQO,EAAML,IAAIJ,UAAYS,EAAMV,MAAMC,UACzG,OAAOL,EAAgBkB,OACpB,GAAIJ,EAAMV,MAAMG,KAAOS,EAAGP,IAAIF,MAASO,EAAMV,MAAMG,OAASS,EAAGP,IAAIF,MAAQO,EAAMV,MAAMC,UAAYW,EAAGP,IAAIJ,UAC7G,OAAOL,EAAgBmB,MAE3B,MAAMC,EAAcN,EAAMV,MAAMG,KAAOS,EAAGZ,MAAMG,MAASO,EAAMV,MAAMG,OAASS,EAAGZ,MAAMG,MAAQO,EAAMV,MAAMC,WAAaW,EAAGZ,MAAMC,UAC3HgB,EAAYP,EAAML,IAAIF,KAAOS,EAAGP,IAAIF,MAASO,EAAML,IAAIF,OAASS,EAAGP,IAAIF,MAAQO,EAAML,IAAIJ,WAAaW,EAAGP,IAAIJ,UACnH,OAAIe,GAAeC,EACRrB,EAAgBsB,OAChBF,EACApB,EAAgBuB,YAEhBvB,EAAgBwB,YAE/B,CAGuBC,CAAaX,EAAOE,GACvC,OAAOC,EAAajB,EAAgBmB,KACxC,ED0tBA,SAAiBpB,GAKGA,EAAA2B,IAAhB,SAAoB9D,GAChB,OAAOA,EAAOb,QAAO,CAAC4E,EAAGC,IAAMD,EAAIC,GAAG,EAC1C,EAKgB7B,EAAA8B,QAAhB,SAAwBjE,GACpB,OAAOA,EAAOb,QAAO,CAAC4E,EAAGC,IAAMD,EAAIC,GAAG,EAC1C,EAKgB7B,EAAA+B,IAAhB,SAAoBlE,GAChB,OAAOA,EAAOb,QAAO,CAAC4E,EAAGC,IAAMG,KAAKD,IAAIH,EAAGC,IAC/C,EAKgB7B,EAAAiC,IAAhB,SAAoBpE,GAChB,OAAOA,EAAOb,QAAO,CAAC4E,EAAGC,IAAMG,KAAKC,IAAIL,EAAGC,IAC/C,CAEH,CA9BD,CAAiB7B,IAAAA,EAAS,KCtvB1B,SAAYC,GACRA,EAAAA,EAAA,mBACAA,EAAAA,EAAA,iBACAA,EAAAA,EAAA,+BACAA,EAAAA,EAAA,6BACAA,EAAAA,EAAA,kBACH,CAND,CAAYA,IAAAA,EAAe,KAgCpB,MAAMiC,EAAoB,ilQAsB3B,SAAUC,EAAgBhM,EAA8BiM,GAC1D,GAAIjM,EAAS,CACT,MAAMkM,EA8FR,SAA0BxI,GAA4B,IAAbyI,IAAMhT,UAAAC,OAAA,QAAAC,IAAAF,UAAA,KAAAA,UAAA,GACjD,KAAOuK,EAAK9F,WAAW,CACnB,MAAMwO,EAAS1I,EAAK9F,UACpB,IAAIyI,EAAQ+F,EAAO/H,QAAQ6B,QAAQxC,GACnC,KAAO2C,EAAQ,GAAG,CACdA,IACA,MAAM6F,EAAWE,EAAO/H,QAAQgC,GAChC,GAAI8F,IAAWD,EAASC,OACpB,OAAOD,C,CAGfxI,EAAO0I,C,CAEX,MACJ,CA5GyBC,CAAgBrM,GAAS,GAC1C,GAAIkM,GAAYI,EAAcJ,EAAUD,GACpC,OAAOC,EAEX,GAAI3H,EAAcvE,GAAU,CAIxB,IAAK,IAAI8H,EADQ9H,EAAQqE,QAAQ8C,WAAUP,IAAMA,EAAEuF,SAC3B,EAAGrE,GAAK,EAAGA,IAAK,CACpC,MAAMyE,EAAQvM,EAAQqE,QAAQyD,GAC9B,GAAIwE,EAAcC,EAAON,GACrB,OAAOM,C,GAM3B,CAEM,SAAUD,EAActM,EAAkBiM,GAC5C,OAAO3H,EAActE,IAAYiM,EAAa7E,SAASpH,EAAQkB,UAAU1G,KAC7E,CCnJM,MAAOgS,UAA0BzO,MACnCtF,WAAAA,CAAYiL,EAA2BV,GACnCtK,MAAMgL,EAAO,GAAH/F,OAAMqF,EAAO,QAAArF,OAAO+F,EAAKkH,MAAMV,MAAMG,KAAI,KAAA1M,OAAI+F,EAAKkH,MAAMV,MAAMC,WAAcnH,EAC1F,EAGE,SAAUyJ,EAAkBC,GAC9B,MAAM,IAAI3O,MAAM,0CACpB,CCPO,MAYM4O,EAAe,eAQrB,MAAMC,EAAe,eAQrB,MAAMC,EAAY,YAoBlB,MAAMC,EAAiB,iBAQvB,MAAMC,EAAe,eAYrB,MAAMC,EAAkB,kBAYxB,MAAMC,EAAe,eAYrB,MAAMC,EAAY,YAYlB,MAAMC,EAAiB,iBAavB,MAAMC,EAAc,cAapB,MAAMC,EAAc,cAmBpB,MAAM7N,EAAU,UAwBhB,MAAM8N,EAAe,eAEtB,SAAUC,EAAelR,GAC3B,OAAOC,GAAWC,WAAWF,EAAMiR,EACvC,CAUO,MAAME,EAAY,YAEnB,SAAUC,EAAYpR,GACxB,OAAOC,GAAWC,WAAWF,EAAMmR,EACvC,CAsBO,MAAME,EAAW,WAYjB,MAAMC,EAAgB,gBAYtB,MAAMC,EAAY,YAYlB,MAAMC,EAAqB,qBAsB3B,MAAMC,EAAa,aAEpB,SAAUC,EAAa1R,GACzB,OAAOC,GAAWC,WAAWF,EAAMyR,EACvC,CAQO,MAAME,EAAgB,gBAYtB,MAAMC,EAAa,aAcnB,MAAMC,EAAa,aAYnB,MAAMC,EAAgB,gBAgBtB,MAAMC,GAAe,eAEtB,SAAUC,GAAehS,GAC3B,OAAOC,GAAWC,WAAWF,EAAM+R,GACvC,CASO,MAAME,GAAO,OAEd,SAAUC,GAAOlS,GACnB,OAAOC,GAAWC,WAAWF,EAAMiS,GACvC,CAuBO,MAAME,GAAY,YAclB,MAAMC,GAAS,SAEhB,SAAUC,GAASrS,GACrB,OAAOC,GAAWC,WAAWF,EAAMoS,GACvC,CAOO,MAAME,GAAe,eAEtB,SAAUC,GAAevS,GAC3B,OAAOC,GAAWC,WAAWF,EAAMsS,GACvC,CASO,MAAME,GAAa,aAEpB,SAAUC,GAAazS,GACzB,OAAOC,GAAWC,WAAWF,EAAMwS,GACvC,CAQO,MAAME,GAAiB,iBAavB,MAAMC,GAAiB,iBAExB,SAAUC,GAAiB5S,GAC7B,OAAOC,GAAWC,WAAWF,EAAM2S,GACvC,CAMO,MAAME,GAAY,YAYlB,MAAMC,GAAQ,QAEf,SAAUC,GAAQ/S,GACpB,OAAOC,GAAWC,WAAWF,EAAM8S,GACvC,CAQO,MAAME,GAAU,UAEjB,SAAUC,GAAUjT,GACtB,OAAOC,GAAWC,WAAWF,EAAMgT,GACvC,CAOO,MAAME,GAAe,eAWrB,MAAMC,GAAa,aAYnB,MAAMC,GAAW,WAElB,SAAUC,GAAWrT,GACvB,OAAOC,GAAWC,WAAWF,EAAMoT,GACvC,CAOO,MAAME,GAAuB,uBAW7B,MAAMC,GAAgB,gBAWtB,MAAMC,GAAmB,mBAE1B,SAAUC,GAAmBzT,GAC/B,OAAOC,GAAWC,WAAWF,EAAMwT,GACvC,CAOO,MAAME,GAAiB,iBAExB,SAAUC,GAAiB3T,GAC7B,OAAOC,GAAWC,WAAWF,EAAM0T,GACvC,CAOO,MAAME,GAAa,aAUnB,MAAMC,GAAW,WAuDlB,MAAOC,WAAoClT,EAE7CC,WAAAA,GACI,MAAO,CAAC,kBAAmB,eAAgB,eAAgB,SAAU,eAAgB,eAAgB,YAAa,aAAc,iBAAkB,iBAAkB,YAAa,cAAe,iBAAkB,cAAe,YAAa,UAAW,gBAAiB,QAAS,eAAgB,YAAa,UAAW,gBAAiB,eAAgB,WAAY,gBAAiB,YAAa,qBAAsB,aAAc,gBAAiB,aAAc,aAAc,WAAY,aAAc,gBAAiB,uBAAwB,gBAAiB,eAAgB,mBAAoB,OAAQ,gBAAiB,iBAAkB,YAAa,iBAAkB,aAAc,eAAgB,WAC3rB,CAEmBC,gBAAAA,CAAiBC,EAAiBC,GACjD,OAAQD,GACJ,KAAKqR,GACL,KAAKE,GACL,KAAKE,GACL,KAAKE,GACL,KAAKC,GACL,KAAKE,GACL,KAAKC,GACL,KAAKE,GACL,KAAKE,GACL,KAAKC,GACL,KAAKC,GACL,KAAKE,GACL,KAAKC,GACL,KAAKC,GACL,KAAKE,GACL,KAAKE,GACL,KAAKC,GACD,OAAO5S,KAAKC,UAAUyP,EAAiB3P,GAE3C,KAAK4P,EACL,KAAKU,EACL,KAAKQ,EACD,OAAO7Q,KAAKC,UAAUwP,EAAc1P,GAExC,KAAK6P,EACL,KAAKc,EACL,KAAKE,EACL,KAAKM,GACD,OAAOlR,KAAKC,UAAUuP,EAAgBzP,GAE1C,KAAK8P,EACD,OAAO7P,KAAKC,UAAUsP,EAAWxP,IAAcC,KAAKC,UAAUwP,EAAc1P,GAEhF,KAAK+P,EACL,KAAKC,EACL,KAAKK,EACL,KAAKG,EACD,OAAOvQ,KAAKC,UAAUsP,EAAWxP,GAErC,KAAKiQ,EACL,KAAKE,EACL,KAAKc,GACD,OAAOhR,KAAKC,UAAUqP,EAAcvP,GAExC,KAAKyQ,EACD,OAAOxQ,KAAKC,UAAUoP,EAActP,IAAcC,KAAKC,UAAUqP,EAAcvP,GAEnF,KAAK+Q,GACD,OAAO9Q,KAAKC,UAAUoP,EAActP,GAExC,QACI,OAAO,EAGnB,CAEAG,gBAAAA,CAAiBC,GACb,MAAMC,EAAc,GAAHC,OAAMF,EAAQG,UAAUC,MAAK,KAAAF,OAAIF,EAAQK,UAC1D,OAAQJ,GACJ,IAAK,cACL,IAAK,sBACL,IAAK,uBACL,IAAK,wBACL,IAAK,qBACD,OAAOkP,EAEX,IAAK,uBACL,IAAK,0BACL,IAAK,gBACD,OAAOD,EAEX,IAAK,uBACD,OAAOnN,EAEX,IAAK,0BACL,IAAK,+BACD,OAAOoO,EAEX,IAAK,wBACD,OAAOQ,GAEX,QACI,MAAM,IAAIrQ,MAAM,GAADJ,OAAID,EAAW,kCAG1C,CAEAM,eAAAA,CAAgBC,GACZ,OAAQA,GACJ,IAAK,kBACD,MAAO,CACHzD,KAAM,kBACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,eAIpB,IAAK,eACD,MAAO,CACHA,KAAM,eACN0D,WAAY,CACR,CAAE1D,KAAM,WAAY2D,aAAc,MAI9C,IAAK,YACD,MAAO,CACH3D,KAAM,YACN0D,WAAY,CACR,CAAE1D,KAAM,iBAIpB,IAAK,iBACD,MAAO,CACHA,KAAM,iBACN0D,WAAY,CACR,CAAE1D,KAAM,OAAQ2D,cAAc,KAI1C,IAAK,cACD,MAAO,CACH3D,KAAM,cACN0D,WAAY,CACR,CAAE1D,KAAM,QACR,CAAEA,KAAM,WAIpB,IAAK,cACD,MAAO,CACHA,KAAM,cACN0D,WAAY,CACR,CAAE1D,KAAM,QACR,CAAEA,KAAM,WAIpB,IAAK,UACD,MAAO,CACHA,KAAM,UACN0D,WAAY,CACR,CAAE1D,KAAM,sBAAuB2D,cAAc,GAC7C,CAAE3D,KAAM,eAAgB2D,aAAc,IACtC,CAAE3D,KAAM,UAAW2D,aAAc,IACjC,CAAE3D,KAAM,aAAc2D,aAAc,IACpC,CAAE3D,KAAM,aAAc2D,cAAc,GACpC,CAAE3D,KAAM,QACR,CAAEA,KAAM,QAAS2D,aAAc,IAC/B,CAAE3D,KAAM,QAAS2D,aAAc,IAC/B,CAAE3D,KAAM,eAAgB2D,aAAc,MAIlD,IAAK,gBACD,MAAO,CACH3D,KAAM,gBACN0D,WAAY,CACR,CAAE1D,KAAM,UAIpB,IAAK,eACD,MAAO,CACHA,KAAM,eACN0D,WAAY,CACR,CAAE1D,KAAM,UAIpB,IAAK,YACD,MAAO,CACHA,KAAM,YACN0D,WAAY,CACR,CAAE1D,KAAM,aAAc2D,aAAc,IACpC,CAAE3D,KAAM,QACR,CAAEA,KAAM,aAAc2D,aAAc,MAIhD,IAAK,gBACD,MAAO,CACH3D,KAAM,gBACN0D,WAAY,CACR,CAAE1D,KAAM,eAAgB2D,cAAc,GACtC,CAAE3D,KAAM,aACR,CAAEA,KAAM,WAIpB,IAAK,WACD,MAAO,CACHA,KAAM,WACN0D,WAAY,CACR,CAAE1D,KAAM,WAIpB,IAAK,gBACD,MAAO,CACHA,KAAM,gBACN0D,WAAY,CACR,CAAE1D,KAAM,WAIpB,IAAK,YACD,MAAO,CACHA,KAAM,YACN0D,WAAY,CACR,CAAE1D,KAAM,UAIpB,IAAK,qBACD,MAAO,CACHA,KAAM,qBACN0D,WAAY,CACR,CAAE1D,KAAM,eAIpB,IAAK,aACD,MAAO,CACHA,KAAM,aACN0D,WAAY,CACR,CAAE1D,KAAM,YACR,CAAEA,KAAM,sBAAuB2D,cAAc,GAC7C,CAAE3D,KAAM,cACR,CAAEA,KAAM,QAAS2D,cAAc,GAC/B,CAAE3D,KAAM,WAAY2D,cAAc,GAClC,CAAE3D,KAAM,eAAgB2D,aAAc,IACtC,CAAE3D,KAAM,gBACR,CAAEA,KAAM,QACR,CAAEA,KAAM,aAAc2D,aAAc,IACpC,CAAE3D,KAAM,cACR,CAAEA,KAAM,WAAY2D,cAAc,KAI9C,IAAK,gBACD,MAAO,CACH3D,KAAM,gBACN0D,WAAY,CACR,CAAE1D,KAAM,mBAIpB,IAAK,aACD,MAAO,CACHA,KAAM,aACN0D,WAAY,CACR,CAAE1D,KAAM,UAIpB,IAAK,aACD,MAAO,CACHA,KAAM,aACN0D,WAAY,CACR,CAAE1D,KAAM,iBACR,CAAEA,KAAM,cACR,CAAEA,KAAM,aAIpB,IAAK,gBACD,MAAO,CACHA,KAAM,gBACN0D,WAAY,CACR,CAAE1D,KAAM,WAIpB,IAAK,eACD,MAAO,CACHA,KAAM,eACN0D,WAAY,CACR,CAAE1D,KAAM,cACR,CAAEA,KAAM,WAAY2D,cAAc,GAClC,CAAE3D,KAAM,SAAU2D,cAAc,GAChC,CAAE3D,KAAM,QACR,CAAEA,KAAM,UAIpB,IAAK,OACD,MAAO,CACHA,KAAM,OACN0D,WAAY,CACR,CAAE1D,KAAM,QACR,CAAEA,KAAM,UAIpB,IAAK,gBACD,MAAO,CACHA,KAAM,gBACN0D,WAAY,CACR,CAAE1D,KAAM,gBACR,CAAEA,KAAM,aAAc2D,cAAc,GACpC,CAAE3D,KAAM,QACR,CAAEA,KAAM,UAIpB,IAAK,YACD,MAAO,CACHA,KAAM,YACN0D,WAAY,CACR,CAAE1D,KAAM,QAAS2D,aAAc,MAI3C,IAAK,SACD,MAAO,CACH3D,KAAM,SACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,WACR,CAAEA,KAAM,gBACR,CAAEA,KAAM,aACR,CAAEA,KAAM,YACR,CAAEA,KAAM,UAIpB,IAAK,eACD,MAAO,CACHA,KAAM,eACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,WAAY2D,aAAc,IAClC,CAAE3D,KAAM,eAIpB,IAAK,aACD,MAAO,CACHA,KAAM,aACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,WACR,CAAEA,KAAM,aACR,CAAEA,KAAM,YACR,CAAEA,KAAM,cAIpB,IAAK,iBACD,MAAO,CACHA,KAAM,iBACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,QACR,CAAEA,KAAM,aACR,CAAEA,KAAM,WAIpB,IAAK,iBACD,MAAO,CACHA,KAAM,iBACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,mBAAoB2D,cAAc,GAC1C,CAAE3D,KAAM,aACR,CAAEA,KAAM,YACR,CAAEA,KAAM,UAIpB,IAAK,YACD,MAAO,CACHA,KAAM,YACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,eAIpB,IAAK,QACD,MAAO,CACHA,KAAM,QACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,WAAY2D,aAAc,IAClC,CAAE3D,KAAM,kBACR,CAAEA,KAAM,eAIpB,IAAK,UACD,MAAO,CACHA,KAAM,UACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,WAIpB,IAAK,eACD,MAAO,CACHA,KAAM,eACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,cAIpB,IAAK,aACD,MAAO,CACHA,KAAM,aACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,WAIpB,IAAK,WACD,MAAO,CACHA,KAAM,WACN0D,WAAY,CACR,CAAE1D,KAAM,YAAa2D,aAAc,IACnC,CAAE3D,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,UAIpB,IAAK,uBACD,MAAO,CACHA,KAAM,uBACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,WAAY2D,aAAc,IAClC,CAAE3D,KAAM,eAIpB,IAAK,gBACD,MAAO,CACHA,KAAM,gBACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,WAAY2D,aAAc,IAClC,CAAE3D,KAAM,eAIpB,IAAK,mBACD,MAAO,CACHA,KAAM,mBACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,UAIpB,IAAK,iBACD,MAAO,CACHA,KAAM,iBACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,WAAY2D,aAAc,IAClC,CAAE3D,KAAM,eAIpB,IAAK,aACD,MAAO,CACHA,KAAM,aACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,cAIpB,IAAK,WACD,MAAO,CACHA,KAAM,WACN0D,WAAY,CACR,CAAE1D,KAAM,eACR,CAAEA,KAAM,eAIpB,QACI,MAAO,CACHA,KAAMyD,EACNC,WAAY,IAI5B,EAGG,MAAM5B,GAAa,IAAI6T,GC3mCxB,SAAUC,GAAuB1M,GACnC,IAAK,MAAOlJ,EAAM2B,KAAUH,OAAOqU,QAAQ3M,GAClClJ,EAAK8V,WAAW,OACbnM,MAAMC,QAAQjI,GACdA,EAAM8E,SAAQ,CAAC5E,EAAMgK,KACbnD,EAAU7G,KACTA,EAA0BkU,WAAa7M,EACvCrH,EAA0BmU,mBAAqBhW,EAC/C6B,EAA0BoU,gBAAkBpK,E,IAG9CnD,EAAU/G,KAChBA,EAA2BoU,WAAa7M,EACxCvH,EAA2BqU,mBAAqBhW,GAIjE,CAOM,SAAUkW,GAAsChN,EAA2BiN,GAC7E,IAAItU,EAAOqH,EACX,KAAOrH,GAAM,CACT,GAAIsU,EAActU,GACd,OAAOA,EAEXA,EAAOA,EAAKkU,U,CAGpB,CAuBM,SAAUK,GAAyClN,GACrD,MAAMmN,EAWJ,SAAuBnN,GACzB,KAAOA,EAAK6M,YACR7M,EAAOA,EAAK6M,WAEhB,OAAO7M,CACX,CAhBqBoN,CAAapN,GACxBhB,EAASmO,EAASE,UACxB,IAAKrO,EACD,MAAM,IAAI3E,MAAM,6BAEpB,OAAO2E,CACX,CAuBM,SAAUsO,GAAetN,EAAe3C,GAC1C,IAAK2C,EACD,MAAM,IAAI3F,MAAM,4BAEpB,MAAM6M,EAAe,OAAP7J,QAAO,IAAPA,OAAO,EAAPA,EAAS6J,MAEvB,OAAO,IAAInG,GAA2B,KAAM,CACxCwM,KAAMjV,OAAOiV,KAAKvN,GAClBwN,SAAU,EACVC,WAAY,MACZtM,IACA,KAAOA,EAAMqM,SAAWrM,EAAMoM,KAAK7X,QAAQ,CACvC,MAAM0E,EAAW+G,EAAMoM,KAAKpM,EAAMqM,UAClC,IAAKpT,EAASwS,WAAW,KAAM,CAC3B,MAAMnU,EAASuH,EAAwB5F,GACvC,GAAIoF,EAAU/G,IAEV,GADA0I,EAAMqM,WACFE,GAAiBjV,EAAOyO,GACxB,MAAO,CAAE1F,MAAM,EAAO/I,cAEvB,GAAIgI,MAAMC,QAAQjI,GAAQ,CAC7B,KAAO0I,EAAMsM,WAAahV,EAAM/C,QAAQ,CACpC,MACMsM,EAAUvJ,EADF0I,EAAMsM,cAEpB,GAAIjO,EAAUwC,IAAY0L,GAAiB1L,EAASkF,GAChD,MAAO,CAAE1F,MAAM,EAAO/I,MAAOuJ,E,CAGrCb,EAAMsM,WAAa,C,EAG3BtM,EAAMqM,U,CAEV,OAAOnL,CAAW,GAE1B,CAMM,SAAUsL,GAAkB/H,EAAevI,GAC7C,IAAKuI,EACD,MAAM,IAAIvL,MAAM,iCAEpB,OAAO,IAAIsL,EAAeC,GAAM5F,GAAQsN,GAAetN,EAAM3C,IACjE,CAMM,SAAUuQ,GAAUhI,EAAevI,GACrC,IAAKuI,EACD,MAAM,IAAIvL,MAAM,iCACb,OAAW,OAAPgD,QAAO,IAAPA,OAAO,EAAPA,EAAS6J,SAAUwG,GAAiB9H,EAAMvI,EAAQ6J,OAElD,IAAIvB,EAAeC,GAAM,IAAM,KAEnC,IAAID,EAAeC,GAAM5F,GAAQsN,GAAetN,EAAM3C,IAAU,CAAE0I,aAAa,GAC1F,CAEA,SAAS2H,GAAiBG,EAAkB3G,G,MACxC,IAAKA,EACD,OAAO,EAEX,MAAM4G,EAA4B,QAAhBC,EAAAF,EAAQG,gBAAQ,IAAAD,OAAA,EAAAA,EAAE7G,MACpC,QAAK4G,GAGE3G,EAAQ2G,EAAW5G,EAC9B,CAMM,SAAU+G,GAAiBjO,GAE7B,OAAO,IAAIe,GAAiC,KAAM,CAC9CwM,KAAMjV,OAAOiV,KAAKvN,GAClBwN,SAAU,EACVC,WAAY,MACZtM,IACA,KAAOA,EAAMqM,SAAWrM,EAAMoM,KAAK7X,QAAQ,CACvC,MAAM0E,EAAW+G,EAAMoM,KAAKpM,EAAMqM,UAClC,IAAKpT,EAASwS,WAAW,KAAM,CAC3B,MAAMnU,EAASuH,EAAwB5F,GACvC,GAAIsF,EAAYjH,GAEZ,OADA0I,EAAMqM,WACC,CAAEhM,MAAM,EAAO/I,MAAO,CAAEoH,UAAWpH,EAAOyB,UAAW8F,EAAM5F,aAC/D,GAAIqG,MAAMC,QAAQjI,GAAQ,CAC7B,KAAO0I,EAAMsM,WAAahV,EAAM/C,QAAQ,CACpC,MAAMiN,EAAQxB,EAAMsM,aACdzL,EAAUvJ,EAAMkK,GACtB,GAAIjD,EAAYsC,GACZ,MAAO,CAAER,MAAM,EAAO/I,MAAO,CAAEoH,UAAWmC,EAAS9H,UAAW8F,EAAM5F,WAAUuI,S,CAGtFxB,EAAMsM,WAAa,C,EAG3BtM,EAAMqM,U,CAEV,OAAOnL,CAAW,GAE1B,CAqCA,SAAS6L,GAAiBC,GACtB,OAAI1N,MAAMC,QAAQyN,GACP,IAAIA,EAAa/O,IAAI8O,KAErBC,CAEf,CC3PM,SAAUC,GAAGC,GACjB,OAAOA,EAAKC,WAAW,EACzB,CAEM,SAAUC,GAAe5V,EAAe+L,GACxCjE,MAAMC,QAAQ/H,GAChBA,EAAK4E,SAAQ,SAAUiR,GACrB9J,EAAInE,KAAKiO,EACX,IAEA9J,EAAInE,KAAK5H,EAEb,CAEM,SAAU8V,GACdC,EACAC,GAEA,IAAyB,IAArBD,EAAQC,GACV,KAAM,kBAAoBA,EAGTD,EAAQC,GAC3BD,EAAQC,IAAW,CACrB,CAEM,SAAUC,GAA0BnP,GAExC,QAAY9J,IAAR8J,EACF,MAAMpF,MAAM,2CAEd,OAAO,CACT,CAGM,SAAUwU,KACd,MAAMxU,MAAM,0CACd,CAEM,SAAUyU,GAAYrP,GAC1B,MAAuB,cAAhBA,EAAU,IACnB,CCzCO,MAAMsP,GAA4B,GACzC,IAAK,IAAI3K,GAAIgK,GAAG,KAAMhK,IAAKgK,GAAG,KAAMhK,KAClC2K,GAAgBxO,KAAK6D,IAGhB,MAAM4K,GAA0B,CAACZ,GAAG,MAAMnU,OAAO8U,IACxD,IAAK,IAAI3K,GAAIgK,GAAG,KAAMhK,IAAKgK,GAAG,KAAMhK,KAClC4K,GAAczO,KAAK6D,IAGrB,IAAK,IAAIA,GAAIgK,GAAG,KAAMhK,IAAKgK,GAAG,KAAMhK,KAClC4K,GAAczO,KAAK6D,IAId,MAAM6K,GAA4B,CACvCb,GAAG,KACHA,GAAG,MACHA,GAAG,MACHA,GAAG,MACHA,GAAG,MACHA,GAAG,MACHA,GAAG,MACHA,GAAG,QACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,UACHA,GAAG,WCZCc,GAAkB,cAClBC,GAAiB,QACjBC,GAAuB,QAIvB,MAAOC,GAAbta,WAAAA,GACY,KAAAua,IAAc,EACd,KAAA1Y,MAAgB,GAChB,KAAA2Y,SAAmB,CA+xB/B,CA7xBYC,SAAAA,GACR,MAAO,CACLF,IAAK1V,KAAK0V,IACV1Y,MAAOgD,KAAKhD,MACZ2Y,SAAU3V,KAAK2V,SAEnB,CAEUE,YAAAA,CAAaC,GAKrB9V,KAAK0V,IAAMI,EAASJ,IACpB1V,KAAKhD,MAAQ8Y,EAAS9Y,MACtBgD,KAAK2V,SAAWG,EAASH,QAC3B,CAEOI,OAAAA,CAAQ/Y,GAEbgD,KAAK0V,IAAM,EACX1V,KAAKhD,MAAQA,EACbgD,KAAK2V,SAAW,EAEhB3V,KAAKgW,YAAY,KACjB,MAAMnX,EAAQmB,KAAKiW,cACnBjW,KAAKgW,YAAY,KAEjB,MAAME,EAAqB,CACzBvV,KAAM,QACNwV,IAAK,CAAEC,MAAOpW,KAAK0V,IAAKzI,IAAKjQ,EAAMlB,QACnCua,QAAQ,EACRC,YAAY,EACZC,WAAW,EACXC,SAAS,EACTC,QAAQ,GAGV,KAAOzW,KAAK0W,gBACV,OAAQ1W,KAAK2W,WACX,IAAK,IACH9B,GAAQqB,EAAO,UACf,MACF,IAAK,IACHrB,GAAQqB,EAAO,cACf,MACF,IAAK,IACHrB,GAAQqB,EAAO,aACf,MACF,IAAK,IACHrB,GAAQqB,EAAO,WACf,MACF,IAAK,IACHrB,GAAQqB,EAAO,UAKrB,GAAIlW,KAAK0V,MAAQ1V,KAAKhD,MAAMlB,OAC1B,MAAM2E,MAAM,oBAAsBT,KAAKhD,MAAM4Z,UAAU5W,KAAK0V,MAE9D,MAAO,CACL/U,KAAM,UACNuV,MAAOA,EACPrX,MAAOA,EACPsX,IAAKnW,KAAKmW,IAAI,GAElB,CAEUF,WAAAA,GACR,MAAMY,EAAO,GACPT,EAAQpW,KAAK0V,IAInB,IAFAmB,EAAKlQ,KAAK3G,KAAK8W,eAEY,MAApB9W,KAAK+W,YACV/W,KAAKgW,YAAY,KACjBa,EAAKlQ,KAAK3G,KAAK8W,eAGjB,MAAO,CAAEnW,KAAM,cAAe9B,MAAOgY,EAAMV,IAAKnW,KAAKmW,IAAIC,GAC3D,CAEUU,WAAAA,GACR,MAAME,EAAQ,GACRZ,EAAQpW,KAAK0V,IAEnB,KAAO1V,KAAKiX,UACVD,EAAMrQ,KAAK3G,KAAKkX,QAGlB,MAAO,CAAEvW,KAAM,cAAe9B,MAAOmY,EAAOb,IAAKnW,KAAKmW,IAAIC,GAC5D,CAEUc,IAAAA,GACR,OAAIlX,KAAKmX,cACAnX,KAAKoX,YAELpX,KAAKqX,MAEhB,CAEUD,SAAAA,GACR,MAAMhB,EAAQpW,KAAK0V,IACnB,OAAQ1V,KAAK2W,WACX,IAAK,IACH,MAAO,CACLhW,KAAM,cACNwV,IAAKnW,KAAKmW,IAAIC,IAElB,IAAK,IACH,MAAO,CAAEzV,KAAM,YAAawV,IAAKnW,KAAKmW,IAAIC,IAE5C,IAAK,KACH,OAAQpW,KAAK2W,WACX,IAAK,IACH,MAAO,CACLhW,KAAM,eACNwV,IAAKnW,KAAKmW,IAAIC,IAElB,IAAK,IACH,MAAO,CACLzV,KAAM,kBACNwV,IAAKnW,KAAKmW,IAAIC,IAIpB,MAAM3V,MAAM,4BAEd,IAAK,IAGH,IAAIE,EACJ,OAHAX,KAAKgW,YAAY,KAGThW,KAAK2W,WACX,IAAK,IACHhW,EAAO,YACP,MACF,IAAK,IACHA,EAAO,oBAGXqU,GAAcrU,GAEd,MAAMsV,EAAcjW,KAAKiW,cAIzB,OAFAjW,KAAKgW,YAAY,KAEV,CACLrV,KAAMA,EACN9B,MAAOoX,EACPE,IAAKnW,KAAKmW,IAAIC,IAIpB,OAAOnB,IACT,CAEUqC,UAAAA,GACuB,IAE3BhK,EAFJiK,EAAA1b,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAGA,MAAMua,EAAQpW,KAAK0V,IACnB,OAAQ1V,KAAK2W,WACX,IAAK,IACHrJ,EAAQ,CACNkK,QAAS,EACTC,OAAQC,KAEV,MACF,IAAK,IACHpK,EAAQ,CACNkK,QAAS,EACTC,OAAQC,KAEV,MACF,IAAK,IACHpK,EAAQ,CACNkK,QAAS,EACTC,OAAQ,GAEV,MACF,IAAK,IACH,MAAMD,EAAUxX,KAAK2X,uBACrB,OAAQ3X,KAAK2W,WACX,IAAK,IACHrJ,EAAQ,CACNkK,QAASA,EACTC,OAAQD,GAEV,MACF,IAAK,IACH,IAAIC,EACAzX,KAAK4X,WACPH,EAASzX,KAAK2X,uBACdrK,EAAQ,CACNkK,QAASA,EACTC,OAAQA,IAGVnK,EAAQ,CACNkK,QAASA,EACTC,OAAQC,KAGZ1X,KAAKgW,YAAY,KAKrB,IAAuB,IAAnBuB,QAAqCxb,IAAVuR,EAC7B,OAEF0H,GAAc1H,GAMlB,IAAuB,IAAnBiK,QAAqCxb,IAAVuR,EAK/B,OAAI0H,GAAc1H,IACS,MAArBtN,KAAK+W,SAAS,IAChB/W,KAAKgW,YAAY,KACjB1I,EAAMuK,QAAS,GAEfvK,EAAMuK,QAAS,EAGjBvK,EAAM3M,KAAO,aACb2M,EAAM6I,IAAMnW,KAAKmW,IAAIC,GACd9I,QAVT,CAYF,CAEU+J,IAAAA,GACR,IAAIA,EACJ,MAAMjB,EAAQpW,KAAK0V,IACnB,OAAQ1V,KAAK+W,YACX,IAAK,IACHM,EAAOrX,KAAK8X,SACZ,MACF,IAAK,KACHT,EAAOrX,KAAK+X,aACZ,MACF,IAAK,IACHV,EAAOrX,KAAKgY,iBACZ,MACF,IAAK,IACHX,EAAOrX,KAAKiY,QAShB,YALalc,IAATsb,GAAsBrX,KAAKkY,uBAC7Bb,EAAOrX,KAAKmY,oBAIVnD,GAAoBqC,IACtBA,EAAKlB,IAAMnW,KAAKmW,IAAIC,GAEhBpW,KAAKoY,iBACPf,EAAKC,WAAatX,KAAKsX,cAGlBD,GAIFpC,IACT,CAEU6C,MAAAA,GAER,OADA9X,KAAKgW,YAAY,KACV,CACLrV,KAAM,MACN0X,YAAY,EACZxZ,MAAO,CAAC2V,GAAG,MAAOA,GAAG,MAAOA,GAAG,UAAWA,GAAG,WAEjD,CAEUuD,UAAAA,GAGR,OAFA/X,KAAKgW,YAAY,MAEThW,KAAK+W,YACX,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAO/W,KAAKsY,oBACd,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAOtY,KAAKuY,uBACd,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAOvY,KAAKwY,oBACd,IAAK,IACH,OAAOxY,KAAKyY,0BACd,IAAK,IACH,OAAOzY,KAAK0Y,mBACd,IAAK,IACH,OAAO1Y,KAAK2Y,wBACd,IAAK,IACH,OAAO3Y,KAAK4Y,kCACd,QACE,OAAO5Y,KAAK6Y,qBAElB,CAEUP,iBAAAA,GAGR,MAAO,CAAE3X,KAAM,qBAAsB9B,MAFvBmB,KAAK8Y,kBAGrB,CAEUP,oBAAAA,GACR,IAAIzN,EACAuN,GAAa,EACjB,OAAQrY,KAAK2W,WACX,IAAK,IACH7L,EAAMqK,GACN,MACF,IAAK,IACHrK,EAAMqK,GACNkD,GAAa,EACb,MACF,IAAK,IACHvN,EAAMuK,GACN,MACF,IAAK,IACHvK,EAAMuK,GACNgD,GAAa,EACb,MACF,IAAK,IACHvN,EAAMsK,GACN,MACF,IAAK,IACHtK,EAAMsK,GACNiD,GAAa,EAKjB,OAAIrD,GAAclK,GACT,CAAEnK,KAAM,MAAO9B,MAAOiM,EAAKuN,WAAYA,GAGzCpD,IACT,CAEUuD,iBAAAA,GACR,IAAIO,EACJ,OAAQ/Y,KAAK2W,WACX,IAAK,IACHoC,EAAavE,GAAG,MAChB,MACF,IAAK,IACHuE,EAAavE,GAAG,MAChB,MACF,IAAK,IACHuE,EAAavE,GAAG,MAChB,MACF,IAAK,IACHuE,EAAavE,GAAG,MAChB,MACF,IAAK,IACHuE,EAAavE,GAAG,MAKpB,OAAIQ,GAAc+D,GACT,CAAEpY,KAAM,YAAa9B,MAAOka,GAG9B9D,IACT,CAEUwD,uBAAAA,GACRzY,KAAKgW,YAAY,KACjB,MAAMgD,EAAShZ,KAAK2W,UACpB,IAAgC,IAA5B,WAAWsC,KAAKD,GAClB,MAAMvY,MAAM,YAId,MAAO,CAAEE,KAAM,YAAa9B,MADTma,EAAOE,cAAcxE,WAAW,GAAK,GAE1D,CAEUgE,gBAAAA,GAIR,OADA1Y,KAAKgW,YAAY,KACV,CAAErV,KAAM,YAAa9B,MAAO2V,GAAG,MACxC,CAEUmE,qBAAAA,GAER,OADA3Y,KAAKgW,YAAY,KACVhW,KAAKmZ,eAAe,EAC7B,CAEUP,+BAAAA,GAER,OADA5Y,KAAKgW,YAAY,KACVhW,KAAKmZ,eAAe,EAC7B,CAEUN,kBAAAA,GAIR,MAAO,CAAElY,KAAM,YAAa9B,MAAO2V,GADfxU,KAAK2W,WAE3B,CAEUyC,yBAAAA,GACR,OAAQpZ,KAAK+W,YAEX,IAAK,KAEL,IAAK,KAEL,IAAK,SAEL,IAAK,SAEL,IAAK,KAEL,IAAK,IACH,MAAMtW,MAAM,OACd,QAEE,MAAO,CAAEE,KAAM,YAAa9B,MAAO2V,GADlBxU,KAAK2W,YAG5B,CAEUqB,cAAAA,GACR,MAAMlN,EAA0B,GAChC,IAAIuN,GAAa,EAOjB,IANArY,KAAKgW,YAAY,KACQ,MAArBhW,KAAK+W,SAAS,KAChB/W,KAAKgW,YAAY,KACjBqC,GAAa,GAGRrY,KAAKqZ,eAAe,CACzB,MAAMC,EAAOtZ,KAAKuZ,YACOD,EAAK3Y,KAC9B,GAAIuU,GAAYoE,IAAStZ,KAAKwZ,cAAe,CAC3CxZ,KAAKgW,YAAY,KACjB,MAAMxI,EAAKxN,KAAKuZ,YACO/L,EAAG7M,KAG1B,GAAIuU,GAAY1H,GAAK,CACnB,GAAIA,EAAG3O,MAAQya,EAAKza,MAClB,MAAM4B,MAAM,yCAEdqK,EAAInE,KAAK,CAAE2S,KAAMA,EAAKza,MAAO2O,GAAIA,EAAG3O,O,MAGpC8V,GAAY2E,EAAKza,MAAOiM,GACxBA,EAAInE,KAAK6N,GAAG,MACZG,GAAYnH,EAAG3O,MAAOiM,E,MAGxB6J,GAAY2E,EAAKza,MAAOiM,E,CAM5B,OAFA9K,KAAKgW,YAAY,KAEV,CAAErV,KAAM,MAAO0X,WAAYA,EAAYxZ,MAAOiM,EACvD,CAEUyO,SAAAA,GACR,OAAQvZ,KAAK+W,YAEX,IAAK,IAEL,IAAK,KAEL,IAAK,KAEL,IAAK,SAEL,IAAK,SACH,MAAMtW,MAAM,OACd,IAAK,KACH,OAAOT,KAAKyZ,cACd,QACE,OAAOzZ,KAAKoZ,4BAElB,CAEUK,WAAAA,GAER,OADAzZ,KAAKgW,YAAY,MACThW,KAAK+W,YAGX,IAAK,IAEH,OADA/W,KAAKgW,YAAY,KACV,CAAErV,KAAM,YAAa9B,MAAO2V,GAAG,OACxC,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAOxU,KAAKuY,uBACd,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAOvY,KAAKwY,oBACd,IAAK,IACH,OAAOxY,KAAKyY,0BACd,IAAK,IACH,OAAOzY,KAAK0Y,mBACd,IAAK,IACH,OAAO1Y,KAAK2Y,wBACd,IAAK,IACH,OAAO3Y,KAAK4Y,kCACd,QACE,OAAO5Y,KAAK6Y,qBAElB,CAEUZ,KAAAA,GACR,IAAIyB,GAAY,EAEhB,GADA1Z,KAAKgW,YAAY,KAEV,MADChW,KAAK+W,SAAS,GAElB/W,KAAKgW,YAAY,KACjBhW,KAAKgW,YAAY,KACjB0D,GAAY,OAGZ1Z,KAAK2V,WAGT,MAAM9W,EAAQmB,KAAKiW,cACnBjW,KAAKgW,YAAY,KAEjB,MAAM2D,EAA+B,CACnChZ,KAAM,QACN+Y,UAAWA,EACX7a,MAAOA,GAOT,OAJI6a,IACFC,EAAc,IAAI3Z,KAAK2V,UAGlBgE,CACT,CAEUb,eAAAA,GACR,IAAIc,EAAS5Z,KAAK2W,UAIlB,IAA0C,IAAtCnB,GAAqByD,KAAKW,GAC5B,MAAMnZ,MAAM,gCAGd,KAAO8U,GAAe0D,KAAKjZ,KAAK+W,SAAS,KACvC6C,GAAU5Z,KAAK2W,UAGjB,OAAOkD,SAASD,EAAQ,GAC1B,CAEUjC,oBAAAA,GACR,IAAIiC,EAAS5Z,KAAK2W,UAClB,IAAoC,IAAhCpB,GAAe0D,KAAKW,GACtB,MAAMnZ,MAAM,wBAGd,KAAO8U,GAAe0D,KAAKjZ,KAAK+W,SAAS,KACvC6C,GAAU5Z,KAAK2W,UAGjB,OAAOkD,SAASD,EAAQ,GAC1B,CAEUzB,gBAAAA,GACR,MAAM2B,EAAW9Z,KAAK2W,UACtB,OAAQmD,GAEN,IAAK,KAEL,IAAK,KAEL,IAAK,SAEL,IAAK,SAEL,IAAK,IAEL,IAAK,IAEL,IAAK,KAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEH,MAAMrZ,MAAM,OACd,QACE,MAAO,CAAEE,KAAM,YAAa9B,MAAO2V,GAAGsF,IAE5C,CACUpD,YAAAA,GACR,OAAQ1W,KAAK+W,SAAS,IACpB,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAO,EACT,QACE,OAAO,EAEb,CAEUyC,WAAAA,GACR,MAA2B,MAApBxZ,KAAK+W,YAAsB/W,KAAKqZ,YAAY,EACrD,CAEUzB,OAAAA,GACR,OAAOrC,GAAe0D,KAAKjZ,KAAK+W,SAAS,GAC3C,CAEUsC,WAAAA,GAAuB,IAAXU,EAAOle,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EAC9B,OAAQmE,KAAK+W,SAASgD,IACpB,IAAK,IACL,IAAK,KACL,IAAK,KACL,IAAK,SACL,IAAK,SACH,OAAO,EACT,QACE,OAAO,EAEb,CAEU9C,MAAAA,GACR,OAAOjX,KAAKga,UAAYha,KAAKmX,aAC/B,CAEU6C,MAAAA,GACR,GAAIha,KAAKkY,qBACP,OAAO,EAGT,OAAQlY,KAAK+W,SAAS,IACpB,IAAK,IACL,IAAK,KACL,IAAK,IAEL,IAAK,IACH,OAAO,EACT,QACE,OAAO,EAEb,CAEUI,WAAAA,GACR,OAAQnX,KAAK+W,SAAS,IACpB,IAAK,IACL,IAAK,IACH,OAAO,EAET,IAAK,KACH,OAAQ/W,KAAK+W,SAAS,IACpB,IAAK,IACL,IAAK,IACH,OAAO,EACT,QACE,OAAO,EAGb,IAAK,IACH,MACuB,MAArB/W,KAAK+W,SAAS,KACQ,MAArB/W,KAAK+W,SAAS,IAAmC,MAArB/W,KAAK+W,SAAS,IAE/C,QACE,OAAO,EAEb,CAEUqB,YAAAA,GACR,MAAM6B,EAAYja,KAAK4V,YACvB,IACE,YAAiC7Z,IAA1BiE,KAAKsX,YAAW,E,CACvB,MAAOhO,GACP,OAAO,C,CACP,QACAtJ,KAAK6V,aAAaoE,E,CAEtB,CAEU/B,kBAAAA,GACR,OAAQlY,KAAK+W,YACX,IAAK,IACL,IAAK,IACL,IAAK,KACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,KACL,IAAK,KACL,IAAK,SACL,IAAK,SACH,OAAO,EACT,QACE,OAAO,EAEb,CAEUoC,cAAAA,CAAee,GACvB,IAAIC,EAAY,GAChB,IAAK,IAAI3P,EAAI,EAAGA,EAAI0P,EAAS1P,IAAK,CAChC,MAAM4P,EAAUpa,KAAK2W,UACrB,IAAsC,IAAlCrB,GAAgB2D,KAAKmB,GACvB,MAAM3Z,MAAM,iCAEd0Z,GAAaC,C,CAGf,MAAO,CAAEzZ,KAAM,YAAa9B,MADXgb,SAASM,EAAW,IAEvC,CAEUpD,QAAAA,GAAoB,IAAXgD,EAAOle,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EAC3B,OAAOmE,KAAKhD,MAAMgD,KAAK0V,IAAMqE,EAC/B,CAEUpD,OAAAA,GACR,MAAMmD,EAAW9Z,KAAK+W,SAAS,GAE/B,OADA/W,KAAKgW,iBAAYja,GACV+d,CACT,CAEU9D,WAAAA,CAAYvB,GACpB,QAAa1Y,IAAT0Y,GAAsBzU,KAAKhD,MAAMgD,KAAK0V,OAASjB,EACjD,MAAMhU,MACJ,cACEgU,EACA,iBACAzU,KAAKhD,MAAMgD,KAAK0V,KAChB,gBACA1V,KAAK0V,KAIX,GAAI1V,KAAK0V,KAAO1V,KAAKhD,MAAMlB,OACzB,MAAM2E,MAAM,2BAEdT,KAAK0V,KACP,CAEUS,GAAAA,CAAIC,GACZ,MAAO,CAAEA,MAAOA,EAAOnJ,IAAKjN,KAAK0V,IACnC,ECvzBI,MAAO2E,GACJC,aAAAA,CAAclU,GACnB,IAAK,MAAM6E,KAAO7E,EAAM,CACtB,MAAM6I,EAAS7I,EAAa6E,GAExB7E,EAAKmU,eAAetP,UACHlP,IAAfkT,EAAMtO,KACRX,KAAKwa,MAAMvL,GACFpI,MAAMC,QAAQmI,IACvBA,EAAMtL,SAAS8W,IACbza,KAAKwa,MAAMC,EAAS,GACnBza,M,CAIX,CAEOwa,KAAAA,CAAMpU,GACX,OAAQA,EAAKzF,MACX,IAAK,UACHX,KAAK0a,aAAatU,GAClB,MACF,IAAK,QACHpG,KAAK2a,WAAWvU,GAChB,MACF,IAAK,cACHpG,KAAK4a,iBAAiBxU,GACtB,MACF,IAAK,cACHpG,KAAK6a,iBAAiBzU,GACtB,MACF,IAAK,cACHpG,KAAK8a,iBAAiB1U,GACtB,MACF,IAAK,YACHpG,KAAK+a,eAAe3U,GACpB,MACF,IAAK,eACHpG,KAAKgb,kBAAkB5U,GACvB,MACF,IAAK,kBACHpG,KAAKib,qBAAqB7U,GAC1B,MACF,IAAK,YACHpG,KAAKkb,eAAe9U,GACpB,MACF,IAAK,oBACHpG,KAAKmb,uBAAuB/U,GAC5B,MACF,IAAK,YACHpG,KAAKob,eAAehV,GACpB,MACF,IAAK,MACHpG,KAAKqb,SAASjV,GACd,MACF,IAAK,QACHpG,KAAKsb,WAAWlV,GAChB,MACF,IAAK,qBACHpG,KAAKub,wBAAwBnV,GAC7B,MACF,IAAK,aACHpG,KAAKwb,gBAAgBpV,GAIzBpG,KAAKsa,cAAclU,EACrB,CAEOsU,YAAAA,CAAatU,GAA4B,CAEzCuU,UAAAA,CAAWvU,GAA0B,CAErCwU,gBAAAA,CAAiBxU,GAA0B,CAE3CyU,gBAAAA,CAAiBzU,GAA0B,CAG3C0U,gBAAAA,CAAiB1U,GAAwB,CAEzC2U,cAAAA,CAAe3U,GAAwB,CAEvC4U,iBAAAA,CAAkB5U,GAAwB,CAE1C6U,oBAAAA,CAAqB7U,GAAwB,CAE7C8U,cAAAA,CAAe9U,GAAwB,CAEvC+U,sBAAAA,CAAuB/U,GAAwB,CAG/CgV,cAAAA,CAAehV,GAAwB,CAEvCiV,QAAAA,CAASjV,GAAkB,CAE3BkV,UAAAA,CAAWlV,GAAoB,CAE/BmV,uBAAAA,CAAwBnV,GAAiC,CAEzDoV,eAAAA,CAAgBpV,GAAyB,ECzG3C,MAAMqV,GAAiB,UAExBC,GAAe,IAAIjG,GA0FzB,MAAMkG,GAAU,IA3EhB,cAAoCtB,GAApClf,WAAAA,G,oBAEY,KAAAygB,YAAa,EAEb,KAAAC,eAA2B,GACnC,KAAAC,WAAY,CAoEhB,CAjEI,YAAIC,GACA,OAAO/b,KAAK6b,eAAelW,KAAK,GACpC,CAEAqW,KAAAA,CAAMpZ,GACF5C,KAAK8b,WAAY,EACjB9b,KAAK4C,MAAQA,EACb5C,KAAKic,YAAc,GACnBjc,KAAK4b,YAAa,EAClB5b,KAAK6b,eAAiB,EAC1B,CAESP,UAAAA,CAAWlV,GACZA,EAAKkR,aACLtX,KAAK4b,YAAa,EAClB5b,KAAK6b,eAAiB,GAE9B,CAEST,cAAAA,CAAehV,GACpB,MAAMqO,EAAOyH,OAAOC,aAAa/V,EAAKvH,OAItC,GAHKmB,KAAK8b,WAAsB,OAATrH,IACnBzU,KAAK8b,WAAY,GAEjB1V,EAAKkR,WACLtX,KAAK4b,YAAa,EAClB5b,KAAK6b,eAAiB,OACnB,CACH,MAAMO,EAAcC,GAAa5H,GACjCzU,KAAK6b,eAAelV,KAAKyV,GACrBpc,KAAK4b,aACL5b,KAAKic,aAAeG,E,CAGhC,CAESf,QAAAA,CAASjV,GACd,IAAKpG,KAAK8b,UAAW,CACjB,MAAMhR,EAAM9K,KAAK4C,MAAMgU,UAAUxQ,EAAK+P,IAAIC,MAAOhQ,EAAK+P,IAAIlJ,KACpDrK,EAAQ,IAAImB,OAAO+G,GACzB9K,KAAK8b,UAAYnU,QAAQ,KAAK9E,MAAMD,G,CAExC,GAAIwD,EAAKkR,WACLtX,KAAK4b,YAAa,EAClB5b,KAAK6b,eAAiB,OACnB,CACH,MAAM/Q,EAAM9K,KAAK4C,MAAMgU,UAAUxQ,EAAK+P,IAAIC,MAAOhQ,EAAK+P,IAAIlJ,KAC1DjN,KAAK6b,eAAelV,KAAKmE,GACrB9K,KAAK4b,aACL5b,KAAKic,aAAenR,E,CAGhC,CAESwP,aAAAA,CAAclU,GACnB,GAAkB,UAAdA,EAAKzF,KAAkB,CAIvB,GADcyF,EACJkR,WACN,M,CAGRlc,MAAMkf,cAAclU,EACxB,GA2BE,SAAUkW,GAAmBC,GAC/B,IAQI,MAPsB,kBAAXA,IACPA,EAAS,IAAIxY,OAAOwY,IAExBA,EAASA,EAAOvY,WAChB2X,GAAQK,MAAMO,GAEdZ,GAAQnB,MAAMkB,GAAa3F,QAAQwG,IAC5BZ,GAAQG,S,CACjB,MAAA3H,GACE,OAAO,C,CAEf,CAEM,SAAUqI,GAAa3d,GAEzB,OADgC,kBAAVA,EAAqB,IAAIkF,OAAOlF,GAASA,GACjDoa,KAAK,IACvB,CAEM,SAAUoD,GAAaxd,GACzB,OAAOA,EAAM1B,QAAQ,sBAAuB,OAChD,CAcM,SAAUsf,GAAe7Z,EAAwB5F,GACnD,MAAM0f,EAWJ,SAAwB9Z,GACL,kBAAVA,IACPA,EAAQ,IAAImB,OAAOnB,IAEvB,MAAM+Z,EAAK/Z,EAAOga,EAASha,EAAMga,OACjC,IAAIpS,EAAI,EAER,SAASqS,IACL,IACIC,EADA1X,EAAS,GAGb,SAAS2X,EAAUC,GACf5X,GAAUwX,EAAOK,OAAOzS,EAAGwS,GAC3BxS,GAAKwS,CACT,CAEA,SAASE,EAAeF,GACpB5X,GAAU,MAAQwX,EAAOK,OAAOzS,EAAGwS,GAAW,MAC9CxS,GAAKwS,CACT,CAEA,KAAOxS,EAAIoS,EAAO9gB,QACd,OAAQ8gB,EAAOpS,IACX,IAAK,KACD,OAAQoS,EAAOpS,EAAI,IACf,IAAK,IACD0S,EAAe,GACf,MACJ,IAAK,IACDA,EAAe,GACf,MACJ,IAAK,IACGP,EAAGnG,QACmB,MAAlBoG,EAAOpS,EAAI,GACX0S,EAAeN,EAAOhU,QAAQ,IAAK4B,GAAKA,EAAI,GAE5C0S,EAAe,GAGnBA,EAAe,GAEnB,MACJ,IAAK,IACL,IAAK,IACGP,EAAGnG,QACH0G,EAAeN,EAAOhU,QAAQ,IAAK4B,GAAKA,EAAI,GAE5C0S,EAAe,GAEnB,MACJ,IAAK,IACDA,EAAeN,EAAOhU,QAAQ,IAAK4B,GAAKA,EAAI,GAC5C,MACJ,QACI0S,EAAe,GAGvB,MAEJ,IAAK,IACDJ,EAAM,mBACNA,EAAIK,UAAY3S,EAChBsS,EAAMA,EAAIha,KAAK8Z,IAAW,GAC1BM,EAAeJ,EAAI,GAAGhhB,QACtB,MAEJ,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACDihB,EAAU,GACV,MACJ,IAAK,IACDD,EAAM,gBACNA,EAAIK,UAAY3S,EAChBsS,EAAMA,EAAIha,KAAK8Z,GACXE,EACAC,EAAUD,EAAI,GAAGhhB,QAEjBohB,EAAe,GAEnB,MACJ,IAAK,IACD,GAAsB,MAAlBN,EAAOpS,EAAI,GACX,OAAQoS,EAAOpS,EAAI,IACf,IAAK,IACDpF,GAAU,MACVoF,GAAK,EACLpF,GAAUyX,IAAY,MACtB,MACJ,IAAK,IACDzX,GAAU,MACVoF,GAAK,EACLpF,GAAUyX,IAAY,IACtB,MACJ,IAAK,IACDC,EAAMtS,EACNA,GAAK,EACLqS,IACAzX,GAAUwX,EAAOK,OAAOH,EAAKtS,EAAIsS,GACjC,MACJ,IAAK,IACD,OAAQF,EAAOpS,EAAI,IACf,IAAK,IACL,IAAK,IACDsS,EAAMtS,EACNA,GAAK,EACLqS,IACAzX,GAAUwX,EAAOK,OAAOH,EAAKtS,EAAIsS,GACjC,MACJ,QACIC,EAAUH,EAAOhU,QAAQ,IAAK4B,GAAKA,EAAI,GACvCpF,GAAUyX,IAAY,YAMtCE,EAAU,GACV3X,GAAUyX,IAAY,MAE1B,MACJ,IAAK,IAED,QADErS,EACKpF,EACX,QACI8X,EAAe,GAK3B,OAAO9X,CACX,CAEA,OAAO,IAAIrB,OAAO8Y,IAAWja,EAAMsT,MACvC,CApJoBkH,CAAcxa,GACxBC,EAAQ7F,EAAM6F,MAAM6Z,GAC1B,QAAS7Z,GAASA,EAAM,GAAG/G,OAAS,CACxC,CChIM,SAAUuhB,GAAqBC,EAAsBC,GACvD,MAAMC,EAAY,IAAIna,IAChBoa,EArBJ,SAAuBH,GACzB,OAAOA,EAAQ/Z,MAAMqG,MAAKN,GAAKoU,EAAiBpU,IAAMA,EAAEqU,OAC5D,CAmBsBC,CAAaN,GAC/B,IAAKG,EACD,OAAO,IAAIpa,IAAIia,EAAQ/Z,OAG3B,MAAMsa,EAAe,CAACJ,GAA+Bpd,OAnBnD,SAAyBid,GAC3B,OAAOA,EAAQ/Z,MAAM6F,QAAQE,GAA6BoU,GAAmBpU,IAAMA,EAAEuF,QACzF,CAiBgEiP,CAAeR,IAC3E,IAAK,MAAMvgB,KAAQ8gB,EACfE,GAAQhhB,EAAMygB,EAAWD,GAG7B,MAAMha,EAAQ,IAAIF,IAClB,IAAK,MAAMtG,KAAQugB,EAAQ/Z,OACnBia,EAAU3Z,IAAI9G,EAAKG,OAAUwgB,GAAmB3gB,IAASA,EAAK8R,SAC9DtL,EAAMwH,IAAIhO,GAGlB,OAAOwG,CACX,CAEA,SAASwa,GAAQhhB,EAAwBihB,EAAyBT,GAC9DS,EAAWjT,IAAIhO,EAAKG,MACpB6W,GAAkBhX,GAAM4G,SAAQyC,IAC5B,GAAIsX,GAAetX,IAAUmX,GAAgBG,GAAuBtX,GAAQ,CACxE,MAAM6X,EAAU7X,EAAKrJ,KAAKmhB,IACtBD,IAAYD,EAAWna,IAAIoa,EAAQ/gB,OACnC6gB,GAAQE,EAASD,EAAYT,E,IAI7C,CAmDM,SAAUY,GAAoB/X,EAA2B5F,EAA8BuI,GACzF,IAAK3C,IAAS5F,EACV,OAEJ,MAAM4d,EAAQC,GAA6BjY,EAAM5F,EAAU4F,EAAK6N,SAAS,GACzE,OAAqB,IAAjBmK,EAAMtiB,OAQHsiB,EAJHrV,OADUhN,IAAVgN,EACQwF,KAAKC,IAAI,EAAGD,KAAKD,IAAIvF,EAAOqV,EAAMtiB,OAAS,IAE3C,QANZ,CASJ,CAEA,SAASuiB,GAA6BjY,EAAe5F,EAAkB4H,EAA8BG,GACjG,IAAKA,EAAO,CACR,MAAM+V,EAAclL,GAAmBhN,EAAKmY,cAAeb,IAC3D,GAAIY,GAAeA,EAAYE,UAAYhe,EACvC,MAAO,CAAC4F,E,CAGhB,OAAIQ,EAAmBR,IAASA,EAAK6N,UAAY7L,EACtChC,EAAKW,QAAQgD,SAAQT,GAAK+U,GAA6B/U,EAAG9I,EAAU4H,GAAS,KAEjF,EACX,CAwCM,SAAUqW,GAA4BrY,EAAesY,EAAiBtW,GACxE,GAAIhC,EAAK6N,UAAY7L,EACjB,MAAO,GAEX,GAAIsV,GAActX,EAAKmY,gBAAkBnY,EAAKmY,cAAc1f,QAAU6f,EAClE,MAAO,CAACtY,GAEZ,MAAMuY,EAAelS,EAAUrG,GAAMkB,WACrC,IAAIlC,EACJ,MAAMwZ,EAA0B,GAChC,GAEI,GADAxZ,EAASuZ,EAAanX,QACjBpC,EAAOwC,KAAM,CACd,MAAMiX,EAAYzZ,EAAOvG,MACrBggB,EAAU5K,UAAY7L,EAClBsV,GAAcmB,EAAUN,gBAAkBM,EAAUN,cAAc1f,QAAU6f,GAC5EE,EAAajY,KAAKkY,GAGtBF,EAAarS,O,SAGflH,EAAOwC,MACjB,OAAOgX,CACX,CA2BM,SAAUE,GAAmBne,GAC/B,IAAIoe,EAAqBpe,EAazB,OAZI+c,EAAmBqB,KAEfrB,GAAaqB,EAAU9L,YAEvB8L,EAAYA,EAAU9L,WAAWA,WAC1ByK,EAAiBqB,EAAU9L,YAElC8L,EAAYA,EAAU9L,WAEtB9D,EAAkB4P,EAAU9L,aAG7B+L,GAA2Bre,EAAMoe,EAAW,IAAI1W,IAC3D,CAEA,SAAS2W,GAA2Bre,EAAwBoe,EAAoBE,G,MPkEnDlgB,EOhEzB,SAASmgB,EAAG9Y,EAAe+Y,GACvB,IAAIC,EAOJ,OANyBhM,GAAmBhN,EAAMsX,MAG9C0B,EAAkBJ,GAA2BG,EAASA,EAASF,IAEnEA,EAAMnU,IAAInK,EAAMye,GACTA,CACX,CAEA,GAAIH,EAAMpb,IAAIlD,GACV,OAAOse,EAAMI,IAAI1e,GAErBse,EAAMnU,IAAInK,OAAM5E,GAChB,IAAK,MAAMqK,KAAQ2N,GAAkBgL,GAAY,CAC7C,GAAIrB,GAAiBtX,IAAwC,SAA/BA,EAAKoY,QAAQc,cAEvC,OADAL,EAAMnU,IAAInK,EAAMyF,GACTA,EACJ,GAAIsX,GAAetX,IAASsX,EAAiBtX,EAAKrJ,KAAKmhB,KAC1D,OAAOgB,EAAG9Y,EAAMA,EAAKrJ,KAAKmhB,KACvB,GP2Ccnf,EO3COqH,EP4CzBpH,GAAWC,WAAWF,EAAM6R,KO5CkB,QAAZuD,EAAA/N,EAAKmZ,eAAO,IAAApL,OAAA,EAAAA,EAAE+J,KAC/C,OAAOgB,EAAG9Y,EAAMA,EAAKmZ,QAAQrB,I,CAIzC,CA6CM,SAAUsB,GAAeziB,GAC3B,OAAO0iB,GAAuB1iB,EAAM,IAAIsG,IAC5C,CAEA,SAASoc,GAAuB1iB,EAAsB2iB,GAClD,GAAIA,EAAQ7b,IAAI9G,GACZ,OAAO,EAEP2iB,EAAQ3U,IAAIhO,GAEhB,IAAK,MAAMqJ,KAAQ2N,GAAkBhX,GACjC,GAAI2gB,GAAetX,GAAO,CACtB,IAAKA,EAAKrJ,KAAKmhB,IAEX,OAAO,EAEX,GAAIR,EAAiBtX,EAAKrJ,KAAKmhB,OAASuB,GAAuBrZ,EAAKrJ,KAAKmhB,IAAKwB,GAC1E,OAAO,C,KAER,IAAIhC,GAAiBtX,GACxB,OAAO,EACJ,GAAIsX,GAAatX,GACpB,OAAO,C,CAGf,OAAOuB,QAAQ5K,EAAK4iB,WACxB,CAsCM,SAAUC,GAAoB7iB,GAChC,GAAIA,EAAK8iB,aACL,OAAO9iB,EAAK8iB,aAAa3iB,KACtB,GAAIH,EAAK+iB,SACZ,OAAO/iB,EAAK+iB,SACT,GAAI/iB,EAAKgjB,WAAY,CACxB,MAAMZ,EAAUpiB,EAAKgjB,WAAW7B,IAChC,GAAGiB,EAAS,CAER,GAAIzB,EAAiByB,GACjB,OAAOA,EAAQjiB,KACX,GAAGwgB,EAAgByB,IAAYzB,GAAWyB,GAC9C,OAAOA,EAAQjiB,I,EAK/B,CAEM,SAAU8iB,GAAYrf,G,MPxGC5B,EOyGzB,GAAI2e,EAAiB/c,GACjB,OAAO6e,GAAe7e,GAAQA,EAAKzD,KAAgC,QAAzBiX,EAAAyL,GAAoBjf,UAAK,IAAAwT,EAAAA,EAAIxT,EAAKzD,KACzE,GAAIwgB,EAAgB/c,IAAS+c,GAAW/c,KP3GtB5B,EO2GgD4B,EP1GlE3B,GAAWC,WAAWF,EAAM4R,IO2G/B,OAAOhQ,EAAKzD,KACT,GAAIwgB,GAAa/c,GAAO,CAC3B,MAAMsf,EAUR,SAAwBC,G,MAC1B,GAAIA,EAAOL,aACP,OAAOK,EAAOL,aAAa3iB,KACxB,GAAe,QAAXiX,EAAA+L,EAAOvf,YAAI,IAAAwT,OAAA,EAAAA,EAAE+J,IACpB,OAAO8B,GAAYE,EAAOvf,KAAKud,KAEnC,MACJ,CAjB2BiC,CAAcxf,GACjC,GAAIsf,EACA,OAAOA,C,MAER,GAAIvC,EAAmB/c,GAC1B,OAAOA,EAAKzD,KAEhB,MAAM,IAAIuD,MAAM,kCACpB,CAmBM,SAAU2f,GAAcC,GAC1B,MAAMnK,EAAe,CACjBoK,GAAG,EACH9V,GAAG,EACH+V,GAAG,GAED3D,EAAS4D,GAAuBH,EAAaV,WAAYzJ,GACzDuK,EAAW/hB,OAAOqU,QAAQmD,GAAO9M,QAAOsX,IAAA,IAAE,CAAE7hB,GAAM6hB,EAAA,OAAK7hB,CAAK,IAAE2G,KAAImb,IAAA,IAAEzjB,GAAKyjB,EAAA,OAAKzjB,CAAI,IAAEyI,KAAK,IAC/F,OAAO,IAAI5B,OAAO6Y,EAAQ6D,EAC9B,CAGA,MAAMG,GAAW,SAAShE,OAQ1B,SAAS4D,GAAuBpY,EAA8B8N,GAC1D,GPkEmCnX,EOlEJqJ,EPmExBpJ,GAAWC,WAAWF,EAAMsT,IOlE/B,OA2CGwO,IAD0BC,EA1CM1Y,GA2CH2Y,SAASvb,KAAI8D,GAAKkX,GAAuBlX,KAAI3D,KAAK,KAAM,CACxFqb,YAAaF,EAAaE,YAC1BC,UAAWH,EAAaG,YA5CrB,GP2EL,SAA0BliB,GAC5B,OAAOC,GAAWC,WAAWF,EAAMuT,GACvC,CO7EeoL,CAAoBtV,GAC3B,OAgDGyY,IADmB5I,EA/CM7P,GAgDH2Y,SAASvb,KAAI8D,GAAKkX,GAAuBlX,KAAI3D,KAAK,IAAK,CAChFqb,YAAa/I,EAAM+I,YACnBC,UAAWhJ,EAAMgJ,YAjDd,GP9BL,SAA2BliB,GAC7B,OAAOC,GAAWC,WAAWF,EAAM0S,GACvC,CO4BeiM,CAAqBtV,GAC5B,OAkER,SAA+BkF,GAC3B,GAAIA,EAAM4T,MACN,OAAOL,GAAgB,IAADxgB,OAAK8gB,GAAe7T,EAAM8T,MAAK,KAAA/gB,OAAI8gB,GAAe7T,EAAM4T,OAAM,KAAK,CACrFF,YAAa1T,EAAM0T,YACnBC,UAAW3T,EAAM2T,UACjBI,MAAM,IAGd,OAAOR,GAAgBM,GAAe7T,EAAM8T,MAAO,CAC/CJ,YAAa1T,EAAM0T,YACnBC,UAAW3T,EAAM2T,UACjBI,MAAM,GAEd,CA/EeC,CAAsBlZ,GAC1B,GAAIsV,GAAuBtV,GAAU,CACxC,MAAMrL,EAAOqL,EAAQrL,KAAKmhB,IAC1B,IAAKnhB,EACD,MAAM,IAAI0D,MAAM,2BAEpB,OAAOogB,GAAgBL,GAAuBzjB,EAAK4iB,YAAa,CAC5DqB,YAAa5Y,EAAQ4Y,YACrBC,UAAW7Y,EAAQ6Y,W,CAEpB,GPiBL,SAAyBliB,GAC3B,OAAOC,GAAWC,WAAWF,EAAMkT,GACvC,COnBeyL,CAAmBtV,GAC1B,OAgDR,SAA4BmZ,GACxB,OAAOV,GAAgB,MAADxgB,OAAOmgB,GAAuBe,EAAOC,UAAS,KAAAnhB,OAAIugB,GAAQ,MAAM,CAClFI,YAAaO,EAAOP,YACpBC,UAAWM,EAAON,WAE1B,CArDeQ,CAAmBrZ,GACvB,GP6FL,SAAuBrJ,GACzB,OAAOC,GAAWC,WAAWF,EAAM4T,GACvC,CO/Fe+K,CAAiBtV,GACxB,OAuCmBsZ,EAvCMtZ,EAwCtByY,GAAgB,GAADxgB,OAAIugB,GAAQ,MAAAvgB,OAAKmgB,GAAuBkB,EAAMF,WAAa,CAC7ER,YAAaU,EAAMV,YACnBC,UAAWS,EAAMT,YAzCd,GPwBL,SAAuBliB,GACzB,OAAOC,GAAWC,WAAWF,EAAMmT,GACvC,CO1BewL,CAAiBtV,GAAU,CAClC,MAAMuZ,EAAYvZ,EAAQxF,MAAMgf,YAAY,KACtChF,EAASxU,EAAQxF,MAAMgU,UAAU,EAAG+K,GACpCE,EAAazZ,EAAQxF,MAAMgU,UAAU+K,EAAY,GAMvD,OALIzL,IACAA,EAAM1L,EAAIqX,EAAW/X,SAAS,KAC9BoM,EAAMoK,EAAIuB,EAAW/X,SAAS,KAC9BoM,EAAMqK,EAAIsB,EAAW/X,SAAS,MAE3B+W,GAAgBjE,EAAQ,CAC3BoE,YAAa5Y,EAAQ4Y,YACrBC,UAAW7Y,EAAQ6Y,UACnBI,MAAM,G,CAEP,GPuFL,SAAqBtiB,GACvB,OAAOC,GAAWC,WAAWF,EAAM6T,GACvC,COzFe8K,CAAetV,GACtB,OAAOyY,GAAgBD,GAAU,CAC7BI,YAAa5Y,EAAQ4Y,YACrBC,UAAW7Y,EAAQ6Y,YAGvB,MAAM,IAAIxgB,MAAM,6BAADJ,OAAqC,OAAP+H,QAAO,IAAPA,OAAO,EAAPA,EAAS7H,QAkB9D,IAA2BmhB,EAPGzJ,EAPO6I,EPuBE/hB,COzBvC,CA6CA,SAASoiB,GAAezC,GACpB,OAAOrC,GAAaqC,EAAQ7f,MAChC,CAEA,SAASgiB,GAAgBje,EAAea,G,MAQpC,QAHqB,IAAjBA,EAAQ4d,MAAkB5d,EAAQwd,aAClCre,EAAQ,IAAHvC,OAAwB,QAAjB8T,EAAA1Q,EAAQwd,iBAAS,IAAA9M,EAAAA,EAAI,IAAE9T,OAAGuC,EAAK,MAE3Ca,EAAQud,YACD,GAAP3gB,OAAUuC,GAAKvC,OAAGoD,EAAQud,aAEvBpe,CACX,C,qECrjBM,SAAUkf,GAAiBC,GAC/B,SAASC,IAAmB,CAG5BA,EAAgB5W,UAAY2W,EAC5B,MAAME,EAAe,IAAKD,EAE1B,SAASE,IACP,cAAcD,EAAaE,GAC7B,CASO,OALPD,IACAA,IAIcH,CAOhB,CCIA,SArBA,SAAmBjW,EAAOc,EAAOK,GAC/B,IAAIlE,GAAS,EACTjN,EAASgQ,EAAMhQ,OAEf8Q,EAAQ,IACVA,GAASA,EAAQ9Q,EAAS,EAAKA,EAAS8Q,IAE1CK,EAAMA,EAAMnR,EAASA,EAASmR,GACpB,IACRA,GAAOnR,GAETA,EAAS8Q,EAAQK,EAAM,EAAMA,EAAML,IAAW,EAC9CA,KAAW,EAGX,IADA,IAAIxH,EAASyB,MAAM/K,KACViN,EAAQjN,GACfsJ,EAAO2D,GAAS+C,EAAM/C,EAAQ6D,GAEhC,OAAOxH,CACT,E,eCSA,SATA,SAAc0G,EAAOsW,EAAGC,GACtB,IAAIvmB,EAAkB,MAATgQ,EAAgB,EAAIA,EAAMhQ,OACvC,OAAKA,GAGLsmB,EAAKC,QAAetmB,IAANqmB,EAAmB,GAAIE,EAAAA,GAAAA,GAAUF,GACxCG,GAAUzW,EAAOsW,EAAI,EAAI,EAAIA,EAAGtmB,IAH9B,EAIX,E,6ECxBIye,GAHc7b,OAAO0M,UAGQmP,eA8CjC,UAZaiI,EAAAA,GAAAA,IAAe,SAASC,EAAQ7F,GAC3C,IAAI8F,EAAAA,GAAAA,GAAY9F,KAAW+F,EAAAA,GAAAA,GAAY/F,IACrCgG,EAAAA,GAAAA,GAAWhG,GAAQjJ,EAAAA,GAAAA,GAAKiJ,GAAS6F,QAGnC,IAAK,IAAIxX,KAAO2R,EACVrC,GAAelP,KAAKuR,EAAQ3R,KAC9B4X,EAAAA,GAAAA,GAAYJ,EAAQxX,EAAK2R,EAAO3R,GAGtC,I,8CCnBA,SAbA,SAAgBwX,EAAQxZ,GACtB,GAAc,MAAVwZ,EACF,MAAO,CAAC,EAEV,IAAIK,GAAQC,EAAAA,GAAAA,IAASC,EAAAA,GAAAA,GAAaP,IAAS,SAASQ,GAClD,MAAO,CAACA,EACV,IAEA,OADAha,GAAYia,EAAAA,GAAAA,GAAaja,IAClBka,EAAAA,GAAAA,GAAWV,EAAQK,GAAO,SAASjkB,EAAOukB,GAC/C,OAAOna,EAAUpK,EAAOukB,EAAK,GAC/B,GACF,E,0BCjBA,SAJA,SAAsBvkB,GACpB,OAAOwkB,EAAAA,GAAAA,GAAaxkB,IAVN,oBAUgBykB,EAAAA,GAAAA,GAAWzkB,EAC3C,E,0BCVI0kB,GAAeC,GAAAA,GAAYA,GAAAA,EAASC,SAqBxC,SAFeF,IAAeG,EAAAA,GAAAA,GAAUH,IAAgBI,GCdxD,SAASC,GAAWC,GAClB,OASAhe,EATkBge,GAWXC,EAAAA,GAAAA,GAASje,EAAIke,QAAwB,KAAdle,EAAIke,MAVzBF,EAAQE,MAERF,EAAQ3mB,KAKnB,IACE2I,CAJF,CASM,MAAgBme,GAGpB,cAAWrE,GACT,OAAO3f,KAAKikB,WACd,CACA,cAAWtE,CAAW9gB,GACpBmB,KAAKikB,YAAcplB,CACrB,CAEA1D,WAAAA,CAAsB8oB,GAAA,KAAAA,YAAAA,CAAmB,CAEzCC,MAAAA,CAAOvI,GACLA,EAAQnB,MAAMxa,OACd2D,EAAAA,GAAAA,GAAQ3D,KAAK2f,YAAawE,IACxBA,EAAKD,OAAOvI,EAAQ,GAExB,EAGI,MAAOyI,WACHJ,GAQR7oB,WAAAA,CAAYsI,GAMVrI,MAAM,IARD,KAAAsa,IAAc,EASnB2O,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,CAEA,cAAI5E,CAAWA,GACb,CAGF,cAAIA,GACF,YAA4B5jB,IAAxBiE,KAAKwkB,eACAxkB,KAAKwkB,eAAe7E,WAEtB,EACT,CAEAuE,MAAAA,CAAOvI,GACLA,EAAQnB,MAAMxa,KAEhB,EAGI,MAAOykB,WAAaT,GAIxB7oB,WAAAA,CAAYsI,GAKVrI,MAAMqI,EAAQkc,YAPT,KAAA+E,QAAkB,GAQvBL,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,EAGI,MAAOI,WAAoBX,GAG/B7oB,WAAAA,CAAYsI,GAIVrI,MAAMqI,EAAQkc,YANT,KAAAiF,mBAA6B,EAOlCP,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,EAGI,MAAOM,WACHb,GAMR7oB,WAAAA,CAAYsI,GAKVrI,MAAMqI,EAAQkc,YART,KAAAjK,IAAc,EASnB2O,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,EAGI,MAAOO,WACHd,GAMR7oB,WAAAA,CAAYsI,GAKVrI,MAAMqI,EAAQkc,YART,KAAAjK,IAAc,EASnB2O,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,EAGI,MAAOQ,WACHf,GAOR7oB,WAAAA,CAAYsI,GAKVrI,MAAMqI,EAAQkc,YART,KAAAjK,IAAc,EASnB2O,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,EAGI,MAAOS,WACHhB,GAOR7oB,WAAAA,CAAYsI,GAKVrI,MAAMqI,EAAQkc,YART,KAAAjK,IAAc,EASnB2O,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,EAGI,MAAOU,WACHjB,GAOR7oB,WAAAA,CAAYsI,GAKVrI,MAAMqI,EAAQkc,YART,KAAAjK,IAAc,EASnB2O,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,EAGI,MAAOW,WACHlB,GAQR,cAAWrE,GACT,OAAO3f,KAAKikB,WACd,CACA,cAAWtE,CAAW9gB,GACpBmB,KAAKikB,YAAcplB,CACrB,CAEA1D,WAAAA,CAAYsI,GAOVrI,MAAMqI,EAAQkc,YAnBT,KAAAjK,IAAc,EACd,KAAAkP,mBAA6B,EAC7B,KAAAO,eAAyB,EAkB9Bd,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,EAGI,MAAOa,GAKXjqB,WAAAA,CAAYsI,GAFL,KAAAiS,IAAc,EAOnB2O,GACErkB,KACAskB,GAAO7gB,GAAU8gB,QAAYxoB,IAANwoB,IAE3B,CAEAL,MAAAA,CAAOvI,GACLA,EAAQnB,MAAMxa,KAChB,EAoDI,SAAUqlB,GAAoBjf,GAClC,SAASkf,EAAkB3F,GACzB,OAAOna,EAAAA,GAAAA,GAAIma,EAAY0F,GACzB,CAEA,GAAIjf,aAAgBge,GAAa,CAC/B,MAAMmB,EAAgD,CACpD5kB,KAAM,cACNzD,KAAMkJ,EAAKof,gBACX9P,IAAKtP,EAAKsP,KAOZ,OAJIoO,EAAAA,GAAAA,GAAS1d,EAAKqf,SAChBF,EAAsBE,MAAQrf,EAAKqf,OAG9BF,C,CACF,GAAInf,aAAgBue,GACzB,MAAyB,CACvBhkB,KAAM,cACNgf,WAAY2F,EAAkBlf,EAAKuZ,aAEhC,GAAIvZ,aAAgBye,GACzB,MAAyB,CACvBlkB,KAAM,SACN+U,IAAKtP,EAAKsP,IACViK,WAAY2F,EAAkBlf,EAAKuZ,aAEhC,GAAIvZ,aAAgB0e,GACzB,MAAyB,CACvBnkB,KAAM,sBACN+U,IAAKtP,EAAKsP,IACViK,WAAY2F,EAAkBlf,EAAKuZ,aAEhC,GAAIvZ,aAAgB2e,GACzB,MAAyC,CACvCpkB,KAAM,mCACN+U,IAAKtP,EAAKsP,IACVhN,UACE2c,GAAoB,IAAID,GAAS,CAAEM,aAActf,EAAKsC,aAExDiX,WAAY2F,EAAkBlf,EAAKuZ,aAEhC,GAAIvZ,aAAgB6e,GACzB,MAAyC,CACvCtkB,KAAM,0BACN+U,IAAKtP,EAAKsP,IACVhN,UACE2c,GAAoB,IAAID,GAAS,CAAEM,aAActf,EAAKsC,aAExDiX,WAAY2F,EAAkBlf,EAAKuZ,aAEhC,GAAIvZ,aAAgB4e,GACzB,MAAyB,CACvBrkB,KAAM,aACN+U,IAAKtP,EAAKsP,IACViK,WAAY2F,EAAkBlf,EAAKuZ,aAEhC,GAAIvZ,aAAgB8e,GACzB,MAAyB,CACvBvkB,KAAM,cACN+U,IAAKtP,EAAKsP,IACViK,WAAY2F,EAAkBlf,EAAKuZ,aAEhC,GAAIvZ,aAAgBgf,GAAU,CACnC,MAAMO,EAA0C,CAC9ChlB,KAAM,WACNzD,KAAMkJ,EAAKsf,aAAaxoB,KACxBuoB,MAAO7B,GAAWxd,EAAKsf,cACvBhQ,IAAKtP,EAAKsP,MAGRoO,EAAAA,GAAAA,GAAS1d,EAAKqf,SAChBE,EAAmBC,cAAgBxf,EAAKqf,OAG1C,MAAM1P,EAAU3P,EAAKsf,aAAa5hB,QAOlC,OANIsC,EAAKsf,aAAa5hB,UACpB6hB,EAAmB5P,QAAU0N,GAAS1N,GAC5BA,EAAS6G,OACf7G,GAGC4P,C,CACF,GAAIvf,aAAgBqe,GACzB,MAA4B,CAC1B9jB,KAAM,OACNzD,KAAMkJ,EAAKlJ,KACXwnB,QAASte,EAAKse,QACd/E,WAAY2F,EAAkBlf,EAAKuZ,aAIrC,MAAMlf,MAAM,uBAEhB,CCjZM,MAAgBolB,GACbrL,KAAAA,CAAMpU,GACX,MAAM0f,EAAe1f,EACrB,OAAQ0f,EAAQ3qB,aACd,KAAKipB,GACH,OAAOpkB,KAAK+lB,iBAAiBD,GAC/B,KAAKnB,GACH,OAAO3kB,KAAK6a,iBAAiBiL,GAC/B,KAAKjB,GACH,OAAO7kB,KAAKgmB,YAAYF,GAC1B,KAAKhB,GACH,OAAO9kB,KAAKimB,yBAAyBH,GACvC,KAAKf,GACH,OAAO/kB,KAAKkmB,sCAAsCJ,GACpD,KAAKb,GACH,OAAOjlB,KAAKmmB,6BAA6BL,GAC3C,KAAKd,GACH,OAAOhlB,KAAKomB,gBAAgBN,GAC9B,KAAKZ,GACH,OAAOllB,KAAKqmB,iBAAiBP,GAC/B,KAAKV,GACH,OAAOplB,KAAKsmB,cAAcR,GAC5B,KAAKrB,GACH,OAAOzkB,KAAKumB,UAAUT,GAExB,QACE,MAAMrlB,MAAM,wBAElB,CAGOslB,gBAAAA,CAAiB3f,GAAyB,CAG1CyU,gBAAAA,CAAiBzU,GAAyB,CAG1C4f,WAAAA,CAAY5f,GAAoB,CAGhCggB,eAAAA,CAAgBhgB,GAAwB,CAGxC6f,wBAAAA,CAAyB7f,GAAiC,CAG1D8f,qCAAAA,CACL9f,GACM,CAGD+f,4BAAAA,CAA6B/f,GAAqC,CAGlEigB,gBAAAA,CAAiBjgB,GAAyB,CAG1CkgB,aAAAA,CAAclgB,GAAsB,CAGpCmgB,SAAAA,CAAUngB,GAAkB,E,0BCrDrC,SAVA,SAAkBuF,EAAY1C,GAC5B,IAAI7D,EAMJ,OAJAohB,EAAAA,GAAAA,GAAS7a,GAAY,SAAS9M,EAAOkK,EAAO4C,GAE1C,QADAvG,EAAS6D,EAAUpK,EAAOkK,EAAO4C,GAEnC,MACSvG,CACX,E,0BC+BA,SARA,SAAcuG,EAAY1C,EAAWoZ,GACnC,IAAIoE,GAAO3f,EAAAA,GAAAA,GAAQ6E,GAAc+a,GAAAA,EAAYC,GAI7C,OAHItE,IAASuE,EAAAA,GAAAA,GAAejb,EAAY1C,EAAWoZ,KACjDpZ,OAAYlN,GAEP0qB,EAAK9a,GAAYuX,EAAAA,GAAAA,GAAaja,EAAW,GAClD,E,eCzCI4d,GAAYtY,KAAKC,IA6CrB,SAbA,SAAkB7C,EAAY9M,EAAOiK,EAAWuZ,GAC9C1W,GAAagX,EAAAA,GAAAA,GAAYhX,GAAcA,GAAamb,EAAAA,GAAAA,GAAOnb,GAC3D7C,EAAaA,IAAcuZ,GAASC,EAAAA,GAAAA,GAAUxZ,GAAa,EAE3D,IAAIhN,EAAS6P,EAAW7P,OAIxB,OAHIgN,EAAY,IACdA,EAAY+d,GAAU/qB,EAASgN,EAAW,KAErCgb,EAAAA,GAAAA,GAASnY,GACX7C,GAAahN,GAAU6P,EAAW/C,QAAQ/J,EAAOiK,IAAc,IAC7DhN,IAAUirB,EAAAA,GAAAA,GAAYpb,EAAY9M,EAAOiK,IAAc,CAChE,EC5BA,SAZA,SAAoBgD,EAAO7C,GAIzB,IAHA,IAAIF,GAAS,EACTjN,EAAkB,MAATgQ,EAAgB,EAAIA,EAAMhQ,SAE9BiN,EAAQjN,GACf,IAAKmN,EAAU6C,EAAM/C,GAAQA,EAAO+C,GAClC,OAAO,EAGX,OAAO,CACT,ECAA,SATA,SAAmBH,EAAY1C,GAC7B,IAAI7D,GAAS,EAKb,OAJAohB,EAAAA,GAAAA,GAAS7a,GAAY,SAAS9M,EAAOkK,EAAO4C,GAE1C,OADAvG,IAAW6D,EAAUpK,EAAOkK,EAAO4C,EAErC,IACOvG,CACT,ECqCA,SARA,SAAeuG,EAAY1C,EAAWoZ,GACpC,IAAIoE,GAAO3f,EAAAA,GAAAA,GAAQ6E,GAAcqb,GAAaC,GAI9C,OAHI5E,IAASuE,EAAAA,GAAAA,GAAejb,EAAY1C,EAAWoZ,KACjDpZ,OAAYlN,GAEP0qB,EAAK9a,GAAYuX,EAAAA,GAAAA,GAAaja,EAAW,GAClD,ECtBM,SAAUie,GACd/C,GACkC,IAAlCgD,EAAAtrB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAgC,GAMhC,SAHEsoB,aAAgBU,IAChBV,aAAgBa,IAChBb,aAAgBc,MAQdd,aAAgBe,GAEXhc,GAAmBib,EAAMxE,YAAayH,GACpCF,GAAeE,EAASD,OAExBhD,aAAgBC,IAAeta,GAASqd,EAAgBhD,MAGxDA,aAAgBH,KACrBG,aAAgBC,IAClB+C,EAAexgB,KAAKwd,GAEfnb,GACgBmb,EAAMxE,YAC1ByH,GACQF,GAAeE,EAASD,OAMvC,CAQM,SAAUE,GAAqBlD,GAEnC,GAAIA,aAAgBC,GAClB,MAAO,UACF,GAAID,aAAgBU,GACzB,MAAO,SACF,GAAIV,aAAgBe,GACzB,MAAO,KACF,GAAIf,aAAgBW,GACzB,MAAO,eACF,GAAIX,aAAgBY,GACzB,MAAO,mBACF,GAAIZ,aAAgBc,GACzB,MAAO,WACF,GAAId,aAAgBa,GACzB,MAAO,OACF,GAAIb,aAAgBiB,GACzB,MAAO,UAGP,MAAM3kB,MAAM,uBAEhB,CChFM,MAAgB6mB,GACpBC,IAAAA,CAAKpD,GAAyD,IAApBqD,EAAA3rB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAkB,IAC1D8H,EAAAA,GAAAA,GAAQwgB,EAAKxE,YAAY,CAACyH,EAAsBre,KAC9C,MAAM0e,EAAWC,GAAKvD,EAAKxE,WAAY5W,EAAQ,GAE/C,GAAIqe,aAAmBhD,GACrBpkB,KAAK2nB,YAAYP,EAASK,EAAUD,QAC/B,GAAIJ,aAAmBhC,GAC5BplB,KAAK4nB,aAAaR,EAASK,EAAUD,QAChC,GAAIJ,aAAmBzC,GAC5B3kB,KAAK6nB,SAAST,EAASK,EAAUD,QAC5B,GAAIJ,aAAmBvC,GAC5B7kB,KAAK8nB,WAAWV,EAASK,EAAUD,QAC9B,GAAIJ,aAAmBtC,GAC5B9kB,KAAK+nB,eAAeX,EAASK,EAAUD,QAClC,GAAIJ,aAAmBrC,GAC5B/kB,KAAKgoB,kBAAkBZ,EAASK,EAAUD,QACrC,GAAIJ,aAAmBnC,GAC5BjlB,KAAKioB,YAAYb,EAASK,EAAUD,QAC/B,GAAIJ,aAAmBpC,GAC5BhlB,KAAKkoB,SAASd,EAASK,EAAUD,OAC5B,MAAIJ,aAAmBlC,IAG5B,MAAMzkB,MAAM,wBAFZT,KAAKmoB,OAAOf,EAASK,EAAUD,E,IAKrC,CAEAI,YAAAA,CACEpG,EACAiG,EACAD,GACO,CAETG,WAAAA,CACES,EACAX,EACAD,GACO,CAETK,QAAAA,CACEQ,EACAZ,EACAD,GAGA,MAAMc,EAAab,EAASpnB,OAAOmnB,GACnCxnB,KAAKunB,KAAKc,EAAeC,EAC3B,CAEAR,UAAAA,CACES,EACAd,EACAD,GAGA,MAAMc,EAAab,EAASpnB,OAAOmnB,GACnCxnB,KAAKunB,KAAKgB,EAAiBD,EAC7B,CAEAP,cAAAA,CACES,EACAf,EACAD,GAGA,MAAMiB,EAAoC,CACxC,IAAI5D,GAAO,CAAElF,WAAY6I,EAAe7I,cACxCtf,OAAYonB,EAAeD,GAC7BxnB,KAAKunB,KAAKiB,EAAgBC,EAC5B,CAEAT,iBAAAA,CACEU,EACAjB,EACAD,GAGA,MAAMmB,EAAwBC,GAC5BF,EACAjB,EACAD,GAEFxnB,KAAKunB,KAAKmB,EAAmBC,EAC/B,CAEAT,QAAAA,CACEW,EACApB,EACAD,GAGA,MAAMsB,EAA8B,CAClC,IAAIjE,GAAO,CAAElF,WAAYkJ,EAASlJ,cAClCtf,OAAYonB,EAAeD,GAC7BxnB,KAAKunB,KAAKsB,EAAUC,EACtB,CAEAb,WAAAA,CACEc,EACAtB,EACAD,GAGA,MAAMwB,EAAkBJ,GACtBG,EACAtB,EACAD,GAEFxnB,KAAKunB,KAAKwB,EAAaC,EACzB,CAEAb,MAAAA,CACEc,EACAxB,EACAD,GAGA,MAAMc,EAAab,EAASpnB,OAAOmnB,IAEnC7jB,EAAAA,GAAAA,GAAQslB,EAAOtJ,YAAauJ,IAI1B,MAAMC,EAAc,IAAIxE,GAAY,CAAEhF,WAAY,CAACuJ,KACnDlpB,KAAKunB,KAAK4B,EAAkBb,EAAW,GAE3C,EAGF,SAASM,GACPQ,EACA3B,EACAD,GAUA,MARmB,CACjB,IAAI3C,GAAO,CACTlF,WAAY,CACV,IAAIyF,GAAS,CAAEM,aAAc0D,EAAW1gB,aACxCrI,OAAO+oB,EAAWzJ,eAGyBtf,OAAOonB,EAAUD,EAEpE,C,eC1IA,SAJA,SAAc1b,GACZ,OAAQA,GAASA,EAAMhQ,QAAUutB,EAAAA,GAAAA,GAASvd,GAAS,EACrD,E,eCZM,SAAUvD,GAAM4b,GAEpB,GAAIA,aAAgBC,GASlB,OAAO7b,GAAoB4b,EAAMK,gBAC5B,GAAIL,aAAgBiB,GACzB,MA6CK,CA7C6BjB,EA6CnBuB,cA5CV,GHRH,SACJvB,GAEA,OACEA,aAAgBQ,IAChBR,aAAgBU,IAChBV,aAAgBa,IAChBb,aAAgBW,IAChBX,aAAgBY,IAChBZ,aAAgBc,IAChBd,aAAgBiB,IAChBjB,aAAgBM,EAEpB,CGLa6E,CAAenF,GACxB,OAQE,SAA2BA,GAG/B,IAAIoF,EAAwB,GAC5B,MAAMC,EAAMrF,EAAKxE,WACjB,IAEI8J,EAFAC,EAAiB,EACjBC,EAAyBH,EAAI1tB,OAAS4tB,EAGtCE,GAA0B,EAE9B,KAAOD,GAA0BC,GAC/BH,EAAcD,EAAIE,GAClBE,EAA0B1C,GAAeuC,GACzCF,EAAWA,EAASlpB,OAAOkI,GAAMkhB,IACjCC,GAAkC,EAClCC,EAAyBH,EAAI1tB,OAAS4tB,EAGxC,OAAOG,GAAKN,EACd,CA5BWO,CAAiB3F,GACnB,GH2CH,SACJA,GAEA,OAAOA,aAAgBe,EACzB,CG/Ca6E,CAAgB5F,GACzB,OA4BE,SAA4BA,GAGhC,MAAM6F,GAAuCxkB,EAAAA,GAAAA,GAC3C2e,EAAKxE,YACJsK,GACQ1hB,GAAM0hB,KAGjB,OAAOJ,IAAKK,EAAAA,GAAAA,GAAmBF,GACjC,CAtCWG,CAAkBhG,GAEzB,MAAM1jB,MAAM,uBAEhB,CC9BO,MAAM2pB,GAAK,SCQZ,MAAOC,WAA4B/C,GAGvCnsB,WAAAA,CAAoBmvB,GAClBlvB,QADkB,KAAAkvB,QAAAA,EAFb,KAAAC,QAAuC,CAAC,CAI/C,CAEAC,YAAAA,GAEE,OADAxqB,KAAKunB,KAAKvnB,KAAKsqB,SACRtqB,KAAKuqB,OACd,CAEA3C,YAAAA,CACEpG,EACAiG,EACAD,GAEA,CAGFG,WAAAA,CACES,EACAX,EACAD,GAEA,MAAMiD,GAuBRC,EAtBkCtC,EAAQ5D,eAuB1CmG,EAvB0DvC,EAAQ1S,IAyB3DgV,EAAMxtB,KAAOytB,EAAoBP,GAxBpCpqB,KAAKsqB,QAAQptB,MAoBb,IACJwtB,EACAC,EArBE,MAAMC,EAA0BnD,EAASpnB,OAAOmnB,GAE1CqD,EAAuBtiB,GADZ,IAAIoc,GAAY,CAAEhF,WAAYiL,KAE/C5qB,KAAKuqB,QAAQE,GAAcI,CAC7B,E,gDCFF,SAhBA,SAAgB5hB,GACd,GAAwB,mBAAbA,EACT,MAAM,IAAI6hB,UAxBQ,uBA0BpB,OAAO,WACL,IAAIC,EAAOlvB,UACX,OAAQkvB,EAAKjvB,QACX,KAAK,EAAG,OAAQmN,EAAUoC,KAAKrL,MAC/B,KAAK,EAAG,OAAQiJ,EAAUoC,KAAKrL,KAAM+qB,EAAK,IAC1C,KAAK,EAAG,OAAQ9hB,EAAUoC,KAAKrL,KAAM+qB,EAAK,GAAIA,EAAK,IACnD,KAAK,EAAG,OAAQ9hB,EAAUoC,KAAKrL,KAAM+qB,EAAK,GAAIA,EAAK,GAAIA,EAAK,IAE9D,OAAQ9hB,EAAU+hB,MAAMhrB,KAAM+qB,EAChC,CACF,ECQA,SALA,SAAgBpf,EAAY1C,GAE1B,QADWnC,EAAAA,GAAAA,GAAQ6E,GAAcsf,GAAAA,EAAcC,GAAAA,GACnCvf,EAAY4V,IAAO2B,EAAAA,GAAAA,GAAaja,EAAW,IACzD,E,eCvCI4d,GAAYtY,KAAKC,IAqCrB,SAZA,SAAiB1C,EAAOjN,EAAOiK,GAC7B,IAAIhN,EAAkB,MAATgQ,EAAgB,EAAIA,EAAMhQ,OACvC,IAAKA,EACH,OAAQ,EAEV,IAAIiN,EAAqB,MAAbD,EAAoB,GAAIwZ,EAAAA,GAAAA,GAAUxZ,GAI9C,OAHIC,EAAQ,IACVA,EAAQ8d,GAAU/qB,EAASiN,EAAO,KAE7Bge,EAAAA,GAAAA,GAAYjb,EAAOjN,EAAOkK,EACnC,E,sEC2BA,SA7CA,SAAwB+C,EAAOgb,EAAQqE,EAAUC,GAC/C,IAAIriB,GAAS,EACTe,EAAWuhB,GAAAA,EACXC,GAAW,EACXxvB,EAASgQ,EAAMhQ,OACfsJ,EAAS,GACTmmB,EAAezE,EAAOhrB,OAE1B,IAAKA,EACH,OAAOsJ,EAEL+lB,IACFrE,GAAS/D,EAAAA,GAAAA,GAAS+D,GAAQpD,EAAAA,GAAAA,GAAUyH,KAElCC,GACFthB,EAAW0hB,GAAAA,EACXF,GAAW,GAEJxE,EAAOhrB,QA/BK,MAgCnBgO,EAAW2hB,GAAAA,EACXH,GAAW,EACXxE,EAAS,IAAI4E,GAAAA,EAAS5E,IAExB6E,EACA,OAAS5iB,EAAQjN,GAAQ,CACvB,IAAI+C,EAAQiN,EAAM/C,GACd6iB,EAAuB,MAAZT,EAAmBtsB,EAAQssB,EAAStsB,GAGnD,GADAA,EAASusB,GAAwB,IAAVvsB,EAAeA,EAAQ,EAC1CysB,GAAYM,IAAaA,EAAU,CAErC,IADA,IAAIC,EAAcN,EACXM,KACL,GAAI/E,EAAO+E,KAAiBD,EAC1B,SAASD,EAGbvmB,EAAOuB,KAAK9H,EACd,MACUiL,EAASgd,EAAQ8E,EAAUR,IACnChmB,EAAOuB,KAAK9H,EAEhB,CACA,OAAOuG,CACT,E,qCChCA,UANiB0mB,EAAAA,GAAAA,IAAS,SAAShgB,EAAOgb,GACxC,OAAOiF,EAAAA,GAAAA,GAAkBjgB,GACrBkgB,GAAelgB,GAAOmgB,EAAAA,GAAAA,GAAYnF,EAAQ,EAAGiF,GAAAA,GAAmB,IAChE,EACN,ICAA,SAfA,SAAiBjgB,GAMf,IALA,IAAI/C,GAAS,EACTjN,EAAkB,MAATgQ,EAAgB,EAAIA,EAAMhQ,OACnCowB,EAAW,EACX9mB,EAAS,KAEJ2D,EAAQjN,GAAQ,CACvB,IAAI+C,EAAQiN,EAAM/C,GACdlK,IACFuG,EAAO8mB,KAAcrtB,EAEzB,CACA,OAAOuG,CACT,ECNA,SAJA,SAAc0G,GACZ,OAAQA,GAASA,EAAMhQ,OAAUgQ,EAAM,QAAK/P,CAC9C,E,cCpBM,SAAUowB,GAAYC,GAEtBC,SAAWA,QAAQC,OACrBD,QAAQC,MAAM,UAADjsB,OAAW+rB,GAE5B,CAEM,SAAUG,GAAcH,GAExBC,SAAWA,QAAQG,MAErBH,QAAQG,KAAK,YAADnsB,OAAa+rB,GAE7B,CCJA,IAAIK,GAAqD,CAAC,EAC1D,MAAMC,GAAe,IAAIjX,GAUnB,SAAUkX,GAAaC,GAC3B,MAAMC,EAAYD,EAAO5oB,WACzB,GAAIyoB,GAAelS,eAAesS,GAChC,OAAOJ,GAAeI,GACjB,CACL,MAAMC,EAAYJ,GAAa3W,QAAQ8W,GAEvC,OADAJ,GAAeI,GAAaC,EACrBA,C,CAEX,CCfA,MAAMC,GACJ,gEACWC,GACX,oDAEI,SAAUC,GACdL,GAC2B,IAA3BM,EAAmBrxB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAEnB,IACE,MAAM6hB,EAAMiP,GAAaC,GAMzB,OALmBO,GACjBzP,EAAI7e,MACJ,CAAC,EACD6e,EAAIxH,MAAMI,W,CAGZ,MAAOhN,GAIP,GAAIA,EAAE5D,UAAYqnB,GACZG,GACFX,GACE,GAAAlsB,OAAG2sB,IAA2B,2BAAA3sB,OACDusB,EAAO5oB,WAAU,QAD9C,oNAOC,CACL,IAAIopB,EAAY,GACZF,IACFE,EACE,gKAGJjB,GACE,GAAA9rB,OAAG2sB,GAA2B,6BAAA3sB,OACLusB,EAAO5oB,WAAU,QAD1C,4HAIEopB,E,EAKR,MAAO,EACT,CAEM,SAAUD,GACdzP,EACAtY,EACAkR,GAEA,OAAQoH,EAAI/c,MACV,IAAK,cACH,IAAK,IAAI6J,EAAI,EAAGA,EAAIkT,EAAI7e,MAAM/C,OAAQ0O,IACpC2iB,GAA0BzP,EAAI7e,MAAM2L,GAAIpF,EAAQkR,GAElD,MACF,IAAK,cACH,MAAMU,EAAQ0G,EAAI7e,MAClB,IAAK,IAAI2L,EAAI,EAAGA,EAAIwM,EAAMlb,OAAQ0O,IAAK,CACrC,MAAM0M,EAAOF,EAAMxM,GAGnB,OAAQ0M,EAAKvW,MACX,IAAK,YAIL,IAAK,qBAEL,IAAK,YACL,IAAK,oBACL,IAAK,cACL,IAAK,eACL,IAAK,kBACH,SAGJ,MAAM0W,EAAOH,EACb,OAAQG,EAAK1W,MACX,IAAK,YACH0sB,GAAwBhW,EAAKxY,MAAOuG,EAAQkR,GAC5C,MACF,IAAK,MACH,IAAwB,IAApBe,EAAKgB,WACP,MAAM5X,MAAMssB,KAEdppB,EAAAA,GAAAA,GAAQ0T,EAAKxY,OAAQyuB,IACnB,GAAoB,kBAATA,EACTD,GAAwBC,EAAMloB,EAAQkR,OACjC,CAEL,MAAMhJ,EAAQggB,EAEd,IAAmB,IAAfhX,EACF,IACE,IAAIiX,EAAYjgB,EAAMgM,KACtBiU,GAAajgB,EAAME,GACnB+f,IAEAF,GAAwBE,EAAWnoB,EAAQkR,OAI1C,CAEH,IACE,IAAIiX,EAAYjgB,EAAMgM,KACtBiU,GAAajgB,EAAME,IAAM+f,EAAYC,GACrCD,IAEAF,GAAwBE,EAAWnoB,EAAQkR,GAI7C,GAAIhJ,EAAME,IAAMggB,GAAoB,CAClC,MAAMC,EACJngB,EAAMgM,MAAQkU,GACVlgB,EAAMgM,KACNkU,GACAE,EAAcpgB,EAAME,GACpBmgB,EAAYC,GAAyBH,GACrCI,EAAYD,GAAyBF,GAE3C,IACE,IAAII,EAAaH,EACjBG,GAAcD,EACdC,IAEA1oB,EAAO0oB,GAAcA,C,OAM/B,MACF,IAAK,QACHX,GAA0B9V,EAAKxY,MAAOuG,EAAQkR,GAC9C,MAEF,QACE,MAAM7V,MAAM,wBAIhB,MAAMstB,OACgBhyB,IAApBsb,EAAKC,YAAwD,IAA5BD,EAAKC,WAAWE,QACnD,GAGiB,UAAdH,EAAK1W,OAA8C,IAA1BqtB,GAAgB3W,IAE3B,UAAdA,EAAK1W,OAA6C,IAAzBotB,EAE1B,K,CAGJ,MAEF,QACE,MAAMttB,MAAM,yBAIhB,OAAOqmB,EAAAA,GAAAA,GAAO1hB,EAChB,CAEA,SAASioB,GACPC,EACAloB,EACAkR,GAEA,MAAM2X,EAAmBL,GAAyBN,GAClDloB,EAAO6oB,GAAoBA,GAER,IAAf3X,GAKN,SACEgX,EACAloB,GAEA,MAAMqP,EAAOyH,OAAOC,aAAamR,GAC3BY,EAAYzZ,EAAKyE,cAEvB,GAAIgV,IAAczZ,EAAM,CACtB,MAAMwZ,EAAmBL,GAAyBM,EAAUxZ,WAAW,IACvEtP,EAAO6oB,GAAoBA,C,KACtB,CACL,MAAME,EAAY1Z,EAAK6K,cACvB,GAAI6O,IAAc1Z,EAAM,CACtB,MAAMwZ,EAAmBL,GACvBO,EAAUzZ,WAAW,IAEvBtP,EAAO6oB,GAAoBA,C,EAGjC,CAvBIG,CAAiBd,EAAMloB,EAE3B,CAuBA,SAASipB,GAASC,EAAcC,GAC9B,OAAO3kB,EAAAA,GAAAA,GAAK0kB,EAAQzvB,OAAQ2vB,IAC1B,GAA2B,kBAAhBA,EACT,OAAO1kB,GAASykB,EAAiBC,GAC5B,CAEL,MAAMlhB,EAAakhB,EACnB,YAIQzyB,KAHN6N,EAAAA,GAAAA,GACE2kB,GACCE,GAAenhB,EAAMgM,MAAQmV,GAAcA,GAAcnhB,EAAME,I,IAK1E,CAEA,SAASwgB,GAAgBtQ,GACvB,MAAMpG,EAAcoG,EAAapG,WACjC,SAAIA,GAAqC,IAAvBA,EAAWE,YAIxBkG,EAAI7e,SAIFiI,EAAAA,GAAAA,GAAQ4W,EAAI7e,OACfmK,GAAM0U,EAAI7e,MAAOmvB,IACjBA,GAAgBtQ,EAAI7e,OAC1B,CAEA,MAAM6vB,WAAuBrU,GAG3Blf,WAAAA,CAAoBozB,GAClBnzB,QADkB,KAAAmzB,gBAAAA,EAFpB,KAAAI,OAAiB,CAIjB,CAEArU,aAAAA,CAAclU,GAEZ,IAAmB,IAAfpG,KAAK2uB,MAAT,CAMA,OAAQvoB,EAAKzF,MACX,IAAK,YAEH,YADAX,KAAKkb,eAAe9U,GAEtB,IAAK,oBAEH,YADApG,KAAKmb,uBAAuB/U,GAIhChL,MAAMkf,cAAclU,E,CACtB,CAEAgV,cAAAA,CAAehV,GACT0D,GAAS9J,KAAKuuB,gBAAiBnoB,EAAKvH,SACtCmB,KAAK2uB,OAAQ,EAEjB,CAEAtT,QAAAA,CAASjV,GACHA,EAAKiS,gBACsCtc,IAAzCsyB,GAASjoB,EAAMpG,KAAKuuB,mBACtBvuB,KAAK2uB,OAAQ,QAG8B5yB,IAAzCsyB,GAASjoB,EAAMpG,KAAKuuB,mBACtBvuB,KAAK2uB,OAAQ,EAGnB,EAGI,SAAUC,GACdC,EACA9Y,GAEA,GAAIA,aAAmBhS,OAAQ,CAC7B,MAAM2Z,EAAMiP,GAAa5W,GACnB+Y,EAAiB,IAAIJ,GAAeG,GAE1C,OADAC,EAAetU,MAAMkD,GACdoR,EAAeH,K,CAEtB,YAGS5yB,KAFP6N,EAAAA,GAAAA,GAAUmM,GAAUtB,GACX3K,GAAS+kB,EAAoBpa,EAAMC,WAAW,KAI7D,CC7QA,MAAM5Q,GAAU,UACHirB,GAAe,cACfC,GAAQ,QAuBd,IAAIC,GACmC,mBAA/B,IAAIlrB,OAAO,QAAS0S,OAU7B,SAAUyY,GACdxrB,EACAD,GAmBA,MAAM0rB,GATN1rB,GAAU2rB,EAAAA,GAAAA,GAAS3rB,EAAS,CAC1B4rB,UAAWJ,GACXK,OAAO,EACPC,UAAU,EACVC,iBAAkB,OAClBC,yBAA0B,CAAC,KAAM,MACjCN,OAAQA,CAAC/C,EAAalM,IAAqBA,OAGtBiP,OAMvB,IAAIO,EAJJP,EAAO,mCAAmC,MAuiC5C,WACE,IAAIznB,EAAAA,GAAAA,GAAQioB,IAA4B,CACtCA,GAA4B,IAAI9oB,MAAM,OACtC,IAAK,IAAI2D,EAAI,EAAGA,EAAI,MAAOA,IACzBmlB,GAA0BnlB,GAAKA,EAAI,IAAM,OAASA,EAAI,KAAOA,C,CAGnE,CA7iCIolB,EAAiC,IAInCT,EAAO,mBAAmB,KACxBO,EAAoBG,GAAOnsB,GAAaosB,GAC/BA,EAAShsB,MAAaisB,GAAMC,IACnC,IAGJ,IACIC,EAmFAC,EACAC,EACAC,EACAC,EACAC,EA0CAC,EAuBAC,EACAC,EACAC,EACAC,EA5JAC,GAAY,EAEhBzB,EAAO,sBAAsB,KAC3ByB,GAAY,EACZX,GAAyBzqB,EAAAA,GAAAA,GACvBkqB,GACCI,IACC,MAAMe,EAAcf,EAAShsB,IAG7B,GAAI2f,GAASoN,GAAc,CACzB,MAAMC,EAAeD,EAAYjU,OACjC,OAC0B,IAAxBkU,EAAah1B,QAEI,MAAjBg1B,GACiB,MAAjBA,GACiB,MAAjBA,GACCD,EAAYva,WAIW,IAAxBwa,EAAah1B,QACO,OAApBg1B,EAAa,IAEZhnB,GACC,CACE,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KAEFgnB,EAAa,IAQRrtB,EAAQ4rB,UACX0B,GAAcF,GACdG,GAAgBH,GAJbC,EAAa,GA9BbA,C,CAoCJ,IAAIG,EAAAA,GAAAA,GAAWJ,GAGpB,OAFAD,GAAY,EAEL,CAAE9tB,KAAM+tB,GACV,GAA2B,kBAAhBA,EAGhB,OAFAD,GAAY,EAELC,EACF,GAA2B,kBAAhBA,EAA0B,CAC1C,GAA2B,IAAvBA,EAAY/0B,OACd,OAAO+0B,EACF,CACL,MAAMK,EAAsBL,EAAY1zB,QACtC,sBACA,QAEIg0B,EAAgB,IAAIptB,OAAOmtB,GACjC,OAAOztB,EAAQ4rB,UACX0B,GAAcI,GACdH,GAAgBG,E,EAGtB,MAAM1wB,MAAM,uB,GAGjB,IAQH0uB,EAAO,gBAAgB,KACrBe,GAAmB1qB,EAAAA,GAAAA,GACjBkqB,GACCI,GAAaA,EAASsB,eAGzBjB,GAAoB3qB,EAAAA,GAAAA,GAAIkqB,GAAoB2B,IAC1C,MAAMC,EAAYD,EAAME,MAExB,GAAID,IAAcvB,GAAMyB,QAAxB,CAEO,IAAI1N,EAAAA,GAAAA,GAASwN,GAClB,OAAOA,EACF,IAAIG,EAAAA,GAAAA,GAAYH,GACrB,OAAO,EAEP,MAAM7wB,MAAM,uB,KAIhB2vB,GAA8B5qB,EAAAA,GAAAA,GAAIkqB,GAAoB2B,IACpD,MAAMK,EAAgBL,EAAMM,WAE5B,GAAID,EAAe,CAIjB,OAHwB5qB,EAAAA,GAAAA,GAAQ4qB,IAC5BlsB,EAAAA,GAAAA,GAAIksB,GAAgB/wB,GAAciI,GAAQ8mB,EAAmB/uB,KAC7D,CAACiI,GAAQ8mB,EAAmBgC,G,KAKpCrB,GAAuB7qB,EAAAA,GAAAA,GACrBkqB,GACC2B,GAAeA,EAAMO,YAGxBtB,GAAsB9qB,EAAAA,GAAAA,GAAIkqB,GAAoB2B,IAC5CxtB,EAAAA,GAAAA,GAAIwtB,EAAO,aACZ,IAIHlC,EAAO,4BAA4B,KACjC,MAAM0C,EAA0BC,GAC9BruB,EAAQgsB,0BAEVc,GAAgC/qB,EAAAA,GAAAA,GAAIkqB,GAAoB7L,IAAY,IACnC,eAA7BpgB,EAAQ+rB,mBACVe,GAAgC/qB,EAAAA,GAAAA,GAAIkqB,GAAoB7L,IAClDhgB,EAAAA,GAAAA,GAAIggB,EAAS,iBACNA,EAAQkO,aAG6C,IAA5DC,GAAsBnO,EAASgO,IAC/BjD,GACEiD,EACAhO,EAAQ/f,W,IAYpBqrB,EAAO,mBAAmB,KACxBqB,GAAuBhrB,EAAAA,GAAAA,GAAIkqB,EAAmBuC,IAC9CxB,GAAoBjrB,EAAAA,GAAAA,GAAIyqB,EAAwBiC,IAEhDxB,GAAcnnB,EAAAA,GAAAA,GACZmmB,GACA,CAACyC,EAAKd,KACJ,MAAMC,EAAYD,EAAME,MAIxB,OAHIzN,EAAAA,GAAAA,GAASwN,IAAgBA,IAAcvB,GAAMyB,UAC/CW,EAAIb,GAAa,IAEZa,CAAG,GAEZ,CAAC,GAGHxB,GAAqBnrB,EAAAA,GAAAA,GACnByqB,GACA,CAACmC,EAAG1c,KACK,CACLK,QAASka,EAAuBva,GAChC2c,UAAWjC,EAA4B1a,GACvC4c,kBAAmB/B,EAA8B7a,GACjD6c,SAAU/B,EAAqB9a,GAC/B8c,MAAO/B,EAAkB/a,GACzBuC,MAAOkY,EAAkBza,GACzB/O,KAAM0pB,EAAqB3a,GAC3BrJ,IAAKikB,EAAoB5a,GACzB0b,aAAclB,EAAiBxa,GAC/B9R,UAAW8rB,EAAkBha,MAGlC,IAGH,IAAI+c,GAAiB,EACjBC,EACF,GAiFF,OA/EKjvB,EAAQ8rB,UACXJ,EAAO,2BAA2B,KAChCuD,GAA+BnpB,EAAAA,GAAAA,GAC7BmmB,GACA,CAACtqB,EAAQutB,EAAajd,KACpB,GAAmC,kBAAxBid,EAAY7uB,QAAsB,CAC3C,MACM8uB,EAAehF,GADJ+E,EAAY7uB,QAAQ4Q,WAAW,IAEhDme,GAAiBztB,EAAQwtB,EAAcjC,EAAmBjb,G,MACrD,IAAI5O,EAAAA,GAAAA,GAAQ6rB,EAAYG,kBAAmB,CAChD,IAAIC,GACJpvB,EAAAA,GAAAA,GAAQgvB,EAAYG,kBAAmBE,IACrC,MAIMC,EAAmBrF,GAHF,kBAAdoF,EACHA,EAAUte,WAAW,GACrBse,GAMFD,IAAqBE,IACvBF,EAAmBE,EACnBJ,GACEztB,EACA6tB,EACAtC,EAAmBjb,I,SAIpB,GAAI+N,GAASkP,EAAY7uB,SAC9B,GAAI6uB,EAAY7uB,QAAQ0S,QACtBic,GAAiB,EACbhvB,EAAQypB,qBACVf,GACE,GAAA9rB,OAAG2sB,IAA2B,yBAAA3sB,OACHsyB,EAAY7uB,QAAQE,WAAU,iBADzD,uPAOC,CACL,MAAMkvB,EAAiBjG,GACrB0F,EAAY7uB,QACZL,EAAQypB,sBAKNxlB,EAAAA,GAAAA,GAAQwrB,KAIVT,GAAiB,IAEnB9uB,EAAAA,GAAAA,GAAQuvB,GAAiB5F,IACvBuF,GAAiBztB,EAAQkoB,EAAMqD,EAAmBjb,GAAK,G,MAIvDjS,EAAQypB,qBACVf,GACE,GAAA9rB,OAAG2sB,IAA2B,iBAAA3sB,OACXsyB,EAAYz1B,KAAI,uFADnC,8JAMJu1B,GAAiB,EAGnB,OAAOrtB,CAAM,GAEf,GACD,IAIE,CACLsrB,YAAaA,EACbC,mBAAoBA,EACpB+B,6BAA8BA,EAC9B9B,UAAWA,EACX6B,eAAgBA,EAEpB,CAEM,SAAUU,GACdzvB,EACA0vB,GAEA,IAAIC,EAAkC,GAEtC,MAAMC,EA8CF,SACJ5vB,GAEA,MAAM6vB,GAA+BnqB,EAAAA,GAAAA,GAAO1F,GAAaosB,KAC/CjsB,EAAAA,GAAAA,GAAIisB,EAAUhsB,MAGlBuvB,GAAS7tB,EAAAA,GAAAA,GAAI+tB,GAA+BzD,IACzC,CACLpqB,QACE,iBACAoqB,EAAS5yB,KACT,uCACFyD,KAAM6yB,GAAyBC,gBAC/B/vB,WAAY,CAACosB,OAIX4D,EAAQC,GAAWjwB,EAAY6vB,GACrC,MAAO,CAAEF,SAAQK,QACnB,CAlEwBE,CAAoBlwB,GAC1C2vB,EAASA,EAAOhzB,OAAOizB,EAAcD,QAErC,MAAMQ,EAiEF,SACJnwB,GAEA,MAAMowB,GAA+B1qB,EAAAA,GAAAA,GAAO1F,GAAaosB,IACvD,MAAM/Z,EAAU+Z,EAAShsB,IACzB,OACG2f,GAAS1N,MACTkb,EAAAA,GAAAA,GAAWlb,MACXlS,EAAAA,GAAAA,GAAIkS,EAAS,WACb+N,EAAAA,GAAAA,GAAS/N,EAAQ,IAIhBsd,GAAS7tB,EAAAA,GAAAA,GAAIsuB,GAA+BhE,IACzC,CACLpqB,QACE,iBACAoqB,EAAS5yB,KADT,0JAIFyD,KAAM6yB,GAAyBO,gBAC/BrwB,WAAY,CAACosB,OAIX4D,EAAQC,GAAWjwB,EAAYowB,GACrC,MAAO,CAAET,SAAQK,QACnB,CA5FwBM,CAAoBV,EAAcI,OAClDO,EAAkBJ,EAAcH,MAatC,OAZAL,EAASA,EAAOhzB,OAAOwzB,EAAcR,QAErCA,EAASA,EAAOhzB,OAalB,SACEqD,GAEA,IAAI2vB,EAAkC,GACtC,MAAMa,GAAqB9qB,EAAAA,GAAAA,GAAO1F,GAAaivB,GAC7ClP,GAASkP,EAAY7uB,OAavB,OAVAuvB,EAASA,EAAOhzB,OAuEZ,SACJqD,GAEA,MAAMywB,UAAwB9Z,GAA9Blf,WAAAA,G,oBACE,KAAAwzB,OAAQ,CAKV,CAHE5T,cAAAA,CAAe3U,GACbpG,KAAK2uB,OAAQ,CACf,EAGF,MAAMyF,GAAehrB,EAAAA,GAAAA,GAAO1F,GAAaosB,IACvC,MAAM/Z,EAAU+Z,EAAShsB,QAEzB,IACE,MAAMuwB,EAAY1H,GAAa5W,GACzBue,EAAmB,IAAIH,EAG7B,OAFAG,EAAiB9Z,MAAM6Z,GAEhBC,EAAiB3F,K,CACxB,MAAOrlB,GAGP,OAAOirB,GAAatb,KAAMlD,EAAmB6G,O,KAI3CyW,GAAS7tB,EAAAA,GAAAA,GAAI4uB,GAAetE,IACzB,CACLpqB,QACE,oDAEAoqB,EAAS5yB,KAFT,+IAMFyD,KAAM6yB,GAAyBgB,iBAC/B9wB,WAAY,CAACosB,OAIjB,OAAOuD,CACT,CAjHyBoB,CAAqBP,IAE5Cb,EAASA,EAAOhzB,OAyIZ,SACJqD,GAEA,MAAMgxB,UAA0Bra,GAAhClf,WAAAA,G,oBACE,KAAAwzB,OAAQ,CAKV,CAHE7T,gBAAAA,CAAiB1U,GACfpG,KAAK2uB,OAAQ,CACf,EAGF,MAAMyF,GAAehrB,EAAAA,GAAAA,GAAO1F,GAAaosB,IACvC,MAAM/Z,EAAU+Z,EAAShsB,QACzB,IACE,MAAMuwB,EAAY1H,GAAa5W,GACzB4e,EAAqB,IAAID,EAG/B,OAFAC,EAAmBna,MAAM6Z,GAElBM,EAAmBhG,K,CAC1B,MAAOrlB,GAGP,OAAOsrB,GAAe3b,KAAKlD,EAAQ6G,O,KAIjCyW,GAAS7tB,EAAAA,GAAAA,GAAI4uB,GAAetE,IACzB,CACLpqB,QACE,oDAEAoqB,EAAS5yB,KAFT,yJAMFyD,KAAM6yB,GAAyBqB,iBAC/BnxB,WAAY,CAACosB,OAIjB,OAAOuD,CACT,CAlLyByB,CAAuBZ,IAE9Cb,EAASA,EAAOhzB,OAkLZ,SACJqD,GAEA,MAAMqxB,GAAe3rB,EAAAA,GAAAA,GAAO1F,GAAaosB,IACvC,MAAM/Z,EAAU+Z,EAAShsB,IACzB,OAAOiS,aAAmBhS,SAAWgS,EAAQ+F,WAAa/F,EAAQM,OAAO,IAGrEgd,GAAS7tB,EAAAA,GAAAA,GAAIuvB,GAAejF,IACzB,CACLpqB,QACE,iBACAoqB,EAAS5yB,KACT,oEACFyD,KAAM6yB,GAAyBwB,wBAC/BtxB,WAAY,CAACosB,OAIjB,OAAOuD,CACT,CAtMyB4B,CAAqBf,IAE5Cb,EAASA,EAAOhzB,OAuMZ,SACJqD,GAEA,MAAMirB,EAAqB,GAC3B,IAAIuG,GAAoB1vB,EAAAA,GAAAA,GAAI9B,GAAayxB,IAChC5rB,EAAAA,GAAAA,GACL7F,GACA,CAAC0B,EAAQgwB,KAELD,EAAUrxB,QAAQ8Y,SAAYwY,EAAUtxB,QAAmB8Y,QAC1D9S,GAAS6kB,EAAOyG,IACjBA,EAAUtxB,UAAYisB,GAAMC,KAI5BrB,EAAMhoB,KAAKyuB,GACXhwB,EAAOuB,KAAKyuB,IAGPhwB,IAET,MAIJ8vB,EAAoBG,GAAQH,GAE5B,MAAMI,GAAoBlsB,EAAAA,GAAAA,GAAO8rB,GAAoBK,GAC5CA,EAAiBz5B,OAAS,IAG7Bu3B,GAAS7tB,EAAAA,GAAAA,GAAI8vB,GAAoBE,IACrC,MAAMC,GAAiBjwB,EAAAA,GAAAA,GAAIgwB,GAAiB1F,GACnCA,EAAS5yB,OAGZw4B,EAAsBntB,GAAMitB,GAAiB1xB,QACnD,MAAO,CACL4B,QACE,6BAAArF,OAA6Bq1B,EAAa,4DAAAr1B,OACYo1B,EAAe9vB,KACnE,MACD,OACHhF,KAAM6yB,GAAyBmC,yBAC/BjyB,WAAY8xB,EACb,IAGH,OAAOnC,CACT,CAxPyBuC,CAAsB1B,IAE7Cb,EAASA,EAAOhzB,OA2GZ,SACJqD,GAEA,MAAMmyB,GAAqBzsB,EAAAA,GAAAA,GAAO1F,GAAaosB,GAC7BA,EAAShsB,QACVmV,KAAK,MAGhBoa,GAAS7tB,EAAAA,GAAAA,GAAIqwB,GAAqB/F,IAC/B,CACLpqB,QACE,iBACAoqB,EAAS5yB,KACT,qDACFyD,KAAM6yB,GAAyBsC,oBAC/BpyB,WAAY,CAACosB,OAIjB,OAAOuD,CACT,CA/HyB0C,CAAsB7B,IAEtCb,CACT,CAhCyB2C,CAAsB/B,IAE7CZ,EAASA,EAAOhzB,OAmRZ,SACJqD,GAEA,MAAMuyB,GAAe7sB,EAAAA,GAAAA,GAAO1F,GAAa2tB,IACvC,KAAKxtB,EAAAA,GAAAA,GAAIwtB,EAAO,SACd,OAAO,EAET,MAAMpZ,EAAQoZ,EAAME,MAEpB,OAAOtZ,IAAU8X,GAAMyB,SAAWvZ,IAAU8X,GAAMC,MAAOlM,EAAAA,GAAAA,GAAS7L,EAAM,IAGpEob,GAAS7tB,EAAAA,GAAAA,GAAIywB,GAAenG,IACzB,CACLpqB,QACE,iBACAoqB,EAAS5yB,KACT,gEACFyD,KAAM6yB,GAAyB0C,yBAC/BxyB,WAAY,CAACosB,OAIjB,OAAOuD,CACT,CA3SyB8C,CAAqBlC,IAE5CZ,EAASA,EAAOhzB,OA2SZ,SACJqD,EACA0yB,GAEA,MAAMC,GAAejtB,EAAAA,GAAAA,GAAO1F,GAAa2tB,QAEjBt1B,IAApBs1B,EAAMO,YAA4B9nB,GAASssB,EAAY/E,EAAMO,aAI3DyB,GAAS7tB,EAAAA,GAAAA,GAAI6wB,GAAexS,IAIzB,CACLne,QAHA,iBAAArF,OAAiBwjB,EAAQ3mB,KAAI,+DAAAmD,OAA8DwjB,EAAQ+N,UAAS,6BAI5GjxB,KAAM6yB,GAAyB8C,yBAC/B5yB,WAAY,CAACmgB,OAIjB,OAAOwP,CACT,CAhUIkD,CAAwBtC,EAAiBb,IAG3CC,EAASA,EAAOhzB,OA+TZ,SACJqD,GAEA,MAAM2vB,EAAkC,GAElCmD,GAAcjtB,EAAAA,GAAAA,GAClB7F,GACA,CAAC0B,EAAQye,EAASnO,KAChB,MAAMK,EAAU8N,EAAQ/f,QAExB,OAAIiS,IAAYga,GAAMC,MAMlBlM,EAAAA,GAAAA,GAAS/N,GACX3Q,EAAOuB,KAAK,CAAE8vB,IAAK1gB,EAASL,MAAK9R,UAAWigB,IACnCJ,GAAS1N,IA8C1B,SAAoB6W,GAElB,MAAM8J,EAAY,CAChB,IACA,KACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KAEF,YACoE36B,KAAlE6N,EAAAA,GAAAA,GAAK8sB,GAAYjiB,IAA0C,IAAjCmY,EAAOhQ,OAAOhU,QAAQ6L,IAEpD,CAlEsCkiB,CAAW5gB,IACzC3Q,EAAOuB,KAAK,CAAE8vB,IAAK1gB,EAAQ6G,OAAQlH,MAAK9R,UAAWigB,KAR5Cze,CAUI,GAEf,IAoBF,OAjBAzB,EAAAA,GAAAA,GAAQD,GAAY,CAACmgB,EAAS+S,MAC5BjzB,EAAAA,GAAAA,GAAQ6yB,GAAa9V,IAA4B,IAA3B,IAAE+V,EAAG,IAAE/gB,EAAG,UAAE9R,GAAW8c,EAC3C,GAAIkW,EAAUlhB,GAkBpB,SAAuB+gB,EAAa1gB,GAElC,GAAI0N,GAAS1N,GAAU,CACrB,MAAM8gB,EAAc9gB,EAAQjT,KAAK2zB,GACjC,OAAuB,OAAhBI,GAA8C,IAAtBA,EAAY9tB,K,CACtC,IAAIkoB,EAAAA,GAAAA,GAAWlb,GAEpB,OAAOA,EAAQ0gB,EAAK,EAAG,GAAI,CAAC,GACvB,IAAI5yB,EAAAA,GAAAA,GAAIkS,EAAS,QAEtB,OAAOA,EAAQjT,KAAK2zB,EAAK,EAAG,GAAI,CAAC,GAC5B,GAAuB,kBAAZ1gB,EAChB,OAAOA,IAAY0gB,EAEnB,MAAMh2B,MAAM,uBAEhB,CAlC2Bq2B,CAAcL,EAAK5S,EAAQ/f,SAAU,CACxD,MAAMsoB,EACJ,YAAA/rB,OAAYuD,EAAU1G,KAAI,2EAAAmD,OACmBwjB,EAAQ3mB,KAAI,MADzD,2GAIFm2B,EAAO1sB,KAAK,CACVjB,QAAS0mB,EACTzrB,KAAM6yB,GAAyBuD,oBAC/BrzB,WAAY,CAACmgB,EAASjgB,I,IAG1B,IAGGyvB,CACT,CA3WyB2D,CAAwB/C,IAExCZ,CACT,CA+EA,MAAMkB,GAAe,WAoErB,MAAMK,GAAiB,iBA+PjB,SAAU5D,GAAgBjb,GAC9B,MAAMG,EAAQH,EAAQO,WAAa,IAAM,GAGzC,OAAO,IAAIvS,OAAO,OAAD1D,OAAQ0V,EAAQ6G,OAAM,KAAK1G,EAC9C,CAEM,SAAU6a,GAAchb,GAC5B,MAAMG,EAAQH,EAAQO,WAAa,KAAO,IAG1C,OAAO,IAAIvS,OAAO,GAAD1D,OAAI0V,EAAQ6G,QAAU1G,EACzC,CA2EM,SAAU+gB,GACdC,EACAC,EACA1H,GAEA,MAAM2H,EAAW,GACjB,IAAIC,GAAkB,EACtB,MAAMC,EAAgBjC,IAAQnL,EAAAA,GAAAA,IAAQpD,EAAAA,GAAAA,GAAOoQ,EAAgBK,SAEvDC,EAAqB3H,GACzByH,GACCxH,GAAaA,EAAShsB,MAAaisB,GAAMC,KAEtCyH,EAAsB3F,GAAarC,GAwCzC,OAvCI0H,IACFxzB,EAAAA,GAAAA,GAAQ6zB,GAAqB3T,IAC3B,MAAM6T,EAAY1F,GAAsBnO,EAAS4T,GACjD,IAAkB,IAAdC,EAAqB,CACvB,MAAMhyB,EAyJR,SACJme,EACA8T,GAQA,GAAIA,EAAQC,QAAUpE,GAAyBqE,oBAC7C,MACE,kEAAiE,4BAAAx3B,OACrCwjB,EAAQ3mB,KAAI,kBAAgB,kBAAAmD,OACtCs3B,EAAQG,OAAM,OAChC,sGAEG,GAAIH,EAAQC,QAAUpE,GAAyBuE,kBACpD,MACE,6EAA4E,4BAAA13B,OAChDwjB,EAAQ3mB,KAAI,kBACxC,oGAGF,MAAMuD,MAAM,uBAEhB,CAnLwBu3B,CAA2BnU,EAAS6T,GAC9CO,EAAoB,CACxBvyB,UACA/E,KAAM+2B,EAAUE,MAChBh0B,UAAWigB,GAEbuT,EAASzwB,KAAKsxB,E,MAGVp0B,EAAAA,GAAAA,GAAIggB,EAAS,gBACa,IAAxBA,EAAQkO,cACVsF,GAAkB,GAIlBzI,GAAiB6I,EAAqB5T,EAAQ/f,WAE9CuzB,GAAkB,E,IAOxBF,IAAeE,GACjBD,EAASzwB,KAAK,CACZjB,QACE,uRAKF/E,KAAM6yB,GAAyB0E,uBAG5Bd,CACT,CAuBM,SAAUnF,GAAgBruB,GAC9B,MAAMmS,EAAUnS,EAAUE,QAE1B,GAAI2f,GAAS1N,GACX,OAAO,EACF,IAAIkb,EAAAA,GAAAA,GAAWlb,GAEpB,OAAO,EACF,IAAIlS,EAAAA,GAAAA,GAAIkS,EAAS,QAEtB,OAAO,EACF,IAAI+N,EAAAA,GAAAA,GAAS/N,GAClB,OAAO,EAEP,MAAMtV,MAAM,uBAEhB,CAEM,SAAUyxB,GAAenc,GAC7B,UAAI+N,EAAAA,GAAAA,GAAS/N,IAA+B,IAAnBA,EAAQja,SACxBia,EAAQrB,WAAW,EAI9B,CAKO,MAAMyjB,GAAwD,CAEnElf,KAAM,SAAU/T,GACd,MAAMkzB,EAAMlzB,EAAKpJ,OACjB,IAAK,IAAI0O,EAAIxK,KAAKmd,UAAW3S,EAAI4tB,EAAK5tB,IAAK,CACzC,MAAM6tB,EAAInzB,EAAKwP,WAAWlK,GAC1B,GAAU,KAAN6tB,EAEF,OADAr4B,KAAKmd,UAAY3S,EAAI,GACd,EACF,GAAU,KAAN6tB,EAMT,OAL+B,KAA3BnzB,EAAKwP,WAAWlK,EAAI,GACtBxK,KAAKmd,UAAY3S,EAAI,EAErBxK,KAAKmd,UAAY3S,EAAI,GAEhB,C,CAGX,OAAO,CACT,EAEA2S,UAAW,GAGb,SAAS6U,GACPnO,EACAgO,GASA,IAAIhuB,EAAAA,GAAAA,GAAIggB,EAAS,eAGf,OAAO,EAGP,GAAIJ,GAASI,EAAQ/f,SAAU,CAC7B,IAEE8qB,GAAiBiD,EAAyBhO,EAAQ/f,Q,CAClD,MAAOwF,GAEP,MAAO,CACLsuB,MAAOpE,GAAyBqE,oBAChCC,OAASxuB,EAAY5D,Q,CAGzB,OAAO,C,CACF,IAAIoe,EAAAA,GAAAA,GAASD,EAAQ/f,SAE1B,OAAO,EACF,GAAImuB,GAAgBpO,GAEzB,MAAO,CAAE+T,MAAOpE,GAAyBuE,mBAEzC,MAAMt3B,MAAM,uBAGlB,CA8BA,SAASqxB,GAAawG,GASpB,OARkB9yB,EAAAA,GAAAA,GAAI8yB,GAAeC,IAC/BzU,EAAAA,GAAAA,GAASyU,GACJA,EAAY7jB,WAAW,GAEvB6jB,GAKb,CAEA,SAAS1F,GACPrtB,EACAyF,EACApM,QAEiB9C,IAAbyJ,EAAIyF,GACNzF,EAAIyF,GAAO,CAACpM,GAEZ2G,EAAIyF,GAAKtE,KAAK9H,EAElB,CAEO,MAAM2uB,GAAqB,IAiBlC,IAAImC,GAAsC,GACpC,SAAU/B,GAAyB4K,GACvC,OAAOA,EAAWhL,GACdgL,EACA7I,GAA0B6I,EAChC,C,qCCroCM,SAAUC,GAAShS,GACvB,MAAM7Z,GAAQ,IAAI8rB,MAAOC,UACnBC,EAAMnS,IAGZ,MAAO,CAAEoS,MAFG,IAAIH,MAAOC,UACH/rB,EACE/N,MAAO+5B,EAC/B,CCQM,SAAUE,GACdC,EACAC,GAEA,MAAMC,EAAeF,EAAY3H,aACjC,OAAI6H,IAAiBD,EAAe5H,eAIJ,IAA5B4H,EAAeE,WACsC,IAArDF,EAAeG,mBAAoBF,EAGzC,CAIM,SAAUG,GACdzsB,EACAkX,GAEA,OAAOlX,EAAMykB,eAAiBvN,EAAQuN,YACxC,CAEO,IAAIiI,GAAoB,EACxB,MAAMC,GAAqD,CAAC,EAE7D,SAAUC,GAAkB71B,GAEhC,MAAM81B,EAcF,SAA2B91B,GAC/B,IAAI0B,GAASq0B,EAAAA,GAAAA,GAAM/1B,GAEfg2B,EAAah2B,EACbi2B,GAAY,EAChB,KAAOA,GAAW,CAChBD,EAAarE,IACXnL,EAAAA,GAAAA,IAAQ1kB,EAAAA,GAAAA,GAAIk0B,GAAa/G,GAAgBA,EAAYiH,eAGvD,MAAMC,EAAgBlG,GAAW+F,EAAYt0B,GAE7CA,EAASA,EAAO/E,OAAOw5B,IAEnBnyB,EAAAA,GAAAA,GAAQmyB,GACVF,GAAY,EAEZD,EAAaG,C,CAGjB,OAAOz0B,CACT,CAnC+B00B,CAAiBp2B,IAqC1C,SAAkCA,IACtCC,EAAAA,GAAAA,GAAQD,GAAaivB,IAyEjB,IAA0C9O,EAxEvCkW,GAAoBpH,KACvB2G,GAAgBD,IAAqB1G,EAC/BA,EAAavB,aAAeiI,MAKlCW,GAAsBrH,MACrB7rB,EAAAA,GAAAA,GAAQ6rB,EAAYiH,cAIrBjH,EAAYiH,WAAa,CAACjH,EAAYiH,aAGnCI,GAAsBrH,KACzBA,EAAYiH,WAAa,IAwDiB/V,EArDP8O,GAsDhC9uB,EAAAA,GAAAA,GAAIggB,EAAS,qBArDhB8O,EAAYsH,gBAAkB,IAwD9B,SACJpW,GAEA,OAAOhgB,EAAAA,GAAAA,GAAIggB,EAAS,qBACtB,CAzDSqW,CAAmCvH,KACtCA,EAAYwG,mBAAqB,CAAC,E,GAGxC,CA/DEgB,CAAwBX,GA6EpB,SAAkC91B,IACtCC,EAAAA,GAAAA,GAAQD,GAAaivB,IACnByH,GAA8B,GAAIzH,EAAY,GAElD,CA9EE0H,CAAwBb,GA8DpB,SAAqC91B,IACzCC,EAAAA,GAAAA,GAAQD,GAAaivB,IAEnBA,EAAYsH,gBAAkB,IAC9Bt2B,EAAAA,GAAAA,GAAQgvB,EAAYwG,oBAAqB,CAACP,EAAK3tB,KAC7C0nB,EAAYsH,gBAAiBtzB,KAC3B2yB,GAAgBruB,GAA0BmmB,aAC3C,GACD,GAEN,CAvEEkJ,CAA2Bd,IAE3B71B,EAAAA,GAAAA,GAAQ61B,GAAuB3V,IAC7BA,EAAQqV,SAAWrV,EAAQoW,gBAAiBn+B,OAAS,CAAC,GAE1D,CA0EM,SAAUs+B,GACdhX,EACAmX,IAEA52B,EAAAA,GAAAA,GAAQyf,GAAOoX,IACbD,EAASpB,mBAAoBqB,EAASpJ,eAAiB,CAAI,KAG7DztB,EAAAA,GAAAA,GAAQ42B,EAASX,YAAaa,IAC5B,MAAMC,EAAUtX,EAAK/iB,OAAOk6B,GAEvBzwB,GAAS4wB,EAASD,IACrBL,GAA8BM,EAASD,E,GAG7C,CAEM,SAAUV,GAAoBlW,GAClC,OAAOhgB,EAAAA,GAAAA,GAAIggB,EAAS,eACtB,CAEM,SAAUmW,GAAsBnW,GACpC,OAAOhgB,EAAAA,GAAAA,GAAIggB,EAAS,aACtB,CAYM,SAAU8W,GAAY9W,GAC1B,OAAOhgB,EAAAA,GAAAA,GAAIggB,EAAS,eACtB,CCpKO,MAAM+W,GAAwD,CACnEC,iCAAiCluB,GACxB,uDAAPtM,OAA8DsM,EAAMmuB,MAAK,8BAG3EC,iCAAgCA,CAC9B7zB,EACA8zB,EACAl/B,EACAiR,EACAkuB,IAGE,2BAAA56B,OAA2B6G,EAASg0B,OAClCF,GACD,kBAAA36B,OAAiB26B,EAAW,iBAAA36B,OAAkBvE,EAAM,iBCgCpD,IAAK03B,IAAZ,SAAYA,GACVA,EAAAA,EAAA,qCACAA,EAAAA,EAAA,qCACAA,EAAAA,EAAA,uCACAA,EAAAA,EAAA,qDACAA,EAAAA,EAAA,uDACAA,EAAAA,EAAA,uDACAA,EAAAA,EAAA,uDACAA,EAAAA,EAAA,iFACAA,EAAAA,EAAA,qFACAA,EAAAA,EAAA,2GACAA,EAAAA,EAAA,0FACAA,EAAAA,EAAA,wCACAA,EAAAA,EAAA,8CACAA,EAAAA,EAAA,gDACAA,EAAAA,EAAA,8CACAA,EAAAA,EAAA,8CACAA,EAAAA,EAAA,0CACAA,EAAAA,EAAA,qGACD,CAnBD,CAAYA,KAAAA,GAAwB,KAyBpC,MAAM2H,GAA+C,CACnDC,+BAA+B,EAC/B5L,iBAAkB,OAClB6L,uBAAwB,YACxB5L,yBAA0B,CAAC,KAAM,MACjCvC,qBAAqB,EACrBqC,UAAU,EACV+L,qBAAsBV,GACtBW,eAAe,EACfC,iBAAiB,EACjBC,iBAAiB,GAGnB/8B,OAAO6M,OAAO4vB,IAER,MAAOpL,GA4BX50B,WAAAA,CACY+7B,GACiC,IAA3CwE,EAAA7/B,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAuBs/B,GAEvB,GAHU,KAAAjE,gBAAAA,EAvBL,KAAAyE,sBAAiD,GACjD,KAAAC,uBAAkD,GAE/C,KAAAjL,mBAAuD,CAAC,EACxD,KAAA+B,6BAEN,CAAC,EAEK,KAAA6E,MAAkB,GAElB,KAAA7G,YAA+C,CAAC,EAGlD,KAAAmL,iBAA2B,EAC3B,KAAAC,eAAyB,EACzB,KAAAlL,WAAqB,EACrB,KAAAmL,mBAA8C,CAAC,EAu0BvD,KAAAC,WAAa,CAAIC,EAAmBC,KAGlC,IAA2B,IAAvBl8B,KAAKu7B,cAAwB,CAC/Bv7B,KAAKm8B,kBACL,MAAMC,EAAS,IAAIv1B,MAAM7G,KAAKm8B,gBAAkB,GAAGx2B,KAAK,MACpD3F,KAAKm8B,gBAAkBn8B,KAAKq8B,mBAC9BhQ,QAAQiQ,IAAI,GAADj8B,OAAI+7B,EAAM,YAAA/7B,OAAQ47B,EAAS,MAExC,MAAM,KAAEpD,EAAI,MAAEh6B,GAAU45B,GAAMyD,GAExBK,EAAc1D,EAAO,GAAKxM,QAAQG,KAAOH,QAAQiQ,IAKvD,OAJIt8B,KAAKm8B,gBAAkBn8B,KAAKq8B,mBAC9BE,EAAY,GAADl8B,OAAI+7B,EAAM,SAAA/7B,OAAQ47B,EAAS,YAAA57B,OAAWw4B,EAAI,OAEvD74B,KAAKm8B,kBACEt9B,C,CAEP,OAAOq9B,G,EA/0Ba,mBAAXR,EACT,MAAMj7B,MACJ,8HAMJT,KAAK07B,OAASrX,GAAO,CAAC,EAAG8W,GAAsBO,GAE/C,MAAMc,EAAex8B,KAAK07B,OAAOH,eACZ,IAAjBiB,GACFx8B,KAAKq8B,kBAAoB3kB,IACzB1X,KAAKu7B,eAAgB,GACY,kBAAjBiB,IAChBx8B,KAAKq8B,kBAAoBG,EACzBx8B,KAAKu7B,eAAgB,GAEvBv7B,KAAKm8B,iBAAmB,EAExBn8B,KAAKg8B,WAAW,qBAAqB,KACnC,IAAIS,EACAC,GAAoB,EACxB18B,KAAKg8B,WAAW,yBAAyB,KACvC,GACEh8B,KAAK07B,OAAOL,yBACZF,GAAqBE,uBAGrBr7B,KAAK07B,OAAOL,uBAAyBlD,QAErC,GACEn4B,KAAK07B,OAAOjM,2BACZ0L,GAAqB1L,yBAErB,MAAMhvB,MACJ,oLAMN,GAAIi7B,EAAOnM,UAAYmM,EAAOxO,oBAC5B,MAAMzsB,MACJ,sEAIJT,KAAK67B,gBAAkB,kBAAkB5iB,KACvCjZ,KAAK07B,OAAOlM,kBAEdxvB,KAAK87B,cAAgB,QAAQ7iB,KAAKjZ,KAAK07B,OAAOlM,mBAG1C1oB,EAAAA,GAAAA,GAAQowB,GACVuF,EAAmB,CACjBlF,MAAO,CAAEoF,aAAalD,EAAAA,GAAAA,GAAMvC,IAC5ByF,YAAa5N,KAIf2N,GAAoB,EACpBD,GAAmBhD,EAAAA,GAAAA,GAAiCvC,G,KAIpB,IAAhCl3B,KAAK07B,OAAOF,kBACdx7B,KAAKg8B,WAAW,wBAAwB,KACtCh8B,KAAK27B,sBAAwB37B,KAAK27B,sBAAsBt7B,OJ0oB5D,SACJ62B,GAIA,MAAM7D,EAAkC,GAiExC,OA9DKxvB,EAAAA,GAAAA,GAAIqzB,EAAiBnI,KACxBsE,EAAO1sB,KAAK,CACVjB,QACE,sDACAqpB,GACA,iCACFpuB,KAAM6yB,GAAyBoJ,yCAG9B/4B,EAAAA,GAAAA,GAAIqzB,EAAiBlI,KACxBqE,EAAO1sB,KAAK,CACVjB,QACE,yFAGF/E,KAAM6yB,GAAyBqJ,2CAKjCh5B,EAAAA,GAAAA,GAAIqzB,EAAiBlI,MACrBnrB,EAAAA,GAAAA,GAAIqzB,EAAiBnI,OACpBlrB,EAAAA,GAAAA,GAAIqzB,EAAgBK,MAAOL,EAAgByF,cAE5CtJ,EAAO1sB,KAAK,CACVjB,QACE,kDAAArF,OAAkD0uB,GAAY,OAAA1uB,OAAM62B,EAAgByF,YAAW,8BAEjGh8B,KAAM6yB,GAAyBsJ,sDAI/Bj5B,EAAAA,GAAAA,GAAIqzB,EAAiBlI,MACvBrrB,EAAAA,GAAAA,GAAQuzB,EAAgBK,OAAO,CAACwF,EAAeC,MAC7Cr5B,EAAAA,GAAAA,GAAQo5B,GAAe,CAACpK,EAAasK,KACnC,IAAIxL,EAAAA,GAAAA,GAAYkB,GACdU,EAAO1sB,KAAK,CACVjB,QACE,yEAAArF,OACI28B,EAAY,iBAAA38B,OAAgB48B,EAAO,OACzCt8B,KAAM6yB,GAAyB0J,iDAE5B,IAAIr5B,EAAAA,GAAAA,GAAI8uB,EAAa,cAAe,CACzC,MAAMN,GAAYvrB,EAAAA,GAAAA,GAAQ6rB,EAAYhB,YAClCgB,EAAYhB,WACZ,CAACgB,EAAYhB,aACjBhuB,EAAAA,GAAAA,GAAQ0uB,GAAY8K,KAEf1L,EAAAA,GAAAA,GAAY0L,IACZrzB,GAASizB,EAAeI,IAEzB9J,EAAO1sB,KAAK,CACVjB,QAAS,8DAAFrF,OAAgE88B,EAAcjgC,KAAI,gBAAAmD,OAAesyB,EAAYz1B,KAAI,uBAAAmD,OAAsB28B,EAAY,OAC1Jr8B,KAAM6yB,GAAyB4J,iD,OAKvC,IAIC/J,CACT,CIhtBYgK,CACEZ,EACAz8B,KAAK67B,gBACL77B,KAAK07B,OAAOjM,0BAEf,IAGHzvB,KAAKg8B,WAAW,+BAA+B,KAC7Ch8B,KAAK47B,uBAAyB57B,KAAK47B,uBAAuBv7B,OACxD42B,GACEwF,EACAz8B,KAAK67B,gBACL77B,KAAK07B,OAAOjM,0BAEf,KAKLgN,EAAiBlF,MAAQkF,EAAiBlF,MACtCkF,EAAiBlF,MACjB,CAAC,GAIL5zB,EAAAA,GAAAA,GAAQ84B,EAAiBlF,OAAO,CAACwF,EAAeC,KAC9CP,EAAiBlF,MAAMyF,GAAgBnN,GACrCkN,GACCpK,IAAgBlB,EAAAA,GAAAA,GAAYkB,IAC9B,IAGH,MAAM2K,GAAe3pB,EAAAA,GAAAA,GAAK8oB,EAAiBlF,OAyD3C,IAvDA5zB,EAAAA,GAAAA,GACE84B,EAAiBlF,OACjB,CAACgG,EAAyBC,KACxBx9B,KAAKg8B,WAAW,UAAD37B,OAAWm9B,EAAW,iBAAgB,KAcnD,GAbAx9B,KAAKu3B,MAAM5wB,KAAK62B,IAEoB,IAAhCx9B,KAAK07B,OAAOF,iBACdx7B,KAAKg8B,WAAW,oBAAoB,KAClCh8B,KAAK27B,sBAAwB37B,KAAK27B,sBAAsBt7B,OACtD8yB,GAAiBoK,EAAYD,GAC9B,KAOD51B,EAAAA,GAAAA,GAAQ1H,KAAK27B,uBAAwB,CAGvC,IAAI8B,EAFJlE,GAAkBgE,GAGlBv9B,KAAKg8B,WAAW,qBAAqB,KACnCyB,EAAoBvO,GAAkBqO,EAAY,CAChD9N,yBACEzvB,KAAK07B,OAAOjM,yBACdD,iBAAkBkM,EAAOlM,iBACzBtC,oBAAqBwO,EAAOxO,oBAC5BqC,SAAUmM,EAAOnM,SACjBJ,OAAQnvB,KAAKg8B,YACb,IAGJh8B,KAAK2wB,mBAAmB6M,GACtBC,EAAkB9M,mBAEpB3wB,KAAK0yB,6BAA6B8K,GAChCC,EAAkB/K,6BAEpB1yB,KAAK0wB,YAAcrM,GACjB,CAAC,EACDrkB,KAAK0wB,YACL+M,EAAkB/M,aAGpB1wB,KAAK4wB,UAAY6M,EAAkB7M,WAAa5wB,KAAK4wB,UAErD5wB,KAAK+7B,mBAAmByB,GACtBC,EAAkBhL,c,IAEtB,IAINzyB,KAAK28B,YAAcF,EAAiBE,cAGjCj1B,EAAAA,GAAAA,GAAQ1H,KAAK27B,yBACb37B,KAAK07B,OAAON,8BACb,CACA,MAGMsC,GAHiBl4B,EAAAA,GAAAA,GAAIxF,KAAK27B,uBAAwBrP,GAC/CA,EAAM5mB,UAE6BC,KAC1C,6BAEF,MAAM,IAAIlF,MACR,4CAA8Ci9B,E,EAKlD/5B,EAAAA,GAAAA,GAAQ3D,KAAK47B,wBAAyB3D,IACpC1L,GAAc0L,EAAkBvyB,QAAQ,IAG1C1F,KAAKg8B,WAAW,wCAAwC,KAwBtD,GApBI/M,IACFjvB,KAAK29B,UAAiBC,GAAAA,EACtB59B,KAAK6C,MAAQ7C,KAAK69B,gBAElB79B,KAAK89B,gBAAkBC,GAAAA,EACvB/9B,KAAK6C,MAAQ7C,KAAKg+B,eAGhBtB,IACF18B,KAAKi+B,YAAcF,GAAAA,IAGQ,IAAzB/9B,KAAK67B,kBACP77B,KAAKk+B,iBAAmBN,GAAAA,IAGC,IAAvB59B,KAAK87B,gBACP97B,KAAKm+B,iCAAmCJ,GAAAA,GAGtC,QAAQ9kB,KAAKjZ,KAAK07B,OAAOlM,kBAC3BxvB,KAAKo+B,oBAAsBp+B,KAAKq+B,qBAC3B,GAAI,aAAaplB,KAAKjZ,KAAK07B,OAAOlM,kBACvCxvB,KAAKo+B,oBAAsBp+B,KAAKs+B,yBAC3B,KAAI,cAAcrlB,KAAKjZ,KAAK07B,OAAOlM,kBAGxC,MAAM/uB,MAAM,8CAADJ,OACqCL,KAAK07B,OAAOlM,iBAAgB,MAH5ExvB,KAAKo+B,oBAAsBp+B,KAAKu+B,qB,CAO9Bv+B,KAAK4wB,WACP5wB,KAAKw+B,SAAWx+B,KAAKy+B,kBACrBz+B,KAAK0+B,cAAgB1+B,KAAK2+B,0BAE1B3+B,KAAKw+B,SAAWx+B,KAAK4+B,0BACrB5+B,KAAK0+B,cAAgB1+B,KAAK6+B,sB,IAI9B7+B,KAAKg8B,WAAW,gCAAgC,KAC9C,MAAM8C,GAAmBv1B,EAAAA,GAAAA,GACvBvJ,KAAK+7B,oBACL,CAACgD,EAAmBtM,EAAgBuM,MACX,IAAnBvM,GACFsM,EAAkBp4B,KAAKq4B,GAElBD,IAET,IAGF,GAAIrD,EAAOxO,uBAAwBxlB,EAAAA,GAAAA,GAAQo3B,GACzC,MAAMr+B,MACJ,kBAAAJ,OAAkBy+B,EAAiBn5B,KACjC,MACD,6BAFD,uM,IASN3F,KAAKg8B,WAAW,0BAA0B,KNhV9CvP,GAAiB,CAAC,CMiVY,IAG1BzsB,KAAKg8B,WAAW,oBAAoB,KAClCla,GAAiB9hB,KAAK,GACtB,GAEN,CAEOi/B,QAAAA,CACL/5B,GACsC,IAAtCg6B,EAAArjC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAsBmE,KAAK28B,YAE3B,KAAKj1B,EAAAA,GAAAA,GAAQ1H,KAAK27B,uBAAwB,CACxC,MAGM+B,GAHiBl4B,EAAAA,GAAAA,GAAIxF,KAAK27B,uBAAwBrP,GAC/CA,EAAM5mB,UAE6BC,KAC1C,6BAEF,MAAM,IAAIlF,MACR,uEACEi9B,E,CAIN,OAAO19B,KAAKm/B,iBAAiBj6B,EAAMg6B,EACrC,CAMQC,gBAAAA,CAAiBj6B,EAAcg6B,GACrC,IAAI10B,EACF40B,EACAC,EACAC,EACAjN,EACAkN,EACAC,EACAC,EACAC,EACAznB,EACA4L,EACA8b,EACAC,EAEAxT,EACAvpB,EACF,MAAM6hB,EAAUxf,EACV26B,EAAYnb,EAAQ5oB,OAC1B,IAAIuR,EAAS,EACTyyB,EAAqB,EAKzB,MAAMC,EAAwB//B,KAAK4wB,UAC/B,EACAriB,KAAKyxB,MAAM96B,EAAKpJ,OAAS,IACvBmkC,EAAgB,IAAIp5B,MAAMk5B,GAC1B1M,EAAyB,GAC/B,IAAItmB,EAAO/M,KAAK67B,gBAAkB,OAAI9/B,EAClCk/B,EAASj7B,KAAK67B,gBAAkB,OAAI9/B,EACxC,MAAMmkC,EJshBJ,SAA2BxP,GAG/B,MAAMyP,EAAoB,CAAC,EACrBC,GAAYzsB,EAAAA,GAAAA,GAAK+c,GAavB,OAXA/sB,EAAAA,GAAAA,GAAQy8B,GAAYC,IAClB,MAAMC,EAAiB5P,EAAY2P,GAGnC,KAAIv5B,EAAAA,GAAAA,GAAQw5B,GAGV,MAAM7/B,MAAM,wBAFZ0/B,EAAaE,GAAW,E,IAMrBF,CACT,CIxiBwBI,CAAiBvgC,KAAK0wB,aACpCyG,EAAan3B,KAAK67B,gBAClB2E,EAAwBxgC,KAAK07B,OAAOL,uBAE1C,IAAIoF,EAAyB,EACzB9P,EAAuC,GACvC+P,EAEA,GAEJ,MAAMC,EAAsB,GAEtBC,EAA+B,GAErC,IAAIC,EAEJ,SAASC,IACP,OAAOnQ,CACT,CAEA,SAASoQ,EAA6BvI,GACpC,MAAMvK,EAAmBL,GAAyB4K,GAC5CwI,EACJN,EAAiCzS,GACnC,YAAyBlyB,IAArBilC,EACKJ,EAEAI,CAEX,CAhBAtiC,OAAO6M,OAAOq1B,GAkBd,MAAMK,EAAYC,IAEhB,GACuB,IAArBP,EAAU7kC,aAGuBC,IAAjCmlC,EAASt9B,UAAUguB,UACnB,CAGA,MAAMxF,EACJpsB,KAAK07B,OAAOJ,qBAAqBT,iCAC/BqG,GAGJ7N,EAAO1sB,KAAK,CACV0G,OAAQ6zB,EAASlG,YACjBjuB,KAAMm0B,EAASl0B,UACfiuB,OAAQiG,EAASp0B,YACjBhR,OAAQolC,EAASpG,MAAMh/B,OACvB4J,QAAS0mB,G,KAEN,CACLuU,EAAUt0B,MACV,MAAM80B,GAAUC,EAAAA,GAAAA,GAAKT,GACrBhQ,EAAqB3wB,KAAK2wB,mBAAmBwQ,GAC7CT,EACE1gC,KAAK0yB,6BAA6ByO,GACpCV,EAAyB9P,EAAmB70B,OAC5C,MAAMulC,EACJrhC,KAAK+7B,mBAAmBoF,KAAqC,IAAzBnhC,KAAK07B,OAAOnM,SAGhDsR,EADEH,GAAoCW,EAChBN,EAEAD,C,GAK5B,SAASQ,EAAuBH,GAC9BR,EAAUh6B,KAAKw6B,GACfT,EACE1gC,KAAK0yB,6BAA6ByO,GAEpCxQ,EAAqB3wB,KAAK2wB,mBAAmBwQ,GAC7CV,EAAyB9P,EAAmB70B,OAE5C2kC,EAAyB9P,EAAmB70B,OAC5C,MAAMulC,EACJrhC,KAAK+7B,mBAAmBoF,KAAqC,IAAzBnhC,KAAK07B,OAAOnM,SAGhDsR,EADEH,GAAoCW,EAChBN,EAEAD,CAE1B,CAMA,IAAIS,EAFJD,EAAUj2B,KAAKrL,KAAMk/B,GAIrB,MAAMzD,EAAkBz7B,KAAK07B,OAAOD,gBAEpC,KAAOpuB,EAASwyB,GAAW,CACzBN,EAAe,KAEf,MAAMiC,EAAe9c,EAAQhQ,WAAWrH,GAClCo0B,EAA2BZ,EAAoBW,GAC/CE,EAAuBD,EAAyB3lC,OAEtD,IAAK0O,EAAI,EAAGA,EAAIk3B,EAAsBl3B,IAAK,CACzC+2B,EAAaE,EAAyBj3B,GACtC,MAAMqmB,EAAc0Q,EAAWxrB,QAC/BypB,EAAU,KAGV,MAAMmC,EAAiBJ,EAAW/O,MA0BlC,IAzBuB,IAAnBmP,EACEH,IAAiBG,IAEnBpC,EAAe1O,IAEgB,IAAxB0Q,EAAWhP,UACpB1vB,EAASguB,EAA4B/tB,KACnC4hB,EACArX,EACA4yB,EACAC,GAEY,OAAVr9B,GACF08B,EAAe18B,EAAM,QACiC9G,IAAjD8G,EAAqC28B,UACxCA,EAAW38B,EAAqC28B,UAGlDD,EAAe,OAGjBv/B,KAAK89B,gBAAgBjN,EAAuBxjB,GAC5CkyB,EAAev/B,KAAK6C,MAAMguB,EAAuB3rB,EAAMmI,IAGpC,OAAjBkyB,EAAuB,CAIzB,GADAlN,EAAYkP,EAAWlP,eACLt2B,IAAds2B,EAAyB,CAG3B,MAAMuP,EAAkBvP,EAAUv2B,OAClC,IAAKujC,EAAI,EAAGA,EAAIuC,EAAiBvC,IAAK,CACpC,MAAMwC,EAAkBlR,EAAmB0B,EAAUgN,IAC/CyC,EAAmBD,EAAgB9rB,QA+BzC,GA9BA0pB,EAAa,MAIoB,IAA7BoC,EAAgBtP,UAClB1vB,EAASi/B,EAAiCh/B,KACxC4hB,EACArX,EACA4yB,EACAC,GAEY,OAAVr9B,GACFy8B,EAAgBz8B,EAAM,QAE8B9G,IAAjD8G,EAAqC28B,UAEtCC,EAAc58B,EAAqC28B,UAGrDF,EAAgB,OAGlBt/B,KAAK89B,gBAAgBgE,EAA4Bz0B,GACjDiyB,EAAgBt/B,KAAK6C,MACnBi/B,EACA58B,EACAmI,IAIAiyB,GAAiBA,EAAcxjC,OAASyjC,EAAazjC,OAAQ,CAC/DyjC,EAAeD,EACfE,EAAUC,EACV8B,EAAaM,EAGb,K,GAIN,K,EAKJ,GAAqB,OAAjBtC,EAAuB,CAoCzB,GAnCAG,EAAcH,EAAazjC,OAC3Bmc,EAAQspB,EAAWtpB,WACLlc,IAAVkc,IACF4L,EAAU0d,EAAWnQ,aAGrBuO,EAAW3/B,KAAKo+B,oBACdmB,EACAlyB,EACAwW,EACA0d,EAAW39B,UACXmJ,EACAkuB,EACAyE,GAGF1/B,KAAK0+B,cAAciB,EAAUH,IAGf,IAAVvnB,EACF6nB,EAAqB9/B,KAAKw+B,SACxByB,EACAH,EACAH,GAGFO,EAAOjoB,GAAOtR,KAAKg5B,IAGvBz6B,EAAOlF,KAAK29B,UAAUz4B,EAAMw6B,GAC5BryB,GAAkBqyB,EAGlBzE,EAASj7B,KAAKk+B,iBAAiBjD,EAASyE,IAErB,IAAfvI,IAAwD,IAAjCoK,EAAWjP,kBAA4B,CAChE,IACIyP,EACAC,EAFAC,EAAkB,EAGtBzB,EAAsBrjB,UAAY,EAClC,GACE4kB,EAAkBvB,EAAsBvnB,KAAKsmB,IACrB,IAApBwC,IACFC,EAAkBxB,EAAsBrjB,UAAY,EACpD8kB,YAEyB,IAApBF,GAEe,IAApBE,IACFl1B,GAAek1B,EACfhH,EAASyE,EAAcsC,EACvBhiC,KAAKm+B,iCACHwB,EACA1nB,EACA+pB,EACAC,EACAl1B,EACAkuB,EACAyE,G,CAKN1/B,KAAKi+B,YAAYsD,EAAYN,EAAUK,EAAW3B,E,KAC7C,CAEL,MAAMuC,EAAmB70B,EACnB80B,EAAYp1B,EACZq1B,EAAcnH,EACpB,IAAIoH,GAAuC,IAApB5G,EAEvB,MAA4B,IAArB4G,GAA8Bh1B,EAASwyB,GAI5C,IAFA36B,EAAOlF,KAAK29B,UAAUz4B,EAAM,GAC5BmI,IACK+xB,EAAI,EAAGA,EAAIqB,EAAwBrB,IAAK,CAC3C,MAAMmC,EAAa5Q,EAAmByO,GAChCvO,EAAc0Q,EAAWxrB,QAGzB4rB,EAAiBJ,EAAW/O,MAmBlC,IAlBuB,IAAnBmP,EACEjd,EAAQhQ,WAAWrH,KAAYs0B,IAEjCU,GAAmB,IAEY,IAAxBd,EAAWhP,SACpB8P,EAMQ,OALLxR,EAA4B/tB,KAC3B4hB,EACArX,EACA4yB,EACAC,IAGJlgC,KAAK89B,gBAAgBjN,EAAuBxjB,GAC5Cg1B,EAA0D,OAAtCxR,EAAuB/tB,KAAKoC,KAGzB,IAArBm9B,EACF,K,CAuBN,GAlBAzC,EAAYvyB,EAAS60B,EACrBjH,EAASj7B,KAAKk+B,iBAAiBjD,EAAS2E,GAExCxT,EAAMpsB,KAAK07B,OAAOJ,qBAAqBP,iCACrCrW,EACAwd,EACAtC,EACAuC,EACAC,GAEF/O,EAAO1sB,KAAK,CACV0G,OAAQ60B,EACRn1B,KAAMo1B,EACNlH,OAAQmH,EACRtmC,OAAQ8jC,EACRl6B,QAAS0mB,KAGa,IAApBqP,EACF,K,EAYN,OALKz7B,KAAK4wB,YAERqP,EAAcnkC,OAASgkC,GAGlB,CACLwC,OAAQrC,EACRC,OAAQA,EACR7M,OAAQA,EAEZ,CAEQ4K,WAAAA,CACNvC,EACAuF,EACAK,EACA3B,GAEA,IAAmB,IAAfjE,EAAOrvB,IAAc,CAGvB,MAAMk2B,EAAW7G,EAAO/0B,KACxBs6B,EAAStB,QACQ5jC,IAAbwmC,GACFjB,EAAUj2B,KAAKrL,KAAMuiC,E,WAEExmC,IAAhB2/B,EAAO/0B,MAChB26B,EAAUj2B,KAAKrL,KAAM07B,EAAO/0B,KAEhC,CAEQg3B,SAAAA,CAAUz4B,EAAcpJ,GAC9B,OAAOoJ,EAAK0R,UAAU9a,EACxB,CAEQgiC,eAAAA,CAAgBlR,EAAgB4V,GACtC5V,EAAOzP,UAAYqlB,CACrB,CAGQrE,gCAAAA,CACNwB,EACA1nB,EACAwqB,EACAR,EACAl1B,EACAkuB,EACAyE,GAEA,IAAIgD,EAAcC,OACJ5mC,IAAVkc,IAEFyqB,EAAeD,IAAc/C,EAAc,EAC3CiD,EAAmBD,GAAgB,EAAI,EACb,IAApBT,IAA0C,IAAjBS,IAE7B/C,EAASxyB,QAAUJ,EAAO41B,EAG1BhD,EAASzyB,UAAY+tB,EAAS,EAAK0H,GAIzC,CAEQzE,gBAAAA,CAAiB0E,EAAmBlD,GAC1C,OAAOkD,EAAYlD,CACrB,CAMQnB,qBAAAA,CACNzD,EACAE,EACA5J,EACAxtB,GAEA,MAAO,CACLk3B,QACAE,cACA5J,eACAxtB,YAEJ,CAEQ06B,oBAAAA,CACNxD,EACAE,EACA5J,EACAxtB,EACAoJ,EACAF,GAEA,MAAO,CACLguB,QACAE,cACAhuB,YACAF,cACAskB,eACAxtB,YAEJ,CAEQy6B,eAAAA,CACNvD,EACAE,EACA5J,EACAxtB,EACAoJ,EACAF,EACA4yB,GAEA,MAAO,CACL5E,QACAE,cACA6H,UAAW7H,EAAc0E,EAAc,EACvC1yB,YACAG,QAASH,EACTF,cACAI,UAAWJ,EAAc4yB,EAAc,EACvCtO,eACAxtB,YAEJ,CAUQ66B,iBAAAA,CACNqE,EACA/5B,EACAg6B,GAGA,OADAD,EAAYn8B,KAAKo8B,GACVh6B,CACT,CAEQ61B,yBAAAA,CACNkE,EACA/5B,EACAg6B,GAIA,OAFAD,EAAY/5B,GAASg6B,IACrBh6B,CAEF,CAKQ81B,qBAAAA,CAAsBlyB,EAAe6yB,GAAqB,CAE1Db,uBAAAA,CAAwBhyB,EAAe6yB,GAC7B,OAAZA,IACF7yB,EAAM6yB,QAAUA,EAEpB,CASQ3B,aAAAA,CACN9nB,EACA7Q,EACAmI,GAGA,OAAc,IADA0I,EAAQkD,KAAK/T,GAElBA,EAAK0R,UAAUvJ,EAAQ0I,EAAQoH,WAEjC,IACT,CAEQ6gB,aAAAA,CAAcjoB,EAAiB7Q,GACrC,MAAM2xB,EAAc9gB,EAAQjT,KAAKoC,GACjC,OAAuB,OAAhB2xB,EAAuBA,EAAY,GAAK,IACjD,EC76BI,SAAUjT,GAAWC,GACzB,OAAImf,GAAcnf,GACTA,EAAQE,MAERF,EAAQ3mB,IAEnB,CAMM,SAAU8lC,GACdn9B,GAEA,OAAOie,EAAAA,GAAAA,GAASje,EAAIke,QAAwB,KAAdle,EAAIke,KACpC,CDqEgBgM,GAAAyB,QACZ,6LAGYzB,GAAAC,GAAK,iBCvErB,MAAMiT,GAAS,SACTrJ,GAAa,aACb7V,GAAQ,QACRwN,GAAQ,QACRK,GAAY,YACZsR,GAAW,WACXvR,GAAa,aACbI,GAAc,cACde,GAAmB,mBAEnB,SAAUqQ,GAAYzH,GAC1B,OAGF,SAA6BA,GAC3B,MAAM3lB,EAAU2lB,EAAO3lB,QAEjBnS,EAA4B,CAAC,EACnCA,EAAU1G,KAAOw+B,EAAOx+B,MAEnBu0B,EAAAA,GAAAA,GAAY1b,KACfnS,EAAUE,QAAUiS,GAGtB,IAAIlS,EAAAA,GAAAA,GAAI63B,EAAQuH,IACd,KACE,6IAKAp/B,EAAAA,GAAAA,GAAI63B,EAAQ9B,MAEdh2B,EAAUg2B,WAAkB8B,EAAO9B,KAGrCL,GAAkB,CAAC31B,KAEfC,EAAAA,GAAAA,GAAI63B,EAAQ3X,MACdngB,EAAUmgB,MAAQ2X,EAAO3X,MAGvBlgB,EAAAA,GAAAA,GAAI63B,EAAQnK,MACd3tB,EAAU2tB,MAAQmK,EAAOnK,MAGvB1tB,EAAAA,GAAAA,GAAI63B,EAAQwH,MACdt/B,EAAUs/B,SAAWxH,EAAOwH,MAG1Br/B,EAAAA,GAAAA,GAAI63B,EAAQ9J,MACdhuB,EAAUguB,UAAY8J,EAAO9J,MAG3B/tB,EAAAA,GAAAA,GAAI63B,EAAQ/J,MACd/tB,EAAU+tB,WAAa+J,EAAO/J,MAG5B9tB,EAAAA,GAAAA,GAAI63B,EAAQ3J,MACdnuB,EAAUmuB,YAAc2J,EAAO3J,MAG7BluB,EAAAA,GAAAA,GAAI63B,EAAQ5I,MACdlvB,EAAUkvB,iBAAmB4I,EAAO5I,KAGtC,OAAOlvB,CACT,CAxDSw/B,CAAoB1H,EAC7B,CAyDO,MAAM2H,GAAMF,GAAY,CAAEjmC,KAAM,MAAO6Y,QAASga,GAAMC,KAGvD,SAAUoO,GACdva,EACAiX,EACAE,EACA6H,EACA71B,EACAG,EACAL,EACAI,GAEA,MAAO,CACL4tB,QACAE,cACA6H,YACA71B,YACAG,UACAL,cACAI,YACAkkB,aAAoBvN,EAASuN,aAC7BxtB,UAAWigB,EAEf,CAEM,SAAUyf,GAAa32B,EAAekX,GAC1C,OAAOiV,GAAuBnsB,EAAOkX,EACvC,CA3BA0V,GAAkB,CAAC8J,KC1EZ,MAAME,GAA0D,CACrEC,yBAAAA,CAAyB9iB,GAAyC,IAAxC,SAAE+iB,EAAQ,OAAEC,EAAM,SAAE90B,EAAQ,SAAE+0B,GAAUjjB,EAChE,MACMkjB,EADWZ,GAAcS,GACH,UAAApjC,OACjBujB,GAAW6f,GAAS,gCAAApjC,OACNojC,EAASvmC,KAAI,QAItC,MAFY,aAAHmD,OAAgBujC,EAAW,uBAAAvjC,OAAmBqjC,EAAO5I,MAAK,QAGrE,EAEA+I,6BAAAA,CAA6BljB,GAA6B,IAA5B,eAAEmjB,EAAc,SAAEH,GAAUhjB,EACxD,MAAO,6CAA+CmjB,EAAehJ,KACvE,EAEAiJ,uBAAAA,CAAuBC,GAMtB,IANuB,oBACtBC,EAAmB,OACnBP,EAAM,SACN90B,EAAQ,sBACRs1B,EAAqB,SACrBP,GACDK,EACC,MAAMG,EAAY,cAGZC,EAAY,iBADC77B,GAAMm7B,GAAS5I,MACgB,IAElD,GAAIoJ,EACF,OAAOC,EAAYD,EAAwBE,EACtC,CACL,MAAMC,GAAoB96B,EAAAA,GAAAA,GACxB06B,GACA,CAAC7+B,EAAQk/B,IAAiBl/B,EAAO/E,OAAOikC,IACxC,IAEIC,GAA0B/+B,EAAAA,GAAAA,GAC9B6+B,GACCG,GAAQ,IAAAnkC,QACHmF,EAAAA,GAAAA,GAAIg/B,GAAWC,GAAkB7gB,GAAW6gB,KAAgB9+B,KAC9D,MACD,OAEC++B,GAAyBl/B,EAAAA,GAAAA,GAC7B++B,GACA,CAACI,EAASjvB,IAAQ,KAALrV,OAAUqV,EAAM,EAAC,MAAArV,OAAKskC,KAMrC,OAAOR,EAJuB,2CAAH9jC,OAA8CqkC,EAAuB/+B,KAC9F,OAGyCy+B,C,CAE/C,EAEAQ,qBAAAA,CAAqBC,GAKpB,IALqB,uBACpBC,EAAsB,OACtBpB,EAAM,sBACNQ,EAAqB,SACrBP,GACDkB,EACC,MAAMV,EAAY,cAGZC,EAAY,iBADC77B,GAAMm7B,GAAS5I,MACgB,IAElD,GAAIoJ,EACF,OAAOC,EAAYD,EAAwBE,EACtC,CACL,MAAMG,GAA0B/+B,EAAAA,GAAAA,GAC9Bs/B,GACCN,GAAQ,IAAAnkC,QACHmF,EAAAA,GAAAA,GAAIg/B,GAAWC,GAAkB7gB,GAAW6gB,KAAgB9+B,KAC9D,KACD,OAML,OAAOw+B,GAHL,qGAAA9jC,OACIkkC,EAAwB5+B,KAAK,MAAK,MAEGy+B,C,CAE/C,GAGF1lC,OAAO6M,OAAOg4B,IAEP,MAAMwB,GACX,CACEC,uBAAsBA,CACpBC,EACAC,IAGE,gEACAA,EAAc1f,gBADd,gCAIAyf,EAAa/nC,KACb,MAKKioC,GACX,CACEC,wBAAAA,CACEH,EACAI,GAcA,MAAMC,EAAeL,EAAa/nC,KAC5BqoC,EAAgBh9B,GAAM88B,GACtBt8B,EAAQw8B,EAAc7vB,IACtB8vB,EAAUne,GAAqBke,GAC/BE,GAfJthB,EAe+CohB,aAb3BngB,GACXjB,EAAKuB,aAAaxoB,KAChBinB,aAAgBC,GAClBD,EAAKqB,gBAEL,GARX,IACErB,EAiBF,MAAMuhB,EAAmB38B,EAAQ,EACjC,IAAIqjB,EAAM,KAAH/rB,OAAQmlC,GAAOnlC,OAAGqlC,EAAmB38B,EAAQ,GAAE,OAAA1I,OACpDolC,EAAgB,oBAAHplC,OAAuBolC,EAAa,MAAO,GAC1D,gDAAAplC,OAEcglC,EAAevpC,OACjB,qCAAAuE,OAAoCilC,EAAY,iJAQ5D,OAHAlZ,EAAMA,EAAIjvB,QAAQ,UAAW,KAC7BivB,EAAMA,EAAIjvB,QAAQ,SAAU,MAErBivB,CACT,EAEAuZ,4BAA4B5oC,GAExB,oHAAAsD,OAC2EtD,EAAKG,KAAI,QADpF,2OASJ0oC,oCAAAA,CAAqCniC,GAMnC,MAAMoiC,GAAUrgC,EAAAA,GAAAA,GAAI/B,EAAQqiC,YAAaC,GACvCniB,GAAWmiB,KACXpgC,KAAK,MACDqgC,EACwB,IAA5BviC,EAAQwiC,YAAYvwB,IAAY,GAAKjS,EAAQwiC,YAAYvwB,IAU3D,MARE,4BAAArV,OAA4BoD,EAAQyiC,iBAAiBvgC,KACnD,MACD,+CAAAtF,OACQ2lC,EAAU,cAAA3lC,OAAaoD,EAAQwhC,aAAa/nC,KAAI,aAAW,IAAAmD,OAChEwlC,EAAO,+DAJX,yGASJ,EAEAM,8BAAAA,CAA+B1iC,GAM7B,MAAMoiC,GAAUrgC,EAAAA,GAAAA,GAAI/B,EAAQqiC,YAAaM,GACvCxiB,GAAWwiB,KACXzgC,KAAK,MACDqgC,EACwB,IAA5BviC,EAAQwiC,YAAYvwB,IAAY,GAAKjS,EAAQwiC,YAAYvwB,IAC3D,IAAI2wB,EACF,qCAAAhmC,OAAqCoD,EAAQyiC,iBAAiBvgC,KAC5D,MACD,YAAAtF,OAAW2lC,EAAU,iBAAA3lC,OACVoD,EAAQwhC,aAAa/nC,KAAI,aAAW,IAAAmD,OAC5CwlC,EAAO,+DAMb,OAJAQ,GACEA,mHAGKA,CACT,EAEAC,yBAAAA,CAA0B7iC,GAIxB,IAAI+hC,EAAUne,GAAqB5jB,EAAQ8iC,YACZ,IAA3B9iC,EAAQ8iC,WAAW7wB,MACrB8vB,GAAW/hC,EAAQ8iC,WAAW7wB,KAOhC,MAHE,mBAAArV,OAAmBmlC,EAAO,mBAAAnlC,OAAkBoD,EAAQwhC,aAAa/nC,KAAI,2EAIzE,EAIAspC,oBAAoB/iC,GAKX,aAGTgjC,2BAA2BhjC,GAMvB,iCAAApD,OAAiCoD,EAAQijC,eAAiB,EAAC,eAAArmC,OACjDoD,EAAQwiC,YAAYvwB,IAAG,cAAArV,OAAaoD,EAAQwhC,aAAa/nC,KAAI,aAAW,yDAMtFypC,8BAA8BljC,GAK1B,iEAAApD,OACMoD,EAAQwiC,YAAYvwB,IAAG,cAAArV,OAC3BoD,EAAQwhC,aAAa/nC,KACvB,kBAAAmD,OACEoD,EAAQwiC,YAAYtmB,WAAW7jB,OAAS,EAC1C,kBAKJ8qC,uBAAAA,CAAwBnjC,GAItB,MAAMkgC,EAAWlgC,EAAQwhC,aAAa/nC,KAChC2pC,GAAYrhC,EAAAA,GAAAA,GAChB/B,EAAQqjC,mBACPC,GAAaA,EAAS7pC,OAEnB8pC,EAAoB,GAAH3mC,OAAMsjC,EAAQ,YAAAtjC,OAAQwmC,EAC1CxmC,OAAO,CAACsjC,IACRh+B,KAAK,aAQR,MANE,+CAAAtF,OACUsjC,EAAQ,2DAAyD,0EAAAtjC,OACD2mC,EAAiB,MAF3F,gIAOJ,EAIAC,0BAA0BxjC,GAKjB,aAGTyjC,2BAAAA,CAA4BzjC,GAI1B,IAAIkgC,EAEFA,EADElgC,EAAQwhC,wBAAwBxgB,GACvBhhB,EAAQwhC,aAAa/nC,KAErBuG,EAAQwhC,aAKrB,MAFe,iCAAH5kC,OAAoCsjC,EAAQ,4CAAAtjC,OAA2CoD,EAAQ0jC,YAAW,KAGxH,GC/SE,MAAOC,WAA+BvhB,GAI1C1qB,WAAAA,CACUksC,EACAC,GAERlsC,QAHQ,KAAAisC,cAAAA,EACA,KAAAC,eAAAA,EALH,KAAAjU,OAAgD,EAQvD,CAEOkU,WAAAA,IACL5jC,EAAAA,GAAAA,IAAQmjB,EAAAA,GAAAA,GAAO9mB,KAAKqnC,gBAAiBljB,IACnCnkB,KAAKwnC,aAAerjB,EACpBA,EAAKD,OAAOlkB,KAAK,GAErB,CAEO+lB,gBAAAA,CAAiB3f,GACtB,MAAM8X,EAAMle,KAAKqnC,cAAcjhC,EAAKof,iBAEpC,GAAKtH,EAYH9X,EAAKoe,eAAiBtG,MAZd,CACR,MAAMkO,EAAMpsB,KAAKsnC,eAAetC,uBAC9BhlC,KAAKwnC,aACLphC,GAEFpG,KAAKqzB,OAAO1sB,KAAK,CACfjB,QAAS0mB,EACTzrB,KAAM8mC,GAA0BC,uBAChC/D,SAAU3jC,KAAKwnC,aAAatqC,KAC5ByqC,kBAAmBvhC,EAAKof,iB,CAK9B,EC3BF,SAJA,SAAiB7Z,EAAYwf,GAC3B,OAAOc,EAAAA,GAAAA,IAAYzmB,EAAAA,GAAAA,GAAImG,EAAYwf,GAAW,EAChD,E,eCLA,SAXA,SAAyBrf,EAAO87B,EAAQzc,EAAU0c,GAIhD,IAHA,IAAI9+B,GAAS,EACTjN,EAAkB,MAATgQ,EAAgB,EAAIA,EAAMhQ,SAE9BiN,EAAQjN,GAAQ,CACvB,IAAI+C,EAAQiN,EAAM/C,GAClB6+B,EAAOC,EAAahpC,EAAOssB,EAAStsB,GAAQiN,EAC9C,CACA,OAAO+7B,CACT,ECCA,SAPA,SAAwBl8B,EAAYi8B,EAAQzc,EAAU0c,GAIpD,OAHArhB,EAAAA,GAAAA,GAAS7a,GAAY,SAAS9M,EAAOoM,EAAKU,GACxCi8B,EAAOC,EAAahpC,EAAOssB,EAAStsB,GAAQ8M,EAC9C,IACOk8B,CACT,ECIA,SATA,SAA0BD,EAAQziC,GAChC,OAAO,SAASwG,EAAYwf,GAC1B,IAAI1E,GAAO3f,EAAAA,GAAAA,GAAQ6E,GAAcm8B,GAAkBC,GAC/CF,EAAc1iC,EAAcA,IAAgB,CAAC,EAEjD,OAAOshB,EAAK9a,EAAYi8B,GAAQ1kB,EAAAA,GAAAA,GAAaiI,EAAU,GAAI0c,EAC7D,CACF,EChBA,IAGIttB,GAHc7b,OAAO0M,UAGQmP,eAiCjC,SARcytB,IAAiB,SAAS5iC,EAAQvG,EAAOoM,GACjDsP,GAAelP,KAAKjG,EAAQ6F,GAC9B7F,EAAO6F,GAAKtE,KAAK9H,IAEjBopC,EAAAA,GAAAA,GAAgB7iC,EAAQ6F,EAAK,CAACpM,GAElC,ICAA,SAVA,SAAmBiN,EAAOsW,EAAGC,GAC3B,IAAIvmB,EAAkB,MAATgQ,EAAgB,EAAIA,EAAMhQ,OACvC,OAAKA,GAGLsmB,EAAKC,QAAetmB,IAANqmB,EAAmB,GAAIE,EAAAA,GAAAA,GAAUF,GAExCG,GAAUzW,EAAO,GADxBsW,EAAItmB,EAASsmB,GACkB,EAAI,EAAIA,IAJ9B,EAKX,ECHM,MAAgB8lB,WAAyC5gB,GAU7DnsB,WAAAA,CACYmvB,EACAlH,GAEVhoB,QAHU,KAAAkvB,QAAAA,EACA,KAAAlH,KAAAA,EAXF,KAAA+kB,iBAAgC,GAIhC,KAAAC,mBAAqB,GACrB,KAAAC,yBAA2B,EAC3B,KAAA1Z,OAAQ,EACR,KAAA2Z,eAAgB,CAO1B,CAEA9d,YAAAA,GAGE,GAFAxqB,KAAK2uB,OAAQ,EAET3uB,KAAKojB,KAAKmlB,UAAU,KAAOvoC,KAAKsqB,QAAQptB,KAC1C,MAAMuD,MAAM,uDAcd,OAVAT,KAAKuoC,WAAY9O,EAAAA,GAAAA,GAAMz5B,KAAKojB,KAAKmlB,WAAWC,UAC5CxoC,KAAKyoC,iBAAkBhP,EAAAA,GAAAA,GAAMz5B,KAAKojB,KAAKqlB,iBAAiBD,UAGxDxoC,KAAKuoC,UAAUl8B,MACfrM,KAAKyoC,gBAAgBp8B,MAErBrM,KAAK0oC,qBACL1oC,KAAKunB,KAAKvnB,KAAKsqB,SAERtqB,KAAKmoC,gBACd,CAEA5gB,IAAAA,CACEpD,GAC4B,IAA5BqD,EAAA3rB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAA0B,GAGrBmE,KAAK2uB,OACRvzB,MAAMmsB,KAAKpD,EAAMqD,EAErB,CAEAG,WAAAA,CACES,EACAX,EACAD,GAGA,GACEY,EAAQ5D,eAAetnB,OAAS8C,KAAKooC,oBACrChgB,EAAQ1S,MAAQ1V,KAAKqoC,yBACrB,CACA,MAAMzd,EAAWnD,EAASpnB,OAAOmnB,GACjCxnB,KAAK0oC,qBACL1oC,KAAKunB,KAAKa,EAAQ5D,eAAqBoG,E,CAE3C,CAEA8d,kBAAAA,IAEMhhC,EAAAA,GAAAA,GAAQ1H,KAAKuoC,YAGfvoC,KAAKooC,mBAAqB,GAC1BpoC,KAAKqoC,yBAA2B,EAChCroC,KAAKsoC,eAAgB,IAErBtoC,KAAKooC,mBAAqBpoC,KAAKuoC,UAAUl8B,MACzCrM,KAAKqoC,yBAA2BroC,KAAKyoC,gBAAgBp8B,MAEzD,EAGI,MAAOs8B,WAA6BT,GAIxC/sC,WAAAA,CACEmvB,EACUlH,GAEVhoB,MAAMkvB,EAASlH,GAFL,KAAAA,KAAAA,EALJ,KAAAwlB,iBAAmB,GACnB,KAAAC,uBAAyB,EAO/B7oC,KAAK4oC,iBAAmB5oC,KAAKojB,KAAK0lB,QAAQ5rC,KAC1C8C,KAAK6oC,uBAAyB7oC,KAAKojB,KAAK2lB,iBAC1C,CAEAnhB,YAAAA,CACEpG,EACAiG,EACAD,GAEA,GACExnB,KAAKsoC,eACL9mB,EAASkE,aAAaxoB,OAAS8C,KAAK4oC,kBACpCpnB,EAAS9L,MAAQ1V,KAAK6oC,yBACrB7oC,KAAK2uB,MACN,CACA,MAAM/D,EAAWnD,EAASpnB,OAAOmnB,GAC3BwhB,EAAW,IAAIrkB,GAAY,CAAEhF,WAAYiL,IAC/C5qB,KAAKmoC,iBAAmB5/B,GAAMygC,GAC9BhpC,KAAK2uB,OAAQ,C,CAEjB,EAeI,MAAOsa,WAAkD3hB,GAO7DnsB,WAAAA,CACY+tC,EACAlD,GAEV5qC,QAHU,KAAA8tC,QAAAA,EACA,KAAAlD,WAAAA,EARF,KAAA5gC,OAAgC,CACxCuH,WAAO5Q,EACPiqC,gBAAYjqC,EACZotC,iBAAaptC,EAQf,CAEAyuB,YAAAA,GAEE,OADAxqB,KAAKunB,KAAKvnB,KAAKkpC,SACRlpC,KAAKoF,MACd,EAGI,MAAOgkC,WAAoCH,GAC/C/gB,QAAAA,CACEW,EACApB,EACAD,GAEA,GAAIqB,EAASnT,MAAQ1V,KAAKgmC,WAAY,CACpC,MAAMqD,EAAiBC,GAAO7hB,EAASpnB,OAAOmnB,IAC9CxnB,KAAKoF,OAAO+jC,iBAAiCptC,IAAnBstC,EACtBA,aAA0BjkB,KAC5BplB,KAAKoF,OAAOuH,MAAQ08B,EAAe3jB,aACnC1lB,KAAKoF,OAAO4gC,WAAaqD,EAAe3zB,I,MAG1Cta,MAAM8sB,SAASW,EAAUpB,EAAUD,EAEvC,EAGI,MAAO+hB,WAAuCN,GAClDhhB,WAAAA,CACEc,EACAtB,EACAD,GAEA,GAAIuB,EAAYrT,MAAQ1V,KAAKgmC,WAAY,CACvC,MAAMwD,EAAoBF,GAAO7hB,EAASpnB,OAAOmnB,IACjDxnB,KAAKoF,OAAO+jC,iBAAoCptC,IAAtBytC,EACtBA,aAA6BpkB,KAC/BplB,KAAKoF,OAAOuH,MAAQ68B,EAAkB9jB,aACtC1lB,KAAKoF,OAAO4gC,WAAawD,EAAkB9zB,I,MAG7Cta,MAAM6sB,YAAYc,EAAatB,EAAUD,EAE7C,EAGI,MAAOiiB,WAA0CR,GACrDlhB,cAAAA,CACES,EACAf,EACAD,GAEA,GAAIgB,EAAe9S,MAAQ1V,KAAKgmC,WAAY,CAC1C,MAAM0D,EAAuBJ,GAAO7hB,EAASpnB,OAAOmnB,IACpDxnB,KAAKoF,OAAO+jC,iBAAuCptC,IAAzB2tC,EACtBA,aAAgCtkB,KAClCplB,KAAKoF,OAAOuH,MAAQ+8B,EAAqBhkB,aACzC1lB,KAAKoF,OAAO4gC,WAAa0D,EAAqBh0B,I,MAGhDta,MAAM2sB,eAAeS,EAAgBf,EAAUD,EAEnD,EAII,MAAOmiB,WAA6CV,GACxDjhB,iBAAAA,CACE4hB,EACAniB,EACAD,GAEA,GAAIoiB,EAAkBl0B,MAAQ1V,KAAKgmC,WAAY,CAC7C,MAAM6D,EAAoCP,GACxC7hB,EAASpnB,OAAOmnB,IAElBxnB,KAAKoF,OAAO+jC,iBAAoDptC,IAAtC8tC,EACtBA,aAA6CzkB,KAC/CplB,KAAKoF,OAAOuH,MAAQk9B,EAAkCnkB,aACtD1lB,KAAKoF,OAAO4gC,WAAa6D,EAAkCn0B,I,MAG7Dta,MAAM4sB,kBAAkB4hB,EAAmBniB,EAAUD,EAEzD,EAQI,SAAUsiB,GACdC,EACAC,GAC0B,IAA1BxF,EAAA3oC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAwB,GAGxB2oC,GAAW/K,EAAAA,GAAAA,GAAM+K,GACjB,IAAIp/B,EAAmC,GACnCoF,EAAI,EAQR,SAASy/B,EAAuBtqB,GAC9B,MAAMmB,EAAegpB,GACDnqB,EANLtf,OAAOqnB,GAAKqiB,EAAWv/B,EAAI,IAOxCw/B,EACAxF,GAEF,OAAOp/B,EAAO/E,OAAOygB,EACvB,CASA,KAAO0jB,EAAS1oC,OAASkuC,GAAax/B,EAAIu/B,EAAUjuC,QAAQ,CAC1D,MAAMqoB,EAAO4lB,EAAUv/B,GAGvB,GAAI2Z,aAAgBQ,GAClB,OAAOslB,EAAuB9lB,EAAKxE,YAC9B,GAAIwE,aAAgBC,GACzB,OAAO6lB,EAAuB9lB,EAAKxE,YAC9B,GAAIwE,aAAgBU,GACzBzf,EAAS6kC,EAAuB9lB,EAAKxE,gBAChC,IAAIwE,aAAgBW,GAAqB,CAM9C,OAAOmlB,EALQ9lB,EAAKxE,WAAWtf,OAAO,CACpC,IAAI2kB,GAAW,CACbrF,WAAYwE,EAAKxE,e,CAIhB,GAAIwE,aAAgBY,GAAkC,CAS3D,OAAOklB,EARQ,CACb,IAAItlB,GAAY,CAAEhF,WAAYwE,EAAKxE,aACnC,IAAIqF,GAAW,CACbrF,WAAY,CAAC,IAAIyF,GAAS,CAAEM,aAAcvB,EAAKzb,aAAcrI,OACtD8jB,EAAKxE,e,CAKX,GAAIwE,aAAgBc,GAAyB,CAClD,MAAMilB,EAAS/lB,EAAKxE,WAAWtf,OAAO,CACpC,IAAI2kB,GAAW,CACbrF,WAAY,CAAC,IAAIyF,GAAS,CAAEM,aAAcvB,EAAKzb,aAAcrI,OACtD8jB,EAAKxE,gBAIhBva,EAAS6kC,EAAuBC,E,MAC3B,GAAI/lB,aAAgBa,GAAY,CACrC,MAAMklB,EAAS/lB,EAAKxE,WAAWtf,OAAO,CACpC,IAAI2kB,GAAW,CACbrF,WAAYwE,EAAKxE,eAGrBva,EAAS6kC,EAAuBC,E,KAC3B,IAAI/lB,aAAgBe,GASzB,OARAvhB,EAAAA,GAAAA,GAAQwgB,EAAKxE,YAAawqB,KAIY,KAAhCziC,EAAAA,GAAAA,GAAQyiC,EAAQxqB,cAClBva,EAAS6kC,EAAuBE,EAAQxqB,Y,IAGrCva,EACF,KAAI+e,aAAgBiB,IAGzB,MAAM3kB,MAAM,wBAFZ+jC,EAAS79B,KAAKwd,EAAKuB,a,EAKrBlb,G,CAOF,OALApF,EAAOuB,KAAK,CACVyjC,YAAa5F,EACb6F,UAAW3iB,GAAKqiB,EAAWv/B,KAGtBpF,CACT,CASM,SAAUklC,GACdC,EACAzH,EACA0H,EACAC,GAEA,MAAMC,EAAyB,qBAEzBC,EAAwB,CAACD,GACzBE,EAAwB,mBAC9B,IAAIC,GAAoB,EAExB,MAAMC,EAAoBhI,EAAYhnC,OAChCivC,EAA2BD,EAAoBL,EAAe,EAE9DrlC,EAAwC,GAExC4lC,EAAkC,GAQxC,IAPAA,EAAcrkC,KAAK,CACjB+O,KAAM,EACNu1B,IAAKV,EACLhC,UAAW,GACXE,gBAAiB,OAGX/gC,EAAAA,GAAAA,GAAQsjC,IAAgB,CAC9B,MAAMxG,EAAWwG,EAAc3+B,MAG/B,GAAIm4B,IAAaoG,EAAkB,CAE/BC,IACAzJ,EAAAA,GAAAA,GAAK4J,GAAgBt1B,KAAOq1B,GAG5BC,EAAc3+B,MAEhB,Q,CAGF,MAAM6+B,EAAU1G,EAASyG,IACnBhO,EAAUuH,EAAS9uB,IACnBy1B,EAAgB3G,EAAS+D,UACzB6C,EAAsB5G,EAASiE,gBAGrC,IAAI/gC,EAAAA,GAAAA,GAAQwjC,GACV,SAGF,MAAM/mB,EAAO+mB,EAAQ,GAErB,GAAI/mB,IAASumB,EAAmB,CAC9B,MAAMW,EAAW,CACf31B,IAAKunB,EACLgO,IAAKvjB,GAAKwjB,GACV3C,UAAW+C,GAAUH,GACrB1C,gBAAiB6C,GAAUF,IAE7BJ,EAAcrkC,KAAK0kC,E,MACd,GAAIlnB,aAAgBiB,GAEzB,GAAI6X,EAAU6N,EAAoB,EAAG,CACnC,MAAMS,EAAUtO,EAAU,EAE1B,GAAIuN,EADgB1H,EAAYyI,GACHpnB,EAAKuB,cAAe,CAC/C,MAAM2lB,EAAW,CACf31B,IAAK61B,EACLN,IAAKvjB,GAAKwjB,GACV3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAK0kC,E,MAGhB,IAAIpO,IAAY6N,EAAoB,EAUzC,MAAMrqC,MAAM,wBARZ2E,EAAOuB,KAAK,CACV6kC,cAAernB,EAAKuB,aACpB+lB,oBAAqBtnB,EAAKzO,IAC1B6yB,UAAW4C,EACX1C,gBAAiB2C,IAEnBP,GAAoB,C,MAIjB,GAAI1mB,aAAgBC,GAAa,CACtC,MAAMsnB,GAAejS,EAAAA,GAAAA,GAAM0R,GAC3BO,EAAa/kC,KAAKwd,EAAKqB,iBAEvB,MAAMmmB,GAAqBlS,EAAAA,GAAAA,GAAM2R,GACjCO,EAAmBhlC,KAAKwd,EAAKzO,KAE7B,MAAM21B,EAAW,CACf31B,IAAKunB,EACLgO,IAAK9mB,EAAKxE,WAAWtf,OAAOsqC,EAAuBjjB,GAAKwjB,IACxD3C,UAAWmD,EACXjD,gBAAiBkD,GAEnBX,EAAcrkC,KAAK0kC,E,MACd,GAAIlnB,aAAgBU,GAAQ,CAEjC,MAAM+mB,EAAkB,CACtBl2B,IAAKunB,EACLgO,IAAKvjB,GAAKwjB,GACV3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAKilC,GAEnBZ,EAAcrkC,KAAKikC,GAEnB,MAAMiB,EAAe,CACnBn2B,IAAKunB,EACLgO,IAAK9mB,EAAKxE,WAAWtf,OAAOqnB,GAAKwjB,IACjC3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAKklC,E,MACd,GAAI1nB,aAAgBW,GAAqB,CAE9C,MAAMgnB,EAAkB,IAAI9mB,GAAW,CACrCrF,WAAYwE,EAAKxE,WACjBjK,IAAKyO,EAAKzO,MAGN21B,EAAW,CACf31B,IAAKunB,EACLgO,IAHc9mB,EAAKxE,WAAWtf,OAAO,CAACyrC,GAAkBpkB,GAAKwjB,IAI7D3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAK0kC,E,MACd,GAAIlnB,aAAgBY,GAAkC,CAE3D,MAAMgnB,EAAgB,IAAI3mB,GAAS,CACjCM,aAAcvB,EAAKzb,YAEfojC,EAAkB,IAAI9mB,GAAW,CACrCrF,WAAY,CAAMosB,GAAe1rC,OAAO8jB,EAAKxE,YAC7CjK,IAAKyO,EAAKzO,MAGN21B,EAAW,CACf31B,IAAKunB,EACLgO,IAHc9mB,EAAKxE,WAAWtf,OAAO,CAACyrC,GAAkBpkB,GAAKwjB,IAI7D3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAK0kC,E,MACd,GAAIlnB,aAAgBc,GAAyB,CAElD,MAAM2mB,EAAkB,CACtBl2B,IAAKunB,EACLgO,IAAKvjB,GAAKwjB,GACV3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAKilC,GAEnBZ,EAAcrkC,KAAKikC,GAEnB,MAAMmB,EAAgB,IAAI3mB,GAAS,CACjCM,aAAcvB,EAAKzb,YAEfsjC,EAAgB,IAAIhnB,GAAW,CACnCrF,WAAY,CAAMosB,GAAe1rC,OAAO8jB,EAAKxE,YAC7CjK,IAAKyO,EAAKzO,MAGNm2B,EAAe,CACnBn2B,IAAKunB,EACLgO,IAHc9mB,EAAKxE,WAAWtf,OAAO,CAAC2rC,GAAgBtkB,GAAKwjB,IAI3D3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAKklC,E,MACd,GAAI1nB,aAAgBa,GAAY,CAErC,MAAM4mB,EAAkB,CACtBl2B,IAAKunB,EACLgO,IAAKvjB,GAAKwjB,GACV3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAKilC,GAEnBZ,EAAcrkC,KAAKikC,GAGnB,MAAMoB,EAAgB,IAAIhnB,GAAW,CACnCrF,WAAYwE,EAAKxE,WACjBjK,IAAKyO,EAAKzO,MAGNm2B,EAAe,CACnBn2B,IAAKunB,EACLgO,IAHc9mB,EAAKxE,WAAWtf,OAAO,CAAC2rC,GAAgBtkB,GAAKwjB,IAI3D3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAKklC,E,MACd,GAAI1nB,aAAgBe,GAEzB,IAAK,IAAI1a,EAAI2Z,EAAKxE,WAAW7jB,OAAS,EAAG0O,GAAK,EAAGA,IAAK,CACpD,MACMyhC,EAAc,CAClBv2B,IAAKunB,EACLgO,IAHmB9mB,EAAKxE,WAAWnV,GAGtBmV,WAAWtf,OAAOqnB,GAAKwjB,IACpC3C,UAAW4C,EACX1C,gBAAiB2C,GAEnBJ,EAAcrkC,KAAKslC,GACnBjB,EAAcrkC,KAAKikC,E,MAEhB,GAAIzmB,aAAgBQ,GACzBqmB,EAAcrkC,KAAK,CACjB+O,IAAKunB,EACLgO,IAAK9mB,EAAKxE,WAAWtf,OAAOqnB,GAAKwjB,IACjC3C,UAAW4C,EACX1C,gBAAiB2C,QAEd,MAAIjnB,aAAgBM,IAMzB,MAAMhkB,MAAM,wBAJZuqC,EAAcrkC,KACZulC,GAAmB/nB,EAAM8Y,EAASkO,EAAeC,G,EAMvD,OAAOhmC,CACT,CAEA,SAAS8mC,GACPhD,EACAjM,EACAkO,EACAC,GAEA,MAAMM,GAAejS,EAAAA,GAAAA,GAAM0R,GAC3BO,EAAa/kC,KAAKuiC,EAAQhsC,MAE1B,MAAMivC,GAAyB1S,EAAAA,GAAAA,GAAM2R,GAIrC,OAFAe,EAAuBxlC,KAAK,GAErB,CACL+O,IAAKunB,EACLgO,IAAK/B,EAAQvpB,WACb4oB,UAAWmD,EACXjD,gBAAiB0D,EAErB,CCjlBO,IAAKC,GASN,SAAUC,GACdloB,GAGA,GAAIA,aAAgBU,IAAmB,WAATV,EAC5B,OAAOioB,GAAUE,OACZ,GAAInoB,aAAgBa,IAAuB,eAATb,EACvC,OAAOioB,GAAUG,WACZ,GACLpoB,aAAgBW,IACP,wBAATX,EAEA,OAAOioB,GAAUI,qBACZ,GACLroB,aAAgBY,IACP,qCAATZ,EAEA,OAAOioB,GAAUK,oCACZ,GACLtoB,aAAgBc,IACP,4BAATd,EAEA,OAAOioB,GAAUM,0BACZ,GAAIvoB,aAAgBe,IAAwB,gBAATf,EACxC,OAAOioB,GAAUO,YAEjB,MAAMlsC,MAAM,uBAEhB,CAEM,SAAUmsC,GAAkBnpC,GAMhC,MAAM,WAAEuiC,EAAU,KAAEjpC,EAAI,SAAE8vC,EAAQ,aAAEC,GAAiBrpC,EAC/C9C,EAAO0rC,GAAYQ,GACzB,OAAIlsC,IAASyrC,GAAUO,YACdI,GAAuB/G,EAAYjpC,EAAM+vC,GAEzCE,GACLhH,EACAjpC,EACA4D,EACAmsC,EAGN,CAwEM,SAAUG,GACdp2B,EACAsO,EACAme,EACA4J,GAEA,MAAMC,EAAYt2B,EAAK/a,OACjBsxC,EAA0BpkC,GAAM6N,GAAOszB,GACpCnhC,GAAMmhC,GAAU3F,GACM,IAApBA,EAAS1oC,WAKpB,GAAIqpB,EAIF,OAAO,SAELkoB,GAKA,MAAMC,GAAwC9nC,EAAAA,GAAAA,GAC5C6nC,GACClD,GAAYA,EAAQoD,OAGvB,IAAK,IAAIC,EAAI,EAAGA,EAAIL,EAAWK,IAAK,CAClC,MAAMrD,EAAUtzB,EAAK22B,GACfC,EAAiBtD,EAAQruC,OAEzB4xC,EAAgBJ,EAAWE,GACjC,QAAsBzxC,IAAlB2xC,IAA4D,IAA7BA,EAAcriC,KAAKrL,MAItDqrC,EAAU,IAAK,IAAIjM,EAAI,EAAGA,EAAIqO,EAAgBrO,IAAK,CACjD,MAAMoF,EAAW2F,EAAQ/K,GACnBuO,EAAiBnJ,EAAS1oC,OAChC,IAAK,IAAI0O,EAAI,EAAGA,EAAImjC,EAAgBnjC,IAAK,CACvC,MAAMojC,EAAY5tC,KAAK6tC,GAAGrjC,EAAI,GAC9B,IAA6C,IAAzC84B,EAAasK,EAAWpJ,EAASh6B,IAGnC,SAAS6gC,C,CAKb,OAAOmC,C,EAOb,EACK,GAAIJ,IAA4BF,EAAsB,CAG3D,MAAMY,GAAkBtoC,EAAAA,GAAAA,GAAIqR,GAAOszB,IAC1BjgB,EAAAA,GAAAA,GAAQigB,KAGX4D,GAAcxkC,EAAAA,GAAAA,GAClBukC,GACA,CAAC1oC,EAAQ+kC,EAASz0B,MAChB/R,EAAAA,GAAAA,GAAQwmC,GAAUxX,KACX9uB,EAAAA,GAAAA,GAAIuB,EAAQutB,EAAYvB,gBAC3BhsB,EAAOutB,EAAYvB,cAAiB1b,IAEtC/R,EAAAA,GAAAA,GAAQgvB,EAAYsH,iBAAmB+T,KAChCnqC,EAAAA,GAAAA,GAAIuB,EAAQ4oC,KACf5oC,EAAO4oC,GAAqBt4B,E,GAE9B,IAEGtQ,IAET,CAAC,GAMH,OAAO,WACL,MAAMwoC,EAAY5tC,KAAK6tC,GAAG,GAC1B,OAAOE,EAAYH,EAAUxc,aAC/B,C,CAOA,OAAO,WACL,IAAK,IAAIoc,EAAI,EAAGA,EAAIL,EAAWK,IAAK,CAClC,MAAMrD,EAAUtzB,EAAK22B,GACfC,EAAiBtD,EAAQruC,OAC/BuvC,EAAU,IAAK,IAAIjM,EAAI,EAAGA,EAAIqO,EAAgBrO,IAAK,CACjD,MAAMoF,EAAW2F,EAAQ/K,GACnBuO,EAAiBnJ,EAAS1oC,OAChC,IAAK,IAAI0O,EAAI,EAAGA,EAAImjC,EAAgBnjC,IAAK,CACvC,MAAMojC,EAAY5tC,KAAK6tC,GAAGrjC,EAAI,GAC9B,IAA6C,IAAzC84B,EAAasK,EAAWpJ,EAASh6B,IAGnC,SAAS6gC,C,CAKb,OAAOmC,C,EAOb,CAEJ,CAEM,SAAUS,GACd/kB,EACAoa,EACA4J,GAEA,MAAME,EAA0BpkC,GAAMkgB,GAAMsb,GACf,IAApBA,EAAS1oC,SAGZoyC,EAAahlB,EAAIptB,OAIvB,GAAIsxC,IAA4BF,EAAsB,CACpD,MAAMiB,GAAoBjkB,EAAAA,GAAAA,GAAQhB,GAElC,GAC+B,IAA7BilB,EAAkBryC,SAClB4L,EAAAA,GAAAA,GAAcymC,EAAkB,GAAIlU,iBACpC,CACA,MACMmU,EADoBD,EAAkB,GACY/c,aAExD,OAAO,WACL,OAAOpxB,KAAK6tC,GAAG,GAAGzc,eAAiBgd,CACrC,C,CACK,CACL,MAAML,GAAcxkC,EAAAA,GAAAA,GAClB4kC,GACA,CAAC/oC,EAAQutB,EAAajd,KACpBtQ,EAAOutB,EAAYvB,eAAiB,GACpCztB,EAAAA,GAAAA,GAAQgvB,EAAYsH,iBAAmB+T,IACrC5oC,EAAO4oC,IAAqB,CAAI,IAE3B5oC,IAET,IAGF,OAAO,WACL,MAAMwoC,EAAY5tC,KAAK6tC,GAAG,GAC1B,OAA+C,IAAxCE,EAAYH,EAAUxc,aAC/B,C,EAGF,OAAO,WACLia,EAAU,IAAK,IAAIjM,EAAI,EAAGA,EAAI8O,EAAY9O,IAAK,CAC7C,MAAMoF,EAAWtb,EAAIkW,GACfuO,EAAiBnJ,EAAS1oC,OAChC,IAAK,IAAI0O,EAAI,EAAGA,EAAImjC,EAAgBnjC,IAAK,CACvC,MAAMojC,EAAY5tC,KAAK6tC,GAAGrjC,EAAI,GAC9B,IAA6C,IAAzC84B,EAAasK,EAAWpJ,EAASh6B,IAGnC,SAAS6gC,C,CAIb,OAAO,C,CAIT,OAAO,CACT,CAEJ,EAhUA,SAAYe,GACVA,EAAAA,EAAA,mBACAA,EAAAA,EAAA,2BACAA,EAAAA,EAAA,+CACAA,EAAAA,EAAA,6EACAA,EAAAA,EAAA,yDACAA,EAAAA,EAAA,4BACD,CAPD,CAAYA,KAAAA,GAAS,KAkUrB,MAAMiC,WAAmC/mB,GAGvCnsB,WAAAA,CACUmvB,EACAgkB,EACAC,GAERnzC,QAJQ,KAAAkvB,QAAAA,EACA,KAAAgkB,iBAAAA,EACA,KAAAC,eAAAA,CAGV,CAEA/jB,YAAAA,GAEE,OADAxqB,KAAKunB,KAAKvnB,KAAKsqB,SACRtqB,KAAKwuC,OACd,CAEQC,aAAAA,CACNroC,EACAsoC,EACAjnB,EACAD,GAEA,OACEphB,EAAKsP,MAAQ1V,KAAKsuC,kBAClBtuC,KAAKuuC,iBAAmBG,IAExB1uC,KAAKwuC,QAAU/mB,EAASpnB,OAAOmnB,IACxB,EAIX,CAEAM,UAAAA,CACES,EACAd,EACAD,GAEKxnB,KAAKyuC,cAAclmB,EAAY6jB,GAAUE,OAAQ7kB,EAAUD,IAC9DpsB,MAAM0sB,WAAWS,EAAYd,EAAUD,EAE3C,CAEAO,cAAAA,CACES,EACAf,EACAD,GAGGxnB,KAAKyuC,cACJjmB,EACA4jB,GAAUI,qBACV/kB,EACAD,IAGFpsB,MAAM0sB,WAAWU,EAAgBf,EAAUD,EAE/C,CAEAQ,iBAAAA,CACEU,EACAjB,EACAD,GAGGxnB,KAAKyuC,cACJ/lB,EACA0jB,GAAUK,oCACVhlB,EACAD,IAGFpsB,MAAM0sB,WAAWY,EAAmBjB,EAAUD,EAElD,CAEAU,QAAAA,CACEW,EACApB,EACAD,GAGGxnB,KAAKyuC,cAAc5lB,EAAUujB,GAAUG,WAAY9kB,EAAUD,IAE9DpsB,MAAM0sB,WAAWe,EAAUpB,EAAUD,EAEzC,CAEAS,WAAAA,CACEc,EACAtB,EACAD,GAGGxnB,KAAKyuC,cACJ1lB,EACAqjB,GAAUM,0BACVjlB,EACAD,IAGFpsB,MAAM0sB,WAAWiB,EAAatB,EAAUD,EAE5C,EAMF,MAAMmnB,WAAsC9oB,GAG1C1qB,WAAAA,CACUmzC,EACAC,EACAK,GAERxzC,QAJQ,KAAAkzC,iBAAAA,EACA,KAAAC,eAAAA,EACA,KAAAK,UAAAA,EALH,KAAAxpC,OAAwB,EAQ/B,CAEQqpC,aAAAA,CACNroC,EACAyoC,GAGEzoC,EAAKsP,MAAQ1V,KAAKsuC,kBAClBtuC,KAAKuuC,iBAAmBM,QACJ9yC,IAAnBiE,KAAK4uC,WAA2BxoC,IAASpG,KAAK4uC,YAE/C5uC,KAAKoF,OAASgB,EAAKuZ,WAEvB,CAEOqG,WAAAA,CAAY5f,GACjBpG,KAAKyuC,cAAcroC,EAAMgmC,GAAUE,OACrC,CAEOlmB,eAAAA,CAAgBhgB,GACrBpG,KAAKyuC,cAAcroC,EAAMgmC,GAAUG,WACrC,CAEOtmB,wBAAAA,CAAyB7f,GAC9BpG,KAAKyuC,cAAcroC,EAAMgmC,GAAUI,qBACrC,CAEOtmB,qCAAAA,CACL9f,GAEApG,KAAKyuC,cAAcroC,EAAMgmC,GAAUK,oCACrC,CAEOtmB,4BAAAA,CAA6B/f,GAClCpG,KAAKyuC,cAAcroC,EAAMgmC,GAAUM,0BACrC,CAEOrmB,gBAAAA,CAAiBjgB,GACtBpG,KAAKyuC,cAAcroC,EAAMgmC,GAAUO,YACrC,EAGF,SAASmC,GAAwBnkC,GAC/B,MAAMvF,EAAS,IAAIyB,MAAM8D,GACzB,IAAK,IAAIH,EAAI,EAAGA,EAAIG,EAAMH,IACxBpF,EAAOoF,GAAK,GAEd,OAAOpF,CACT,CAOA,SAAS2pC,GAAe3rB,GACtB,IAAIzP,EAAO,CAAC,IACZ,IAAK,IAAInJ,EAAI,EAAGA,EAAI4Y,EAAKtnB,OAAQ0O,IAAK,CACpC,MAAMqZ,EAAUT,EAAK5Y,GACfwkC,EAAa,GACnB,IAAK,IAAI5P,EAAI,EAAGA,EAAIzrB,EAAK7X,OAAQsjC,IAAK,CACpC,MAAM6P,EAAiBt7B,EAAKyrB,GAC5B4P,EAAWroC,KAAKsoC,EAAiB,IAAMprB,EAAQuN,cAC/C,IAAK,IAAIoc,EAAI,EAAGA,EAAI3pB,EAAQoW,gBAAiBn+B,OAAQ0xC,IAAK,CACxD,MAAM0B,EAAsB,IAAMrrB,EAAQoW,gBAAiBuT,GAC3DwB,EAAWroC,KAAKsoC,EAAiBC,E,EAGrCv7B,EAAOq7B,C,CAET,OAAOr7B,CACT,CAKA,SAASw7B,GACPC,EACAC,EACA35B,GAEA,IACE,IAAI45B,EAAa,EACjBA,EAAaF,EAAkBtzC,OAC/BwzC,IACA,CAEA,GAAIA,IAAe55B,EACjB,SAEF,MAAM65B,EAAyBH,EAAkBE,GACjD,IAAK,IAAIE,EAAY,EAAGA,EAAYH,EAAevzC,OAAQ0zC,IAAa,CAEtE,IAA0C,IAAtCD,EADcF,EAAeG,IAE/B,OAAO,C,EAKb,OAAO,CACT,CAEM,SAAUC,GACdC,EACArQ,GAEA,MAAMsQ,GAAcnqC,EAAAA,GAAAA,GAAIkqC,GAAWvF,GACjCL,GAAkB,CAACK,GAAU,KAEzByF,EAAcd,GAAwBa,EAAY7zC,QAClD+zC,GAAarqC,EAAAA,GAAAA,GAAImqC,GAAcrL,IACnC,MAAMwL,EAAmC,CAAC,EAO1C,OANAnsC,EAAAA,GAAAA,GAAQ2gC,GAAevlC,IACrB,MAAM4U,EAAOo7B,GAAehwC,EAAKqrC,cACjCzmC,EAAAA,GAAAA,GAAQgQ,GAAO0sB,IACbyP,EAAKzP,IAAW,CAAI,GACpB,IAEGyP,CAAI,IAEb,IAAIC,EAAUJ,EAGd,IAAK,IAAIK,EAAa,EAAGA,GAAc3Q,EAAG2Q,IAAc,CACtD,MAAMC,EAAcF,EACpBA,EAAUjB,GAAwBmB,EAAYn0C,QAG9C,IAAK,IAAIo0C,EAAS,EAAGA,EAASD,EAAYn0C,OAAQo0C,IAAU,CAC1D,MAAMC,EAA0BF,EAAYC,GAE5C,IACE,IAAIE,EAAc,EAClBA,EAAcD,EAAwBr0C,OACtCs0C,IACA,CACA,MAAMC,EAAiBF,EAAwBC,GAAahG,YACtDC,EAAY8F,EAAwBC,GAAa/F,UACjDiG,EAAavB,GAAesB,GAGlC,GAFiBlB,GAAmBU,EAAYS,EAAYJ,KAE5CxoC,EAAAA,GAAAA,GAAQ2iC,IAAcgG,EAAev0C,SAAWujC,EAAG,CACjE,MAAMkR,EAAgBX,EAAYM,GAElC,IAAoD,IAAhDM,GAAaD,EAAeF,GAA2B,CACzDE,EAAc5pC,KAAK0pC,GAEnB,IAAK,IAAIjR,EAAI,EAAGA,EAAIkR,EAAWx0C,OAAQsjC,IAAK,CAC1C,MAAMiB,EAAUiQ,EAAWlR,GAC3ByQ,EAAWK,GAAQ7P,IAAW,C,OAK/B,CACH,MAAMoQ,EAA6B3G,GACjCO,EACA2F,EAAa,EACbK,GAEFN,EAAQG,GAAUH,EAAQG,GAAQ7vC,OAAOowC,IAGzC9sC,EAAAA,GAAAA,GAAQ8sC,GAA6B1xC,IACnC,MAAMuxC,EAAavB,GAAehwC,EAAKqrC,cACvCzmC,EAAAA,GAAAA,GAAQ2sC,GAAarlC,IACnB4kC,EAAWK,GAAQjlC,IAAO,CAAI,GAC9B,G,IAOZ,OAAO2kC,CACT,CAEM,SAAU7C,GACd/G,EACA0K,EACArR,EACApW,GAEA,MAAMtN,EAAU,IAAIgzB,GAClB3I,EACAoG,GAAUO,YACV1jB,GAGF,OADAynB,EAAYxsB,OAAOvI,GACZ8zB,GAAkC9zB,EAAQvW,OAAQi6B,EAC3D,CAEM,SAAU2N,GACdhH,EACA0K,EACA7D,EACAxN,GAEA,MAAMsR,EAAmB,IAAIhC,GAC3B3I,EACA6G,GAEF6D,EAAYxsB,OAAOysB,GACnB,MAAMC,EAAYD,EAAiBvrC,OAO7ByrC,EALiB,IAAIxC,GACzBqC,EACA1K,EACA6G,GAE8BriB,eAKhC,OAAOilB,GAAkC,CAHtB,IAAIqB,GAAgB,CAAEnxB,WAAYixB,IACnC,IAAIE,GAAgB,CAAEnxB,WAAYkxB,KAEcxR,EACpE,CAEM,SAAUmR,GACd15B,EACAi6B,GAEAC,EAAkB,IAAK,IAAIxmC,EAAI,EAAGA,EAAIsM,EAAYhb,OAAQ0O,IAAK,CAC7D,MAAMymC,EAAYn6B,EAAYtM,GAC9B,GAAIymC,EAAUn1C,SAAWi1C,EAAWj1C,OAApC,CAGA,IAAK,IAAIsjC,EAAI,EAAGA,EAAI6R,EAAUn1C,OAAQsjC,IAAK,CACzC,MAAM8R,EAAYH,EAAW3R,GACvB+R,EAAWF,EAAU7R,GAK3B,IAAuB,KAFrB8R,IAAcC,QAC4Cp1C,IAA1Do1C,EAAShY,mBAAoB+X,EAAU9f,eAEvC,SAAS4f,C,CAGb,OAAO,C,EAGT,OAAO,CACT,CAkBM,SAAUI,GACdC,GAEA,OAAOroC,GAAMqoC,GAAiBC,GAC5BtoC,GAAMsoC,GAAiBC,GACrBvoC,GAAMuoC,GAAa5kC,IAAUjF,EAAAA,GAAAA,GAAQiF,EAAMstB,sBAGjD,CCnpBM,SAAUuX,GACdC,EACA/tC,EACA4jC,EACAH,GAEA,MAAMuK,EAA4C3nC,GAChD0nC,GACCjK,GA8BL,SACEvC,EACAqC,GAEA,MAAMqK,EAAmB,IAAIC,GAC7B3M,EAAa/gB,OAAOytB,GACpB,MAAME,EAAqBF,EAAiBG,eAEtCC,EAAmBC,GACvBH,EACAI,IAGIC,EAAkB5tB,GAAOytB,GAAmBI,GACzCA,EAAUr2C,OAAS,IAGtBu3B,GAAS7tB,EAAAA,GAAAA,IAAIshB,EAAAA,GAAAA,GAAOorB,IAAcE,IACtC,MAAMC,EAAiB9pC,GAAM6pC,GACvBhmB,EAAMkb,EAAelC,yBACzBH,EACAmN,GAEI5M,EAAUne,GAAqBgrB,GAC/BC,EAA6C,CACjD5sC,QAAS0mB,EACTzrB,KAAM8mC,GAA0B8K,sBAChC5O,SAAUsB,EAAa/nC,KACvBsoC,QAASA,EACTQ,WAAYqM,EAAU38B,KAGlB88B,EAAQC,GAA2BJ,GAKzC,OAJIG,IACFF,EAASI,UAAYF,GAGhBF,CAAQ,IAEjB,OAAOjf,CACT,CArEMsf,CAA6BnL,EAAcF,KAGzCsL,EAqlBR,SACEnB,EACA/tC,EACA4jC,GAEA,MAAMjU,EAAmC,GAEnCwf,GAAartC,EAAAA,GAAAA,GAAI9B,GAAaovC,GAAcA,EAAU51C,OAe5D,OAbAyG,EAAAA,GAAAA,GAAQ8tC,GAAY1K,IAClB,MAAMgM,EAAehM,EAAS7pC,KAC9B,GAAI4M,GAAS+oC,EAAYE,GAAe,CACtC,MAAMjb,EAASwP,EAAe3B,4BAA4BoB,GAE1D1T,EAAO1sB,KAAK,CACVjB,QAASoyB,EACTn3B,KAAM8mC,GAA0BuL,gCAChCrP,SAAUoP,G,KAKT1f,CACT,CA5mBuC4f,CACnCxB,EACA/tC,EACA4jC,GAGI4L,EAAoBnpC,GAAQ0nC,GAAY0B,GAyX1C,SACJlO,EACAqC,GAEA,MAAM8L,EAAc,IAAIC,GACxBpO,EAAa/gB,OAAOkvB,GACpB,MAAME,EAAMF,EAAYG,aAElBlgB,EAAStpB,GAAQupC,GAAME,GACvBA,EAAO7zB,WAAW7jB,OAAS,IACtB,CACL,CACE4J,QAAS4hC,EAAeX,8BAA8B,CACpD1B,aAAcA,EACdgB,YAAauN,IAEf7yC,KAAM8mC,GAA0BgM,cAChC9P,SAAUsB,EAAa/nC,KACvB8oC,WAAYwN,EAAO99B,MAIhB,KAIX,OAAO2d,CACT,CAnZIqgB,CAAoBP,EAAS7L,KAGzBqM,EAAsB5pC,GAAQ0nC,GAAY0B,GAkH5C,SACJp2C,EACA62C,EACAC,EACAvM,GAEA,MAAMjU,EAAS,GACTygB,GAAcvqC,EAAAA,GAAAA,GAClBqqC,GACA,CAACxuC,EAAQ+tC,IACHA,EAAQj2C,OAASH,EAAKG,KACjBkI,EAAS,EAEXA,GAET,GAEF,GAAI0uC,EAAc,EAAG,CACnB,MAAMhc,EAASwP,EAAeJ,4BAA4B,CACxDjC,aAAcloC,EACdoqC,YAAa0M,IAEfxgB,EAAO1sB,KAAK,CACVjB,QAASoyB,EACTn3B,KAAM8mC,GAA0BsM,oBAChCpQ,SAAU5mC,EAAKG,M,CAInB,OAAOm2B,CACT,CA/II2gB,CACEb,EACA1B,EACAtK,EACAG,KAIJ,OAAOoK,EAAgBrxC,OACrBuyC,EACAM,EACAS,EAEJ,CA4CM,SAAU1B,GACd9tB,GAEA,MAAO,GAAP9jB,OAAUgnB,GAAqBlD,GAAK,OAAA9jB,OAClC8jB,EAAKzO,IACP,OAAArV,OAAMoyC,GAA2BtuB,GACnC,CAEA,SAASsuB,GAA2BtuB,GAClC,OAAIA,aAAgBiB,GACXjB,EAAKuB,aAAaxoB,KAChBinB,aAAgBC,GAClBD,EAAKqB,gBAEL,EAEX,CAEM,MAAOosB,WAAsC/rB,GAAnD1qB,WAAAA,G,oBACS,KAAA22C,eAA8C,EAmCvD,CAjCS/rB,gBAAAA,CAAiBkuB,GACtBj0C,KAAK8xC,eAAenrC,KAAKstC,EAC3B,CAEOjuB,WAAAA,CAAYkuB,GACjBl0C,KAAK8xC,eAAenrC,KAAKutC,EAC3B,CAEO/tB,4BAAAA,CAA6BguB,GAClCn0C,KAAK8xC,eAAenrC,KAAKwtC,EAC3B,CAEOluB,wBAAAA,CAAyBmuB,GAC9Bp0C,KAAK8xC,eAAenrC,KAAKytC,EAC3B,CAEOluB,qCAAAA,CACLmuB,GAEAr0C,KAAK8xC,eAAenrC,KAAK0tC,EAC3B,CAEOjuB,eAAAA,CAAgBkuB,GACrBt0C,KAAK8xC,eAAenrC,KAAK2tC,EAC3B,CAEOjuB,gBAAAA,CAAiBkuB,GACtBv0C,KAAK8xC,eAAenrC,KAAK4tC,EAC3B,CAEOjuB,aAAAA,CAAc9E,GACnBxhB,KAAK8xC,eAAenrC,KAAK6a,EAC3B,EA4DI,SAAUgzB,GACdtL,EACAnC,EACAO,GACiB,IAAjBlkB,EAAAvnB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAe,GAEf,MAAMw3B,EAAmC,GACnCohB,EAAmBC,GAAqB3N,EAASpnB,YACvD,IAAIjY,EAAAA,GAAAA,GAAQ+sC,GACV,MAAO,GACF,CACL,MAAM9Q,EAAWuF,EAAQhsC,KACE4M,GAAS2qC,EAAkBvL,IAEpD7V,EAAO1sB,KAAK,CACVjB,QAAS4hC,EAAeV,wBAAwB,CAC9C3B,aAAciE,EACdpC,kBAAmB1jB,IAErBziB,KAAM8mC,GAA0BkN,eAChChR,SAAUA,IAMd,MAAMiR,EAAiBjhB,GAAW8gB,EAAkBrxB,EAAK/iB,OAAO,CAAC6oC,KAC3D2L,EAAsB9qC,GAAQ6qC,GAAiBE,IACnD,MAAMpa,GAAUjB,EAAAA,GAAAA,GAAMrW,GAEtB,OADAsX,EAAQ/zB,KAAKmuC,GACNN,GACLtL,EACA4L,EACAxN,EACA5M,EACD,IAGH,OAAOrH,EAAOhzB,OAAOw0C,E,CAEzB,CAEM,SAAUH,GAAqB/0B,GACnC,IAAIva,EAAiB,GACrB,IAAIsC,EAAAA,GAAAA,GAAQiY,GACV,OAAOva,EAET,MAAMitC,EAAY9pC,GAAMoX,GAGxB,GAAI0yB,aAAqBjuB,GACvBhf,EAAOuB,KAAK0rC,EAAU7tB,qBACjB,GACL6tB,aAAqBvB,IACrBuB,aAAqBxtB,IACrBwtB,aAAqBvtB,IACrButB,aAAqBttB,IACrBstB,aAAqBptB,IACrBotB,aAAqBrtB,GAErB5f,EAASA,EAAO/E,OACdq0C,GAAoCrC,EAAU1yB,kBAE3C,GAAI0yB,aAAqBntB,GAE9B9f,GAAS8kB,EAAAA,GAAAA,IACP1kB,EAAAA,GAAAA,GAAI6sC,EAAU1yB,YAAao1B,GACzBL,GAAuCK,EAAYp1B,oBAGlD,KAAI0yB,aAAqBjtB,IAG9B,MAAM3kB,MAAM,wBAGd,MAAMu0C,EAAkB9tB,GAAemrB,GACjC4C,EAAUt1B,EAAW7jB,OAAS,EACpC,GAAIk5C,GAAmBC,EAAS,CAC9B,MAAMC,EAAOxtB,GAAK/H,GAClB,OAAOva,EAAO/E,OAAOq0C,GAAqBQ,G,CAE1C,OAAO9vC,CAEX,CAEA,MAAMiuC,WAAoBxtB,GAA1B1qB,WAAAA,G,oBACS,KAAAo4C,aAA8B,EAKvC,CAHSltB,gBAAAA,CAAiBjgB,GACtBpG,KAAKuzC,aAAa5sC,KAAKP,EACzB,EA8CI,SAAU+uC,GACdlQ,EACAmQ,EACA9N,GAEA,MAAM8L,EAAc,IAAIC,GACxBpO,EAAa/gB,OAAOkvB,GACpB,IAAIE,EAAMF,EAAYG,aAItBD,EAAMzjB,GAAOyjB,GAAME,IAAwC,IAA7BA,EAAO5uB,oBAErC,MAAMyO,EAAStpB,GAAQupC,GAAME,IAC3B,MAAM6B,EAAiB7B,EAAO99B,IACxB4/B,EAAqB9B,EAAO1G,cAAgBsI,EAC5Ct0B,EAAeisB,GACnBsI,EACApQ,EACAqQ,EACA9B,GAEI+B,EAmHV,SACEz0B,EACAmlB,EACAlpC,EACAuqC,GAEA,MAAMkO,EAAmC,GACnCC,GAAuBlsC,EAAAA,GAAAA,GAC3BuX,GACA,CAAC1b,EAAQ+kC,EAASmF,MAE6C,IAAzDrJ,EAAYtmB,WAAW2vB,GAAY1qB,oBAIvCjhB,EAAAA,GAAAA,GAAQwmC,GAAU3F,IAChB,MAAMkR,EAAwB,CAACpG,IAC/B3rC,EAAAA,GAAAA,GAAQmd,GAAc,CAAC60B,EAAcC,KAEjCtG,IAAesG,GACfpF,GAAamF,EAAcnR,KAEmC,IAA9DyB,EAAYtmB,WAAWi2B,GAAiBhxB,mBAExC8wB,EAAsB/uC,KAAKivC,E,IAK7BF,EAAsB55C,OAAS,IAC9B00C,GAAagF,EAAqBhR,KAEnCgR,EAAoB7uC,KAAK69B,GACzBp/B,EAAOuB,KAAK,CACVkQ,KAAM6+B,EACNtyB,KAAMohB,I,IAvBHp/B,IA6BX,IAGIywC,GAAarwC,EAAAA,GAAAA,GAAIiwC,GAAuBK,IAC5C,MAAMC,GAAcvwC,EAAAA,GAAAA,GAClBswC,EAAkBj/B,MACjBy4B,GAAeA,EAAa,IAU/B,MAAO,CACL5pC,QARkB4hC,EAAenB,+BAA+B,CAChElB,aAAcloC,EACdkpC,YAAaA,EACbC,iBAAkB6P,EAClBjQ,WAAYgQ,EAAkB1yB,OAK9BziB,KAAM8mC,GAA0BuO,eAChCrS,SAAU5mC,EAAKG,KACf8oC,WAAYC,EAAYvwB,IACxBoL,aAAcg1B,EAAkBj/B,KACjC,IAGH,OAAOg/B,CACT,CAtLgCI,CAC1Bn1B,EACA0yB,EACAvO,EACAqC,GAEI4O,EAkLJ,SACJp1B,EACAmlB,EACAlpC,EACAuqC,GAGA,MAAM6O,GAAkB5sC,EAAAA,GAAAA,GACtBuX,GACA,CAAC1b,EAAQ+kC,EAASz0B,KAChB,MAAM0gC,GAAkB5wC,EAAAA,GAAAA,GAAI2kC,GAAU3F,IAC7B,CAAE9uB,IAAKA,EAAK0N,KAAMohB,MAE3B,OAAOp/B,EAAO/E,OAAO+1C,EAAgB,GAEvC,IAGI/iB,EAASgC,GACbtrB,GAAQosC,GAAkBE,IAGxB,IAA0C,IAFlBpQ,EAAYtmB,WAAW02B,EAAe3gC,KAE1CkP,kBAClB,MAAO,GAET,MAAM0xB,EAAYD,EAAe3gC,IAC3B6gC,EAAaF,EAAejzB,KAE5BozB,GAAmCptC,EAAAA,GAAAA,GACvC+sC,GACCM,IAEC,OAGI,IADFxQ,EAAYtmB,WAAW82B,EAAiB/gC,KAAKkP,mBAE7C6xB,EAAiB/gC,IAAM4gC,IDgEjCI,EC7D+BD,EAAiBrzB,KD8DhD9a,EC9DsDiuC,EDiEpDG,EAAO56C,OAASwM,EAAMxM,QACtBkN,GAAM0tC,GAAQ,CAAC7yB,EAASnO,KACtB,MAAMihC,EAAeruC,EAAMoN,GAC3B,OACEmO,IAAY8yB,GACZA,EAAaxd,mBAAoBtV,EAAQuN,aAAc,KAVzD,IACJslB,EACApuC,CC9DiE,IA2B7D,OAtB6B9C,EAAAA,GAAAA,GAC3BgxC,GACCI,IACC,MAAMb,EAAc,CAACa,EAAkBlhC,IAAM,EAAG4gC,EAAY,GACtDtQ,EAAiC,IAApBC,EAAYvwB,IAAY,GAAKuwB,EAAYvwB,IAQ5D,MAAO,CACLhQ,QAPc4hC,EAAe1B,qCAAqC,CAClEX,aAAcloC,EACdkpC,YAAaA,EACbC,iBAAkB6P,EAClBjQ,WAAY8Q,EAAkBxzB,OAI9BziB,KAAM8mC,GAA0BoP,sBAChClT,SAAU5mC,EAAKG,KACf8oC,WAAYA,EACZllB,aAAci1B,EACf,GAIsB,KAI/B,OAAO1iB,CACT,CAzPsCyjB,CAChCh2B,EACA0yB,EACAvO,EACAqC,GAGF,OAAOiO,EAAoBl1C,OAAO61C,EAA0B,IAG9D,OAAO7iB,CACT,CAEM,MAAO0jB,WAA4BlxB,GAAzC1qB,WAAAA,G,oBACS,KAAA22C,eAEA,EAmBT,CAjBS3rB,4BAAAA,CAA6BguB,GAClCn0C,KAAK8xC,eAAenrC,KAAKwtC,EAC3B,CAEOluB,wBAAAA,CAAyBmuB,GAC9Bp0C,KAAK8xC,eAAenrC,KAAKytC,EAC3B,CAEOluB,qCAAAA,CACLmuB,GAEAr0C,KAAK8xC,eAAenrC,KAAK0tC,EAC3B,CAEOjuB,eAAAA,CAAgBkuB,GACrBt0C,KAAK8xC,eAAenrC,KAAK2tC,EAC3B,ECpcI,SAAU0C,GACdvzC,GAEA,MAAMwzC,GAA8C7nB,EAAAA,GAAAA,GAAS3rB,EAAS,CACpE6jC,eAAgBvC,KAGZmS,EAA8C,CAAC,EAIrD,OAHAvzC,EAAAA,GAAAA,GAAQF,EAAQF,OAAQxG,IACtBm6C,EAAcn6C,EAAKG,MAAQH,CAAI,IVjB7B,SACJ00C,EACAnK,GAEA,MAAM6P,EAAc,IAAI/P,GAAuBqK,EAAWnK,GAE1D,OADA6P,EAAY5P,cACL4P,EAAY9jB,MACrB,CUYS+jB,CAAkBF,EAAeD,EAAc3P,eACxD,CCxBA,MAAM+P,GAA6B,2BAC7BC,GAA0B,uBAC1BC,GAAuB,qBACvBC,GAAiC,6BAEjCC,GAA8B,CAClCJ,GACAC,GACAC,GACAC,IAMI,SAAUE,GAAuBprB,GAErC,OAAOxiB,GAAS2tC,GAA6BnrB,EAAMpvB,KACrD,CANAwB,OAAO6M,OAAOksC,IAQd,MAAeE,WACLl3C,MAMRtF,WAAAA,CACEuK,EACOiH,GAEPvR,MAAMsK,GAFC,KAAAiH,MAAAA,EAJT,KAAAirC,eAA2B,GASzBl5C,OAAOm5C,eAAe73C,gBAAiBoL,WAGnC3K,MAAMq3C,mBACRr3C,MAAMq3C,kBAAkB93C,KAAMA,KAAK7E,YAEvC,EAGI,MAAO48C,WAAiCJ,GAC5Cx8C,WAAAA,CACEuK,EACAiH,EACOqrC,GAEP58C,MAAMsK,EAASiH,GAFR,KAAAqrC,cAAAA,EAGPh4C,KAAK9C,KAAOm6C,EACd,EAGI,MAAOY,WAA6BN,GACxCx8C,WAAAA,CACEuK,EACAiH,EACOqrC,GAEP58C,MAAMsK,EAASiH,GAFR,KAAAqrC,cAAAA,EAGPh4C,KAAK9C,KAAOo6C,EACd,EAGI,MAAOY,WAAmCP,GAC9Cx8C,WAAAA,CAAYuK,EAAiBiH,GAC3BvR,MAAMsK,EAASiH,GACf3M,KAAK9C,KAAOs6C,EACd,EAGI,MAAOW,WAA2BR,GACtCx8C,WAAAA,CACEuK,EACAiH,EACOqrC,GAEP58C,MAAMsK,EAASiH,GAFR,KAAAqrC,cAAAA,EAGPh4C,KAAK9C,KAAOq6C,EACd,ECzDK,MAAMa,GAAsB,CAAC,EAQvBC,GAA6B,0BAEpC,MAAOC,WAAgC73C,MAC3CtF,WAAAA,CAAYuK,GACVtK,MAAMsK,GACN1F,KAAK9C,KAAOm7C,EACd,EAiXI,SAAUE,GAEdC,EACAztB,EACA0tB,EACAC,EACAC,EACAC,EACAC,GAEA,MAAM5tC,EAAMjL,KAAK84C,4BAA4BJ,EAAcC,GAC3D,IAAII,EAAoB/4C,KAAKg5C,iBAAiB/tC,GAC9C,QAA0BlP,IAAtBg9C,EAAiC,CACnC,MAAMhG,EAAe/yC,KAAKi5C,sBAI1BF,EADE,IAAIH,EAFc54C,KAAKk5C,qBAAqBnG,GAEZ4F,GACPnuB,eAC3BxqB,KAAKg5C,iBAAiB/tC,GAAO8tC,C,CAG/B,IAAII,EAA0BJ,EAAkBpsC,MAC5CysC,EAAaL,EAAkB/S,WACnC,MAAMmD,EAAc4P,EAAkB5P,YAKT,IAA3BnpC,KAAKq5C,WAAWv9C,QAChBqtC,QAC4BptC,IAA5Bo9C,IAEAA,EAA0B9V,GAC1B+V,EAAa,QAKiBr9C,IAA5Bo9C,QAAwDp9C,IAAfq9C,GAK3Cp5C,KAAKs5C,kCACHH,EACAC,EACAP,IAMF74C,KAAKu5C,wBACHf,EACAztB,EACA0tB,EACAU,EAGN,CCjdO,MAYMK,GAAmB,KACnBC,GAAe,KACfC,GAAuB,KAG9B,SAAUZ,GACda,EACAjB,EACA1S,GAEA,OAAOA,EAAa0S,EAAeiB,CACrC,CCJM,MAAOC,GAGXz+C,WAAAA,CAAYsI,G,MACVzD,KAAK8sC,aACkB,QAArB34B,EAAO,OAAP1Q,QAAO,IAAPA,OAAO,EAAPA,EAASqpC,oBAAY,IAAA34B,EAAAA,EAAI0lC,GAAsB/M,YACnD,CAEAgN,QAAAA,CAASr2C,GAKP,MAAMs2C,EAAsB/5C,KAAKw0C,wBAAwB/wC,EAAQF,OAEjE,IAAImE,EAAAA,GAAAA,GAAQqyC,GAAsB,CAChC,MAAMC,EAAiBh6C,KAAKi6C,4BAA4Bx2C,EAAQF,OAC1D22C,EAAsBl6C,KAAKm1C,yCAC/B1xC,EAAQF,MACRvD,KAAK8sC,cAEDqN,EAAwBn6C,KAAKo6C,kCACjC32C,EAAQF,MACRvD,KAAK8sC,cAQP,MANkB,IACbiN,KACAC,KACAE,KACAC,E,CAIP,OAAOJ,CACT,CAEAvF,uBAAAA,CAAwBjxC,GACtB,OAAOwG,GAAQxG,GAAQ82C,GACrB7F,GACE6F,EACAA,EACAlV,KAGN,CAEA8U,2BAAAA,CAA4B12C,GAC1B,OAAOwG,GAAQxG,GAAQ82C,GLqSrB,SACJpV,EACAqC,GAEA,MAAM8L,EAAc,IAAIC,GACxBpO,EAAa/gB,OAAOkvB,GACpB,MAAME,EAAMF,EAAYG,aAkCxB,OAhCexpC,GACbupC,GACCE,IACC,MAAM8G,EAAahP,GAAUkI,EAAO7zB,YACpC,OAAO5V,GAAQuwC,GAAY,CAACC,EAAiBjL,KAC3C,MAAMkL,EAAqBlQ,GACzB,CAACiQ,GACD,GACAzhB,GACA,GAEF,OAAIpxB,EAAAA,GAAAA,GAAQ8yC,GACH,CACL,CACE90C,QAAS4hC,EAAeb,2BAA2B,CACjDxB,aAAcA,EACdgB,YAAauN,EACb9M,eAAgB4I,IAElB3uC,KAAM8mC,GAA0BgT,oBAChC9W,SAAUsB,EAAa/nC,KACvB8oC,WAAYwN,EAAO99B,IACnBoB,YAAaw4B,EAAa,IAIvB,E,GAET,GAKR,CK7UMoL,CACEL,EACAlV,KAGN,CAEAgQ,wCAAAA,CACE5xC,EACAupC,GAEA,OAAO/iC,GAAQxG,GAAQ82C,GACrBlF,GACEkF,EACAvN,EACA3H,KAGN,CAEAiV,iCAAAA,CACE72C,EACAupC,GAEA,OLqZE,SACJ6N,EACA7N,EACAxF,GAEA,MAAMjU,EAAmC,GA8BzC,OA7BA1vB,EAAAA,GAAAA,GAAQg3C,GAAgBN,IACtB,MAAM1I,EAAmB,IAAIoF,GAC7BsD,EAAYn2B,OAAOytB,GACnB,MAAME,EAAqBF,EAAiBG,gBAC5CnuC,EAAAA,GAAAA,GAAQkuC,GAAqB+I,IAC3B,MAAM/N,EAAWR,GAAYuO,GACvBtF,EAAqBsF,EAAS9N,cAAgBA,EAQ9C+N,EANQ7N,GADS4N,EAASllC,IAG9B2kC,EACAxN,EACAyI,GAEkC,GACpC,IAAI5tC,EAAAA,GAAAA,IAAQwiB,EAAAA,GAAAA,GAAQ2wB,IAAyB,CAC3C,MAAM/iB,EAASwP,EAAehB,0BAA0B,CACtDrB,aAAcoV,EACd9T,WAAYqU,IAEdvnB,EAAO1sB,KAAK,CACVjB,QAASoyB,EACTn3B,KAAM8mC,GAA0BqT,uBAChCnX,SAAU0W,EAAYn9C,M,IAG1B,IAGGm2B,CACT,CKzbW+mB,CACL72C,EACAupC,EACA3H,GAEJ,CAEA4V,4BAAAA,CAA6Bt3C,GAO3B,ONxBE,SACJuiC,EACA0K,EACA5D,EACA3nB,EACA+nB,EACA8N,GAEA,MAAM3J,EAAiBtE,GACrB/G,EACA0K,EACA5D,GAOF,OAAOkO,EACL3J,EACAlsB,EANmBisB,GAA0BC,GAC3CjY,GACAN,GAMFoU,EAEJ,CMAW+N,CACLx3C,EAAQk1C,eACRl1C,EAAQ1G,KACR0G,EAAQqpC,aACRrpC,EAAQ0hB,cACR1hB,EAAQypC,qBACRD,GAEJ,CAEAiO,yBAAAA,CAA0Bz3C,GAOxB,ONHE,SACJuiC,EACA0K,EACArR,EACA6N,EACAL,EACAsO,GAMA,MAAM9J,EAAiBrE,GACrBhH,EACA0K,EACA7D,EACAxN,GAGIiE,EAAe8N,GAA0BC,GAC3CjY,GACAN,GAEJ,OAAOqiB,EACL9J,EAAe,GACf/N,EACA4J,EAEJ,CMzBWkO,CACL33C,EAAQk1C,eACRl1C,EAAQ1G,KACR0G,EAAQqpC,aACRrpC,EAAQypC,qBACRb,GAAY5oC,EAAQopC,UACpBoB,GAEJ,ECoHF,MAAM0D,GAAmB,IAvDzB,cAAyC9rB,GAAzC1qB,WAAAA,G,oBACS,KAAAkgD,WAOH,CACFnH,OAAQ,GACRjO,YAAa,GACbM,WAAY,GACZ+U,wBAAyB,GACzBC,oBAAqB,GACrBC,iCAAkC,GAuCtC,CApCEx/B,KAAAA,GACEhc,KAAKq7C,WAAa,CAChBnH,OAAQ,GACRjO,YAAa,GACbM,WAAY,GACZ+U,wBAAyB,GACzBC,oBAAqB,GACrBC,iCAAkC,GAEtC,CAEOx1B,WAAAA,CAAYkuB,GACjBl0C,KAAKq7C,WAAWnH,OAAOvtC,KAAKutC,EAC9B,CAEO/tB,4BAAAA,CAA6BguB,GAClCn0C,KAAKq7C,WAAWC,wBAAwB30C,KAAKwtC,EAC/C,CAEOluB,wBAAAA,CAAyBmuB,GAC9Bp0C,KAAKq7C,WAAWE,oBAAoB50C,KAAKytC,EAC3C,CAEOluB,qCAAAA,CACLmuB,GAEAr0C,KAAKq7C,WAAWG,iCAAiC70C,KAAK0tC,EACxD,CAEOjuB,eAAAA,CAAgBkuB,GACrBt0C,KAAKq7C,WAAW9U,WAAW5/B,KAAK2tC,EAClC,CAEOjuB,gBAAAA,CAAiBkuB,GACtBv0C,KAAKq7C,WAAWpV,YAAYt/B,KAAK4tC,EACnC,GCjPI,SAAUkH,GACdC,EACAC,IAG4C,IAAxCC,MAAMF,EAAiB1gB,cAIzB0gB,EAAiB1gB,YAAc2gB,EAAgB3gB,YAC/C0gB,EAAiB7Y,UAAY8Y,EAAgB9Y,WAMtC6Y,EAAiB7Y,UAAa8Y,EAAgB9Y,aAAc,IACnE6Y,EAAiB7Y,UAAY8Y,EAAgB9Y,UAEjD,CASM,SAAUgZ,GACdH,EACAC,IAG4C,IAAxCC,MAAMF,EAAiB1gB,cAIzB0gB,EAAiB1gB,YAAc2gB,EAAgB3gB,YAC/C0gB,EAAiB5uC,YAAc6uC,EAAgB7uC,YAC/C4uC,EAAiB1uC,UAAY2uC,EAAgB3uC,UAC7C0uC,EAAiB7Y,UAAY8Y,EAAgB9Y,UAC7C6Y,EAAiBxuC,UAAYyuC,EAAgBzuC,UAC7CwuC,EAAiBvuC,QAAUwuC,EAAgBxuC,SAMpCuuC,EAAiB7Y,UAAa8Y,EAAgB9Y,aAAe,IACpE6Y,EAAiB7Y,UAAY8Y,EAAgB9Y,UAC7C6Y,EAAiBxuC,UAAYyuC,EAAgBzuC,UAC7CwuC,EAAiBvuC,QAAUwuC,EAAgBxuC,QAE/C,CC5DM,SAAU2uC,GAAej2C,EAASk2C,GACtCr9C,OAAOC,eAAekH,EAHX,OAGsB,CAC/Bm2C,YAAY,EACZl9C,cAAc,EACdm9C,UAAU,EACVp9C,MAAOk9C,GAEX,CCKM,SAAUG,GAAiBC,EAAU3J,GACzC,MAAM4J,GAAgBzoC,EAAAA,GAAAA,GAAKwoC,GACrBE,EAAsBD,EAActgD,OAC1C,IAAK,IAAI0O,EAAI,EAAGA,EAAI6xC,EAAqB7xC,IAAK,CAC5C,MACM8xC,EAAiBH,EADDC,EAAc5xC,IAE9B+xC,EAAuBD,EAAexgD,OAC5C,IAAK,IAAIsjC,EAAI,EAAGA,EAAImd,EAAsBnd,IAAK,CAC7C,MAAMod,EAAiBF,EAAeld,QAEPrjC,IAA3BygD,EAAUprB,cACZpxB,KAAKw8C,EAAUt/C,MAAMs/C,EAAUvwC,SAAUumC,E,EAKjD,CAEM,SAAUiK,GACdtV,EACA3pB,GAIA,MAAMk/B,EAA0B,WAAa,EAK7CZ,GAAeY,EAAoBvV,EAAc,iBAEjD,MAAMwV,EAAgB,CACpBniC,MAAO,SAAU9X,EAA8B8vC,GAS7C,IAPI1rC,EAAAA,GAAAA,GAAQpE,KAGVA,EAAUA,EAAQ,MAIhB+uB,EAAAA,GAAAA,GAAY/uB,GAIhB,OAAO1C,KAAK0C,EAAQxF,MAAMwF,EAAQuJ,SAAUumC,EAC9C,EAEAoK,gBAAiB,WACf,MAAMC,EA0DN,SACJC,EACAt/B,GAEA,MAAMu/B,EAKF,SACJD,EACAt/B,GAEA,MAAMw/B,GAAmB5zC,EAAAA,GAAAA,GAAOoU,GAAYu1B,IACoB,KAAvD9hB,EAAAA,GAAAA,GAAY6rB,EAAwB/J,MAGvC1f,GAAoC7tB,EAAAA,GAAAA,GACxCw3C,GACCjK,IACQ,CACL3mB,IAAK,4BAAF/rB,OAA8B0yC,EAAY,SAAA1yC,OAC3Cy8C,EAAgB3hD,YAAY+B,KAAI,iBAElCyD,KAAMs8C,GAA0BC,eAChCC,WAAYpK,MAKlB,OAAO1d,GAAiChC,EAC1C,CA3BwB+pB,CAA0BN,EAAiBt/B,GAEjE,OAAOu/B,CACT,CAjEuCH,CAAgB58C,KAAMwd,GACvD,KAAK9V,EAAAA,GAAAA,GAAQm1C,GAA2B,CACtC,MAAMQ,GAAgB73C,EAAAA,GAAAA,GACpBq3C,GACCS,GAAiBA,EAAalxB,MAEjC,MAAM3rB,MACJ,mCAAAJ,OAAmCL,KAAK7E,YAAY+B,KAAI,aAAAmD,OACnDg9C,EAAc13C,KAAK,QAAQxI,QAAQ,MAAO,S,CAGrD,GAQF,OALAu/C,EAAmBtxC,UAAYuxC,GACFxhD,YAAcuhD,EAE3CA,EAAmBa,YAAc//B,EAE1Bk/B,CACT,CA2BO,IAAKO,IAAZ,SAAYA,GACVA,EAAAA,EAAA,uCACAA,EAAAA,EAAA,kCACD,CAHD,CAAYA,KAAAA,GAAyB,K,eC3DrC,MAAMO,GAAwB,CAC5BC,YAAa,8DAEf/+C,OAAO6M,OAAOiyC,IAEd,MAAME,IAAmB,EACnBC,GAAiBpvC,KAAKqvC,IAAI,ENjDO,GMiDuB,EAExDC,GAAM1a,GAAY,CAAEjmC,KAAM,wBAAyB6Y,QAASga,GAAMC,KACxEuJ,GAAkB,CAACskB,KACnB,MAAMC,GAAwB1f,GAC5Byf,GACA,gJAKC,GACA,GACA,GACA,GACA,GACA,GAEHn/C,OAAO6M,OAAOuyC,IAEd,MAAMC,GAAmC,CACvC7gD,KACE,gJAEF+O,SAAU,CAAC,GAqSb,SAAS+xC,GACPC,EACAC,EACAlY,GAC0B,IAA1BmY,EAAAtiD,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAEAuiD,GAAuBpY,GACvB,MAAMqY,GAAgBC,EAAAA,GAAAA,GAAKt+C,KAAKu+C,oBAC1BC,GAAgBvtB,EAAAA,GAAAA,GAAWitB,GAAeA,EAAcA,EAAYO,IAEpEC,EAAU,IAAIT,EAAgB,CAAEt+B,WAAY,GAAIjK,IAAKswB,IAa3D,OAZImY,IACFO,EAAQh2C,UAAYw1C,EAAYS,MAE9B96C,EAAAA,GAAAA,GAAIq6C,EAAa,mBACnBQ,EAAQ5R,aAAeoR,EAAYU,eAGrC5+C,KAAKu+C,mBAAmB53C,KAAK+3C,GAC7BF,EAAcnzC,KAAKrL,MACnBq+C,EAAS1+B,WAAWhZ,KAAK+3C,GACzB1+C,KAAKu+C,mBAAmBlyC,MAEjBmxC,EACT,CAEA,SAASqB,GAAaX,EAAkBlY,GACtCoY,GAAuBpY,GACvB,MAAMqY,GAAgBC,EAAAA,GAAAA,GAAKt+C,KAAKu+C,oBAE1BO,GAAsC,KAAzBh4C,EAAAA,GAAAA,GAAQo3C,GACrBrnC,GACW,IAAfioC,EAAuBZ,EAAcA,EAAYO,IAE7CM,EAAY,IAAI75B,GAAY,CAChCvF,WAAY,GACZjK,IAAKswB,EACLphB,kBAAmBk6B,IAAiD,IAAnCZ,EAAYc,sBAE3Cn7C,EAAAA,GAAAA,GAAIq6C,EAAa,mBACnBa,EAAUjS,aAAeoR,EAAYU,eAGvC,MAAMz5B,EAAgBjc,GAAK2N,GAAOszB,IAAiBlZ,EAAAA,GAAAA,GAAWkZ,EAAQoD,QAmBtE,OAlBAwR,EAAU55B,cAAgBA,EAE1Bk5B,EAAS1+B,WAAWhZ,KAAKo4C,IAEzBp7C,EAAAA,GAAAA,GAAQkT,GAAOszB,IACb,MAAM8U,EAAc,IAAIt6B,GAAY,CAAEhF,WAAY,KAClDo/B,EAAUp/B,WAAWhZ,KAAKs4C,IACtBp7C,EAAAA,GAAAA,GAAIsmC,EAAS,sBACf8U,EAAYr6B,kBAAoBulB,EAAQ6U,oBAGjCn7C,EAAAA,GAAAA,GAAIsmC,EAAS,UACpB8U,EAAYr6B,mBAAoB,GAElC5kB,KAAKu+C,mBAAmB53C,KAAKs4C,GAC7B9U,EAAQ+U,IAAI7zC,KAAKrL,MACjBA,KAAKu+C,mBAAmBlyC,KAAK,IAExBmxC,EACT,CAEA,SAAS2B,GAAazpC,GACpB,OAAe,IAARA,EAAY,GAAK,GAAHrV,OAAMqV,EAC7B,CAEA,SAAS0oC,GAAuB1oC,GAC9B,GAAIA,EAAM,GAAKA,EAAMioC,GAAgB,CACnC,MAAMrxB,EAAa,IAAI7rB,MAErB,kCAAAJ,OAAkCqV,EAAG,iEAAArV,OAEjCs9C,GAAiB,IAIvB,MADArxB,EAAM8yB,sBAAuB,EACvB9yB,C,CAEV,CChaO,MAAM+yB,GAAcjhB,GACzBiF,GACA,GACAic,IACAA,IACAA,IACAA,IACAA,IACAA,KAEF5gD,OAAO6M,OAAO8zC,IAIP,MAAMxF,GAETn7C,OAAO6M,OAAO,CAChBkwB,iBAAiB,EACjBqR,aAAc,EACdI,sBAAsB,EACtBqS,WAAW,EACXjkB,qBAAsBiI,GACtBic,qBAAsB,OACtBjkB,eAAe,EACfC,iBAAiB,IAGNikB,GAAkD/gD,OAAO6M,OAAO,CAC3Em0C,kBAAmBA,KAAe,EAClCC,eAAe,IAGV,IAAKlY,GCvEgBmY,GAAkBC,GD2HxC,SAAUC,KAAgC,IAAtBjhD,EAAAhD,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,QAAaE,EACrC,OAAO,WACL,OAAO8C,CACT,CACF,EAxDA,SAAY4oC,GACVA,EAAAA,EAAA,yCACAA,EAAAA,EAAA,6CACAA,EAAAA,EAAA,iDACAA,EAAAA,EAAA,iDACAA,EAAAA,EAAA,mDACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,6CACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,qEACAA,EAAAA,EAAA,2CACAA,EAAAA,EAAA,oDACAA,EAAAA,EAAA,kDACAA,EAAAA,EAAA,kCACAA,EAAAA,EAAA,6DACD,CAfD,CAAYA,KAAAA,GAAyB,KA0D/B,MAAOsY,GAYX,0BAAOC,CAAoBC,GACzB,MAAMx/C,MACJ,8HAGJ,CAEOu/C,mBAAAA,GACLhgD,KAAKg8B,WAAW,uBAAuB,KACrC,IAAIkkB,EAEJlgD,KAAKmgD,kBAAmB,EACxB,MAAMtM,EAAY7zC,KAAK6zC,UAEvB7zC,KAAKg8B,WAAW,eAAe,KAI7Bla,GAAiB9hB,KAAK,IAGxBA,KAAKg8B,WAAW,qBAAqB,KACnC,IACEh8B,KAAKogD,mBAELz8C,EAAAA,GAAAA,GAAQ3D,KAAKqgD,mBAAoBtN,IAC/B,MAGMuN,EAHetgD,KACnB+yC,GAE+D,sBACjE,IAAIwN,EACJvgD,KAAKg8B,WAAW,GAAD37B,OAAI0yC,EAAY,UAAS,KACtCwN,EAAmBvgD,KAAKwgD,mBACtBzN,EACAuN,EACD,IAEHtgD,KAAKygD,qBAAqB1N,GAAgBwN,CAAgB,G,CAE5D,QACAvgD,KAAK0gD,kB,KAIT,IAAIC,EAA2C,GAmD/C,GAlDA3gD,KAAKg8B,WAAW,qBAAqB,KACnC2kB,EAAiB3J,GAAe,CAC9BzzC,OAAOujB,EAAAA,GAAAA,GAAO9mB,KAAKygD,wBAErBzgD,KAAK4gD,iBAAmB5gD,KAAK4gD,iBAAiBvgD,OAAOsgD,EAAe,IAGtE3gD,KAAKg8B,WAAW,uBAAuB,KAGrC,IAAIt0B,EAAAA,GAAAA,GAAQi5C,KAA4C,IAAzB3gD,KAAKw7B,gBAA2B,CAC7D,MAAMqlB,GVpKgBp9C,EUoKmB,CACvCF,OAAOujB,EAAAA,GAAAA,GAAO9mB,KAAKygD,sBACnB/8C,YAAYojB,EAAAA,GAAAA,GAAO9mB,KAAK8gD,WACxBxZ,eAAgBnC,GAChBgC,YAAa0M,GV9JhBkN,IAJPt9C,GAAU2rB,EAAAA,GAAAA,GAAS3rB,EAAS,CAC1B6jC,eAAgBnC,MAIR5hC,MACRE,EAAQC,WACRD,EAAQ6jC,eACR7jC,EAAQ0jC,cU4JI6Z,EX7IV,SAA4Bv9C,GAMhC,MAAMw9C,EAAmCx9C,EAAQy9C,kBAAkBpH,SAAS,CAC1Ev2C,MAAOE,EAAQF,MACfG,WAAYD,EAAQC,WACpByjC,YAAa1jC,EAAQ0jC,cAEvB,OAAO3hC,EAAAA,GAAAA,GAAIy7C,GAAmCE,GAAiBziD,OAAA2lB,OAAC,CAC9D1jB,KAAM8mC,GAA0B2Z,6BAC7BD,IAEP,CW8H4CE,CAAkB,CAClDH,kBAAmBlhD,KAAKkhD,kBACxB39C,OAAOujB,EAAAA,GAAAA,GAAO9mB,KAAKygD,sBACnB/8C,YAAYojB,EAAAA,GAAAA,GAAO9mB,KAAK8gD,WACxB3Z,YAAa0M,IAEf7zC,KAAK4gD,iBAAmB5gD,KAAK4gD,iBAAiBvgD,OAC5CwgD,EACAG,E,CVlLN,IAA0Bv9C,C,KUwLtBiE,EAAAA,GAAAA,GAAQ1H,KAAK4gD,oBAEX5gD,KAAKy7B,iBACPz7B,KAAKg8B,WAAW,0BAA0B,KACxC,MAAMslB,EtCjLZ,SACJC,GAEA,MAAMC,EAAgB,CAAC,EAMvB,OAJA79C,EAAAA,GAAAA,GAAQ49C,GAAiBj3B,IACvB,MAAMm3B,EAAiB,IAAIp3B,GAAoBC,GAASE,eACxDnG,GAAOm9B,EAAeC,EAAe,IAEhCD,CACT,CsCuK+BE,EACjB56B,EAAAA,GAAAA,GAAO9mB,KAAKygD,uBAEdzgD,KAAK2hD,cAAgBL,CAAU,IAInCthD,KAAKg8B,WAAW,6BAA6B,K,QACV,QAAjC4lB,GAAAztC,EAAAnU,KAAKkhD,mBAAkBW,kBAAU,IAAAD,GAAAA,EAAAv2C,KAAA8I,EAAG,CAClC5Q,OAAOujB,EAAAA,GAAAA,GAAO9mB,KAAKygD,wBAErBzgD,KAAK8hD,8BAA6Bh7B,EAAAA,GAAAA,GAAO9mB,KAAKygD,sBAAsB,MAKrEV,GAAOgC,oCACPr6C,EAAAA,GAAAA,GAAQ1H,KAAK4gD,kBAMd,MAJAV,GAAgB16C,EAAAA,GAAAA,GACdxF,KAAK4gD,kBACJtO,GAAaA,EAAS5sC,UAEnB,IAAIjF,MAAM,wCAADJ,OAC2B6/C,EAAcv6C,KACpD,wC,GAKV,CAMAxK,WAAAA,CAAY6mD,EAAkCtmB,GAJ9C,KAAAklB,iBAA6C,GAC7C,KAAAT,kBAAmB,EAIjB,MAAM8B,EAAsBjiD,KAW5B,GAVAiiD,EAAKC,iBAAiBxmB,GACtBumB,EAAKE,mBACLF,EAAKG,eAAe1mB,GACpBumB,EAAKI,qBAAqBL,EAAiBtmB,GAC3CumB,EAAKK,gBAAgB5mB,GACrBumB,EAAKM,gBAAgB7mB,GACrBumB,EAAKO,oBACLP,EAAKQ,iBAAiB/mB,GACtBumB,EAAKS,sBAAsBhnB,IAEvB73B,EAAAA,GAAAA,GAAI63B,EAAQ,iBACd,MAAM,IAAIj7B,MACR,uQAOJT,KAAKw7B,iBAAkB33B,EAAAA,GAAAA,GAAI63B,EAAQ,mBAC9BA,EAAOF,gBACRqe,GAAsBre,eAC5B,EAjJOukB,GAAAgC,kCAA4C,ECxIzBnC,GD4RhBG,GC5RkCF,GD4R1B,CR1Od,MAKJyC,eAAAA,CAAgB5mB,GACd17B,KAAKg5C,iBAAmB,CAAC,EACzBh5C,KAAK2hD,cAAgB,CAAC,EAEtB3hD,KAAKy7B,iBAAkB53B,EAAAA,GAAAA,GAAI63B,EAAQ,mBAC9BA,EAAOD,gBACRoe,GAAsBpe,gBAKtBz7B,KAAKy7B,kBACPz7B,KAAKu4C,4BAA8BA,GAEvC,CAEOoK,gBAAAA,CAAiB9+B,GACtB,MAAM++B,EAAcxkB,GAClBva,EACA,GACAy7B,IACAA,IACAA,IACAA,IACAA,IACAA,KAGF,OADAsD,EAAYC,sBAAuB,EAC5BD,CACT,CAEOE,gCAAAA,CAAiCj/B,GACtC,OAAO,CACT,CAEOk/B,+BAAAA,CAAgCl/B,GACrC,OAAO,CACT,CAEA01B,uBAAAA,CAEEyJ,EACAC,EACAC,EACAC,GAGA,MAAMC,EAAgBpjD,KAAKqjD,sBACrBC,EAAkBtjD,KAAKujD,mBACvB3L,EAA2B,GACjC,IAAI4L,GAAoB,EAExB,MAAMC,EAAyBzjD,KAAK6tC,GAAG,GACvC,IAAIiF,EAAY9yC,KAAK6tC,GAAG,GAExB,MAAM6V,EAAuBA,KAC3B,MAAM1L,EAAgBh4C,KAAK6tC,GAAG,GAGxBzhB,EAAMpsB,KAAKs7B,qBAAqBkI,0BAA0B,CAC9DC,SAAU0f,EACVzf,OAAQ+f,EACR70C,SAAUopC,EACVrU,SAAU3jC,KAAKi5C,wBAEX3sB,EAAQ,IAAIyrB,GAChB3rB,EACAq3B,EACAzjD,KAAK6tC,GAAG,IAGVvhB,EAAMsrB,eAAiBtM,GAAUsM,GACjC53C,KAAK2jD,WAAWr3B,EAAM,EAGxB,MAAQk3B,GAAmB,CAEzB,GAAIxjD,KAAKsjC,aAAawP,EAAWqQ,GAE/B,YADAO,IAEK,GAAIR,EAAc73C,KAAKrL,MAK5B,OAHA0jD,SAEAV,EAAYh4B,MAAMhrB,KAAMijD,GAEfjjD,KAAKsjC,aAAawP,EAAWsQ,GACtCI,GAAoB,GAEpB1Q,EAAY9yC,KAAK4jD,aACjB5jD,KAAK6jD,kBAAkB/Q,EAAW8E,G,CAOtC53C,KAAK8jD,iBAAiBR,EACxB,CAEAhK,iCAAAA,CAEEH,EACAC,EACAP,GAIA,OAAiB,IAAbA,IAKA74C,KAAKsjC,aAAatjC,KAAK6tC,GAAG,GAAIsL,KAM9Bn5C,KAAK+jD,mBAQP/jD,KAAKgkD,yBACH7K,EACAn5C,KAAKikD,4BAA4B9K,EAAyBC,GAOhE,CAGA6K,2BAAAA,CAEEpgC,EACAqgC,GAEA,MAAMC,EAAcnkD,KAAKokD,sBAAsBvgC,EAASqgC,GAExD,OADgBlkD,KAAKqkD,0BAA0BF,EAEjD,CAEAG,iBAAAA,CAEEnB,EACA54B,GAEA,GAAIvqB,KAAKukD,mCAAmCpB,EAAiB54B,GAE3D,OADoBvqB,KAAK2iD,iBAAiBQ,GAI5C,GAAInjD,KAAKwkD,kCAAkCrB,GAAkB,CAC3D,MAAMsB,EAAUzkD,KAAK4jD,aAErB,OADA5jD,KAAK0kD,eACED,C,CAGT,MAAM,IAAInM,GAAwB,gBACpC,CAEA0L,wBAAAA,CAEEW,EACAp6B,GAEA,OACEvqB,KAAKukD,mCAAmCI,EAAep6B,IACvDvqB,KAAKwkD,kCAAkCG,EAE3C,CAEAJ,kCAAAA,CAEEpB,EACA54B,GAEA,IAAKvqB,KAAK8iD,iCAAiCK,GACzC,OAAO,EAIT,IAAIz7C,EAAAA,GAAAA,GAAQ6iB,GACV,OAAO,EAGT,MAAMq6B,EAAgB5kD,KAAK6tC,GAAG,GAM9B,YAFS9xC,KAFP6N,EAAAA,GAAAA,GAAK2gB,GAAUs6B,GACN7kD,KAAKsjC,aAAashB,EAAeC,IAI9C,CAEAL,iCAAAA,CAEErB,GAEA,QAAKnjD,KAAK+iD,gCAAgCI,IAIRnjD,KAAKsjC,aACrCtjC,KAAK6tC,GAAG,GACRsV,EAGJ,CAEA2B,wBAAAA,CAEE1zB,GAEA,MAAM2zB,EAAY/kD,KAAKglD,mBACjBC,EAAuBjlD,KAAKklD,0BAA0BH,GAC5D,OAAOj7C,GAASm7C,EAAsB7zB,EACxC,CAEAiyB,mBAAAA,GACE,MAAM8B,EAA4BnlD,KAAKolD,mBAEvC,IAAIxX,EAAY5tC,KAAK6tC,GAAG,GACpBxO,EAAI,EACR,OAAa,CACX,MAAMgmB,GAAaz7C,EAAAA,GAAAA,GAAKu7C,GAA4BG,GACjChiB,GAAasK,EAAW0X,KAG3C,QAAmBvpD,IAAfspD,EACF,OAAOA,EAETzX,EAAY5tC,KAAK6tC,GAAGxO,GACpBA,G,CAEJ,CAEA2lB,gBAAAA,GAEE,GAA+B,IAA3BhlD,KAAKq5C,WAAWv9C,OAClB,OAAOs8C,GAET,MAAMmN,EAAoBvlD,KAAKwlD,+BACzBC,EAAczlD,KAAK0lD,qCACnBC,EAAoB3lD,KAAK4lD,mCAE/B,MAAO,CACLjiB,SAAU3jC,KAAK6lD,wBAAwBN,GACvCO,iBAAkBL,EAClBM,OAAQ/lD,KAAK6lD,wBAAwBF,GAEzC,CAEAK,uBAAAA,GACE,MAAMC,EAAoBjmD,KAAKq5C,WACzB6M,EAA0BlmD,KAAKmmD,sBAErC,OAAO3gD,EAAAA,GAAAA,GAAIygD,GAAmB,CAACtiB,EAAUjuB,IAC3B,IAARA,EACK0iC,GAEF,CACLzU,SAAU3jC,KAAK6lD,wBAAwBliB,GACvCmiB,iBAAkBI,EAAwBxwC,GAC1CqwC,OAAQ/lD,KAAK6lD,wBAAwBI,EAAkBvwC,EAAM,MAGnE,CAEA0vC,gBAAAA,GACE,MAAMgB,GAAc5gD,EAAAA,GAAAA,GAAIxF,KAAKgmD,2BAA4B3lB,GAChDrgC,KAAKklD,0BAA0B7kB,KAExC,OAAYnW,EAAAA,GAAAA,GAAQk8B,EACtB,CAEAlB,yBAAAA,CAEEH,GAEA,GAAIA,IAAc3M,GAChB,MAAO,CAAC/U,IAGV,MAAM5Y,EACJs6B,EAAUphB,SAAWohB,EAAUe,iBAAmB17B,GAAK26B,EAAUgB,OAEnE,OAAO/lD,KAAK2hD,cAAcl3B,EAC5B,CAIAo5B,iBAAAA,CAEEl3C,EACA05C,GAKA,OAHKrmD,KAAKsjC,aAAa32B,EAAO02B,KAC5BgjB,EAAa1/C,KAAKgG,GAEb05C,CACT,CAEAC,QAAAA,CAA8BziC,GAC5B,MAAM+zB,EAA2B,GACjC,IAAI6M,EAAUzkD,KAAK6tC,GAAG,GACtB,MAA+C,IAAxC7tC,KAAKsjC,aAAamhB,EAAS5gC,IAChC4gC,EAAUzkD,KAAK4jD,aACf5jD,KAAK6jD,kBAAkBY,EAAS7M,GAGlC,OAAOtM,GAAUsM,EACnB,CAEAW,2BAAAA,CAEEC,EACAztB,EACA0tB,EACAC,EACAC,EACAC,EACAC,GAGA,CAGFuL,qBAAAA,CAEEvgC,EACAqgC,GAWA,MAPyB,CACvB3b,UAH8BvoC,KAAKumD,4BAInC9d,iBAHoChP,EAAAA,GAAAA,GAAMz5B,KAAKmmD,uBAI/Crd,QAASjlB,EACTklB,kBAAmBmb,EAIvB,CACAqC,yBAAAA,GACE,OAAO/gD,EAAAA,GAAAA,GAAIxF,KAAKq5C,YAAamN,GAC3BxmD,KAAK6lD,wBAAwBW,IAEjC,GGzXI,MAMJpE,cAAAA,CAAe1mB,GACb17B,KAAKktC,sBAAuBrpC,EAAAA,GAAAA,GAAI63B,EAAQ,wBACnCA,EAAOwR,qBACR2M,GAAsB3M,qBAE1BltC,KAAK8sC,cAAejpC,EAAAA,GAAAA,GAAI63B,EAAQ,gBAC3BA,EAAOoR,aACR+M,GAAsB/M,aAE1B9sC,KAAKkhD,mBAAoBr9C,EAAAA,GAAAA,GAAI63B,EAAQ,qBAChCA,EAAOwlB,kBACR,IAAItH,GAAqB,CAAE9M,aAAc9sC,KAAK8sC,eAElD9sC,KAAKymD,oBAAsB,IAAIp+C,GACjC,CAEAy5C,4BAAAA,CAAkDv+C,IAChDI,EAAAA,GAAAA,GAAQJ,GAAQwjC,IACd/mC,KAAKg8B,WAAW,GAAD37B,OAAI0mC,EAAS7pC,KAAI,oBAAmB,KACjD,MAAM,YACJ+oC,EAAW,WACXM,EAAU,OACV2N,EAAM,oBACNqH,EAAmB,iCACnBC,EAAgC,wBAChCF,GA8LJ,SAAyBv+C,GAQ7B40C,GAAiB31B,QACjBjf,EAAKmnB,OAAOytB,IACZ,MAAM0J,EAAa1J,GAAiB0J,WAGpC,OADA1J,GAAiB31B,QACLq/B,CACd,CA3MYqL,CAAe3f,IAEnBpjC,EAAAA,GAAAA,GAAQsiC,GAAc2U,IACpB,MAAM+L,EAA2B,IAAjB/L,EAASllC,IAAY,GAAKklC,EAASllC,IACnD1V,KAAKg8B,WAAW,GAAD37B,OAAIgnB,GAAqBuzB,IAASv6C,OAAGsmD,IAAW,KAC7D,MAAMC,EAAS5mD,KAAKkhD,kBAAkBnG,6BAA6B,CACjEpC,eAAgBiC,EAASllC,IACzB3Y,KAAMgqC,EACN+F,aAAc8N,EAAS9N,cAAgB9sC,KAAK8sC,aAC5C3nB,cAAey1B,EAASz1B,cACxB+nB,qBAAsBltC,KAAKktC,uBAGvBjiC,EAAM6tC,GACV94C,KAAK6mD,oBAAoB9f,EAAS7pC,MF/D1B,IEiER09C,EAASllC,KAEX1V,KAAK8mD,eAAe77C,EAAK27C,EAAO,GAChC,KAGJjjD,EAAAA,GAAAA,GAAQ4iC,GAAaqU,IACnB56C,KAAK+mD,qBACHhgB,EACA6T,EAASllC,IFxEG,IE0EZ,aACAklC,EAAS9N,aACTzlB,GAAqBuzB,GACtB,KAGHj3C,EAAAA,GAAAA,GAAQuwC,GAAS0G,IACf56C,KAAK+mD,qBACHhgB,EACA6T,EAASllC,IFpFK,IEsFd,SACAklC,EAAS9N,aACTzlB,GAAqBuzB,GACtB,KAGHj3C,EAAAA,GAAAA,GAAQ43C,GAAsBX,IAC5B56C,KAAK+mD,qBACHhgB,EACA6T,EAASllC,IACT8jC,GACA,sBACAoB,EAAS9N,aACTzlB,GAAqBuzB,GACtB,KAGHj3C,EAAAA,GAAAA,GAAQ63C,GAAmCZ,IACzC56C,KAAK+mD,qBACHhgB,EACA6T,EAASllC,IACTgkC,GACA,mCACAkB,EAAS9N,aACTzlB,GAAqBuzB,GACtB,KAGHj3C,EAAAA,GAAAA,GAAQ23C,GAA0BV,IAChC56C,KAAK+mD,qBACHhgB,EACA6T,EAASllC,IACT+jC,GACA,0BACAmB,EAAS9N,aACTzlB,GAAqBuzB,GACtB,GACD,GACF,GAEN,CAEAmM,oBAAAA,CAEEhqD,EACA47C,EACAqO,EACAna,EACAoa,EACAC,GAEAlnD,KAAKg8B,WAAW,GAAD37B,OACV6mD,GAAa7mD,OAAsB,IAAnBs4C,EAAuB,GAAKA,IAC/C,KACE,MAAMiO,EAAS5mD,KAAKkhD,kBAAkBhG,0BAA0B,CAC9DvC,iBACA57C,OACA+vC,aAAcma,GAAoBjnD,KAAK8sC,aACvCI,qBAAsBltC,KAAKktC,qBAC3BL,aAEI5hC,EAAM6tC,GACV94C,KAAK6mD,oBAAoB9pD,EAAKG,MAC9B8pD,EACArO,GAEF34C,KAAK8mD,eAAe77C,EAAK27C,EAAO,GAGtC,CAGA9N,2BAAAA,CAEEJ,EACA1S,GAGA,OAAO8S,GADwB94C,KAAKwlD,+BAGlC9M,EACA1S,EAEJ,CAEAmhB,kBAAAA,CAAwCl8C,GACtC,OAAOjL,KAAKymD,oBAAoBpnC,IAAIpU,EACtC,CAGA67C,cAAAA,CAAoC77C,EAAapM,GAC/CmB,KAAKymD,oBAAoB37C,IAAIG,EAAKpM,EACpC,GO1KI,MAoBJ0jD,eAAAA,CAAqC7mB,GAUnC,GATA17B,KAAKonD,UAAY,GAGjBpnD,KAAKu/C,UAAa7jB,EAAe6jB,UAEjCv/C,KAAKw/C,sBAAuB37C,EAAAA,GAAAA,GAAI63B,EAAQ,wBACnCA,EAAO8jB,qBACR3F,GAAsB2F,qBAErBx/C,KAAKu/C,UAOR,GAAI,QAAQtmC,KAAKjZ,KAAKw/C,sBAChBx/C,KAAKy7B,iBACPz7B,KAAKqnD,yBAA2BxL,GAChC77C,KAAKsnD,wBAA0BzL,GAC/B77C,KAAKunD,YAAcxpB,GAAAA,EACnB/9B,KAAKwnD,uBAAyBxnD,KAAKynD,qCAEnCznD,KAAKqnD,yBAA2BtpB,GAAAA,EAChC/9B,KAAKsnD,wBAA0BvpB,GAAAA,EAC/B/9B,KAAKunD,YAAcvnD,KAAK0nD,gBACxB1nD,KAAKwnD,uBAAyBxnD,KAAK2nD,wCAEhC,GAAI,cAAc1uC,KAAKjZ,KAAKw/C,sBAC7Bx/C,KAAKy7B,iBACPz7B,KAAKqnD,yBAAgC5L,GACrCz7C,KAAKsnD,wBAA+B7L,GACpCz7C,KAAKunD,YAAcxpB,GAAAA,EACnB/9B,KAAKwnD,uBACHxnD,KAAK4nD,2CAEP5nD,KAAKqnD,yBAA2BtpB,GAAAA,EAChC/9B,KAAKsnD,wBAA0BvpB,GAAAA,EAC/B/9B,KAAKunD,YAAcvnD,KAAK6nD,sBACxB7nD,KAAKwnD,uBACHxnD,KAAK8nD,6CAEJ,KAAI,QAAQ7uC,KAAKjZ,KAAKw/C,sBAM3B,MAAM/+C,MAAM,kDAADJ,OACyCq7B,EAAO8jB,qBAAoB,MAN/Ex/C,KAAKqnD,yBAA2BtpB,GAAAA,EAChC/9B,KAAKsnD,wBAA0BvpB,GAAAA,EAC/B/9B,KAAKunD,YAAcxpB,GAAAA,EACnB/9B,KAAKwnD,uBAAyBzpB,GAAAA,C,MApChC/9B,KAAK+nD,yBAA2BhqB,GAAAA,EAChC/9B,KAAKgoD,sBAAwBjqB,GAAAA,EAC7B/9B,KAAKioD,gBAAkBlqB,GAAAA,EACvB/9B,KAAKkoD,mBAAqBnqB,GAAAA,EAC1B/9B,KAAKunD,YAAcxpB,GAAAA,CAuCvB,CAEA6pB,wCAAAA,CAEEllD,GAEAA,EAAQylD,SAAW,CACjBntB,YAAaskB,IACbzc,UAAWyc,IAEf,CAEAwI,uCAAAA,CAEEplD,GAEAA,EAAQylD,SAAW,CAKjBntB,YAAah7B,KAAK6tC,GAAG,GAAG7S,YACxB6H,UAAWyc,IAEf,CAEAmI,kCAAAA,CAAwD/kD,GACtDA,EAAQylD,SAAW,CACjBntB,YAAaskB,IACbtyC,UAAWsyC,IACXxyC,YAAawyC,IACbzc,UAAWyc,IACXnyC,QAASmyC,IACTpyC,UAAWoyC,IAEf,CAOAqI,iCAAAA,CAAuDjlD,GACrD,MAAMkrC,EAAY5tC,KAAK6tC,GAAG,GAC1BnrC,EAAQylD,SAAW,CACjBntB,YAAa4S,EAAU5S,YACvBhuB,UAAW4gC,EAAU5gC,UACrBF,YAAa8gC,EAAU9gC,YACvB+1B,UAAWyc,IACXnyC,QAASmyC,IACTpyC,UAAWoyC,IAEf,CAEAyI,wBAAAA,CAA8CK,GAC5C,MAAM1lD,EAAmB,CACvBxF,KAAMkrD,EACNn8C,SAAUvN,OAAO2pD,OAAO,OAG1BroD,KAAKwnD,uBAAuB9kD,GAC5B1C,KAAKonD,UAAUzgD,KAAKjE,EACtB,CAEAslD,qBAAAA,GACEhoD,KAAKonD,UAAU/6C,KACjB,CAEAq7C,eAAAA,CAAqCY,GAEnC,MAAMC,EAAYvoD,KAAK6tC,GAAG,GACpB13B,EAAMmyC,EAAYH,SAIpBhyC,EAAI6kB,aAAeutB,EAAUvtB,eAAgB,GAC/C7kB,EAAI0sB,UAAY0lB,EAAU1lB,UAC1B1sB,EAAIhJ,QAAUo7C,EAAUp7C,QACxBgJ,EAAIjJ,UAAYq7C,EAAUr7C,YAI1BiJ,EAAI6kB,YAAcskB,IAClBnpC,EAAInJ,UAAYsyC,IAChBnpC,EAAIrJ,YAAcwyC,IAEtB,CAEAuI,qBAAAA,CAA2CS,GACzC,MAAMC,EAAYvoD,KAAK6tC,GAAG,GAEpB13B,EAAMmyC,EAAYH,SAIpBhyC,EAAI6kB,aAAeutB,EAAUvtB,eAAgB,EAC/C7kB,EAAI0sB,UAAY0lB,EAAU1lB,UAI1B1sB,EAAI6kB,YAAcskB,GAEtB,CAEA2I,eAAAA,CAEEh9C,EACAu9C,GAEA,MAAMC,EAAUzoD,KAAKonD,UAAUpnD,KAAKonD,UAAUtrD,OAAS,GNhJrD,IACJsK,EACAuG,EACA+7C,EADA/7C,EM+I4B67C,EN9I5BE,EM8I2Cz9C,ON5INlP,KAJrCqK,EMgJmBqiD,GN5IVx8C,SAASy8C,GAChBtiD,EAAK6F,SAASy8C,GAAiB,CAAC/7C,GAEhCvG,EAAK6F,SAASy8C,GAAe/hD,KAAKgG,GM2IlC3M,KAAKqnD,yBAAyBoB,EAAQN,SAAgBK,EACxD,CAEAN,kBAAAA,CAEES,EACAhlB,GAEA,MAAMilB,EAAa5oD,KAAKonD,UAAUpnD,KAAKonD,UAAUtrD,OAAS,IN/IxD,SACJsK,EACAu9B,EACAklB,QAEgC9sD,IAA5BqK,EAAK6F,SAAS03B,GAChBv9B,EAAK6F,SAAS03B,GAAY,CAACklB,GAE3BziD,EAAK6F,SAAS03B,GAAUh9B,KAAKkiD,EAEjC,CMsIIC,CAAqBF,EAAYjlB,EAAUglB,GAE3C3oD,KAAKsnD,wBAAwBsB,EAAWT,SAAWQ,EAAcR,SACnE,CAEAY,4BAAAA,GAKE,IAAIt3B,EAAAA,GAAAA,GAAYzxB,KAAKgpD,2BAA4B,CAC/C,MAAMC,EAA+BxM,GACnCz8C,KAAK6zC,WACLlgC,EAAAA,GAAAA,GAAK3T,KAAKygD,uBAGZ,OADAzgD,KAAKgpD,0BAA4BC,EAC1BA,C,CAGT,OAAYjpD,KAAKgpD,yBACnB,CAEAE,wCAAAA,GAKE,IAAIz3B,EAAAA,GAAAA,GAAYzxB,KAAKmpD,uCAAwC,CAC3D,MAAMC,EJnKN,SACJjiB,EACA3pB,EACA6rC,GAIA,MAAM3M,EAA0B,WAAa,EAK7CZ,GAAeY,EAAoBvV,EAAc,6BAEjD,MAAMmiB,EAAoB5qD,OAAO2pD,OAAOgB,EAAgBj+C,WAQxD,OAPAzH,EAAAA,GAAAA,GAAQ6Z,GAAYmmB,IAClB2lB,EAAkB3lB,GAAYuY,EAAY,KAG5CQ,EAAmBtxC,UAAYk+C,GACFnuD,YAAcuhD,EAEpCA,CACT,CI4I6B6M,CACrBvpD,KAAK6zC,WACLlgC,EAAAA,GAAAA,GAAK3T,KAAKygD,sBACVzgD,KAAK+oD,gCAGP,OADA/oD,KAAKmpD,sCAAwCC,EACtCA,C,CAGT,OAAYppD,KAAKmpD,qCACnB,CAEA3D,4BAAAA,GACE,MAAMjd,EAAYvoC,KAAKq5C,WACvB,OAAO9Q,EAAUA,EAAUzsC,OAAS,EACtC,CAEA8pD,gCAAAA,GACE,MAAMrd,EAAYvoC,KAAKq5C,WACvB,OAAO9Q,EAAUA,EAAUzsC,OAAS,EACtC,CAEA4pD,kCAAAA,GACE,MAAMjd,EAAkBzoC,KAAKmmD,sBAC7B,OAAO1d,EAAgBA,EAAgB3sC,OAAS,EAClD,GCtQI,MAKJqmD,gBAAAA,GACEniD,KAAKwpD,UAAY,GACjBxpD,KAAKypD,gBAAkB,EACvBzpD,KAAKi9B,SAAW,CAClB,CAEA,SAAIjgC,CAAM0sD,GAGR,IAA8B,IAA1B1pD,KAAKmgD,iBACP,MAAM1/C,MAAM,oFAMdT,KAAKgc,QACLhc,KAAKwpD,UAAYE,EACjB1pD,KAAKypD,gBAAkBC,EAAS5tD,MAClC,CAEA,SAAIkB,GACF,OAAOgD,KAAKwpD,SACd,CAGA5F,UAAAA,GACE,OAAI5jD,KAAKi9B,SAAWj9B,KAAKwpD,UAAU1tD,OAAS,GAC1CkE,KAAK0kD,eACE1kD,KAAK6tC,GAAG,IAERwR,EAEX,CAIAxR,EAAAA,CAAwB9zB,GACtB,MAAM4vC,EAAY3pD,KAAKi9B,QAAUljB,EACjC,OAAI4vC,EAAY,GAAK3pD,KAAKypD,iBAAmBE,EACpCtK,GAEAr/C,KAAKwpD,UAAUG,EAE1B,CAEAjF,YAAAA,GACE1kD,KAAKi9B,SACP,CAEAsmB,gBAAAA,GACE,OAAOvjD,KAAKi9B,OACd,CAEA6mB,gBAAAA,CAAsChuC,GACpC9V,KAAKi9B,QAAUnnB,CACjB,CAEA8zC,eAAAA,GACE5pD,KAAKi9B,SAAW,CAClB,CAEA4sB,qBAAAA,GACE7pD,KAAKi9B,QAAUj9B,KAAKwpD,UAAU1tD,OAAS,CACzC,CAEAguD,gBAAAA,GACE,OAAO9pD,KAAKujD,kBACd,GCdI,MAeJlB,oBAAAA,CACEL,EACAtmB,GAiBA,GAfA17B,KAAK6zC,UAAY7zC,KAAK7E,YAAY+B,KAElC8C,KAAK+pD,oBAAsB,CAAC,EAC5B/pD,KAAK6mD,oBAAsB,CAAC,EAC5B7mD,KAAKgqD,iBAAmB,IACxBhqD,KAAKsjC,aAAelK,GACpBp5B,KAAKiqD,WAAa,EAElBjqD,KAAKqgD,kBAAoB,GACzBrgD,KAAK8gD,UAAY,CAAC,EAClB9gD,KAAKkqD,oBAAsB,GAC3BlqD,KAAKq5C,WAAa,GAClBr5C,KAAKmmD,sBAAwB,GAC7BnmD,KAAKygD,qBAAuB,CAAC,GAEzB58C,EAAAA,GAAAA,GAAI63B,EAAQ,qBACd,MAAMj7B,MACJ,oLAMJ,IAAIqG,EAAAA,GAAAA,GAAQk7C,GAAkB,CAI5B,IAAIt6C,EAAAA,GAAAA,GAAQs6C,GACV,MAAMvhD,MACJ,+IAMJ,GAAyD,kBAA7CuhD,EAA0B,GAAGhnB,YACvC,MAAMv6B,MACJ,iL,CAON,IAAIqG,EAAAA,GAAAA,GAAQk7C,GACVhiD,KAAK8gD,WAAYv3C,EAAAA,GAAAA,GACfy4C,GACA,CAAC7vB,EAAKtO,KACJsO,EAAItO,EAAQ3mB,MAAQ2mB,EACbsO,IAET,CAAC,QAEE,IACLtuB,EAAAA,GAAAA,GAAIm+C,EAAiB,UACrBh5C,IAAMkhB,EAAAA,GAAAA,IAAQpD,EAAAA,GAAAA,GAAak7B,EAAiBzqB,QAASoD,IACrD,CACA,MAAMrD,GAAgBpN,EAAAA,GAAAA,IAAQpD,EAAAA,GAAAA,GAAak7B,EAAiBzqB,QACtD4yB,EAAetgC,GAAKyN,GAC1Bt3B,KAAK8gD,WAAiBv3C,EAAAA,GAAAA,GACpB4gD,GACA,CAACh4B,EAAKtO,KACJsO,EAAItO,EAAQ3mB,MAAQ2mB,EACbsO,IAET,CAAC,E,KAEE,MAAIi4B,EAAAA,GAAAA,GAASpI,GAGlB,MAAM,IAAIvhD,MACR,0IAHFT,KAAK8gD,WAAYrnB,EAAAA,GAAAA,GAAMuoB,E,CAUzBhiD,KAAK8gD,UAAe,IAAIzd,GAExB,MAAM/L,GAAgBzzB,EAAAA,GAAAA,GAAIm+C,EAAiB,UACvC93B,EAAAA,GAAAA,IAAQpD,EAAAA,GAAAA,GAAak7B,EAAiBzqB,SACtCzQ,EAAAA,GAAAA,GAAOk7B,GACLqI,EAAwBrhD,GAAMsuB,GAAgBgzB,IAClD5iD,EAAAA,GAAAA,GAAQ4iD,EAAiBrwB,mBAG3Bj6B,KAAKsjC,aAAe+mB,EAChBjxB,GACAN,GAKJS,IAAkBzS,EAAAA,GAAAA,GAAO9mB,KAAK8gD,WAChC,CAEAyJ,UAAAA,CAEE5mB,EACA6mB,EACA9uB,GAEA,GAAI17B,KAAKmgD,iBACP,MAAM1/C,MACJ,iBAAAJ,OAAiBsjC,EAAQ,kLAI7B,MAAMgc,GAAyB97C,EAAAA,GAAAA,GAAI63B,EAAQ,iBACtCA,EAAOikB,cACRF,GAAoBE,cAClBD,GAAoB77C,EAAAA,GAAAA,GAAI63B,EAAQ,qBACjCA,EAAOgkB,kBACRD,GAAoBC,kBAIlB+K,EACJzqD,KAAKgqD,kBAAqBU,GAM5B,IAAIC,EA0CJ,OA9CA3qD,KAAKgqD,mBACLhqD,KAAK+pD,oBAAoBU,GAAa9mB,EACtC3jC,KAAK6mD,oBAAoBljB,GAAY8mB,EAOnCE,GADqB,IAAnB3qD,KAAKu/C,UACa,WAIlB,IACEv/C,KAAK4qD,0BAA0BH,EAAW9mB,EAAU3jC,KAAKiqD,YAAY,QAAAz+C,EAAA3P,UAAAC,OAHpEivB,EAAU,IAAAlkB,MAAA2E,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAVqf,EAAUrf,GAAA7P,UAAA6P,GAIX8+C,EAAKx/B,MAAMhrB,KAAM+qB,GACjB,MAAM8/B,EAAM7qD,KAAKonD,UAAUpnD,KAAKonD,UAAUtrD,OAAS,GAEnD,OADAkE,KAAKunD,YAAYsD,GACVA,C,CACP,MAAOvhD,GACP,OAAOtJ,KAAK8qD,gBAAgBxhD,EAAGq2C,EAAeD,E,CAC9C,QACA1/C,KAAK+qD,wB,CAET,EAEoB,WAIlB,IACE/qD,KAAK4qD,0BAA0BH,EAAW9mB,EAAU3jC,KAAKiqD,YAAY,QAAAe,EAAAnvD,UAAAC,OAHpEivB,EAAU,IAAAlkB,MAAAmkD,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAVlgC,EAAUkgC,GAAApvD,UAAAovD,GAIX,OAAOT,EAAKx/B,MAAMhrB,KAAM+qB,E,CACxB,MAAOzhB,GACP,OAAOtJ,KAAK8qD,gBAAgBxhD,EAAGq2C,EAAeD,E,CAC9C,QACA1/C,KAAK+qD,wB,CAET,EAGwDrsD,OAAO2lB,OAC/DsmC,EACA,CAAEhnB,WAAU2c,sBAAuBkK,GAIvC,CAEAM,eAAAA,CAEExhD,EACA4hD,EACAxL,GAEA,MAAMyL,EAAgD,IAA3BnrD,KAAKq5C,WAAWv9C,OAKrCsvD,EACJF,IAAwBlrD,KAAK+jD,kBAAoB/jD,KAAKy7B,gBAExD,GAAIic,GAAuBpuC,GAAI,CAC7B,MAAM+hD,EAAkB/hD,EACxB,GAAI8hD,EAAe,CACjB,MAAMhI,EAAgBpjD,KAAKqjD,sBAC3B,GAAIrjD,KAAK8kD,yBAAyB1B,GAAgB,CAEhD,GADAiI,EAAWzT,eAAiB53C,KAAKsmD,SAASlD,GACtCpjD,KAAKu/C,UAAW,CAClB,MAAM+L,EACJtrD,KAAKonD,UAAUpnD,KAAKonD,UAAUtrD,OAAS,GAEzC,OADAwvD,EAAiBC,eAAgB,EAC1BD,C,CAEP,OAAO5L,EAAkBp2C,E,CAG3B,GAAItJ,KAAKu/C,UAAW,CAClB,MAAM+L,EACJtrD,KAAKonD,UAAUpnD,KAAKonD,UAAUtrD,OAAS,GACzCwvD,EAAiBC,eAAgB,EACjCF,EAAWC,iBAAmBA,C,CAGhC,MAAMD,C,CAEH,GAAIF,EAKT,OAHAnrD,KAAK6pD,wBAGEnK,EAAkBp2C,GAGzB,MAAM+hD,C,CAIR,MAAM/hD,CAEV,CAGAkiD,cAAAA,CAEEC,EACAzlB,GAEA,MAAM/6B,EAAMjL,KAAK84C,4BX9SK,IW8SmC9S,GACzD,OAAOhmC,KAAK0rD,oBAAoBD,EAAmBzlB,EAAY/6B,EACjE,CAEAygD,mBAAAA,CAEED,EACAzlB,EACA/6B,GAEA,IACIiV,EADAgjC,EAAgBljD,KAAKmnD,mBAAmBl8C,GAE5C,GAAiC,oBAAtBwgD,EAAkC,CAC3CvrC,EAASurC,EAAkBhN,IAC3B,MAAMx1C,EAAYwiD,EAAkBle,KAEpC,QAAkBxxC,IAAdkN,EAAyB,CAC3B,MAAM0iD,EAAuBzI,EAC7BA,EAAgBA,IACPj6C,EAAUoC,KAAKrL,OAAS2rD,EAAqBtgD,KAAKrL,K,OAI7DkgB,EAASurC,EAGX,IAAiC,IAA7BvI,EAAc73C,KAAKrL,MACrB,OAAOkgB,EAAO7U,KAAKrL,KAGvB,CAEA4rD,kBAAAA,CAEEjT,EACA8S,GAEA,MAAMI,EAAQ7rD,KAAK84C,4BACjBU,GACAb,GAEF,OAAO34C,KAAK8rD,wBACVnT,EACA8S,EACAI,EAEJ,CAEAC,uBAAAA,CAEEnT,EACA8S,EACAxgD,GAEA,IACIiV,EADAgjC,EAAgBljD,KAAKmnD,mBAAmBl8C,GAE5C,GAAiC,oBAAtBwgD,EAAkC,CAC3CvrC,EAASurC,EAAkBhN,IAC3B,MAAMx1C,EAAYwiD,EAAkBle,KAEpC,QAAkBxxC,IAAdkN,EAAyB,CAC3B,MAAM0iD,EAAuBzI,EAC7BA,EAAgBA,IACPj6C,EAAUoC,KAAKrL,OAAS2rD,EAAqBtgD,KAAKrL,K,OAI7DkgB,EAASurC,EAGX,IAA6C,IAA9BvI,EAAe73C,KAAKrL,MASjC,MAAMA,KAAK+rD,wBACTpT,EACAvM,GAAUI,qBACkBif,EAAmBO,SAZA,CACjD,IAAInT,EAAW74C,KAAKisD,mBAAmB/rC,GACvC,MAC2C,IAA9BgjC,EAAe73C,KAAKrL,QAClB,IAAb64C,GAEAA,EAAW74C,KAAKisD,mBAAmB/rC,E,CAevClgB,KAAKu4C,4BACHv4C,KAAK4rD,mBACL,CAACjT,EAAgB8S,GACZvI,EACL1J,GACAb,EACAlP,GAEJ,CAEAyiB,0BAAAA,CAEEvT,EACAl1C,GAEA,MAAMooD,EAAQ7rD,KAAK84C,4BACjBY,GACAf,GAEF34C,KAAKmsD,gCAAgCxT,EAAgBl1C,EAASooD,EAChE,CAEAM,+BAAAA,CAEExT,EACAl1C,EACAwH,GAEA,MAAMiV,EAASzc,EAAQg7C,IACjB/1C,EAAYjF,EAAQk7C,IAK1B,IAA+C,IAHX3+C,KAAKmnD,mBAAmBl8C,GAG5BI,KAAKrL,MAkCnC,MAAMA,KAAK+rD,wBACTpT,EACAvM,GAAUK,oCACVhpC,EAAQuoD,SArCyC,CAC9B9rC,EAAQ7U,KAAKrL,MAIlC,MAAMosD,EAAyBA,IACtBpsD,KAAKsjC,aAAatjC,KAAK6tC,GAAG,GAAInlC,GAIvC,MAAoD,IAA7C1I,KAAKsjC,aAAatjC,KAAK6tC,GAAG,GAAInlC,IAGnC1I,KAAKqsD,QAAQ3jD,GAEQwX,EAAQ7U,KAAKrL,MAIpCA,KAAKu4C,4BACHv4C,KAAKssD,4BACL,CACE3T,EACAjwC,EACA0jD,EACAlsC,EACAypB,IAEFyiB,EACA1S,GACAf,EACAhP,G,CASN,CAEA4iB,YAAAA,CAEE5T,EACA8S,GAEA,MAAMI,EAAQ7rD,KAAK84C,4BXzdC,IWydqCH,GACzD,OAAO34C,KAAKwsD,kBAAkB7T,EAAgB8S,EAAmBI,EACnE,CAEAW,iBAAAA,CAEE7T,EACA8S,EACAxgD,GAEA,IACIiV,EADAusC,EAAoBzsD,KAAKmnD,mBAAmBl8C,GAEhD,GAAiC,oBAAtBwgD,EAAkC,CAC3CvrC,EAASurC,EAAkBhN,IAC3B,MAAMx1C,EAAYwiD,EAAkBle,KAEpC,QAAkBxxC,IAAdkN,EAAyB,CAC3B,MAAM0iD,EAAuBc,EAC7BA,EAAoBA,IACXxjD,EAAUoC,KAAKrL,OAAS2rD,EAAqBtgD,KAAKrL,K,OAI7DkgB,EAASurC,EAGX,IAAI5S,GAAW,EACf,MAAwC,IAAjC4T,EAAkBphD,KAAKrL,QAA+B,IAAb64C,GAC9CA,EAAW74C,KAAKisD,mBAAmB/rC,GAIrClgB,KAAKu4C,4BACHv4C,KAAKusD,aACL,CAAC5T,EAAgB8S,GACZgB,EX5fa,IW8flB9T,EACAvP,GAMAyP,EAEJ,CAEA6T,oBAAAA,CAEE/T,EACAl1C,GAEA,MAAMooD,EAAQ7rD,KAAK84C,4BACjBW,GACAd,GAEF34C,KAAK2sD,0BAA0BhU,EAAgBl1C,EAASooD,EAC1D,CAEAc,yBAAAA,CAEEhU,EACAl1C,EACAwH,GAEA,MAAMiV,EAASzc,EAAQg7C,IACjB/1C,EAAYjF,EAAQk7C,IAI1B,IAAwC,IAHX3+C,KAAKmnD,mBAAmBl8C,GAG5BI,KAAKrL,MAAgB,CAC5CkgB,EAAO7U,KAAKrL,MAEZ,MAAMosD,EAAyBA,IACtBpsD,KAAKsjC,aAAatjC,KAAK6tC,GAAG,GAAInlC,GAGvC,MAAoD,IAA7C1I,KAAKsjC,aAAatjC,KAAK6tC,GAAG,GAAInlC,IAGnC1I,KAAKqsD,QAAQ3jD,GAEbwX,EAAO7U,KAAKrL,MAIdA,KAAKu4C,4BACHv4C,KAAKssD,4BACL,CACE3T,EACAjwC,EACA0jD,EACAlsC,EACAqpB,IAEF6iB,EACA3S,GACAd,EACApP,G,CAGN,CAEA+iB,2BAAAA,CAEE3T,EACAjwC,EACA0jD,EACAlsC,EACA0sC,GAEA,KAAOR,KAGLpsD,KAAKqsD,QAAQ3jD,GACbwX,EAAO7U,KAAKrL,MASdA,KAAKu4C,4BACHv4C,KAAKssD,4BACL,CACE3T,EACAjwC,EACA0jD,EACAlsC,EACA0sC,GAEFR,EACA1S,GACAf,EACAiU,EAEJ,CAEAX,kBAAAA,CAAwC/rC,GACtC,MAAM2sC,EAAkB7sD,KAAK8pD,mBAM7B,OALA5pC,EAAO7U,KAAKrL,MACWA,KAAK8pD,mBAIJ+C,CAC1B,CAEAC,UAAAA,CAEEC,EACA/mB,GAEA,MAAM6lB,EAAQ7rD,KAAK84C,4BXvnBD,IWunBqC9S,GACjDnvB,GAAO/P,EAAAA,GAAAA,GAAQimD,GAAcA,EAAaA,EAAWtO,IAGrDuO,EADShtD,KAAKmnD,mBAAmB0E,GACXxgD,KAAKrL,KAAM6W,GACvC,QAAqB9a,IAAjBixD,EAEF,OAD+Bn2C,EAAKm2C,GACX9N,IAAI7zC,KAAKrL,MAEpCA,KAAKitD,oBACHjnB,EACC+mB,EAAqCf,QAE1C,CAEAjB,sBAAAA,GAOE,GANA/qD,KAAKq5C,WAAWhtC,MAChBrM,KAAKmmD,sBAAsB95C,MAG3BrM,KAAKgoD,wBAE0B,IAA3BhoD,KAAKq5C,WAAWv9C,SAA0C,IAA1BkE,KAAKktD,iBAA4B,CACnE,MAAMC,EAAoBntD,KAAK6tC,GAAG,GAC5B/V,EAAS93B,KAAKs7B,qBAAqBuI,8BAA8B,CACrEC,eAAgBqpB,EAChBxpB,SAAU3jC,KAAKi5C,wBAEjBj5C,KAAK2jD,WACH,IAAIzL,GAA2BpgB,EAAQq1B,G,CAG7C,CAEAC,eAAAA,CAEEC,EACA33C,EACAjS,GAEA,IAAIolD,EACJ,IACE,MAAM99B,OAAmBhvB,IAAZ0H,EAAwBA,EAAQ6pD,UAAOvxD,EASpD,OARAiE,KAAKiqD,WAAav0C,EAClBmzC,EAAawE,EAAWriC,MAAMhrB,KAAM+qB,GACpC/qB,KAAKkoD,mBACHW,OACY9sD,IAAZ0H,QAA2C1H,IAAlB0H,EAAQsgB,MAC7BtgB,EAAQsgB,MACRspC,EAAW1pB,UAEVklB,C,CACP,MAAOv/C,GACP,MAAMtJ,KAAKutD,qBAAqBjkD,EAAG7F,EAAS4pD,EAAW1pB,S,CAE3D,CAEA4pB,oBAAAA,CAEEjkD,EACA7F,EACAkgC,GAYA,MAVI+T,GAAuBpuC,SAA6BvN,IAAvBuN,EAAEgiD,mBACjCtrD,KAAKkoD,mBACH5+C,EAAEgiD,sBACUvvD,IAAZ0H,QAA2C1H,IAAlB0H,EAAQsgB,MAC7BtgB,EAAQsgB,MACR4f,UAGCr6B,EAAEgiD,kBAELhiD,CACR,CAEAkkD,eAAAA,CAEE3pC,EACAnO,EACAjS,GAEA,IAAI+kD,EACJ,IACE,MAAM5a,EAAY5tC,KAAK6tC,GAAG,IACoB,IAA1C7tC,KAAKsjC,aAAasK,EAAW/pB,IAC/B7jB,KAAK0kD,eACL8D,EAAgB5a,GAEhB5tC,KAAKytD,qBAAqB5pC,EAAS+pB,EAAWnqC,E,CAEhD,MAAOiqD,GACPlF,EAAgBxoD,KAAK2tD,wBACnB9pC,EACAnO,EACAg4C,E,CAUJ,OANA1tD,KAAKioD,qBACSlsD,IAAZ0H,QAA2C1H,IAAlB0H,EAAQsgB,MAC7BtgB,EAAQsgB,MACRF,EAAQ3mB,KACZsrD,GAEKA,CACT,CAEAiF,oBAAAA,CAEE5pC,EACA+pB,EACAnqC,GAEA,IAAI2oB,EACJ,MAAM4rB,EAAgBh4C,KAAK6tC,GAAG,GAW9B,MATEzhB,OADcrwB,IAAZ0H,GAAyBA,EAAQuoD,QAC7BvoD,EAAQuoD,QAERhsD,KAAKs7B,qBAAqBkI,0BAA0B,CACxDC,SAAU5f,EACV6f,OAAQkK,EACRh/B,SAAUopC,EACVrU,SAAU3jC,KAAKi5C,wBAGbj5C,KAAK2jD,WACT,IAAI5L,GAAyB3rB,EAAKwhB,EAAWoK,GAEjD,CAEA2V,uBAAAA,CAEE9pC,EACAnO,EACAg4C,GAIA,IACE1tD,KAAKy7B,iBAEqB,6BAA1BiyB,EAAiBxwD,MAChB8C,KAAK+jD,iBAeN,MAAM2J,EAdN,CACA,MAAMnjC,EAAUvqB,KAAKikD,4BAAiCpgC,EAASnO,GAC/D,IACE,OAAO1V,KAAKskD,kBAAuBzgC,EAAS0G,E,CAC5C,MAAOqjC,GACP,MAAIA,EAAoB1wD,OAASm7C,GAGzBqV,EAEAE,C,EAMd,CAEAC,cAAAA,GAEE,MAAMC,EAAc9tD,KAAKqzB,OACnB06B,GAAiBt0B,EAAAA,GAAAA,GAAMz5B,KAAKq5C,YAClC,MAAO,CACLhmB,OAAQy6B,EACRE,WAAYhuD,KAAKujD,mBACjBlK,WAAY0U,EACZ3G,UAAWpnD,KAAKonD,UAEpB,CAEA6G,gBAAAA,CAAsCn4C,GACpC9V,KAAKqzB,OAASvd,EAASud,OACvBrzB,KAAK8jD,iBAAiBhuC,EAASk4C,YAC/BhuD,KAAKq5C,WAAavjC,EAASujC,UAC7B,CAEAuR,yBAAAA,CAEEH,EACAyD,EACApI,GAEA9lD,KAAKmmD,sBAAsBx/C,KAAKm/C,GAChC9lD,KAAKq5C,WAAW1yC,KAAK8jD,GAErBzqD,KAAK+nD,yBAAyBmG,EAChC,CAEAnK,cAAAA,GACE,OAA2C,IAApC/jD,KAAKkqD,oBAAoBpuD,MAClC,CAEAm9C,mBAAAA,GACE,MAAMwR,EAAYzqD,KAAKwlD,+BACvB,OAAOxlD,KAAK+pD,oBAAoBU,EAClC,CAEA5E,uBAAAA,CAA6C4E,GAC3C,OAAOzqD,KAAK+pD,oBAAoBU,EAClC,CAEOyC,cAAAA,GACL,OAAOltD,KAAKsjC,aAAatjC,KAAK6tC,GAAG,GAAIxK,GACvC,CAEOrnB,KAAAA,GACLhc,KAAK4pD,kBACL5pD,KAAKiqD,WAAa,EAClBjqD,KAAKkqD,oBAAsB,GAC3BlqD,KAAKqzB,OAAS,GACdrzB,KAAKq5C,WAAa,GAElBr5C,KAAKonD,UAAY,GACjBpnD,KAAKmmD,sBAAwB,EAC/B,GCh0BI,MACJgI,MAAAA,CAA+B3D,GAC7B,OAAOA,EAAKn/C,KAAKrL,KACnB,CAEAouD,OAAAA,CAEE14C,EACAmO,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAASnO,EAAKjS,EAC5C,CAEAwwC,OAAAA,CAEEv+B,EACA23C,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY33C,EAAKjS,EAC/C,CAEAywC,MAAAA,CAEEx+B,EACA+1C,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB/1C,EAChD,CAEA6+B,EAAAA,CAEE7+B,EACAq3C,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAYr3C,EACrC,CAEA4+B,IAAAA,CAEE5+B,EACA+1C,GAEA,OAAOzrD,KAAKusD,aAAa72C,EAAK+1C,EAChC,CAEArX,UAAAA,CAEE1+B,EACA+1C,GAEA,OAAOzrD,KAAK4rD,mBAAmBl2C,EAAK+1C,EACtC,CAEAY,OAAAA,CAEExoC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEA4qD,QAAAA,CAEExqC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEA6qD,QAAAA,CAEEzqC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEA8qD,QAAAA,CAEE1qC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEA+qD,QAAAA,CAEE3qC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEAgrD,QAAAA,CAEE5qC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEAirD,QAAAA,CAEE7qC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEAkrD,QAAAA,CAEE9qC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEAmrD,QAAAA,CAEE/qC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEAorD,QAAAA,CAEEhrC,EACApgB,GAEA,OAAOzD,KAAKwtD,gBAAgB3pC,EAAS,EAAGpgB,EAC1C,CAEAqrD,OAAAA,CAEEzB,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEAsrD,QAAAA,CAEE1B,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEAurD,QAAAA,CAEE3B,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEAwrD,QAAAA,CAEE5B,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEAyrD,QAAAA,CAEE7B,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEA0rD,QAAAA,CAEE9B,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEA2rD,QAAAA,CAEE/B,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEA4rD,QAAAA,CAEEhC,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEA6rD,QAAAA,CAEEjC,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEA8rD,QAAAA,CAEElC,EACA5pD,GAEA,OAAOzD,KAAKotD,gBAAgBC,EAAY,EAAG5pD,EAC7C,CAEA6oC,MAAAA,CAEEmf,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEA+D,OAAAA,CAEE/D,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEAgE,OAAAA,CAEEhE,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEAiE,OAAAA,CAEEjE,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEAkE,OAAAA,CAEElE,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEAmE,OAAAA,CAEEnE,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEAoE,OAAAA,CAEEpE,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEAqE,OAAAA,CAEErE,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEAsE,OAAAA,CAEEtE,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEAuE,OAAAA,CAEEvE,GAEA,OAAOzrD,KAAKwrD,eAAeC,EAAmB,EAChD,CAEAwE,EAAAA,CAEElD,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEAmD,GAAAA,CAEEnD,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEAoD,GAAAA,CAEEpD,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEAqD,GAAAA,CAEErD,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEAsD,GAAAA,CAEEtD,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEAuD,GAAAA,CAEEvD,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEAwD,GAAAA,CAEExD,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEAyD,GAAAA,CAEEzD,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEA0D,GAAAA,CAEE1D,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEA2D,GAAAA,CAEE3D,GAEA,OAAO/sD,KAAK8sD,WAAWC,EAAY,EACrC,CAEA4D,IAAAA,CAEElF,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEAmF,KAAAA,CAEEnF,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEAoF,KAAAA,CAEEpF,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEAqF,KAAAA,CAEErF,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEAsF,KAAAA,CAEEtF,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEAuF,KAAAA,CAEEvF,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEAwF,KAAAA,CAEExF,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEAyF,KAAAA,CAEEzF,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEA0F,KAAAA,CAEE1F,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEA2F,KAAAA,CAEE3F,GAEAzrD,KAAKusD,aAAa,EAAGd,EACvB,CAEA4F,QAAAA,CAAmC5tD,GACjCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEA6tD,SAAAA,CAAoC7tD,GAClCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEA8tD,SAAAA,CAAoC9tD,GAClCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEA+tD,SAAAA,CAAoC/tD,GAClCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEAguD,SAAAA,CAAoChuD,GAClCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEAiuD,SAAAA,CAAoCjuD,GAClCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEAkuD,SAAAA,CAAoCluD,GAClCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEAmuD,SAAAA,CAAoCnuD,GAClCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEAouD,SAAAA,CAAoCpuD,GAClCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEAquD,SAAAA,CAAoCruD,GAClCzD,KAAK0sD,qBAAqB,EAAGjpD,EAC/B,CAEAsuD,YAAAA,CAEEtG,GAEAzrD,KAAK4rD,mBAAmB,EAAGH,EAC7B,CAEAuG,aAAAA,CAEEvG,GAEA,OAAOzrD,KAAK4rD,mBAAmB,EAAGH,EACpC,CAEAwG,aAAAA,CAEExG,GAEAzrD,KAAK4rD,mBAAmB,EAAGH,EAC7B,CAEAyG,aAAAA,CAEEzG,GAEAzrD,KAAK4rD,mBAAmB,EAAGH,EAC7B,CAEA0G,aAAAA,CAEE1G,GAEAzrD,KAAK4rD,mBAAmB,EAAGH,EAC7B,CAEA2G,aAAAA,CAEE3G,GAEAzrD,KAAK4rD,mBAAmB,EAAGH,EAC7B,CAEA4G,aAAAA,CAEE5G,GAEAzrD,KAAK4rD,mBAAmB,EAAGH,EAC7B,CAEA6G,aAAAA,CAEE7G,GAEAzrD,KAAK4rD,mBAAmB,EAAGH,EAC7B,CAEA8G,aAAAA,CAEE9G,GAEAzrD,KAAK4rD,mBAAmB,EAAGH,EAC7B,CAEA+G,aAAAA,CAEE/G,GAEAzrD,KAAK4rD,mBAAmB,EAAGH,EAC7B,CAEAgH,gBAAAA,CAEEhvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEAivD,iBAAAA,CAEEjvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEAkvD,iBAAAA,CAEElvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEAmvD,iBAAAA,CAEEnvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEAovD,iBAAAA,CAEEpvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEAqvD,iBAAAA,CAEErvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEAsvD,iBAAAA,CAEEtvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEAuvD,iBAAAA,CAEEvvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEAwvD,iBAAAA,CAEExvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEAyvD,iBAAAA,CAEEzvD,GAEAzD,KAAKksD,2BAA2B,EAAGzoD,EACrC,CAEA0vD,IAAAA,CAEEj2D,EACAk2D,GAC4C,IAA5C13B,EAAA7/B,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAyB4jD,GAEzB,GAAI31C,GAAS9J,KAAKqgD,kBAAmBnjD,GAAO,CAC1C,MAMMovB,EAAQ,CACZ5mB,QANAy/B,GAAqC+B,4BAA4B,CAC/DjC,aAAc/nC,EACdiqC,YAAannC,KAAK6zC,YAKpBlzC,KAAM8mC,GAA0BsM,oBAChCpQ,SAAUzmC,GAEZ8C,KAAK4gD,iBAAiBj6C,KAAK2lB,E,CAG7BtsB,KAAKqgD,kBAAkB15C,KAAKzJ,GAE5B,MAAMm2D,EAAqBrzD,KAAKuqD,WAAWrtD,EAAMk2D,EAAgB13B,GAEjE,OADC17B,KAAa9C,GAAQm2D,EACfA,CACT,CAEAC,aAAAA,CAEEp2D,EACAstD,GAC4C,IAA5C9uB,EAAA7/B,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAyB4jD,GAEzB,MAAM8T,EhBtaJ,SACJ5vB,EACA0c,EACAxM,GAEA,MAAMxgB,EAAS,GACf,IAAIyE,EAaJ,OAXKhuB,GAASu2C,EAAmB1c,KAC/B7L,EACE,kCAAAz3B,OAAkCsjC,EAAQ,8CAAAtjC,OAA6CwzC,EAAS,2DAElGxgB,EAAO1sB,KAAK,CACVjB,QAASoyB,EACTn3B,KAAM8mC,GAA0B+rB,sBAChC7vB,SAAUA,KAIPtQ,CACT,CgBkZiDogC,CAC3Cv2D,EACA8C,KAAKqgD,kBACLrgD,KAAK6zC,WAEP7zC,KAAK4gD,iBAAmB5gD,KAAK4gD,iBAAiBvgD,OAAOkzD,GAErD,MAAMF,EAAqBrzD,KAAKuqD,WAAWrtD,EAAMstD,EAAM9uB,GAEvD,OADC17B,KAAa9C,GAAQm2D,EACfA,CACT,CAEAK,SAAAA,CAEE1Q,EACAj4B,GAEA,OAAO,WAEL/qB,KAAKkqD,oBAAoBvjD,KAAK,GAC9B,MAAMgtD,EAAW3zD,KAAK6tD,iBACtB,IAGE,OAFA7K,EAAYh4B,MAAMhrB,KAAM+qB,IAEjB,C,CACP,MAAOzhB,GACP,GAAIouC,GAAuBpuC,GACzB,OAAO,EAEP,MAAMA,C,CAER,QACAtJ,KAAKiuD,iBAAiB0F,GACtB3zD,KAAKkqD,oBAAoB79C,K,CAE7B,CACF,CAGO6sC,kBAAAA,GACL,OAAOl5C,KAAKygD,oBACd,CAEOmT,4BAAAA,GACL,OxDhZ6BC,GwDgZL/sC,EAAAA,GAAAA,GAAO9mB,KAAKygD,uBxD/Y/Bj7C,EAAAA,GAAAA,GAAIquD,EAAUxuC,IADjB,IAA2BwuC,CwDiZ/B,GCvrBI,MAIJ3R,gBAAAA,CAAiBxmB,GACf17B,KAAK8zD,QAAU,GACf9zD,KAAKs7B,sBAAuBz3B,EAAAA,GAAAA,GAAI63B,EAAQ,wBACnCA,EAAOJ,qBACRue,GAAsBve,oBAC5B,CAEAqoB,UAAAA,CAEEr3B,GAEA,GAAIorB,GAAuBprB,GAMzB,OALAA,EAAM1wB,QAAU,CACd2sC,UAAWvoC,KAAKumD,4BAChBwN,qBAAqBt6B,EAAAA,GAAAA,GAAMz5B,KAAKmmD,wBAElCnmD,KAAK8zD,QAAQntD,KAAK2lB,GACXA,EAEP,MAAM7rB,MACJ,8DAGN,CAEA,UAAI4yB,GACF,OAAOoG,EAAAA,GAAAA,GAAMz5B,KAAK8zD,QACpB,CAEA,UAAIzgC,CAAO2gC,GACTh0D,KAAK8zD,QAAUE,CACjB,CAGAjI,uBAAAA,CAEE/lB,EACA6G,EACAonB,GAEA,MAAMtwB,EAAW3jC,KAAKi5C,sBAQhBib,EAN+BlnB,GACnChH,EAFkBhmC,KAAKk5C,qBAAqBvV,GAI5CkJ,EACA7sC,KAAK8sC,cAE8C,GAC/CqnB,EAAe,GACrB,IAAK,IAAI3pD,EAAI,EAAGA,GAAKxK,KAAK8sC,aAActiC,IACtC2pD,EAAaxtD,KAAK3G,KAAK6tC,GAAGrjC,IAE5B,MAAM4hB,EAAMpsB,KAAKs7B,qBAAqBsJ,sBAAsB,CAC1DE,uBAAwBovB,EACxBxwB,OAAQywB,EACRvlD,SAAU5O,KAAK6tC,GAAG,GAClB3J,sBAAuB+vB,EACvBtwB,SAAUA,IAGZ,MAAM3jC,KAAK2jD,WAAW,IAAIxL,GAAmB/rB,EAAKpsB,KAAK6tC,GAAG,GAAI7tC,KAAK6tC,GAAG,IACxE,CAGAof,mBAAAA,CAEEjnB,EACAouB,GAEA,MAAMzwB,EAAW3jC,KAAKi5C,sBAGhBob,EAA+BtnB,GACnC/G,EAHkBhmC,KAAKk5C,qBAAqBvV,GAK5C3jC,KAAK8sC,cAGDqnB,EAAe,GACrB,IAAK,IAAI3pD,EAAI,EAAGA,GAAKxK,KAAK8sC,aAActiC,IACtC2pD,EAAaxtD,KAAK3G,KAAK6tC,GAAGrjC,IAE5B,MAAMwtC,EAAgBh4C,KAAK6tC,GAAG,GAExB/V,EAAS93B,KAAKs7B,qBAAqByI,wBAAwB,CAC/DE,oBAAqBowB,EACrB3wB,OAAQywB,EACRvlD,SAAUopC,EACV9T,sBAAuBkwB,EACvBzwB,SAAU3jC,KAAKi5C,wBAGjB,MAAMj5C,KAAK2jD,WACT,IAAI1L,GAAqBngB,EAAQ93B,KAAK6tC,GAAG,GAAImK,GAEjD,GC7GI,MACJwK,iBAAAA,GAAqB,CAEd8R,oBAAAA,CAELC,EACAC,GAEA,MAAMC,EAAgBz0D,KAAKygD,qBAAqB8T,GAEhD,IAAI9iC,EAAAA,GAAAA,GAAYgjC,GACd,MAAMh0D,MAAM,UAADJ,OAAWk0D,EAAa,uCAGrC,OAAOjqB,GACL,CAACmqB,GACDD,EACAx0D,KAAKsjC,aACLtjC,KAAK8sC,aAET,CAIOuX,yBAAAA,CAELF,GAEA,MAAMuQ,EAAcnsD,GAAM47C,EAAY5b,WAEhCosB,EADkB30D,KAAKk5C,qBACSwb,GAKtC,OAJ+B,IAAI/rB,GACjCgsB,EACAxQ,GACA35B,cAEJ,GRsCI,MAIJi4B,gBAAAA,CAAsC/mB,GACpC17B,KAAKu+C,mBAAqB,GAC1Bv+C,KAAK40D,iBAAkB,CACzB,CAEAxU,eAAAA,GACEpgD,KAAK40D,iBAAkB,EAEvB50D,KAAKg8B,WAAW,oBAAoB,KAUlC,IAAK,IAAIxxB,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,MAAMkL,EAAMlL,EAAI,EAAIA,EAAI,GACxBxK,KAAK,UAADK,OAAWqV,IAAsB,SAAUm/C,EAAMC,GACnD,OAAO90D,KAAK+0D,sBAAsBF,EAAMrqD,EAAGsqD,EAC7C,EACA90D,KAAK,UAADK,OAAWqV,IAAsB,SAAUm/C,EAAMC,GACnD,OAAO90D,KAAKg1D,sBAAsBH,EAAMrqD,EAAGsqD,EAC7C,EACA90D,KAAK,SAADK,OAAUqV,IAAqB,SAAUm/C,GAC3C,OAAO70D,KAAKi1D,qBAAqBJ,EAAMrqD,EACzC,EACAxK,KAAK,KAADK,OAAMqV,IAAiB,SAAUm/C,GACnC,OAAO70D,KAAKk1D,iBAAiBL,EAAMrqD,EACrC,EACAxK,KAAK,OAADK,OAAQqV,IAAmB,SAAUm/C,GACvC70D,KAAKm1D,mBAAmB3qD,EAAGqqD,EAC7B,EACA70D,KAAK,WAADK,OAAYqV,IAAuB,SAAUm/C,GAC/C70D,KAAKo1D,2BAA2B5qD,EAAGqqD,EACrC,EACA70D,KAAK,eAADK,OAAgBqV,IAA2B,SAAUm/C,GACvD70D,KAAKq1D,yBAAyB7qD,EAAGqqD,EACnC,EACA70D,KAAK,mBAADK,OAAoBqV,IAA+B,SAAUm/C,GAC/D70D,KAAKs1D,iCAAiC9qD,EAAGqqD,EAC3C,C,CAIF70D,KAAI,QAAc,SAAU0V,EAAKm/C,EAAMC,GACrC,OAAO90D,KAAK+0D,sBAAsBF,EAAMn/C,EAAKo/C,EAC/C,EACA90D,KAAI,QAAc,SAAU0V,EAAKm/C,EAAMC,GACrC,OAAO90D,KAAKg1D,sBAAsBH,EAAMn/C,EAAKo/C,EAC/C,EACA90D,KAAI,OAAa,SAAU0V,EAAKm/C,GAC9B,OAAO70D,KAAKi1D,qBAAqBJ,EAAMn/C,EACzC,EACA1V,KAAI,GAAS,SAAU0V,EAAKm/C,GAC1B,OAAO70D,KAAKk1D,iBAAiBL,EAAMn/C,EACrC,EACA1V,KAAI,KAAW,SAAU0V,EAAKm/C,GAC5B70D,KAAKm1D,mBAAmBz/C,EAAKm/C,EAC/B,EACA70D,KAAI,WAAiB,SAAU0V,EAAKm/C,GAClC70D,KAAKq1D,yBAAyB3/C,EAAKm/C,EACrC,EAEA70D,KAAKmuD,OAASnuD,KAAKu1D,cACnBv1D,KAAK0zD,UAAY1zD,KAAKw1D,iBACtBx1D,KAAK6tC,GAAK7tC,KAAKy1D,SAAS,GAE5B,CAEA/U,gBAAAA,GACE1gD,KAAK40D,iBAAkB,EAKvB50D,KAAKg8B,WAAW,8BAA8B,KAC5C,MAAMimB,EAAYjiD,KAElB,IAAK,IAAIwK,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,MAAMkL,EAAMlL,EAAI,EAAIA,EAAI,UACjBy3C,EAAK,UAAD5hD,OAAWqV,WACfusC,EAAK,UAAD5hD,OAAWqV,WACfusC,EAAK,SAAD5hD,OAAUqV,WACdusC,EAAK,KAAD5hD,OAAMqV,WACVusC,EAAK,OAAD5hD,OAAQqV,WACZusC,EAAK,WAAD5hD,OAAYqV,WAChBusC,EAAK,eAAD5hD,OAAgBqV,WACpBusC,EAAK,mBAAD5hD,OAAoBqV,G,QAG1BusC,EAAI,eACJA,EAAI,eACJA,EAAI,cACJA,EAAI,UACJA,EAAI,YACJA,EAAI,kBAEJA,EAAKkM,cACLlM,EAAKyR,iBACLzR,EAAKpU,EAAE,GAElB,CAKA0nB,aAAAA,CAAsC/K,GACpC,CAIFgL,gBAAAA,CACExS,EACAj4B,GAEA,MAAO,KAAM,CACf,CAIA0qC,SAAAA,CAAU17C,GAGR,OAAOslC,EACT,CAEAmB,kBAAAA,CAAmBtjD,EAAc+tC,GAC/B,IACE,MAAMyqB,EAAkB,IAAIjxC,GAAK,CAAE9E,WAAY,GAAIziB,KAAMA,IAKzD,OAJAw4D,EAAgBx4D,KAAOA,EACvB8C,KAAKu+C,mBAAmB53C,KAAK+uD,GAC7BzqB,EAAI5/B,KAAKrL,MACTA,KAAKu+C,mBAAmBlyC,MACjBqpD,C,CACP,MAAOC,GACP,IAA2C,IAAvCA,EAAcvW,qBAChB,IACEuW,EAAcjwD,QACZiwD,EAAcjwD,QAAdiwD,yJ,CAGF,MAAOC,GAEP,MAAMD,C,CAGV,MAAMA,C,CAEV,CAGAV,oBAAAA,CAEExJ,EACAzlB,GAEA,OAAOgY,GAAW3yC,KAAKrL,KAAM6kB,GAAQ4mC,EAAmBzlB,EAC1D,CAEAqvB,wBAAAA,CAEErvB,EACAylB,GAEAzN,GAAW3yC,KAAKrL,KAAM8kB,GAAqB2mC,EAAmBzlB,EAChE,CAEAsvB,gCAAAA,CAEEtvB,EACAviC,GAEAu6C,GAAW3yC,KACTrL,KACA+kB,GACAthB,EACAuiC,EACA0X,GAEJ,CAEAyX,kBAAAA,CAEEnvB,EACAylB,GAEAzN,GAAW3yC,KAAKrL,KAAMglB,GAAYymC,EAAmBzlB,EACvD,CAEAovB,0BAAAA,CAEEpvB,EACAviC,GAEAu6C,GAAW3yC,KACTrL,KACAilB,GACAxhB,EACAuiC,EACA0X,GAEJ,CAEAwX,gBAAAA,CAEEnI,EACA/mB,GAEA,OAAO6Y,GAAaxzC,KAAKrL,KAAM+sD,EAAY/mB,EAC7C,CAEAgvB,qBAAAA,CAEE3H,EACArnB,EACAviC,GAGA,GADA26C,GAAuBpY,IAClBqnB,IAA8C,KAAhCxpD,EAAAA,GAAAA,GAAIwpD,EAAY,YAAuB,CACxD,MAAM/gC,EAAa,IAAI7rB,MACrB,WAAAJ,OAAW8+C,GAAanZ,GAAW,2EAAA3lC,OACiBw1D,KAAKC,UACrDzI,GACD,KAAG,8BAAAhtD,OAEKL,KAAKu+C,mBAAmB,GAAIrhD,KACrC,MAGJ,MADAovB,EAAM8yB,sBAAuB,EACvB9yB,C,CAGR,MAAM+xB,GAAgBC,EAAAA,GAAAA,GAAKt+C,KAAKu+C,oBAC1B5a,EAAW0pB,EAAW1pB,SACtBoyB,EAAkB,IAAI3xC,GAAY,CACtC1O,IAAKswB,EACLxgB,gBAAiBme,EACjBle,MAAc,OAAPhiB,QAAO,IAAPA,OAAO,EAAPA,EAASsgB,MAEhBS,oBAAgBzoB,IAIlB,OAFAsiD,EAAS1+B,WAAWhZ,KAAKovD,GAElB/1D,KAAKu/C,UACRxB,GACKP,EACX,CAEAuX,qBAAAA,CAEElxC,EACAmiB,EACAviC,GAGA,GADA26C,GAAuBpY,IAClBjM,GAAoBlW,GAAU,CACjC,MAAMyI,EAAa,IAAI7rB,MACrB,WAAAJ,OAAW8+C,GAAanZ,GAAW,uEAAA3lC,OACaw1D,KAAKC,UACjDjyC,GACD,KAAG,8BAAAxjB,OAEKL,KAAKu+C,mBAAmB,GAAIrhD,KACrC,MAGJ,MADAovB,EAAM8yB,sBAAuB,EACvB9yB,C,CAER,MAAM+xB,GAAgBC,EAAAA,GAAAA,GAAKt+C,KAAKu+C,oBAC1BwX,EAAkB,IAAI3wC,GAAS,CACnC1P,IAAKswB,EACLtgB,aAAc7B,EACd4B,MAAc,OAAPhiB,QAAO,IAAPA,OAAO,EAAPA,EAASsgB,QAIlB,OAFAs6B,EAAS1+B,WAAWhZ,KAAKovD,GAElBjY,EACT,GS1WI,MAKJ4E,qBAAAA,CAAsBhnB,GACpB,IAAI73B,EAAAA,GAAAA,GAAI63B,EAAQ,iBAAkB,CAChC,MAAMs6B,EAAoBt6B,EAAOH,cAC3B06B,EAA6C,kBAAtBD,EAC7Bh2D,KAAKq8B,kBAAoB45B,EACbD,EACRt+C,IACJ1X,KAAKu7B,cAAgB06B,EACjBD,EAAoB,EACnBA,C,MAELh2D,KAAKq8B,kBAAoB,EACzBr8B,KAAKu7B,cAAgBse,GAAsBte,cAG7Cv7B,KAAKm8B,iBAAmB,CAC1B,CAEAH,UAAAA,CAAmCC,EAAmBC,GAGpD,IAA2B,IAAvBl8B,KAAKu7B,cAAwB,CAC/Bv7B,KAAKm8B,kBACL,MAAMC,EAAS,IAAIv1B,MAAM7G,KAAKm8B,gBAAkB,GAAGx2B,KAAK,MACpD3F,KAAKm8B,gBAAkBn8B,KAAKq8B,mBAC9BhQ,QAAQiQ,IAAI,GAADj8B,OAAI+7B,EAAM,YAAA/7B,OAAQ47B,EAAS,MAExC,MAAM,KAAEpD,EAAI,MAAEh6B,GAAU45B,GAAMyD,GAExBK,EAAc1D,EAAO,GAAKxM,QAAQG,KAAOH,QAAQiQ,IAKvD,OAJIt8B,KAAKm8B,gBAAkBn8B,KAAKq8B,mBAC9BE,EAAY,GAADl8B,OAAI+7B,EAAM,SAAA/7B,OAAQ47B,EAAS,YAAA57B,OAAWw4B,EAAI,OAEvD74B,KAAKm8B,kBACEt9B,C,CAEP,OAAOq9B,GAEX,IPnDA2jB,GAAUl8C,SAASuyD,IACjB,MAAMC,EAAYD,EAAS9qD,UAC3B1M,OAAO03D,oBAAoBD,GAAWxyD,SAAS0yD,IAC7C,GAAiB,gBAAbA,EACF,OAGF,MAAMC,EAAqB53D,OAAO63D,yBAChCJ,EACAE,GAIAC,IACCA,EAAmBj3C,KAAOi3C,EAAmBxrD,KAE9CpM,OAAOC,eACLihD,GAAYx0C,UACZirD,EACAC,GAGF1W,GAAYx0C,UAAUirD,GAAYH,EAAS9qD,UAAUirD,E,GAEvD,ID2RA,MAAOG,WAA8BzW,GACzC5kD,WAAAA,CACE6mD,GACqD,IAArDtmB,EAAA7/B,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAgCg+C,GAEhC,MAAM4c,GAAch9B,EAAAA,GAAAA,GAAMiC,GAC1B+6B,EAAYlX,WAAY,EACxBnkD,MAAM4mD,EAAiByU,EACzB,ESnSI,SAAUC,GAAY35D,EAAY4D,EAA+BqlC,GACnE,MAAO,GAAP3lC,OAAUtD,EAAKG,KAAI,KAAAmD,OAAIM,EAAI,KAAAN,OAAI2lC,EACnC,CA6GM,MAAgB2wB,GAGlBx7D,WAAAA,CAAYyD,GACRoB,KAAKpB,OAASA,CAClB,CAEAg4D,SAAAA,GACI,OAAO,CACX,EAGE,MAAOC,WAAuBF,GAGhCx7D,WAAAA,CAAYyD,EAAkBgF,GAC1BxI,MAAMwD,GACNoB,KAAK4D,UAAYA,CACrB,EAGE,MAAOkzD,WAA0BH,GACnCx7D,WAAAA,CAAYyD,GACRxD,MAAMwD,EACV,CAEAg4D,SAAAA,GACI,OAAO,CACX,EAGE,MAAOG,WAAuBJ,GAIhCx7D,WAAAA,CAAY67D,EAA2Bj6D,EAAYk6D,GAC/C77D,MAAM47D,GACNh3D,KAAKjD,KAAOA,EACZiD,KAAKi3D,YAAcA,CACvB,CAEAL,SAAAA,GACI,OAAO,CACX,EAQE,SAAUM,GAAU3zD,GACtB,MAAM4zD,EAAW,CACbC,YAAa,CAAC,EACdC,eAAgB,GAChBC,iBAAkB,IAAIjvD,IACtBkvD,gBAAiB,IAAIlvD,IACrBmvD,OAAQ,KAehB,SAAyCL,EAAU5zD,GAC/C,MAAMk0D,EAAal0D,EAAMzH,OACzB,IAAK,IAAI0O,EAAI,EAAGA,EAAIitD,EAAYjtD,IAAK,CACjC,MAAMzN,EAAOwG,EAAMiH,GACboC,EAAQkJ,GAAyBqhD,EAAKp6D,OAAMhB,EAAW,CACzD4E,KA9KkB,IAgLhB+2D,EAAO5hD,GAAwBqhD,EAAKp6D,OAAMhB,EAAW,CACvD4E,KA5KiB,IA8KrBiM,EAAM8qD,KAAOA,EACbP,EAAIG,iBAAiBxsD,IAAI/N,EAAM6P,GAC/BuqD,EAAII,gBAAgBzsD,IAAI/N,EAAM26D,E,CAEtC,CA3BIC,CAAgCR,EAAK5zD,GACrC,MAAMk0D,EAAal0D,EAAMzH,OACzB,IAAK,IAAI0O,EAAI,EAAGA,EAAIitD,EAAYjtD,IAAK,CACjC,MAAMzN,EAAOwG,EAAMiH,GACbotD,EAAYC,GAAMV,EAAKp6D,EAAMA,QACjBhB,IAAd67D,GAGJE,GAAgBX,EAAKp6D,EAAM66D,E,CAE/B,OAAOT,CACX,CAkBA,SAAS9/C,GACL8/C,EACAp6D,EACAg7D,GAEA,OAAIA,aAAsB3yC,GACf4yC,GAASb,EAAKp6D,EAAMg7D,EAAWryC,aAAcqyC,GAC7CA,aAAsB3zC,GAmVrC,SACI+yC,EACAc,EACAC,GAEA,MAAMn7D,EAAOm7D,EAAY1zC,eACnB5X,EAAQuqD,EAAIG,iBAAiBj4C,IAAItiB,GACjCqkB,EAAOtL,GAA+BqhD,EAAKc,EAAaC,EAAa,CACvEv3D,KA5hBiB,IA8hBfugB,EAAQpL,GAA+BqhD,EAAKc,EAAaC,EAAa,CACxEv3D,KA/hBiB,IAkiBf0K,EAAO,IAAI0rD,GAAenqD,EAAO7P,EAAMmkB,GAG7C,OAFAi3C,GAAc/2C,EAAM/V,GAEb,CACH+V,OACAF,QAER,CAvWek3C,CAAQjB,EAAKp6D,EAAMg7D,GACnBA,aAAsB7yC,GA2FrC,SACIiyC,EACAp6D,EACAkpC,GAEA,MAAMr5B,EAAQkJ,GAA+BqhD,EAAKp6D,EAAMkpC,EAAa,CACjEtlC,KApSiB,IAsSrB03D,GAAoBlB,EAAKvqD,GACzB,MAAMiK,GAAOrR,EAAAA,GAAAA,GAAIygC,EAAYtmB,YAAarW,GAAM+N,GAAK8/C,EAAKp6D,EAAMuM,KAC1DgvD,EAASC,GAASpB,EAAKp6D,EAAM6P,EAAOq5B,KAAgBpvB,GAC1D,OAAOyhD,CACX,CAtGeryB,CAAYkxB,EAAKp6D,EAAMg7D,GACvBA,aAAsBlzC,GAuGrC,SAAgBsyC,EAAUp6D,EAAYm3C,GAClC,MAAMtnC,EAAQkJ,GAA+BqhD,EAAKp6D,EAAMm3C,EAAQ,CAC5DvzC,KA9SiB,IAgTrB03D,GAAoBlB,EAAKvqD,GACzB,MAAM0rD,EAASC,GAASpB,EAAKp6D,EAAM6P,EAAOsnC,EAAQ2jB,GAAMV,EAAKp6D,EAAMm3C,IACnE,OAwGJ,SAAkBijB,EAAUp6D,EAAYy7D,EAAkBF,GACtD,MAAM1rD,EAAQ0rD,EAAOl3C,KACfnU,EAAMqrD,EAAOp3C,MAKnB,OAHAu3C,GAAQ7rD,EAAOK,GAEfkqD,EAAIC,YAAYV,GAAY35D,EAAM,SAAUy7D,EAAS9iD,MAAQ9I,EACtD0rD,CACX,CAhHWE,CAASrB,EAAKp6D,EAAMm3C,EAAQokB,EACvC,CA7GepkB,CAAOijB,EAAKp6D,EAAMg7D,GAClBA,aAAsB/yC,GAarC,SAAoBmyC,EAAUp6D,EAAYwpC,GACtC,MAAMmyB,EAAY5iD,GAA8BqhD,EAAKp6D,EAAMwpC,EAAY,CACnE5lC,KAnN4B,IAqNhC03D,GAAoBlB,EAAKuB,GACzB,MAAMJ,EAASC,GACXpB,EACAp6D,EACA27D,EACAnyB,EACAsxB,GAAMV,EAAKp6D,EAAMwpC,IAErB,OAAOoyB,GAAKxB,EAAKp6D,EAAMwpC,EAAY+xB,EACvC,CAzBe/xB,CAAW4wB,EAAKp6D,EAAMg7D,GACtBA,aAAsB9yC,GA0BrC,SACIkyC,EACAp6D,EACAwpC,GAEA,MAAMmyB,EAAY5iD,GAA8BqhD,EAAKp6D,EAAMwpC,EAAY,CACnE5lC,KAtO4B,IAwOhC03D,GAAoBlB,EAAKuB,GACzB,MAAMJ,EAASC,GACXpB,EACAp6D,EACA27D,EACAnyB,EACAsxB,GAAMV,EAAKp6D,EAAMwpC,IAEfqyB,EAAMZ,GAASb,EAAKp6D,EAAMwpC,EAAW79B,UAAW69B,GACtD,OAAOoyB,GAAKxB,EAAKp6D,EAAMwpC,EAAY+xB,EAAQM,EAC/C,CA3CeC,CAAc1B,EAAKp6D,EAAMg7D,GACzBA,aAAsBjzC,GA4CrC,SACIqyC,EACAp6D,EACAwpC,GAEA,MAAMuyB,EAAYhjD,GAA8BqhD,EAAKp6D,EAAMwpC,EAAY,CACnE5lC,KA3P4B,IA6PhC03D,GAAoBlB,EAAK2B,GACzB,MAAMR,EAASC,GACXpB,EACAp6D,EACA+7D,EACAvyB,EACAsxB,GAAMV,EAAKp6D,EAAMwpC,IAErB,OAAOwyB,GAAK5B,EAAKp6D,EAAMwpC,EAAY+xB,EACvC,CA5De/c,CAAoB4b,EAAKp6D,EAAMg7D,GAC/BA,aAAsBhzC,GA6DrC,SACIoyC,EACAp6D,EACAwpC,GAEA,MAAMuyB,EAAYhjD,GAA8BqhD,EAAKp6D,EAAMwpC,EAAY,CACnE5lC,KA9Q4B,IAgRhC03D,GAAoBlB,EAAK2B,GACzB,MAAMR,EAASC,GACXpB,EACAp6D,EACA+7D,EACAvyB,EACAsxB,GAAMV,EAAKp6D,EAAMwpC,IAEfqyB,EAAMZ,GAASb,EAAKp6D,EAAMwpC,EAAW79B,UAAW69B,GACtD,OAAOwyB,GAAK5B,EAAKp6D,EAAMwpC,EAAY+xB,EAAQM,EAC/C,CA9EeI,CAAuB7B,EAAKp6D,EAAMg7D,GAElCF,GAAMV,EAAKp6D,EAAMg7D,EAEhC,CAmGA,SAASF,GACLV,EACAp6D,EACA86D,GAEA,MAAMoB,GAAU7vD,EAAAA,GAAAA,IACZ5D,EAAAA,GAAAA,GAAIqyD,EAAMl4C,YAAarW,GAAM+N,GAAK8/C,EAAKp6D,EAAMuM,MAC5CA,QAAYvN,IAANuN,IAEX,OAAuB,IAAnB2vD,EAAQn9D,OACDm9D,EAAQ,GACW,IAAnBA,EAAQn9D,YACf,EAyJR,SAAmBq7D,EAAUtgD,GACzB,MAAMqiD,EAAariD,EAAK/a,OACxB,IAAK,IAAI0O,EAAI,EAAGA,EAAI0uD,EAAa,EAAG1uD,IAAK,CACrC,MAAM8tD,EAASzhD,EAAKrM,GACpB,IAAI2uD,EACmC,IAAnCb,EAAOl3C,KAAKg4C,YAAYt9D,SACxBq9D,EAAab,EAAOl3C,KAAKg4C,YAAY,IAEzC,MAAMC,EAAmBF,aAAsBpC,GACzCuC,EAAiBH,EACjB3xD,EAAOqP,EAAKrM,EAAI,GAAG4W,KApeR,IAsebk3C,EAAOl3C,KAAKzgB,MAteC,IAueb23D,EAAOp3C,MAAMvgB,WACE5E,IAAfo9D,IACEE,GAAoBC,EAAerC,cAAgBqB,EAAOp3C,OACxDi4C,EAAWv6D,SAAW05D,EAAOp3C,QAG7Bm4C,EACAC,EAAerC,YAAczvD,EAE7B2xD,EAAWv6D,OAAS4I,EAExB+xD,GAAYpC,EAAKmB,EAAOp3C,QAGxBu3C,GAAQH,EAAOp3C,MAAO1Z,E,CAI9B,MAAMe,EAAQsO,EAAK,GACbuqB,EAAOvqB,EAAKqiD,EAAa,GAC/B,MAAO,CACH93C,KAAM7Y,EAAM6Y,KACZF,MAAOkgB,EAAKlgB,MAEpB,CA5Les4C,CAAUrC,EAAK8B,EAE9B,CAEA,SAASF,GACL5B,EACAp6D,EACAg8D,EACAT,EACAM,GAEA,MAAMa,EAAWnB,EAAOl3C,KAClBs4C,EAASpB,EAAOp3C,MAEhBy4C,EAAO7jD,GAA4BqhD,EAAKp6D,EAAMg8D,EAAM,CACtDp4D,KAxU0B,KA0U9B03D,GAAoBlB,EAAKwC,GACzB,MAAM1sD,EAAM6I,GAAuBqhD,EAAKp6D,EAAMg8D,EAAM,CAChDp4D,KA3UoB,KA8VxB,OAjBA84D,EAASG,SAAWD,EACpB1sD,EAAI2sD,SAAWD,EACfxC,EAAIC,YAAYV,GAAY35D,EAAM67D,EAAM,mCAAqC,sBAAuBG,EAAKrjD,MAAQikD,EACjHlB,GAAQiB,EAAQC,QAIJ59D,IAAR68D,GACAH,GAAQkB,EAAMF,GACdhB,GAAQkB,EAAM1sD,KAEdwrD,GAAQkB,EAAM1sD,GAEdwrD,GAAQkB,EAAMf,EAAIx3C,MAClBq3C,GAAQG,EAAI13C,MAAOu4C,IAGhB,CACHr4C,KAAMq4C,EACNv4C,MAAOjU,EAEf,CAEA,SAAS0rD,GACLxB,EACAp6D,EACA47D,EACAL,EACAM,GAEA,MAAMhsD,EAAQ0rD,EAAOl3C,KACfnU,EAAMqrD,EAAOp3C,MAEbvD,EAAQ7H,GAA6BqhD,EAAKp6D,EAAM47D,EAAM,CACxDh4D,KAjX2B,KAmX/B03D,GAAoBlB,EAAKx5C,GACzB,MAAMk8C,EAAU/jD,GAAuBqhD,EAAKp6D,EAAM47D,EAAM,CACpDh4D,KAnXoB,KAqXlBg5D,EAAO7jD,GAA4BqhD,EAAKp6D,EAAM47D,EAAM,CACtDh4D,KAzX0B,IA4Y9B,OAjBAgd,EAAMi8C,SAAWD,EACjBE,EAAQD,SAAWD,EAEnBlB,GAAQ96C,EAAO/Q,GACf6rD,GAAQ96C,EAAOk8C,GACfpB,GAAQxrD,EAAK0sD,QAED59D,IAAR68D,GACAH,GAAQkB,EAAME,GAEdpB,GAAQkB,EAAMf,EAAIx3C,MAClBq3C,GAAQG,EAAI13C,MAAOtU,IAEnB6rD,GAAQkB,EAAMh8C,GAGlBw5C,EAAIC,YAAYV,GAAY35D,EAAM67D,EAAM,0BAA4B,aAAcD,EAAKjjD,MAAQiI,EACxF,CACHyD,KAAMzD,EACNuD,MAAO24C,EAEf,CAYA,SAASxB,GAAoBlB,EAAU5vD,GAGnC,OAFA4vD,EAAIE,eAAe1wD,KAAKY,GACxBA,EAAMuyD,SAAW3C,EAAIE,eAAev7D,OAAS,EACtCyL,EAAMuyD,QACjB,CAEA,SAASvB,GACLpB,EACAp6D,EACA6P,EACAmrD,GAGA,MAAM9qD,EAAM6I,GAAwBqhD,EAAKp6D,EAAMg7D,EAAY,CACvDp3D,KA3aqB,EA4arBiM,UAEJA,EAAMK,IAAMA,EAAG,QAAAzB,EAAA3P,UAAAC,OANZ+a,EAA+B,IAAAhQ,MAAA2E,EAAA,EAAAA,EAAA,KAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAA/BmL,EAA+BnL,EAAA,GAAA7P,UAAA6P,GAOlC,IAAK,MAAMwd,KAAOrS,OACF9a,IAARmtB,GAEAuvC,GAAQ7rD,EAAOsc,EAAI9H,MACnBq3C,GAAQvvC,EAAIhI,MAAOjU,IAEnBwrD,GAAQ7rD,EAAOK,GAIvB,MAAMqrD,EAAoB,CACtBl3C,KAAMxU,EACNsU,MAAOjU,GAGX,OADAkqD,EAAIC,YAAYV,GAAY35D,EAIhC,SAAqBg7D,GACjB,GAAIA,aAAsB7yC,GACtB,MAAO,cACJ,GAAI6yC,aAAsBlzC,GAC7B,MAAO,SACJ,GAAIkzC,aAAsB/yC,GAC7B,MAAO,aACJ,GAAI+yC,aAAsB9yC,GAC7B,MAAO,0BACJ,GAAI8yC,aAAsBjzC,GAC7B,MAAO,sBACJ,GAAIizC,aAAsBhzC,GAC7B,MAAO,mCAEP,MAAM,IAAItkB,MAAM,sCAExB,CApBsC4rC,CAAY0rB,GAAaA,EAAWriD,MAAQ9I,EACvE0rD,CACX,CA2DA,SAASN,GACLb,EACAp6D,EACA6G,EACAm0D,GAEA,MAAM32C,EAAOtL,GAAqBqhD,EAAKp6D,EAAMg7D,EAAY,CACrDp3D,KAxgBiB,IA0gBfugB,EAAQpL,GAAqBqhD,EAAKp6D,EAAMg7D,EAAY,CACtDp3D,KA3gBiB,IA8gBrB,OADAw3D,GAAc/2C,EAAM,IAAIy1C,GAAe31C,EAAOtd,IACvC,CACHwd,OACAF,QAER,CAyBA,SAAS42C,GAAgBX,EAAUp6D,EAAY86D,GAC3C,MAAMjrD,EAAQuqD,EAAIG,iBAAiBj4C,IAAItiB,GACvC07D,GAAQ7rD,EAAOirD,EAAMz2C,MACrB,MAAMs2C,EAAOP,EAAII,gBAAgBl4C,IAAItiB,GACrC07D,GAAQZ,EAAM32C,MAAOw2C,GAKrB,MAJ0B,CACtBt2C,KAAMxU,EACNsU,MAAOw2C,EAGf,CAEA,SAASe,GAAQtqD,EAAiBC,GAE9B+pD,GAAchqD,EADK,IAAI2oD,GAAkB1oD,GAE7C,CAEA,SAAS0H,GACLqhD,EACAp6D,EACAg7D,EACAr7C,GAEA,MAAM8wB,EAAO9uC,OAAA2lB,OAAA,CACT8yC,MACAY,aACAgC,wBAAwB,EACxBh9D,OACAq8D,YAAa,GACbY,oBAAqB,GACrBC,YAAa9C,EAAIK,OAAO17D,QACrB4gB,GAGP,OADAy6C,EAAIK,OAAO7wD,KAAK6mC,GACTA,CACX,CAEA,SAAS2qB,GAAc5wD,EAAqB4xD,GAGP,IAA7B5xD,EAAM6xD,YAAYt9D,SAClByL,EAAMwyD,uBAAyBZ,EAAWvC,aAE9CrvD,EAAM6xD,YAAYzyD,KAAKwyD,EAC3B,CAEA,SAASI,GAAYpC,EAAU5vD,GAC3B4vD,EAAIK,OAAO0C,OAAO/C,EAAIK,OAAO5uD,QAAQrB,GAAQ,EACjD,CC1mBO,MAAM4yD,GAAY,CAAC,EAQpB,MAAOC,GAAbj/D,WAAAA,GACU,KAAAqK,IAA8B,CAAC,EAC/B,KAAA60D,QAAuB,EAsCjC,CAlCE,QAAI1vD,GACF,OAAO3K,KAAKq6D,QAAQv+D,MACtB,CAEAw+D,QAAAA,GAEEt6D,KAAKwF,IAAM,CAAC,CACd,CAEAuF,GAAAA,CAAI2wB,GACF,MAAMzwB,EAAMsvD,GAAgB7+B,GAGtBzwB,KAAOjL,KAAKwF,MAChBxF,KAAKwF,IAAIyF,GAAOjL,KAAKq6D,QAAQv+D,OAC7BkE,KAAKq6D,QAAQ1zD,KAAK+0B,GAEtB,CAEA,YAAI3a,GACF,OAAO/gB,KAAKq6D,OACd,CAEA,QAAIxjD,GACF,OAAOrR,EAAAA,GAAAA,GAAIxF,KAAKq6D,SAAU/wD,GAAMA,EAAE4f,KACpC,CAEA,OAAIje,GACF,IAAIpM,EAAQ,GACZ,IAAK,MAAMwgC,KAAKr/B,KAAKwF,IACnB3G,GAASwgC,EAAI,IAEf,OAAOxgC,CACT,EAGI,SAAU07D,GAAgB7+B,GAC9B,MAAO,GAAPr7B,SADoDxE,UAAAC,OAAA,QAAAC,IAAAF,UAAA,KAAAA,UAAA,GACpC,IAAHwE,OAAOq7B,EAAOxS,KAAQ,GAAE,KAAA7oB,OACnCq7B,EAAOn0B,MAAM0yD,YACf,KAAA55D,OAAIq7B,EAAO8+B,MAAMh1D,KAAK8D,GAAMA,EAAE2wD,YAAYj2D,aAAY2B,KAAK,KAC7D,C,eC/CA,SAJA,SAAgBmG,EAAOqf,GACrB,OAAQrf,GAASA,EAAMhQ,QAAUutB,EAAAA,GAAAA,GAASvd,GAAOoX,EAAAA,GAAAA,GAAaiI,EAAU,IAAM,EAChF,ECiCA,SAASsvC,GAAeC,EAA2BZ,GAC/C,MAAMt0D,EAAuC,CAAC,EAC9C,OAAQm1D,IACJ,MAAM1vD,EAAM0vD,EAAa32D,WACzB,IAAIsC,EAAWd,EAAIyF,GACnB,YAAiBlP,IAAbuK,IAGAA,EAAW,CACPs0D,cAAeF,EACfZ,WACAtC,OAAQ,CAAC,GAEbhyD,EAAIyF,GAAO3E,GAPJA,C,CAWnB,CAEA,MAAMu0D,GAAN1/D,WAAAA,GACY,KAAAmyC,WAAwB,EAkBpC,CAhBIwtB,EAAAA,CAAG/xD,GACC,OAAOA,GAAS/I,KAAKstC,WAAWxxC,QAAUkE,KAAKstC,WAAWvkC,EAC9D,CAEA+B,GAAAA,CAAI/B,EAAelK,GACfmB,KAAKstC,WAAWvkC,GAASlK,CAC7B,CAEAmF,QAAAA,GACI,IAAInF,EAAQ,GACZ,MAAM8L,EAAO3K,KAAKstC,WAAWxxC,OAC7B,IAAK,IAAI0O,EAAI,EAAGA,EAAIG,EAAMH,IACtB3L,IAAgC,IAAvBmB,KAAKstC,WAAW9iC,GAAc,IAAM,IAEjD,OAAO3L,CACX,EASJ,MAAMk8D,GAAmB,IAAIF,GAMvB,MAAOG,WAAgCphB,GAMzCz+C,WAAAA,CAAYsI,G,MACRrI,QACA4E,KAAKi7D,QAA0B,QAAhB9mD,EAAO,OAAP1Q,QAAO,IAAPA,OAAO,EAAPA,EAASw3D,eAAO,IAAA9mD,EAAAA,EAAMzO,GAAY2mB,QAAQiQ,IAAI52B,EACjE,CAESm8C,UAAAA,CAAWp+C,GAChBzD,KAAKm3D,IAAMD,GAAUzzD,EAAQF,OAC7BvD,KAAKk7D,KA0Lb,SAA0B/D,GACtB,MAAMgE,EAAiBhE,EAAIE,eAAev7D,OACpCs/D,EAA4Bv0D,MAAMs0D,GACxC,IAAK,IAAI3wD,EAAI,EAAGA,EAAI2wD,EAAgB3wD,IAChC4wD,EAAc5wD,GAAKiwD,GAAetD,EAAIE,eAAe7sD,GAAIA,GAE7D,OAAO4wD,CACX,CAjMoBC,CAAiBr7D,KAAKm3D,IACtC,CAEShiB,wCAAAA,GACL,MAAO,EACX,CAES8E,2BAAAA,GACL,MAAO,EACX,CAESc,4BAAAA,CAA6Bt3C,GAOlC,MAAM,eAAEk1C,EAAc,KAAE57C,EAAI,cAAEooB,EAAa,qBAAE+nB,GAAyBzpC,EAChEy3D,EAAOl7D,KAAKk7D,KACZD,EAAUj7D,KAAKi7D,QACfhwD,EAAMyrD,GAAY35D,EAAM,cAAe47C,GAEvC2iB,EADgBt7D,KAAKm3D,IAAIC,YAAYnsD,GACP6uD,SAC9BnqB,GAA2CnqC,EAAAA,GAAAA,GAC7ConC,GAAkB,CACdE,aAAc,EACd9G,WAAY2S,EACZ9L,SAAU,cACV9vC,KAAMA,KAETotC,IAAY3kC,EAAAA,GAAAA,GAAI2kC,GAAU/mB,GAASA,EAAK,OAG7C,GAAIm4C,GAAc5rB,GAAa,KAAWzC,EAAsB,CAC5D,MAAMa,GAAcxkC,EAAAA,GAAAA,GAChBomC,GACA,CAACvqC,EAAQ+kC,EAASz0B,MACd/R,EAAAA,GAAAA,GAAQwmC,GAAUxX,IACVA,IACAvtB,EAAOutB,EAAYvB,cAAiB1b,GACpC/R,EAAAA,GAAAA,GAAQgvB,EAAYsH,iBAAmB+T,IACnC5oC,EAAO4oC,GAAqBt4B,CAAG,I,IAIpCtQ,IAEX,CAAC,GAGL,OAAI+f,EACO,SAA4BkoB,G,MAC/B,MAAMO,EAAY5tC,KAAK6tC,GAAG,GACpB2tB,EAAiCztB,EAAYH,EAAUxc,cAC7D,QAAer1B,IAAXsxC,QAAuCtxC,IAAfy/D,EAA0B,CAClD,MAAMC,EAAyB,QAAlBtnD,EAAAk5B,EAAOmuB,UAAW,IAAArnD,OAAA,EAAAA,EAAEo5B,KACjC,QAAaxxC,IAAT0/D,IAA0C,IAApBA,EAAKpwD,KAAKrL,MAChC,M,CAGR,OAAOw7D,CACX,EAEO,WACH,MAAM5tB,EAAY5tC,KAAK6tC,GAAG,GAC1B,OAAOE,EAAYH,EAAUxc,aACjC,C,CAED,OAAIjM,EACA,SAA4BkoB,GAC/B,MAAMC,EAAa,IAAIutB,GACjB/+D,OAAoBC,IAAXsxC,EAAuB,EAAIA,EAAOvxC,OACjD,IAAK,IAAI0O,EAAI,EAAGA,EAAI1O,EAAQ0O,IAAK,CAC7B,MAAMixD,EAAa,OAANpuB,QAAM,IAANA,OAAM,EAANA,EAAS7iC,GAAG+iC,KACzBD,EAAWxiC,IAAIN,OAAYzO,IAAT0/D,GAAsBA,EAAKpwD,KAAKrL,M,CAEtD,MAAMoF,EAASs2D,GAAgBrwD,KAAKrL,KAAMk7D,EAAMI,EAAehuB,EAAY2tB,GAC3E,MAAyB,kBAAX71D,EAAsBA,OAASrJ,CACjD,EAEO,WACH,MAAMqJ,EAASs2D,GAAgBrwD,KAAKrL,KAAMk7D,EAAMI,EAAeP,GAAkBE,GACjF,MAAyB,kBAAX71D,EAAsBA,OAASrJ,CACjD,CAER,CAESm/C,yBAAAA,CAA0Bz3C,GAO/B,MAAM,eAAEk1C,EAAc,KAAE57C,EAAI,SAAE8vC,EAAQ,qBAAEK,GAAyBzpC,EAC3Dy3D,EAAOl7D,KAAKk7D,KACZD,EAAUj7D,KAAKi7D,QACfhwD,EAAMyrD,GAAY35D,EAAM8vC,EAAU8L,GAElC2iB,EADgBt7D,KAAKm3D,IAAIC,YAAYnsD,GACP6uD,SAC9BjjD,GAAOrR,EAAAA,GAAAA,GACTonC,GAAkB,CACdE,aAAc,EACd9G,WAAY2S,EACZ9L,WACA9vC,UAEHuM,IACQ9D,EAAAA,GAAAA,GAAI8D,GAAIqyD,GAAMA,EAAE,OAI3B,GAAIJ,GAAc1kD,IAASA,EAAK,GAAG,KAAOq2B,EAAsB,CAC9D,MAAMhkB,EAAMrS,EAAK,GACXs3B,GAAoBjkB,EAAAA,GAAAA,GAAQhB,GAElC,GAC+B,IAA7BilB,EAAkBryC,SAClB4L,EAAAA,GAAAA,GAAQymC,EAAkB,GAAGlU,iBAC7B,CACA,MACMmU,EADoBD,EAAkB,GACK/c,aAEjD,OAAO,WACL,OAAOpxB,KAAK6tC,GAAG,GAAGzc,eAAiBgd,CACrC,C,CACK,CACL,MAAML,GAAcxkC,EAAAA,GAAAA,GAClB4kC,GACA,CAAC/oC,EAAQutB,UACa52B,IAAhB42B,IACFvtB,EAAOutB,EAAYvB,eAAiB,GACpCztB,EAAAA,GAAAA,GAAQgvB,EAAYsH,iBAAkB+T,IACpC5oC,EAAO4oC,IAAqB,CAAI,KAG7B5oC,IAET,CAAC,GAGH,OAAO,WACL,MAAMwoC,EAAY5tC,KAAK6tC,GAAG,GAC1B,OAA+C,IAAxCE,EAAYH,EAAUxc,aAC/B,C,EAGJ,OAAO,WACL,MAAMhsB,EAASs2D,GAAgBrwD,KAAKrL,KAAMk7D,EAAMI,EAAeP,GAAkBE,GAC/E,MAAyB,kBAAX71D,GAAyC,IAAXA,CAChD,CACN,EAIJ,SAASm2D,GAAcK,GAAyD,IAAjBC,IAAUhgE,UAAAC,OAAA,QAAAC,IAAAF,UAAA,KAAAA,UAAA,GACrE,MAAMigE,EAAU,IAAIz4D,IAEpB,IAAK,MAAM6lB,KAAO0yC,EAAW,CACzB,MAAMG,EAAS,IAAI14D,IACnB,IAAK,MAAMwgB,KAAWqF,EAAK,CACvB,QAAgBntB,IAAZ8nB,EAAuB,CACvB,GAAIg4C,EAEA,MAEA,OAAO,C,CAGf,MAAMG,EAAU,CAACn4C,EAAQuN,cAAe/wB,OAAOwjB,EAAQoW,iBACvD,IAAK,MAAMlxB,KAASizD,EAChB,GAAIF,EAAQj4D,IAAIkF,IACZ,IAAKgzD,EAAOl4D,IAAIkF,GACZ,OAAO,OAGX+yD,EAAQ/wD,IAAIhC,GACZgzD,EAAOhxD,IAAIhC,E,EAK3B,OAAO,CACX,CAWA,SAAS2yD,GAELO,EACAnC,EACAa,EACAM,GAEA,MAAMiB,EAAMD,EAAUnC,GAAUa,GAChC,IAAI/tD,EAAQsvD,EAAItvD,MAChB,QAAc7Q,IAAV6Q,EAAqB,CAErBA,EAAQuvD,GAAYD,EAAKE,GADTC,GAAkBH,EAAItB,iBAEtCsB,EAAItvD,MAAQA,C,CAIhB,OADY0vD,GAAiBtxC,MAAMhrB,KAAM,CAACk8D,EAAKtvD,EAAO+tD,EAAcM,GAExE,CAEA,SAASqB,GAELJ,EACAK,EACA5B,EACAM,GAEA,IAAIuB,EAAYD,EAEZ/xD,EAAI,EACR,MAAM4Y,EAAiB,GACvB,IAAIoqB,EAAIxtC,KAAK6tC,GAAGrjC,KAEhB,OAAa,CACT,IAAIiyD,GAmJR9vD,EAnJ8C6gC,EAAXgvB,EAqJtBE,MAAM/vD,EAAMykB,eAhJrB,QAJUr1B,IAAN0gE,IACAA,EAAIE,GAAuB3xC,MAAMhrB,KAAM,CAACk8D,EAAKM,EAAWhvB,EAAGhjC,EAAGmwD,EAAcM,KAG5EwB,IAAMtC,GACN,OAAOyC,GAA0Bx5C,EAAMo5C,EAAWhvB,GAGtD,IAAwB,IAApBivB,EAAEI,cACF,OAAOJ,EAAEjB,WAGbgB,EAAYC,EACZr5C,EAAKzc,KAAK6mC,GACVA,EAAIxtC,KAAK6tC,GAAGrjC,I,CAkIpB,IAEImC,CAlIJ,CAEA,SAASgwD,GAELT,EACAM,EACA7vD,EACAsU,EACA05C,EACAM,GAEA,MAAM6B,EA4HV,SACIzC,EACA1tD,EACAguD,GAEA,MAAMoC,EAAe,IAAI3C,GACnB4C,EAAiC,GAEvC,IAAK,MAAM3kC,KAAKgiC,EAAQt5C,SAAU,CAC9B,IAA+B,IAA3B45C,EAAaG,GAAGziC,EAAEnP,KAClB,SAEJ,GH1dqB,IG0djBmP,EAAE9wB,MAAM5G,KAAwB,CAChCq8D,EAAkBr2D,KAAK0xB,GACvB,Q,CAEJ,MAAM4kC,EAAmB5kC,EAAE9wB,MAAM6xD,YAAYt9D,OAC7C,IAAK,IAAI0O,EAAI,EAAGA,EAAIyyD,EAAkBzyD,IAAK,CACvC,MACM5L,EAASs+D,GADI7kC,EAAE9wB,MAAM6xD,YAAY5uD,GACOmC,QAC/B5Q,IAAX6C,GACAm+D,EAAahyD,IAAI,CACbxD,MAAO3I,EACPsqB,IAAKmP,EAAEnP,IACPsxC,MAAOniC,EAAEmiC,O,EAMzB,IAAIsC,EAE6B,IAA7BE,EAAkBlhE,QAAsC,IAAtBihE,EAAapyD,OAC/CmyD,EAAQC,GAGZ,QAAchhE,IAAV+gE,EAAqB,CACrBA,EAAQ,IAAI1C,GACZ,IAAK,MAAM/hC,KAAK0kC,EAAah8C,SACzBo8C,GAAQ9kC,EAAGykC,E,CAInB,GAAIE,EAAkBlhE,OAAS,IAqJnC,SAAkCu+D,GAC9B,IAAK,MAAMhiC,KAAKgiC,EAAQt5C,SACpB,GHhpBqB,IGgpBjBsX,EAAE9wB,MAAM5G,KACR,OAAO,EAGf,OAAO,CACX,CA5JyCy8D,CAAyBN,GAC1D,IAAK,MAAMzkC,KAAK2kC,EACZF,EAAM/xD,IAAIstB,GAIlB,OAAOykC,CACX,CA9KkBO,CAAgBb,EAAUnC,QAAS1tD,EAAOguD,GACxD,GAAmB,IAAfmC,EAAMnyD,KAEN,OADA2yD,GAAWpB,EAAKM,EAAW7vD,EAAOwtD,IAC3BA,GAGX,IAAIrkD,EAAWsmD,GAAYU,GAC3B,MAAMS,EAsLV,SACIlD,EACAM,GAEA,IAAIzxC,EACJ,IAAK,MAAMmP,KAAKgiC,EAAQt5C,SACpB,IAA+B,IAA3B45C,EAAaG,GAAGziC,EAAEnP,KAClB,QAAYntB,IAARmtB,EACAA,EAAMmP,EAAEnP,SACL,GAAIA,IAAQmP,EAAEnP,IACjB,OAIZ,OAAOA,CACX,CArMyBs0C,CAAaV,EAAOnC,GAEzC,QAAqB5+D,IAAjBwhE,EACAznD,EAAS+mD,eAAgB,EACzB/mD,EAAS0lD,WAAa+B,EACtBznD,EAASukD,QAAQoD,UAAYF,OAC1B,GAiUX,SAA0ClD,GACtC,GAVJ,SAAoCA,GAChC,IAAK,MAAMhiC,KAAKgiC,EAAQt5C,SACpB,GHzpBqB,IGypBjBsX,EAAE9wB,MAAM5G,KACR,OAAO,EAGf,OAAO,CACX,CAGQ+8D,CAA2BrD,GAC3B,OAAO,EAEX,MAAMsD,EAMV,SACItD,GAEA,MAAMuD,EAAe,IAAIv1D,IACzB,IAAK,MAAMgwB,KAAKgiC,EAAS,CACrB,MAAMpvD,EAAMsvD,GAAgBliC,GAAG,GAC/B,IAAIxhB,EAAO+mD,EAAav+C,IAAIpU,QACflP,IAAT8a,IACAA,EAAO,CAAC,EACR+mD,EAAa9yD,IAAIG,EAAK4L,IAE1BA,EAAKwhB,EAAEnP,MAAO,C,CAElB,OAAO00C,CACX,CApBoBC,CAAsBxD,EAAQt5C,UAG9C,OAmBJ,SACI48C,GAEA,IAAK,MAAM9+D,KAASgI,MAAMyS,KAAKqkD,EAAQ72C,UACnC,GAAIpoB,OAAOiV,KAAK9U,GAAO/C,OAAS,EAC5B,OAAO,EAGf,OAAO,CACX,CA7BQgiE,CAAqBH,KA+B7B,SACIA,GAEA,IAAK,MAAM9+D,KAASgI,MAAMyS,KAAKqkD,EAAQ72C,UACnC,GAAkC,IAA9BpoB,OAAOiV,KAAK9U,GAAO/C,OACnB,OAAO,EAGf,OAAO,CACX,CAxC0CiiE,CAA6BJ,EAEvE,CAzUeK,CAAiClB,GAAQ,CAChD,MAAMtB,GAAaltD,EAAAA,GAAAA,GAAIwuD,EAAMjmD,MAC7Bf,EAAS+mD,eAAgB,EACzB/mD,EAAS0lD,WAAaA,EACtB1lD,EAASukD,QAAQoD,UAAYjC,EAC7ByC,GAAyBjzC,MAAMhrB,KAAM,CAACk8D,EAAKj7C,EAAW67C,EAAMjmD,KAAMokD,G,CAItE,OADAnlD,EAAWwnD,GAAWpB,EAAKM,EAAW7vD,EAAOmJ,GACtCA,CACX,CAEA,SAASmoD,GAEL/B,EACAj7C,EACAilB,EACA+0B,GAEA,MAAMn1B,EAA0B,GAChC,IAAK,IAAIt7B,EAAI,EAAGA,GAAKyW,EAAWzW,IAC5Bs7B,EAAWn/B,KAAK3G,KAAK6tC,GAAGrjC,GAAG5G,WAE/B,MAAMs6D,EAAWhC,EAAItB,cASrBK,EAGJ,SAA6Bx3D,GAMzB,MAAMoiC,GAAUrgC,EAAAA,GAAAA,GAAI/B,EAAQqiC,YAAaM,GACrCxiB,GAAWwiB,KACbzgC,KAAK,MACDqgC,EACyB,IAA3BviC,EAAQs0D,WAAWriD,IAAY,GAAKjS,EAAQs0D,WAAWriD,IAC3D,IAAI2wB,EACA,qCAAAhmC,OAAqCoD,EAAQyiC,iBAAiBvgC,KAC1D,MACH,UAAAtF,OAWT,SAA8B8jB,GAC1B,GAAIA,aAAgBC,GAChB,MAAO,UACJ,GAAID,aAAgBU,GACvB,MAAO,SACJ,GAAIV,aAAgBe,GACvB,MAAO,KACJ,GAAIf,aAAgBW,GACvB,MAAO,eACJ,GAAIX,aAAgBY,GACvB,MAAO,mBACJ,GAAIZ,aAAgBc,GACvB,MAAO,WACJ,GAAId,aAAgBa,GACvB,MAAO,OACJ,GAAIb,aAAgBiB,GACvB,MAAO,UAEP,MAAM3kB,MAAM,uBAEpB,CA/BkB4mB,CAAqB5jB,EAAQs0D,aAAW13D,OAAG2lC,EAAU,iBAAA3lC,OACnDoD,EAAQwhC,aAAa/nC,KAAI,aAAW,IAAAmD,OAC5CwlC,EAAO,+DAMf,OAJAQ,GACIA,mHAGGA,CACX,CAhCoB83B,CAAoB,CAChCl5B,aAHiBi5B,EAASnhE,KAI1BmpC,mBACA6xB,WAJemG,EAASnG,WAKxBjyB,eAGR,CAiDA,SAAS82B,GACLx5C,EACAxU,EACAwvD,GAEA,MAAMC,EAAkBt0D,GACpB6E,EAASyrD,QAAQt5C,UAChBzX,GAAMA,EAAE/B,MAAM6xD,cAQnB,MAAO,CACHkF,YAAaF,EACbG,mBARmBC,GACnBH,EACKj1D,QAAQE,GAA2BA,aAAautD,KAChDrxD,KAAK8D,GAAMA,EAAE1F,aACjB0F,GAAMA,EAAE8nB,eAKTqtC,UAAWr7C,EAEnB,CA6DA,SAAS85C,GACL/D,EACAxsD,GAEA,GACIwsD,aAAsBtC,IACtBvzB,GAAa32B,EAAOwsD,EAAWv1D,WAE/B,OAAOu1D,EAAWv6D,MAG1B,CAmBA,SAASw9D,GAAYe,GACjB,MAAO,CACH9C,QAAS8C,EACTT,MAAO,CAAC,EACRG,eAAe,EACfrB,YAAa,EAErB,CAEA,SAAS8B,GACLpB,EACA5iD,EACA3M,EACAa,GAIA,OAFAA,EAAK2uD,GAAYD,EAAK1uD,GACtB8L,EAAKojD,MAAM/vD,EAAMykB,cAAgB5jB,EAC1BA,CACX,CAEA,SAAS2uD,GAAYD,EAAU30D,GAC3B,GAAIA,IAAU4yD,GACV,OAAO5yD,EAIX,MAAMm3D,EAASn3D,EAAM8yD,QAAQpvD,IACvB3E,EAAW41D,EAAI1E,OAAOkH,GAC5B,YAAiB3iE,IAAbuK,EACOA,GAEXiB,EAAM8yD,QAAQC,WACd4B,EAAI1E,OAAOkH,GAAUn3D,EACdA,EACX,CAEA,SAAS80D,GAAkB6B,GACvB,MAAM7D,EAAU,IAAID,GAEduE,EAAsBT,EAAS9E,YAAYt9D,OACjD,IAAK,IAAI0O,EAAI,EAAGA,EAAIm0D,EAAqBn0D,IAAK,CAO1C2yD,GAL0B,CACtB51D,MAFW22D,EAAS9E,YAAY5uD,GAAG5L,OAGnCsqB,IAAK1e,EACLgwD,MAAO,IAEKH,E,CAGpB,OAAOA,CACX,CAEA,SAAS8C,GAAQzhC,EAAmB2+B,GAChC,MAAMuE,EAAIljC,EAAOn0B,MAEjB,GHxlByB,IGwlBrBq3D,EAAEj+D,KAAwB,CAC1B,GAAI+6B,EAAO8+B,MAAM1+D,OAAS,EAAG,CACzB,MAAM+iE,EAAW,IAAInjC,EAAO8+B,OAO5B2C,GALgC,CAC5B51D,MAFgBs3D,EAASxyD,MAGzB6c,IAAKwS,EAAOxS,IACZsxC,MAAOqE,GAEWxE,E,MAItBA,EAAQtvD,IAAI2wB,GAEhB,M,CAGCkjC,EAAE7E,wBACHM,EAAQtvD,IAAI2wB,GAGhB,MAAMuhC,EAAmB2B,EAAExF,YAAYt9D,OACvC,IAAK,IAAI0O,EAAI,EAAGA,EAAIyyD,EAAkBzyD,IAAK,CACvC,MACM6tB,EAAIymC,GAAiBpjC,EADRkjC,EAAExF,YAAY5uD,SAGvBzO,IAANs8B,GACA8kC,GAAQ9kC,EAAGgiC,E,CAGvB,CAEA,SAASyE,GACLpjC,EACAy9B,GAEA,GAAIA,aAAsBrC,GACtB,MAAO,CACHvvD,MAAO4xD,EAAWv6D,OAClBsqB,IAAKwS,EAAOxS,IACZsxC,MAAO9+B,EAAO8+B,OAEf,GAAIrB,aAAsBpC,GAAgB,CAC7C,MAAMyD,EAAQ,IAAI9+B,EAAO8+B,MAAOrB,EAAWlC,aAC3C,MAAO,CACH1vD,MAAO4xD,EAAWv6D,OAClBsqB,IAAKwS,EAAOxS,IACZsxC,Q,CAIZ,CCnrBO,IAAIuE,GAOAC,GAOAC,GASAC,GAaAC,GA8BAC,GA2BAC,GAwBAC,GA4BAC,GA8BAC,GAyBAC,GA2BAC,GAmBAC,GAyCAC,GAwBAC,GAwBAC,GAqBAC,GAYAC,GA2CAC,GA0BAC,GAoCAC,GAqBAC,GAQAC,GA4CAC,GAiBAC,GAuBAC,GAwBAC,GAuBAC,GAuTAC,GAuBAC,GAwBAC,GAwBAC,GA6BAC,GAmBAC,GAcAC,GAgCAC,GAwBAC,GAYAC,GAwBAC,GAqBAC,GAaAC,GAeAC,GAaAC,GAoBAC,GAiBAC,GAiBAC,GAoBAC,GAmBAC,GAmBAC,GAkCAC,GAOAC,GAwBAC,GAkBAC,GA4CAC,GA2EAC,GAkBAC,GA2BAC,GAqCAC,GA0BAC,GAsBAC,GAsBAC,GAwBAC,GAwCAC,GAgBAC,GAcAC,GAoBAC,GAqBAC,GAsBAC,GAuBAC,GAeAC,GAeAC,GAsBAC,GAOAC,GAOAC,GAaAC,GAWAC,GAOAC,GAOAC,IA57DX,SAAW7E,GAIPA,EAAYjE,GAHZ,SAAYj8D,GACR,MAAwB,kBAAVA,CAClB,CAEH,CALD,CAKGkgE,KAAgBA,GAAc,CAAC,IAElC,SAAWC,GAIPA,EAAIlE,GAHJ,SAAYj8D,GACR,MAAwB,kBAAVA,CAClB,CAEH,CALD,CAKGmgE,KAAQA,GAAM,CAAC,IAElB,SAAWC,GACPA,EAAQ4E,WAAa,WACrB5E,EAAQ6E,UAAY,WAIpB7E,EAAQnE,GAHR,SAAYj8D,GACR,MAAwB,kBAAVA,GAAsBogE,EAAQ4E,WAAahlE,GAASA,GAASogE,EAAQ6E,SACvF,CAEH,CAPD,CAOG7E,KAAYA,GAAU,CAAC,IAE1B,SAAWC,GACPA,EAAS2E,UAAY,EACrB3E,EAAS4E,UAAY,WAIrB5E,EAASpE,GAHT,SAAYj8D,GACR,MAAwB,kBAAVA,GAAsBqgE,EAAS2E,WAAahlE,GAASA,GAASqgE,EAAS4E,SACzF,CAEH,CAPD,CAOG5E,KAAaA,GAAW,CAAC,IAM5B,SAAWC,GAePA,EAAS9W,OATT,SAAgBt7C,EAAMF,GAOlB,OANIE,IAASg3D,OAAOD,YAChB/2D,EAAOmyD,GAAS4E,WAEhBj3D,IAAck3D,OAAOD,YACrBj3D,EAAYqyD,GAAS4E,WAElB,CAAE/2D,OAAMF,YACnB,EASAsyD,EAASrE,GAJT,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAGC,cAAcF,IAAcC,GAAG/E,SAAS8E,EAAUj3D,OAASk3D,GAAG/E,SAAS8E,EAAUn3D,UAC/F,CAEH,CAxBD,CAwBGsyD,KAAaA,GAAW,CAAC,IAM5B,SAAWC,GAYPA,EAAM/W,OAXN,SAAgB8b,EAAKC,EAAKC,EAAOC,GAC7B,GAAIL,GAAG/E,SAASiF,IAAQF,GAAG/E,SAASkF,IAAQH,GAAG/E,SAASmF,IAAUJ,GAAG/E,SAASoF,GAC1E,MAAO,CAAE13D,MAAOuyD,GAAS9W,OAAO8b,EAAKC,GAAMn3D,IAAKkyD,GAAS9W,OAAOgc,EAAOC,IAEtE,GAAInF,GAASrE,GAAGqJ,IAAQhF,GAASrE,GAAGsJ,GACrC,MAAO,CAAEx3D,MAAOu3D,EAAKl3D,IAAKm3D,GAG1B,MAAM,IAAI3jE,MAAM,8CAADJ,OAA+C8jE,EAAG,MAAA9jE,OAAK+jE,EAAG,MAAA/jE,OAAKgkE,EAAK,MAAAhkE,OAAKikE,EAAI,KAEpG,EASAlF,EAAMtE,GAJN,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAGC,cAAcF,IAAc7E,GAASrE,GAAGkJ,EAAUp3D,QAAUuyD,GAASrE,GAAGkJ,EAAU/2D,IAChG,CAEH,CArBD,CAqBGmyD,KAAUA,GAAQ,CAAC,IAMtB,SAAWC,GASPA,EAAShX,OAHT,SAAgBkc,EAAKj3D,GACjB,MAAO,CAAEi3D,MAAKj3D,QAClB,EASA+xD,EAASvE,GAJT,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAGC,cAAcF,IAAc5E,GAAMtE,GAAGkJ,EAAU12D,SAAW22D,GAAGO,OAAOR,EAAUO,MAAQN,GAAGloE,UAAUioE,EAAUO,KAC3H,CAEH,CAlBD,CAkBGlF,KAAaA,GAAW,CAAC,IAM5B,SAAWC,GAWPA,EAAajX,OAHb,SAAgBoc,EAAWC,EAAaC,EAAsBC,GAC1D,MAAO,CAAEH,YAAWC,cAAaC,uBAAsBC,uBAC3D,EAWAtF,EAAaxE,GANb,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAGC,cAAcF,IAAc5E,GAAMtE,GAAGkJ,EAAUU,cAAgBT,GAAGO,OAAOR,EAAUS,YACtFrF,GAAMtE,GAAGkJ,EAAUW,wBAClBvF,GAAMtE,GAAGkJ,EAAUY,uBAAyBX,GAAGloE,UAAUioE,EAAUY,sBAC/E,CAEH,CAtBD,CAsBGtF,KAAiBA,GAAe,CAAC,IAMpC,SAAWC,GAYPA,EAAMlX,OARN,SAAgBwc,EAAKC,EAAOC,EAAMC,GAC9B,MAAO,CACHH,MACAC,QACAC,OACAC,QAER,EAYAzF,EAAMzE,GAPN,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,IAAcC,GAAGgB,YAAYjB,EAAUa,IAAK,EAAG,IAChEZ,GAAGgB,YAAYjB,EAAUc,MAAO,EAAG,IACnCb,GAAGgB,YAAYjB,EAAUe,KAAM,EAAG,IAClCd,GAAGgB,YAAYjB,EAAUgB,MAAO,EAAG,EAC9C,CAEH,CAxBD,CAwBGzF,KAAUA,GAAQ,CAAC,IAMtB,SAAWC,GAUPA,EAAiBnX,OANjB,SAAgB/6C,EAAO43D,GACnB,MAAO,CACH53D,QACA43D,QAER,EASA1F,EAAiB1E,GAJjB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,IAAc5E,GAAMtE,GAAGkJ,EAAU12D,QAAUiyD,GAAMzE,GAAGkJ,EAAUkB,MAC1F,CAEH,CAnBD,CAmBG1F,KAAqBA,GAAmB,CAAC,IAM5C,SAAWC,GAWPA,EAAkBpX,OAPlB,SAAgB5iC,EAAO0/C,EAAUC,GAC7B,MAAO,CACH3/C,QACA0/C,WACAC,sBAER,EAWA3F,EAAkB3E,GANlB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,IAAcC,GAAGO,OAAOR,EAAUv+C,SAClDw+C,GAAGloE,UAAUioE,EAAUmB,WAAajF,GAASpF,GAAGkJ,MAChDC,GAAGloE,UAAUioE,EAAUoB,sBAAwBnB,GAAGoB,WAAWrB,EAAUoB,oBAAqBlF,GAASpF,IACjH,CAEH,CAtBD,CAsBG2E,KAAsBA,GAAoB,CAAC,IAK9C,SAAWC,GAIPA,EAAiB4F,QAAU,UAI3B5F,EAAiB6F,QAAU,UAI3B7F,EAAiB8F,OAAS,QAC7B,CAbD,CAaG9F,KAAqBA,GAAmB,CAAC,IAM5C,SAAWC,GAuBPA,EAAatX,OAnBb,SAAgBr7C,EAAWG,EAASs4D,EAAgBC,EAAcC,EAAMC,GACpE,MAAMxgE,EAAS,CACX4H,YACAG,WAcJ,OAZI82D,GAAG4B,QAAQJ,KACXrgE,EAAOqgE,eAAiBA,GAExBxB,GAAG4B,QAAQH,KACXtgE,EAAOsgE,aAAeA,GAEtBzB,GAAG4B,QAAQF,KACXvgE,EAAOugE,KAAOA,GAEd1B,GAAG4B,QAAQD,KACXxgE,EAAOwgE,cAAgBA,GAEpBxgE,CACX,EAYAu6D,EAAa7E,GAPb,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,IAAcC,GAAG/E,SAAS8E,EAAUh3D,YAAci3D,GAAG/E,SAAS8E,EAAUh3D,aACxFi3D,GAAGloE,UAAUioE,EAAUyB,iBAAmBxB,GAAG/E,SAAS8E,EAAUyB,mBAChExB,GAAGloE,UAAUioE,EAAU0B,eAAiBzB,GAAG/E,SAAS8E,EAAU0B,iBAC9DzB,GAAGloE,UAAUioE,EAAU2B,OAAS1B,GAAGO,OAAOR,EAAU2B,MAChE,CAEH,CAnCD,CAmCGhG,KAAiBA,GAAe,CAAC,IAMpC,SAAWC,GAUPA,EAA6BvX,OAN7B,SAAgBF,EAAUziD,GACtB,MAAO,CACHyiD,WACAziD,UAER,EASAk6D,EAA6B9E,GAJ7B,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAc3E,GAASvE,GAAGkJ,EAAU7b,WAAa8b,GAAGO,OAAOR,EAAUt+D,QAC3F,CAEH,CAnBD,CAmBGk6D,KAAiCA,GAA+B,CAAC,IAKpE,SAAWC,GAIPA,EAAmBp/D,MAAQ,EAI3Bo/D,EAAmBiG,QAAU,EAI7BjG,EAAmBkG,YAAc,EAIjClG,EAAmBmG,KAAO,CAC7B,CAjBD,CAiBGnG,KAAuBA,GAAqB,CAAC,IAOhD,SAAWC,GAOPA,EAAcmG,YAAc,EAM5BnG,EAAcoG,WAAa,CAC9B,CAdD,CAcGpG,KAAkBA,GAAgB,CAAC,IAOtC,SAAWC,GAKPA,EAAgBjF,GAJhB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,IAAcC,GAAGO,OAAOR,EAAUmC,KAC9D,CAEH,CAND,CAMGpG,KAAoBA,GAAkB,CAAC,IAM1C,SAAWC,GAoBPA,EAAW3X,OAhBX,SAAgB/6C,EAAO5H,EAAS0gE,EAAU94C,EAAM1Q,EAAQypD,GACpD,IAAIjhE,EAAS,CAAEkI,QAAO5H,WAatB,OAZIu+D,GAAG4B,QAAQO,KACXhhE,EAAOghE,SAAWA,GAElBnC,GAAG4B,QAAQv4C,KACXloB,EAAOkoB,KAAOA,GAEd22C,GAAG4B,QAAQjpD,KACXxX,EAAOwX,OAASA,GAEhBqnD,GAAG4B,QAAQQ,KACXjhE,EAAOihE,mBAAqBA,GAEzBjhE,CACX,EAiBA46D,EAAWlF,GAZX,SAAYj8D,GACR,IAAIsV,EACJ,IAAI6vD,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IACX5E,GAAMtE,GAAGkJ,EAAU12D,QACnB22D,GAAGO,OAAOR,EAAUt+D,WACnBu+D,GAAGrqD,OAAOoqD,EAAUoC,WAAanC,GAAGloE,UAAUioE,EAAUoC,aACxDnC,GAAGhF,QAAQ+E,EAAU12C,OAAS22C,GAAGO,OAAOR,EAAU12C,OAAS22C,GAAGloE,UAAUioE,EAAU12C,SAClF22C,GAAGloE,UAAUioE,EAAUsC,kBAAqBrC,GAAGO,OAA4C,QAApCrwD,EAAK6vD,EAAUsC,uBAAoC,IAAPnyD,OAAgB,EAASA,EAAGgyD,SAC/HlC,GAAGO,OAAOR,EAAUpnD,SAAWqnD,GAAGloE,UAAUioE,EAAUpnD,WACtDqnD,GAAGloE,UAAUioE,EAAUqC,qBAAuBpC,GAAGoB,WAAWrB,EAAUqC,mBAAoBzG,GAA6B9E,IACnI,CAEH,CArCD,CAqCGkF,KAAeA,GAAa,CAAC,IAMhC,SAAWC,GAWPA,EAAQ5X,OAPR,SAAgBke,EAAOC,GACnB,IAAIphE,EAAS,CAAEmhE,QAAOC,WAAU,QAAAh7D,EAAA3P,UAAAC,OADDivB,EAAI,IAAAlkB,MAAA2E,EAAA,EAAAA,EAAA,KAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAJqf,EAAIrf,EAAA,GAAA7P,UAAA6P,GAKnC,OAHIu4D,GAAG4B,QAAQ96C,IAASA,EAAKjvB,OAAS,IAClCsJ,EAAOvJ,UAAYkvB,GAEhB3lB,CACX,EASA66D,EAAQnF,GAJR,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAcC,GAAGO,OAAOR,EAAUuC,QAAUtC,GAAGO,OAAOR,EAAUwC,QACtF,CAEH,CApBD,CAoBGvG,KAAYA,GAAU,CAAC,IAM1B,SAAWC,GASPA,EAAS/iE,QAHT,SAAiBmQ,EAAOm5D,GACpB,MAAO,CAAEn5D,QAAOm5D,UACpB,EAUAvG,EAASwG,OAHT,SAAgBC,EAAUF,GACtB,MAAO,CAAEn5D,MAAO,CAAEV,MAAO+5D,EAAU15D,IAAK05D,GAAYF,UACxD,EASAvG,EAAS0G,IAHT,SAAat5D,GACT,MAAO,CAAEA,QAAOm5D,QAAS,GAC7B,EAQAvG,EAASpF,GANT,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,IACjBC,GAAGO,OAAOR,EAAUyC,UACpBrH,GAAMtE,GAAGkJ,EAAU12D,MAC9B,CAEH,CAlCD,CAkCG4yD,KAAaA,GAAW,CAAC,IAE5B,SAAWC,GAWPA,EAAiB9X,OAVjB,SAAgB5iC,EAAOohD,EAAmBppB,GACtC,MAAMr4C,EAAS,CAAEqgB,SAOjB,YAN0B1pB,IAAtB8qE,IACAzhE,EAAOyhE,kBAAoBA,QAEX9qE,IAAhB0hD,IACAr4C,EAAOq4C,YAAcA,GAElBr4C,CACX,EAQA+6D,EAAiBrF,GANjB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,IAAcC,GAAGO,OAAOR,EAAUv+C,SACrDw+C,GAAG6C,QAAQ9C,EAAU6C,yBAAsD9qE,IAAhCioE,EAAU6C,qBACrD5C,GAAGO,OAAOR,EAAUvmB,mBAA0C1hD,IAA1BioE,EAAUvmB,YACvD,CAEH,CAnBD,CAmBG0iB,KAAqBA,GAAmB,CAAC,IAE5C,SAAWC,GAKPA,EAA2BtF,GAJ3B,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGO,OAAOR,EACrB,CAEH,CAND,CAMG5D,KAA+BA,GAA6B,CAAC,IAEhE,SAAWC,GAWPA,EAAkBljE,QAHlB,SAAiBmQ,EAAOm5D,EAASM,GAC7B,MAAO,CAAEz5D,QAAOm5D,UAASO,aAAcD,EAC3C,EAYA1G,EAAkBqG,OAHlB,SAAgBC,EAAUF,EAASM,GAC/B,MAAO,CAAEz5D,MAAO,CAAEV,MAAO+5D,EAAU15D,IAAK05D,GAAYF,UAASO,aAAcD,EAC/E,EAWA1G,EAAkBuG,IAHlB,SAAat5D,EAAOy5D,GAChB,MAAO,CAAEz5D,QAAOm5D,QAAS,GAAIO,aAAcD,EAC/C,EAMA1G,EAAkBvF,GAJlB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOqhE,GAASpF,GAAGkJ,KAAe7D,GAAiBrF,GAAGkJ,EAAUgD,eAAiB5G,GAA2BtF,GAAGkJ,EAAUgD,cAC7H,CAEH,CAtCD,CAsCG3G,KAAsBA,GAAoB,CAAC,IAM9C,SAAWC,GAOPA,EAAiBjY,OAHjB,SAAgB4e,EAAcC,GAC1B,MAAO,CAAED,eAAcC,QAC3B,EAQA5G,EAAiBxF,GANjB,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IACXnD,GAAwC/F,GAAGkJ,EAAUiD,eACrDpgE,MAAMC,QAAQk9D,EAAUkD,MACnC,CAEH,CAfD,CAeG5G,KAAqBA,GAAmB,CAAC,IAE5C,SAAWC,GAcPA,EAAWlY,OAbX,SAAgBkc,EAAK9gE,EAASsjE,GAC1B,IAAI3hE,EAAS,CACTugE,KAAM,SACNpB,OAQJ,YANgBxoE,IAAZ0H,QAAgD1H,IAAtB0H,EAAQ0jE,gBAAsDprE,IAA3B0H,EAAQ2jE,iBACrEhiE,EAAO3B,QAAUA,QAEF1H,IAAfgrE,IACA3hE,EAAO4hE,aAAeD,GAEnB3hE,CACX,EAOAm7D,EAAWzF,GALX,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOmlE,GAAgC,WAAnBA,EAAU2B,MAAqB1B,GAAGO,OAAOR,EAAUO,YAA+BxoE,IAAtBioE,EAAUvgE,eACpD1H,IAAhCioE,EAAUvgE,QAAQ0jE,WAA2BlD,GAAG6C,QAAQ9C,EAAUvgE,QAAQ0jE,mBAAqDprE,IAArCioE,EAAUvgE,QAAQ2jE,gBAAgCnD,GAAG6C,QAAQ9C,EAAUvgE,QAAQ2jE,yBAAkDrrE,IAA3BioE,EAAUgD,cAA8B5G,GAA2BtF,GAAGkJ,EAAUgD,cAC1R,CAEH,CArBD,CAqBGzG,KAAeA,GAAa,CAAC,IAEhC,SAAWC,GAePA,EAAWnY,OAdX,SAAgBgf,EAAQC,EAAQ7jE,EAASsjE,GACrC,IAAI3hE,EAAS,CACTugE,KAAM,SACN0B,SACAC,UAQJ,YANgBvrE,IAAZ0H,QAAgD1H,IAAtB0H,EAAQ0jE,gBAAsDprE,IAA3B0H,EAAQ2jE,iBACrEhiE,EAAO3B,QAAUA,QAEF1H,IAAfgrE,IACA3hE,EAAO4hE,aAAeD,GAEnB3hE,CACX,EAOAo7D,EAAW1F,GALX,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOmlE,GAAgC,WAAnBA,EAAU2B,MAAqB1B,GAAGO,OAAOR,EAAUqD,SAAWpD,GAAGO,OAAOR,EAAUsD,eAAkCvrE,IAAtBioE,EAAUvgE,eACtF1H,IAAhCioE,EAAUvgE,QAAQ0jE,WAA2BlD,GAAG6C,QAAQ9C,EAAUvgE,QAAQ0jE,mBAAqDprE,IAArCioE,EAAUvgE,QAAQ2jE,gBAAgCnD,GAAG6C,QAAQ9C,EAAUvgE,QAAQ2jE,yBAAkDrrE,IAA3BioE,EAAUgD,cAA8B5G,GAA2BtF,GAAGkJ,EAAUgD,cAC1R,CAEH,CAtBD,CAsBGxG,KAAeA,GAAa,CAAC,IAEhC,SAAWC,GAcPA,EAAWpY,OAbX,SAAgBkc,EAAK9gE,EAASsjE,GAC1B,IAAI3hE,EAAS,CACTugE,KAAM,SACNpB,OAQJ,YANgBxoE,IAAZ0H,QAAgD1H,IAAtB0H,EAAQ8jE,gBAAyDxrE,IAA9B0H,EAAQ+jE,oBACrEpiE,EAAO3B,QAAUA,QAEF1H,IAAfgrE,IACA3hE,EAAO4hE,aAAeD,GAEnB3hE,CACX,EAOAq7D,EAAW3F,GALX,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOmlE,GAAgC,WAAnBA,EAAU2B,MAAqB1B,GAAGO,OAAOR,EAAUO,YAA+BxoE,IAAtBioE,EAAUvgE,eACpD1H,IAAhCioE,EAAUvgE,QAAQ8jE,WAA2BtD,GAAG6C,QAAQ9C,EAAUvgE,QAAQ8jE,mBAAwDxrE,IAAxCioE,EAAUvgE,QAAQ+jE,mBAAmCvD,GAAG6C,QAAQ9C,EAAUvgE,QAAQ+jE,4BAAqDzrE,IAA3BioE,EAAUgD,cAA8B5G,GAA2BtF,GAAGkJ,EAAUgD,cAChS,CAEH,CArBD,CAqBGvG,KAAeA,GAAa,CAAC,IAEhC,SAAWC,GAcPA,EAAc5F,GAbd,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOmlE,SACoBjoE,IAAtBioE,EAAUyD,cAAuD1rE,IAA9BioE,EAAU0D,wBACf3rE,IAA9BioE,EAAU0D,iBAAiC1D,EAAU0D,gBAAgB1+D,OAAO2+D,GACrE1D,GAAGO,OAAOmD,EAAOhC,MACVpF,GAAWzF,GAAG6M,IAAWnH,GAAW1F,GAAG6M,IAAWlH,GAAW3F,GAAG6M,GAGhErH,GAAiBxF,GAAG6M,KAG3C,CAEH,CAfD,CAeGjH,KAAkBA,GAAgB,CAAC,KAwStC,SAAWC,GAQPA,EAAuBtY,OAHvB,SAAgBkc,GACZ,MAAO,CAAEA,MACb,EASA5D,EAAuB7F,GAJvB,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAcC,GAAGO,OAAOR,EAAUO,IACxD,CAEH,CAjBD,CAiBG5D,KAA2BA,GAAyB,CAAC,IAMxD,SAAWC,GASPA,EAAgCvY,OAHhC,SAAgBkc,EAAKqD,GACjB,MAAO,CAAErD,MAAKqD,UAClB,EASAhH,EAAgC9F,GAJhC,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAcC,GAAGO,OAAOR,EAAUO,MAAQN,GAAGhF,QAAQ+E,EAAU4D,QACrF,CAEH,CAlBD,CAkBGhH,KAAoCA,GAAkC,CAAC,IAM1E,SAAWC,GASPA,EAAwCxY,OAHxC,SAAgBkc,EAAKqD,GACjB,MAAO,CAAErD,MAAKqD,UAClB,EASA/G,EAAwC/F,GAJxC,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAcC,GAAGO,OAAOR,EAAUO,OAA+B,OAAtBP,EAAU4D,SAAoB3D,GAAGhF,QAAQ+E,EAAU4D,SACpH,CAEH,CAlBD,CAkBG/G,KAA4CA,GAA0C,CAAC,IAM1F,SAAWC,GAWPA,EAAiBzY,OAHjB,SAAgBkc,EAAK7iE,EAAYkmE,EAAS1iE,GACtC,MAAO,CAAEq/D,MAAK7iE,aAAYkmE,UAAS1iE,OACvC,EASA47D,EAAiBhG,GAJjB,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAcC,GAAGO,OAAOR,EAAUO,MAAQN,GAAGO,OAAOR,EAAUtiE,aAAeuiE,GAAGhF,QAAQ+E,EAAU4D,UAAY3D,GAAGO,OAAOR,EAAU9+D,KACxJ,CAEH,CApBD,CAoBG47D,KAAqBA,GAAmB,CAAC,IAS5C,SAAWC,GAIPA,EAAW8G,UAAY,YAIvB9G,EAAW+G,SAAW,WAQtB/G,EAAWjG,GAJX,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOmlE,IAAcjD,EAAW8G,WAAa7D,IAAcjD,EAAW+G,QAC1E,CAEH,CAjBD,CAiBG/G,KAAeA,GAAa,CAAC,IAEhC,SAAWC,GAQPA,EAAclG,GAJd,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcrlE,IAAUkiE,GAAWjG,GAAGkJ,EAAU2B,OAAS1B,GAAGO,OAAOR,EAAUnlE,MAC3F,CAEH,CATD,CASGmiE,KAAkBA,GAAgB,CAAC,IAKtC,SAAWC,GACPA,EAAmB8G,KAAO,EAC1B9G,EAAmB+G,OAAS,EAC5B/G,EAAmBgH,SAAW,EAC9BhH,EAAmBiH,YAAc,EACjCjH,EAAmBkH,MAAQ,EAC3BlH,EAAmBmH,SAAW,EAC9BnH,EAAmBoH,MAAQ,EAC3BpH,EAAmB/wD,UAAY,EAC/B+wD,EAAmBqH,OAAS,EAC5BrH,EAAmBsH,SAAW,GAC9BtH,EAAmBuH,KAAO,GAC1BvH,EAAmBwH,MAAQ,GAC3BxH,EAAmByH,KAAO,GAC1BzH,EAAmBlvD,QAAU,GAC7BkvD,EAAmB0H,QAAU,GAC7B1H,EAAmB1B,MAAQ,GAC3B0B,EAAmB2H,KAAO,GAC1B3H,EAAmB4H,UAAY,GAC/B5H,EAAmB6H,OAAS,GAC5B7H,EAAmB8H,WAAa,GAChC9H,EAAmB+H,SAAW,GAC9B/H,EAAmBgI,OAAS,GAC5BhI,EAAmBiI,MAAQ,GAC3BjI,EAAmBkI,SAAW,GAC9BlI,EAAmBmI,cAAgB,EACtC,CA1BD,CA0BGnI,KAAuBA,GAAqB,CAAC,IAMhD,SAAWC,GAIPA,EAAiB2G,UAAY,EAW7B3G,EAAiByH,QAAU,CAC9B,CAhBD,CAgBGzH,KAAqBA,GAAmB,CAAC,IAQ5C,SAAWC,GAIPA,EAAkB+E,WAAa,CAClC,CALD,CAKG/E,KAAsBA,GAAoB,CAAC,IAO9C,SAAWC,GAOPA,EAAkB/Y,OAHlB,SAAgBoe,EAASC,EAAQvpE,GAC7B,MAAO,CAAEspE,UAASC,SAAQvpE,UAC9B,EASAikE,EAAkBtG,GAJlB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOmlE,GAAaC,GAAGO,OAAOR,EAAUyC,UAAYrH,GAAMtE,GAAGkJ,EAAU0C,SAAWtH,GAAMtE,GAAGkJ,EAAU7mE,QACzG,CAEH,CAhBD,CAgBGikE,KAAsBA,GAAoB,CAAC,IAQ9C,SAAWC,GAQPA,EAAegI,KAAO,EAUtBhI,EAAeiI,kBAAoB,CACtC,CAnBD,CAmBGjI,KAAmBA,GAAiB,CAAC,IAExC,SAAWC,GAMPA,EAA2BxG,GAL3B,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOmlE,IAAcC,GAAGO,OAAOR,EAAUuF,cAAgCxtE,IAArBioE,EAAUuF,UACzDtF,GAAGO,OAAOR,EAAUvmB,mBAA0C1hD,IAA1BioE,EAAUvmB,YACvD,CAEH,CAPD,CAOG6jB,KAA+BA,GAA6B,CAAC,IAMhE,SAAWC,GAQPA,EAAelZ,OAHf,SAAgB5iC,GACZ,MAAO,CAAEA,QACb,CAEH,CATD,CASG87C,KAAmBA,GAAiB,CAAC,IAMxC,SAAWC,GAUPA,EAAenZ,OAHf,SAAgBmhB,EAAOC,GACnB,MAAO,CAAED,MAAOA,GAAgB,GAAIC,eAAgBA,EACxD,CAEH,CAXD,CAWGjI,KAAmBA,GAAiB,CAAC,IAExC,SAAWC,GASPA,EAAaiI,cAHb,SAAuBC,GACnB,OAAOA,EAAUxsE,QAAQ,wBAAyB,OACtD,EASAskE,EAAa3G,GAJb,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGO,OAAOR,IAAeC,GAAGC,cAAcF,IAAcC,GAAGO,OAAOR,EAAU4F,WAAa3F,GAAGO,OAAOR,EAAUnlE,MACxH,CAEH,CAlBD,CAkBG4iE,KAAiBA,GAAe,CAAC,IAEpC,SAAWC,GAUPA,EAAM5G,GANN,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,QAASmlE,GAAaC,GAAGC,cAAcF,KAAehD,GAAclG,GAAGkJ,EAAU6F,WAC7EpI,GAAa3G,GAAGkJ,EAAU6F,WAC1B5F,GAAGoB,WAAWrB,EAAU6F,SAAUpI,GAAa3G,YAAyB/+D,IAAhB8C,EAAMyO,OAAuB8xD,GAAMtE,GAAGj8D,EAAMyO,OAC5G,CAEH,CAXD,CAWGo0D,KAAUA,GAAQ,CAAC,IAMtB,SAAWC,GAUPA,EAAqBtZ,OAHrB,SAAgB5iC,EAAOqkD,GACnB,OAAOA,EAAgB,CAAErkD,QAAOqkD,iBAAkB,CAAErkD,QACxD,CAEH,CAXD,CAWGk8C,KAAyBA,GAAuB,CAAC,IAMpD,SAAWC,GAcPA,EAAqBvZ,OAbrB,SAAgB5iC,EAAOqkD,GACnB,IAAI1kE,EAAS,CAAEqgB,SACXw+C,GAAG4B,QAAQiE,KACX1kE,EAAO0kE,cAAgBA,GAC1B,QAAA9e,EAAAnvD,UAAAC,OAJoCiuE,EAAU,IAAAljE,MAAAmkD,EAAA,EAAAA,EAAA,KAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAV8e,EAAU9e,EAAA,GAAApvD,UAAAovD,GAW/C,OANIgZ,GAAG4B,QAAQkE,GACX3kE,EAAO2kE,WAAaA,EAGpB3kE,EAAO2kE,WAAa,GAEjB3kE,CACX,CAEH,CAfD,CAeGw8D,KAAyBA,GAAuB,CAAC,IAKpD,SAAWC,GAIPA,EAAsBkG,KAAO,EAI7BlG,EAAsBmI,KAAO,EAI7BnI,EAAsBoI,MAAQ,CACjC,CAbD,CAaGpI,KAA0BA,GAAwB,CAAC,IAMtD,SAAWC,GAaPA,EAAkBzZ,OAPlB,SAAgB/6C,EAAOq4D,GACnB,IAAIvgE,EAAS,CAAEkI,SAIf,OAHI22D,GAAGrqD,OAAO+rD,KACVvgE,EAAOugE,KAAOA,GAEXvgE,CACX,CAEH,CAdD,CAcG08D,KAAsBA,GAAoB,CAAC,IAK9C,SAAWC,GACPA,EAAW6G,KAAO,EAClB7G,EAAWuG,OAAS,EACpBvG,EAAWmI,UAAY,EACvBnI,EAAWoI,QAAU,EACrBpI,EAAWsG,MAAQ,EACnBtG,EAAWiG,OAAS,EACpBjG,EAAWwG,SAAW,EACtBxG,EAAWoG,MAAQ,EACnBpG,EAAWmG,YAAc,EACzBnG,EAAW2G,KAAO,GAClB3G,EAAW7xD,UAAY,GACvB6xD,EAAWkG,SAAW,GACtBlG,EAAWqG,SAAW,GACtBrG,EAAWiH,SAAW,GACtBjH,EAAW7lD,OAAS,GACpB6lD,EAAWgC,OAAS,GACpBhC,EAAWp6D,QAAU,GACrBo6D,EAAWl7D,MAAQ,GACnBk7D,EAAWrjE,OAAS,GACpBqjE,EAAWqI,IAAM,GACjBrI,EAAWsI,KAAO,GAClBtI,EAAWgH,WAAa,GACxBhH,EAAWkH,OAAS,GACpBlH,EAAWmH,MAAQ,GACnBnH,EAAWoH,SAAW,GACtBpH,EAAWqH,cAAgB,EAC9B,CA3BD,CA2BGrH,KAAeA,GAAa,CAAC,IAOhC,SAAWC,GAIPA,EAAUkE,WAAa,CAC1B,CALD,CAKGlE,KAAcA,GAAY,CAAC,IAE9B,SAAWC,GAqBPA,EAAkB5Z,OAXlB,SAAgBnrD,EAAMyoE,EAAMr4D,EAAOi3D,EAAK+F,GACpC,IAAIllE,EAAS,CACTlI,OACAyoE,OACAxd,SAAU,CAAEoc,MAAKj3D,UAKrB,OAHIg9D,IACAllE,EAAOklE,cAAgBA,GAEpBllE,CACX,CAEH,CAtBD,CAsBG68D,KAAsBA,GAAoB,CAAC,IAE9C,SAAWC,GAePA,EAAgB7Z,OALhB,SAAgBnrD,EAAMyoE,EAAMpB,EAAKj3D,GAC7B,YAAiBvR,IAAVuR,EACD,CAAEpQ,OAAMyoE,OAAMxd,SAAU,CAAEoc,MAAKj3D,UAC/B,CAAEpQ,OAAMyoE,OAAMxd,SAAU,CAAEoc,OACpC,CAEH,CAhBD,CAgBGrC,KAAoBA,GAAkB,CAAC,IAE1C,SAAWC,GAwBPA,EAAe9Z,OAbf,SAAgBnrD,EAAMqsE,EAAQ5D,EAAMr4D,EAAOi9D,EAAgBt+D,GACvD,IAAI7G,EAAS,CACTlI,OACAqsE,SACA5D,OACAr4D,QACAi9D,kBAKJ,YAHiBxuE,IAAbkQ,IACA7G,EAAO6G,SAAWA,GAEf7G,CACX,EAeA+8D,EAAerH,GAVf,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOmlE,GACHC,GAAGO,OAAOR,EAAU9mE,OAAS+mE,GAAGrqD,OAAOoqD,EAAU2B,OACjDvG,GAAMtE,GAAGkJ,EAAU12D,QAAU8xD,GAAMtE,GAAGkJ,EAAUuG,uBAC1BxuE,IAArBioE,EAAUuF,QAAwBtF,GAAGO,OAAOR,EAAUuF,gBAC7BxtE,IAAzBioE,EAAUwG,YAA4BvG,GAAG6C,QAAQ9C,EAAUwG,oBACpCzuE,IAAvBioE,EAAU/3D,UAA0BpF,MAAMC,QAAQk9D,EAAU/3D,kBACzClQ,IAAnBioE,EAAUyG,MAAsB5jE,MAAMC,QAAQk9D,EAAUyG,MACjE,CAEH,CAvCD,CAuCGtI,KAAmBA,GAAiB,CAAC,IAKxC,SAAWC,GAIPA,EAAesI,MAAQ,GAIvBtI,EAAeuI,SAAW,WAI1BvI,EAAewI,SAAW,WAY1BxI,EAAeyI,gBAAkB,mBAWjCzI,EAAe0I,eAAiB,kBAahC1I,EAAe2I,gBAAkB,mBAMjC3I,EAAe4I,OAAS,SAIxB5I,EAAe6I,sBAAwB,yBASvC7I,EAAe8I,aAAe,eACjC,CApED,CAoEG9I,KAAmBA,GAAiB,CAAC,IAOxC,SAAWC,GAIPA,EAAsB8I,QAAU,EAOhC9I,EAAsB+I,UAAY,CACrC,CAZD,CAYG/I,KAA0BA,GAAwB,CAAC,IAMtD,SAAWC,GAcPA,EAAkBja,OAVlB,SAAgBgjB,EAAaC,EAAMC,GAC/B,IAAInmE,EAAS,CAAEimE,eAOf,YANatvE,IAATuvE,GAA+B,OAATA,IACtBlmE,EAAOkmE,KAAOA,QAEEvvE,IAAhBwvE,GAA6C,OAAhBA,IAC7BnmE,EAAOmmE,YAAcA,GAElBnmE,CACX,EAWAk9D,EAAkBxH,GANlB,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAcC,GAAGoB,WAAWrB,EAAUqH,YAAarL,GAAWlF,WACrD/+D,IAAnBioE,EAAUsH,MAAsBrH,GAAGoB,WAAWrB,EAAUsH,KAAMrH,GAAGO,gBACvCzoE,IAA1BioE,EAAUuH,aAA6BvH,EAAUuH,cAAgBlJ,GAAsB8I,SAAWnH,EAAUuH,cAAgBlJ,GAAsB+I,UAC9J,CAEH,CAzBD,CAyBG9I,KAAsBA,GAAoB,CAAC,IAE9C,SAAWC,GAmBPA,EAAWla,OAlBX,SAAgBke,EAAOiF,EAAqB7F,GACxC,IAAIvgE,EAAS,CAAEmhE,SACXkF,GAAY,EAchB,MAbmC,kBAAxBD,GACPC,GAAY,EACZrmE,EAAOugE,KAAO6F,GAETvL,GAAQnF,GAAG0Q,GAChBpmE,EAAOohE,QAAUgF,EAGjBpmE,EAAOsmE,KAAOF,EAEdC,QAAsB1vE,IAAT4pE,IACbvgE,EAAOugE,KAAOA,GAEXvgE,CACX,EAYAm9D,EAAWzH,GAVX,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOmlE,GAAaC,GAAGO,OAAOR,EAAUuC,cACTxqE,IAA1BioE,EAAUqH,aAA6BpH,GAAGoB,WAAWrB,EAAUqH,YAAarL,GAAWlF,YACpE/+D,IAAnBioE,EAAU2B,MAAsB1B,GAAGO,OAAOR,EAAU2B,cACjC5pE,IAAnBioE,EAAU0H,WAA4C3vE,IAAtBioE,EAAUwC,gBACpBzqE,IAAtBioE,EAAUwC,SAAyBvG,GAAQnF,GAAGkJ,EAAUwC,iBAC9BzqE,IAA1BioE,EAAU2H,aAA6B1H,GAAG6C,QAAQ9C,EAAU2H,qBACzC5vE,IAAnBioE,EAAU0H,MAAsBhL,GAAc5F,GAAGkJ,EAAU0H,MACpE,CAEH,CA/BD,CA+BGnJ,KAAeA,GAAa,CAAC,IAMhC,SAAWC,GAWPA,EAASna,OAPT,SAAgB/6C,EAAOs+D,GACnB,IAAIxmE,EAAS,CAAEkI,SAIf,OAHI22D,GAAG4B,QAAQ+F,KACXxmE,EAAOwmE,KAAOA,GAEXxmE,CACX,EASAo9D,EAAS1H,GAJT,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAc5E,GAAMtE,GAAGkJ,EAAU12D,SAAW22D,GAAGloE,UAAUioE,EAAUwC,UAAYvG,GAAQnF,GAAGkJ,EAAUwC,SAC1H,CAEH,CApBD,CAoBGhE,KAAaA,GAAW,CAAC,IAM5B,SAAWC,GAOPA,EAAkBpa,OAHlB,SAAgBwjB,EAASC,GACrB,MAAO,CAAED,UAASC,eACtB,EASArJ,EAAkB3H,GAJlB,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAcC,GAAG/E,SAAS8E,EAAU6H,UAAY5H,GAAG6C,QAAQ9C,EAAU8H,aAC3F,CAEH,CAhBD,CAgBGrJ,KAAsBA,GAAoB,CAAC,IAM9C,SAAWC,GAOPA,EAAara,OAHb,SAAgB/6C,EAAO1O,EAAQgtE,GAC3B,MAAO,CAAEt+D,QAAO1O,SAAQgtE,OAC5B,EASAlJ,EAAa5H,GAJb,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAG4B,QAAQ7B,IAAc5E,GAAMtE,GAAGkJ,EAAU12D,SAAW22D,GAAGloE,UAAUioE,EAAUplE,SAAWqlE,GAAGO,OAAOR,EAAUplE,QACxH,CAEH,CAhBD,CAgBG8jE,KAAiBA,GAAe,CAAC,IAMpC,SAAWC,GASPA,EAAeta,OAHf,SAAgB/6C,EAAOwB,GACnB,MAAO,CAAExB,QAAOwB,SACpB,EAMA6zD,EAAe7H,GAJf,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,OAAOolE,GAAGC,cAAcF,IAAc5E,GAAMtE,GAAGkJ,EAAU12D,cAAgCvR,IAArBioE,EAAUl1D,QAAwB6zD,EAAe7H,GAAGkJ,EAAUl1D,QACtI,CAEH,CAfD,CAeG6zD,KAAmBA,GAAiB,CAAC,IASxC,SAAWC,GACPA,EAA8B,UAAI,YAKlCA,EAAyB,KAAI,OAC7BA,EAA0B,MAAI,QAC9BA,EAAyB,KAAI,OAC7BA,EAA8B,UAAI,YAClCA,EAA2B,OAAI,SAC/BA,EAAkC,cAAI,gBACtCA,EAA8B,UAAI,YAClCA,EAA6B,SAAI,WACjCA,EAA6B,SAAI,WACjCA,EAA+B,WAAI,aACnCA,EAA0B,MAAI,QAC9BA,EAA6B,SAAI,WACjCA,EAA2B,OAAI,SAC/BA,EAA0B,MAAI,QAC9BA,EAA4B,QAAI,UAChCA,EAA6B,SAAI,WACjCA,EAA4B,QAAI,UAChCA,EAA2B,OAAI,SAC/BA,EAA2B,OAAI,SAC/BA,EAA2B,OAAI,SAC/BA,EAA6B,SAAI,WAIjCA,EAA8B,UAAI,WACrC,CA/BD,CA+BGA,KAAuBA,GAAqB,CAAC,IAShD,SAAWC,GACPA,EAAoC,YAAI,cACxCA,EAAmC,WAAI,aACvCA,EAAiC,SAAI,WACrCA,EAA+B,OAAI,SACnCA,EAAmC,WAAI,aACvCA,EAAiC,SAAI,WACrCA,EAA8B,MAAI,QAClCA,EAAqC,aAAI,eACzCA,EAAsC,cAAI,gBAC1CA,EAAuC,eAAI,gBAC9C,CAXD,CAWGA,KAA2BA,GAAyB,CAAC,IAKxD,SAAWC,GAMPA,EAAehI,GALf,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,UAAsCjoE,IAAvBioE,EAAU+H,UAAwD,kBAAvB/H,EAAU+H,WACxFllE,MAAMC,QAAQk9D,EAAU4H,QAAoC,IAA1B5H,EAAU4H,KAAK9vE,QAA6C,kBAAtBkoE,EAAU4H,KAAK,GAC/F,CAEH,CAPD,CAOG9I,KAAmBA,GAAiB,CAAC,IAOxC,SAAWC,GAOPA,EAAgB1a,OAHhB,SAAgB/6C,EAAOpI,GACnB,MAAO,CAAEoI,QAAOpI,OACpB,EAMA69D,EAAgBjI,GAJhB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,YAAqB9C,IAAdioE,GAAyC,OAAdA,GAAsB5E,GAAMtE,GAAGkJ,EAAU12D,QAAU22D,GAAGO,OAAOR,EAAU9+D,KAC7G,CAEH,CAbD,CAaG69D,KAAoBA,GAAkB,CAAC,IAO1C,SAAWC,GAOPA,EAA0B3a,OAH1B,SAAgB/6C,EAAO0+D,EAAcC,GACjC,MAAO,CAAE3+D,QAAO0+D,eAAcC,sBAClC,EAOAjJ,EAA0BlI,GAL1B,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,YAAqB9C,IAAdioE,GAAyC,OAAdA,GAAsB5E,GAAMtE,GAAGkJ,EAAU12D,QAAU22D,GAAG6C,QAAQ9C,EAAUiI,uBAClGhI,GAAGO,OAAOR,EAAUgI,oBAA4CjwE,IAA3BioE,EAAUgI,aAC3D,CAEH,CAdD,CAcGhJ,KAA8BA,GAA4B,CAAC,IAO9D,SAAWC,GAOPA,EAAiC5a,OAHjC,SAAgB/6C,EAAO4+D,GACnB,MAAO,CAAE5+D,QAAO4+D,aACpB,EAOAjJ,EAAiCnI,GALjC,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,YAAqB9C,IAAdioE,GAAyC,OAAdA,GAAsB5E,GAAMtE,GAAGkJ,EAAU12D,SACnE22D,GAAGO,OAAOR,EAAUkI,kBAAwCnwE,IAAzBioE,EAAUkI,WACzD,CAEH,CAdD,CAcGjJ,KAAqCA,GAAmC,CAAC,IAQ5E,SAAWC,GAOPA,EAAmB7a,OAHnB,SAAgB8jB,EAASC,GACrB,MAAO,CAAED,UAASC,kBACtB,EASAlJ,EAAmBpI,GAJnB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAG4B,QAAQ7B,IAAc5E,GAAMtE,GAAGj8D,EAAMutE,gBACnD,CAEH,CAhBD,CAgBGlJ,KAAuBA,GAAqB,CAAC,IAOhD,SAAWC,GAIPA,EAAcnyD,KAAO,EAIrBmyD,EAAc7yD,UAAY,EAI1B6yD,EAAcrI,GAHd,SAAYj8D,GACR,OAAiB,IAAVA,GAAyB,IAAVA,CAC1B,CAEH,CAbD,CAaGskE,KAAkBA,GAAgB,CAAC,IAEtC,SAAWC,GAIPA,EAAmB/a,OAHnB,SAAgBxpD,GACZ,MAAO,CAAEA,QACb,EASAukE,EAAmBtI,GAPnB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,UACMjoE,IAAtBioE,EAAUqI,SAAyBpI,GAAGO,OAAOR,EAAUqI,UAAYrL,GAAclG,GAAGkJ,EAAUqI,iBACvEtwE,IAAvBioE,EAAU7b,UAA0BkX,GAASvE,GAAGkJ,EAAU7b,kBACpCpsD,IAAtBioE,EAAUwC,SAAyBvG,GAAQnF,GAAGkJ,EAAUwC,SACpE,CAEH,CAbD,CAaGpD,KAAuBA,GAAqB,CAAC,IAEhD,SAAWC,GAQPA,EAAUhb,OAPV,SAAgBse,EAAUlhD,EAAOkgD,GAC7B,MAAMvgE,EAAS,CAAEuhE,WAAUlhD,SAI3B,YAHa1pB,IAAT4pE,IACAvgE,EAAOugE,KAAOA,GAEXvgE,CACX,EAYAi+D,EAAUvI,GAVV,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,IAAc7E,GAASrE,GAAGkJ,EAAU2C,YACpD1C,GAAGO,OAAOR,EAAUv+C,QAAUw+C,GAAGoB,WAAWrB,EAAUv+C,MAAO29C,GAAmBtI,YAC7D/+D,IAAnBioE,EAAU2B,MAAsBxC,GAAcrI,GAAGkJ,EAAU2B,aACnC5pE,IAAxBioE,EAAUsI,WAA4BrI,GAAGoB,WAAWrB,EAAUsI,UAAWpM,GAASpF,WAC5D/+D,IAAtBioE,EAAUqI,SAAyBpI,GAAGO,OAAOR,EAAUqI,UAAYrL,GAAclG,GAAGkJ,EAAUqI,iBACpEtwE,IAA1BioE,EAAUuI,aAA6BtI,GAAG6C,QAAQ9C,EAAUuI,qBACjCxwE,IAA3BioE,EAAUwI,cAA8BvI,GAAG6C,QAAQ9C,EAAUwI,cACzE,CAEH,CApBD,CAoBGnJ,KAAcA,GAAY,CAAC,IAE9B,SAAWC,GAIPA,EAAYmJ,cAHZ,SAAuB5tE,GACnB,MAAO,CAAE8mE,KAAM,UAAW9mE,QAC9B,CAEH,CALD,CAKGykE,KAAgBA,GAAc,CAAC,IAElC,SAAWC,GAIPA,EAAqBlb,OAHrB,SAAgBqkB,EAAYC,EAAYr/D,EAAOk5D,GAC3C,MAAO,CAAEkG,aAAYC,aAAYr/D,QAAOk5D,UAC5C,CAEH,CALD,CAKGjD,KAAyBA,GAAuB,CAAC,IAEpD,SAAWC,GAIPA,EAAqBnb,OAHrB,SAAgBmhB,GACZ,MAAO,CAAEA,QACb,CAEH,CALD,CAKGhG,KAAyBA,GAAuB,CAAC,IAQpD,SAAWC,GAIPA,EAA4B0H,QAAU,EAItC1H,EAA4B2H,UAAY,CAC3C,CATD,CASG3H,KAAgCA,GAA8B,CAAC,IAElE,SAAWC,GAIPA,EAAuBrb,OAHvB,SAAgB/6C,EAAOpI,GACnB,MAAO,CAAEoI,QAAOpI,OACpB,CAEH,CALD,CAKGw+D,KAA2BA,GAAyB,CAAC,IAExD,SAAWC,GAIPA,EAAwBtb,OAHxB,SAAgBkjB,EAAaqB,GACzB,MAAO,CAAErB,cAAaqB,yBAC1B,CAEH,CALD,CAKGjJ,KAA4BA,GAA0B,CAAC,IAE1D,SAAWC,GAKPA,EAAgB9I,GAJhB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOolE,GAAGC,cAAcF,IAAchF,GAAIlE,GAAGkJ,EAAUO,MAAQN,GAAGO,OAAOR,EAAU9mE,KACvF,CAEH,CAND,CAMG0mE,KAAoBA,GAAkB,CAAC,IAKnC,IAAIiJ,GA6KP5I,IA5KJ,SAAW4I,GA8CP,SAASC,EAAUlB,EAAMmB,GACrB,GAAInB,EAAK9vE,QAAU,EAEf,OAAO8vE,EAEX,MAAMhN,EAAKgN,EAAK9vE,OAAS,EAAK,EACxBslB,EAAOwqD,EAAKoB,MAAM,EAAGpO,GACrB19C,EAAQ0qD,EAAKoB,MAAMpO,GACzBkO,EAAU1rD,EAAM2rD,GAChBD,EAAU5rD,EAAO6rD,GACjB,IAAIE,EAAU,EACVC,EAAW,EACX1iE,EAAI,EACR,KAAOyiE,EAAU7rD,EAAKtlB,QAAUoxE,EAAWhsD,EAAMplB,QAAQ,CACrD,IAAIqxE,EAAMJ,EAAQ3rD,EAAK6rD,GAAU/rD,EAAMgsD,IAGnCtB,EAAKphE,KAFL2iE,GAAO,EAEK/rD,EAAK6rD,KAIL/rD,EAAMgsD,IAE1B,CACA,KAAOD,EAAU7rD,EAAKtlB,QAClB8vE,EAAKphE,KAAO4W,EAAK6rD,KAErB,KAAOC,EAAWhsD,EAAMplB,QACpB8vE,EAAKphE,KAAO0W,EAAMgsD,KAEtB,OAAOtB,CACX,CAlEAiB,EAAaxkB,OAHb,SAAgBkc,EAAK7iE,EAAYkmE,EAAS7gE,GACtC,OAAO,IAAIqmE,GAAiB7I,EAAK7iE,EAAYkmE,EAAS7gE,EAC1D,EAUA8lE,EAAa/R,GALb,SAAYj8D,GACR,IAAImlE,EAAYnlE,EAChB,SAAOolE,GAAG4B,QAAQ7B,IAAcC,GAAGO,OAAOR,EAAUO,OAASN,GAAGloE,UAAUioE,EAAUtiE,aAAeuiE,GAAGO,OAAOR,EAAUtiE,cAAgBuiE,GAAG/E,SAAS8E,EAAUqJ,YACtJpJ,GAAGx9C,KAAKu9C,EAAUsJ,UAAYrJ,GAAGx9C,KAAKu9C,EAAUuJ,aAAetJ,GAAGx9C,KAAKu9C,EAAUwJ,UAC5F,EA0BAX,EAAaY,WAxBb,SAAoBC,EAAUxG,GAC1B,IAAIhiE,EAAOwoE,EAASJ,UAChBK,EAAcb,EAAU5F,GAAO,CAAC/4D,EAAGC,KACnC,IAAIw/D,EAAOz/D,EAAEb,MAAMV,MAAMG,KAAOqB,EAAEd,MAAMV,MAAMG,KAC9C,OAAa,IAAT6gE,EACOz/D,EAAEb,MAAMV,MAAMC,UAAYuB,EAAEd,MAAMV,MAAMC,UAE5C+gE,CAAI,IAEXC,EAAqB3oE,EAAKpJ,OAC9B,IAAK,IAAI0O,EAAImjE,EAAY7xE,OAAS,EAAG0O,GAAK,EAAGA,IAAK,CAC9C,IAAIlB,EAAIqkE,EAAYnjE,GAChBwwB,EAAc0yC,EAASF,SAASlkE,EAAEgE,MAAMV,OACxCi2B,EAAY6qC,EAASF,SAASlkE,EAAEgE,MAAML,KAC1C,KAAI41B,GAAagrC,GAIb,MAAM,IAAIptE,MAAM,oBAHhByE,EAAOA,EAAK0R,UAAU,EAAGokB,GAAe1xB,EAAEm9D,QAAUvhE,EAAK0R,UAAUisB,EAAW39B,EAAKpJ,QAKvF+xE,EAAqB7yC,CACzB,CACA,OAAO91B,CACX,CAkCH,CA9ED,CA8EG2nE,KAAiBA,GAAe,CAAC,IAIpC,MAAMO,GACFjyE,WAAAA,CAAYopE,EAAK7iE,EAAYkmE,EAAS7gE,GAClC/G,KAAK8tE,KAAOvJ,EACZvkE,KAAK+tE,YAAcrsE,EACnB1B,KAAKguE,SAAWpG,EAChB5nE,KAAKiuE,SAAWlnE,EAChB/G,KAAKkuE,kBAAenyE,CACxB,CACA,OAAIwoE,GACA,OAAOvkE,KAAK8tE,IAChB,CACA,cAAIpsE,GACA,OAAO1B,KAAK+tE,WAChB,CACA,WAAInG,GACA,OAAO5nE,KAAKguE,QAChB,CACAV,OAAAA,CAAQhgE,GACJ,GAAIA,EAAO,CACP,IAAIV,EAAQ5M,KAAKwtE,SAASlgE,EAAMV,OAC5BK,EAAMjN,KAAKwtE,SAASlgE,EAAML,KAC9B,OAAOjN,KAAKiuE,SAASr3D,UAAUhK,EAAOK,EAC1C,CACA,OAAOjN,KAAKiuE,QAChB,CACAE,MAAAA,CAAOC,EAAOxG,GACV5nE,KAAKiuE,SAAWG,EAAMlpE,KACtBlF,KAAKguE,SAAWpG,EAChB5nE,KAAKkuE,kBAAenyE,CACxB,CACAsyE,cAAAA,GACI,QAA0BtyE,IAAtBiE,KAAKkuE,aAA4B,CACjC,IAAII,EAAc,GACdppE,EAAOlF,KAAKiuE,SACZM,GAAc,EAClB,IAAK,IAAI/jE,EAAI,EAAGA,EAAItF,EAAKpJ,OAAQ0O,IAAK,CAC9B+jE,IACAD,EAAY3nE,KAAK6D,GACjB+jE,GAAc,GAElB,IAAIC,EAAKtpE,EAAKg2B,OAAO1wB,GACrB+jE,EAAsB,OAAPC,GAAsB,OAAPA,EACnB,OAAPA,GAAehkE,EAAI,EAAItF,EAAKpJ,QAAiC,OAAvBoJ,EAAKg2B,OAAO1wB,EAAI,IACtDA,GAER,CACI+jE,GAAerpE,EAAKpJ,OAAS,GAC7BwyE,EAAY3nE,KAAKzB,EAAKpJ,QAE1BkE,KAAKkuE,aAAeI,CACxB,CACA,OAAOtuE,KAAKkuE,YAChB,CACAX,UAAAA,CAAWlgE,GACPA,EAASkB,KAAKC,IAAID,KAAKD,IAAIjB,EAAQrN,KAAKiuE,SAASnyE,QAAS,GAC1D,IAAIwyE,EAActuE,KAAKquE,iBACnBI,EAAM,EAAGC,EAAOJ,EAAYxyE,OAChC,GAAa,IAAT4yE,EACA,OAAOvP,GAAS9W,OAAO,EAAGh7C,GAE9B,KAAOohE,EAAMC,GAAM,CACf,IAAIC,EAAMpgE,KAAKyxB,OAAOyuC,EAAMC,GAAQ,GAChCJ,EAAYK,GAAOthE,EACnBqhE,EAAOC,EAGPF,EAAME,EAAM,CAEpB,CAGA,IAAI5hE,EAAO0hE,EAAM,EACjB,OAAOtP,GAAS9W,OAAOt7C,EAAMM,EAASihE,EAAYvhE,GACtD,CACAygE,QAAAA,CAAS7G,GACL,IAAI2H,EAActuE,KAAKquE,iBACvB,GAAI1H,EAAS55D,MAAQuhE,EAAYxyE,OAC7B,OAAOkE,KAAKiuE,SAASnyE,OAEpB,GAAI6qE,EAAS55D,KAAO,EACrB,OAAO,EAEX,IAAI6hE,EAAaN,EAAY3H,EAAS55D,MAClC8hE,EAAkBlI,EAAS55D,KAAO,EAAIuhE,EAAYxyE,OAAUwyE,EAAY3H,EAAS55D,KAAO,GAAK/M,KAAKiuE,SAASnyE,OAC/G,OAAOyS,KAAKC,IAAID,KAAKD,IAAIsgE,EAAajI,EAAS95D,UAAWgiE,GAAiBD,EAC/E,CACA,aAAIvB,GACA,OAAOrtE,KAAKquE,iBAAiBvyE,MACjC,GAGJ,SAAWmoE,GACP,MAAMjgE,EAAWtF,OAAO0M,UAAUpH,SAIlCigE,EAAG4B,QAHH,SAAiBhnE,GACb,MAAwB,qBAAVA,CAClB,EAKAolE,EAAGloE,UAHH,SAAmB8C,GACf,MAAwB,qBAAVA,CAClB,EAKAolE,EAAG6C,QAHH,SAAiBjoE,GACb,OAAiB,IAAVA,IAA4B,IAAVA,CAC7B,EAKAolE,EAAGO,OAHH,SAAgB3lE,GACZ,MAAgC,oBAAzBmF,EAASqH,KAAKxM,EACzB,EAKAolE,EAAGrqD,OAHH,SAAgB/a,GACZ,MAAgC,oBAAzBmF,EAASqH,KAAKxM,EACzB,EAKAolE,EAAGgB,YAHH,SAAqBpmE,EAAOyP,EAAKE,GAC7B,MAAgC,oBAAzBxK,EAASqH,KAAKxM,IAAgCyP,GAAOzP,GAASA,GAAS2P,CAClF,EAKAy1D,EAAGhF,QAHH,SAAiBpgE,GACb,MAAgC,oBAAzBmF,EAASqH,KAAKxM,KAAiC,YAAcA,GAASA,GAAS,UAC1F,EAKAolE,EAAG/E,SAHH,SAAkBrgE,GACd,MAAgC,oBAAzBmF,EAASqH,KAAKxM,IAAgC,GAAKA,GAASA,GAAS,UAChF,EAKAolE,EAAGx9C,KAHH,SAAc5nB,GACV,MAAgC,sBAAzBmF,EAASqH,KAAKxM,EACzB,EAQAolE,EAAGC,cANH,SAAuBrlE,GAInB,OAAiB,OAAVA,GAAmC,kBAAVA,CACpC,EAKAolE,EAAGoB,WAHH,SAAoBxmE,EAAOiwE,GACvB,OAAOjoE,MAAMC,QAAQjI,IAAUA,EAAMmK,MAAM8lE,EAC/C,CAEH,CAjDD,CAiDG7K,KAAOA,GAAK,CAAC,IC/pEV,MAAO8K,GAAb5zE,WAAAA,GAGY,KAAA6zE,UAAoC,EAmFhD,CAjFI,WAAY5Q,GACR,OAAOp+D,KAAKgvE,UAAUhvE,KAAKgvE,UAAUlzE,OAAS,EAClD,CAEAmzE,aAAAA,CAAcjyE,GAIV,OAHAgD,KAAKuT,SAAW,IAAI27D,GAAgBlyE,GACpCgD,KAAKuT,SAASvH,KAAOhM,KAAKuT,SAC1BvT,KAAKgvE,UAAY,CAAChvE,KAAKuT,UAChBvT,KAAKuT,QAChB,CAEA47D,kBAAAA,CAAmB3wD,GACf,MAAM4wD,EAAgB,IAAIC,GAK1B,OAJAD,EAAc7wD,cAAgBC,EAC9B4wD,EAAcpjE,KAAOhM,KAAKuT,SAC1BvT,KAAKo+D,QAAQr3D,QAAQJ,KAAKyoE,GAC1BpvE,KAAKgvE,UAAUroE,KAAKyoE,GACbA,CACX,CAEAE,aAAAA,CAAc3iE,EAAe6R,GACzB,MAAM+wD,EAAW,IAAIC,GAAgB7iE,EAAMquB,YAAaruB,EAAMmuB,MAAMh/B,OAAQ4Q,EAAaC,GAAQA,EAAM/I,WAAW,GAIlH,OAHA2rE,EAAShxD,cAAgBC,EACzB+wD,EAASvjE,KAAOhM,KAAKuT,SACrBvT,KAAKo+D,QAAQr3D,QAAQJ,KAAK4oE,GACnBA,CACX,CAEAE,UAAAA,CAAWrpE,GACP,MAAM0I,EAAS1I,EAAK9F,UACpB,GAAIwO,EAAQ,CACR,MAAM/F,EAAQ+F,EAAO/H,QAAQ6B,QAAQxC,GACjC2C,GAAS,GACT+F,EAAO/H,QAAQmzD,OAAOnxD,EAAO,E,CAGzC,CAEA2mE,SAAAA,CAAU3wE,GACN,MAAMq/D,EAAmBp+D,KAAKo+D,QAGJ,kBAAfr/D,EAAKwB,QACZP,KAAKo+D,QAAQnqD,QAAmBlV,GAEpCA,EAAKqV,SAAWgqD,EAChB,MAAMh4D,EAAOpG,KAAKgvE,UAAU3iE,MAGC,KAArB,OAAJjG,QAAI,IAAJA,OAAI,EAAJA,EAAMW,QAAQjL,SACdkE,KAAKyvE,WAAWrpE,EAExB,CAEAupE,eAAAA,CAAgBC,GACZ,IAAK,MAAMjjE,KAASijE,EAAc,CAC9B,MAAMC,EAAa,IAAIL,GAAgB7iE,EAAMquB,YAAaruB,EAAMmuB,MAAMh/B,OAAQ4Q,EAAaC,GAAQA,EAAM/I,WAAW,GACpHisE,EAAW7jE,KAAOhM,KAAKuT,SACvBvT,KAAK8vE,eAAe9vE,KAAKuT,SAAUs8D,E,CAE3C,CAEQC,cAAAA,CAAe1pE,EAAwBuG,GAC3C,MAAQU,OAAQ0iE,EAAY9iE,IAAK+iE,GAAarjE,EAE9C,IAAK,IAAInC,EAAI,EAAGA,EAAIpE,EAAKW,QAAQjL,OAAQ0O,IAAK,CAC1C,MAAMyE,EAAQ7I,EAAKW,QAAQyD,IACnB6C,OAAQ4iE,EAAYhjE,IAAKijE,GAAajhE,EAC9C,GAAIrI,EAAmBqI,IAAU8gE,EAAaE,GAAcD,EAAWE,EAEnE,YADAlwE,KAAK8vE,eAAe7gE,EAAOtC,GAExB,GAAIqjE,GAAYC,EAEnB,YADA7pE,EAAKW,QAAQmzD,OAAO1vD,EAAG,EAAGmC,E,CAOlCvG,EAAKW,QAAQJ,KAAKgG,EACtB,EAGE,MAAgBwjE,GAYlB,UAAIrhE,GACA,OAAO9O,KAAKM,SAChB,CAGA,WAAIke,GACA,OAAOxe,KAAKue,aAChB,CAEA,UAAI1P,GACA,OAAO,CACX,CAEA,WAAIoF,G,QACA,MAAM7N,EAAuC,kBAAZ,QAAb+N,EAAAnU,KAAKowE,gBAAQ,IAAAj8D,OAAA,EAAAA,EAAE5T,OAAqBP,KAAKowE,SAAyB,QAAdxuB,EAAA5hD,KAAKM,iBAAS,IAAAshD,OAAA,EAAAA,EAAE3tC,QACxF,IAAK7N,EACD,MAAM,IAAI3F,MAAM,2CAEpB,OAAO2F,CACX,CAEA,WAAI6N,CAAQpV,GACRmB,KAAKowE,SAAWvxE,CACpB,CAGA,WAAIuJ,GACA,OAAOpI,KAAKiU,OAChB,CAEA,QAAI/O,GACA,OAAOlF,KAAKgM,KAAK9E,SAAS0P,UAAU5W,KAAKqN,OAAQrN,KAAKiN,IAC1D,EAGE,MAAOuiE,WAAwBW,GACjC,UAAI9iE,GACA,OAAOrN,KAAKqwE,OAChB,CAEA,UAAIv0E,GACA,OAAOkE,KAAKswE,OAChB,CAEA,OAAIrjE,GACA,OAAOjN,KAAKqwE,QAAUrwE,KAAKswE,OAC/B,CAEA,UAAazhE,GACT,OAAO7O,KAAKuwE,OAChB,CAEA,aAAI3sE,GACA,OAAO5D,KAAKwwE,UAChB,CAEA,SAAIljE,GACA,OAAOtN,KAAKywE,MAChB,CAQAt1E,WAAAA,CAAYkS,EAAgBvR,EAAgBwR,EAAc1J,GAAoC,IAAdiL,EAAMhT,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAClFT,QACA4E,KAAKuwE,QAAU1hE,EACf7O,KAAKqwE,QAAUhjE,EACfrN,KAAKwwE,WAAa5sE,EAClB5D,KAAKswE,QAAUx0E,EACfkE,KAAKywE,OAASnjE,CAClB,EAGE,MAAO+hE,WAA6Bc,GAA1Ch1E,WAAAA,G,oBACa,KAAA4L,QAAqB,IAAI2pE,GAAiB1wE,KAqDvD,CAjDI,YAAIiM,GACA,OAAOjM,KAAK+G,OAChB,CAEA,UAAIsG,G,QACA,OAAsC,QAA/Bu0C,EAAuB,QAAvBztC,EAAAnU,KAAK2wE,0BAAkB,IAAAx8D,OAAA,EAAAA,EAAE9G,cAAM,IAAAu0C,EAAAA,EAAI,CAC9C,CAEA,UAAI9lD,GACA,OAAOkE,KAAKiN,IAAMjN,KAAKqN,MAC3B,CAEA,OAAIJ,G,QACA,OAAkC,QAA3B20C,EAAsB,QAAtBztC,EAAAnU,KAAK4wE,yBAAiB,IAAAz8D,OAAA,EAAAA,EAAElH,WAAG,IAAA20C,EAAAA,EAAI,CAC1C,CAEA,SAAIt0C,GACA,MAAMujE,EAAY7wE,KAAK2wE,mBACjBG,EAAW9wE,KAAK4wE,kBACtB,GAAIC,GAAaC,EAAU,CACvB,QAAyB/0E,IAArBiE,KAAK+wE,YAA2B,CAChC,MAAQzjE,MAAO0jE,GAAeH,GACtBvjE,MAAO2jE,GAAcH,EAC7B9wE,KAAK+wE,YAAc,CAAEnkE,MAAOokE,EAAWpkE,MAAOK,IAAKgkE,EAAUhkE,IAAIF,KAAOikE,EAAWpkE,MAAMG,KAAOikE,EAAWpkE,MAAQqkE,EAAUhkE,I,CAEjI,OAAOjN,KAAK+wE,W,CAEZ,MAAO,CAAEnkE,MAAOuyD,GAAS9W,OAAO,EAAG,GAAIp7C,IAAKkyD,GAAS9W,OAAO,EAAG,GAEvE,CAEA,sBAAYsoB,GACR,IAAK,MAAM1hE,KAASjP,KAAK+G,QACrB,IAAKkI,EAAMJ,OACP,OAAOI,EAGf,OAAOjP,KAAK+G,QAAQ,EACxB,CAEA,qBAAY6pE,GACR,IAAK,IAAIpmE,EAAIxK,KAAK+G,QAAQjL,OAAS,EAAG0O,GAAK,EAAGA,IAAK,CAC/C,MAAMyE,EAAQjP,KAAK+G,QAAQyD,GAC3B,IAAKyE,EAAMJ,OACP,OAAOI,C,CAGf,OAAOjP,KAAK+G,QAAQ/G,KAAK+G,QAAQjL,OAAS,EAC9C,EAGJ,MAAM40E,WAAyB7pE,MAG3B1L,WAAAA,CAAY2T,GACR1T,QACA4E,KAAK8O,OAASA,EACdpQ,OAAOm5C,eAAe73C,KAAM0wE,GAAiBtlE,UACjD,CAESzE,IAAAA,GAAwB,QAAA6E,EAAA3P,UAAAC,OAAhB0tE,EAAgB,IAAA3iE,MAAA2E,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAhB89D,EAAgB99D,GAAA7P,UAAA6P,GAE7B,OADA1L,KAAKkxE,WAAW1H,GACTpuE,MAAMuL,QAAQ6iE,EACzB,CAES2H,OAAAA,GAA2B,QAAAnmB,EAAAnvD,UAAAC,OAAhB0tE,EAAgB,IAAA3iE,MAAAmkD,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAhBue,EAAgBve,GAAApvD,UAAAovD,GAEhC,OADAjrD,KAAKkxE,WAAW1H,GACTpuE,MAAM+1E,WAAW3H,EAC5B,CAEStP,MAAAA,CAAOttD,EAAe/E,GAAkC,QAAAupE,EAAAv1E,UAAAC,OAAhB0tE,EAAgB,IAAA3iE,MAAAuqE,EAAA,EAAAA,EAAA,KAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAhB7H,EAAgB6H,EAAA,GAAAx1E,UAAAw1E,GAE7D,OADArxE,KAAKkxE,WAAW1H,GACTpuE,MAAM8+D,OAAOttD,EAAO/E,KAAU2hE,EACzC,CAEQ0H,UAAAA,CAAW1H,GACf,IAAK,MAAMzqE,KAAQyqE,EACGzqE,EAAMuB,UAAYN,KAAK8O,MAEjD,EAGE,MAAOogE,WAAwBG,GAGjC,QAAanqE,GACT,OAAOlF,KAAKsxE,MAAM16D,UAAU5W,KAAKqN,OAAQrN,KAAKiN,IAClD,CAEA,YAAI/F,GACA,OAAOlH,KAAKsxE,KAChB,CAEAn2E,WAAAA,CAAY6B,GACR5B,QAXI,KAAAk2E,MAAQ,GAYZtxE,KAAKsxE,MAAa,OAALt0E,QAAK,IAALA,EAAAA,EAAS,EAC1B,ECvQG,MAAMu0E,GAAiB9pE,OAAO,YAUrC,SAAS+pE,GAAeprE,GACpB,OAAOA,EAAK7F,QAAUgxE,EAC1B,CA4BA,MACME,GAAkBv0E,GAAyBA,EAAKw0E,SADnC,UAC0Dx0E,EAAOA,EADjE,SAGb,MAAgBy0E,GAMlBx2E,WAAAA,CAAYy2E,GAFF,KAAAC,iBAA2C,IAAIxpE,IAGrDrI,KAAK8xE,MAAQF,EAASr2E,OAAOw0B,MAC7B,MAAMuS,EAAStiC,KAAK8xE,MAAMnyD,WAC1B3f,KAAK+xE,QAAU,IAAIC,GAAkB1vC,EAAM5jC,OAAA2lB,OAAA3lB,OAAA2lB,OAAA,GACpCutD,EAASr2E,OAAO02E,cAAY,CAC/B32C,qBAAsBs2C,EAASr2E,OAAO22E,6BAE9C,CAEApxD,YAAAA,CAAapL,EAAay8D,GACtBnyE,KAAK+xE,QAAQK,OAAO18D,EAAKy8D,EAC7B,CAEA3Z,QAAAA,CAAS9iD,EAAa28D,GAClBryE,KAAK+xE,QAAQO,WAAW58D,EAAK28D,EACjC,CAEA/9B,IAAAA,CAAK5+B,EAAa28D,GACdryE,KAAK+xE,QAAQQ,SAAS78D,EAAK28D,EAC/B,CAEAj+B,UAAAA,CAAW1+B,EAAa28D,GACpBryE,KAAK+xE,QAAQS,eAAe98D,EAAK28D,EACrC,CAQAI,WAAAA,GACI,OAAOzyE,KAAK+xE,QAAQW,YACxB,CAEA,mBAAIC,GACA,OAAO3yE,KAAK6xE,gBAChB,CAEAe,YAAAA,GACI,OAAQ5yE,KAAK+xE,QAAgB14B,UACjC,CAEAihB,QAAAA,GACIt6D,KAAK+xE,QAAQc,kBACjB,EAGE,MAAOtuE,WAAsBotE,GAS/B,WAAYvT,GACR,OAAOp+D,KAAKw6D,MAAMx6D,KAAKw6D,MAAM1+D,OAAS,EAC1C,CAEAX,WAAAA,CAAYy2E,GACRx2E,MAAMw2E,GAVO,KAAAkB,YAAc,IAAI/D,GAC3B,KAAAvU,MAAe,GAEf,KAAAuY,cAAgB,IAAI1qE,IAQxBrI,KAAKgzE,OAASpB,EAASqB,WAAWC,OAClClzE,KAAKmzE,UAAYvB,EAASr2E,OAAOE,eACjCuE,KAAKozE,cAAgBxB,EAAS31E,OAAOgG,aACzC,CAEAlF,IAAAA,CAAKA,EAAkBytD,GACnB,MAAM7pD,EAAO5D,EAAKs2E,cAAWt3E,EAAYyjB,GAAeziB,GAAQw0E,GAAiBvxD,GAAYjjB,GACvFu2E,EAAatzE,KAAK+xE,QAAQwB,YAAY9B,GAAe10E,EAAKG,MAAO8C,KAAKwzE,oBAAoB7yE,EAAM6pD,GAAMipB,KAAKzzE,OAIjH,OAHIjD,EAAK4gB,QACL3d,KAAK0zE,SAAWJ,GAEbA,CACX,CAEAtuE,KAAAA,CAAmChI,GAC/BgD,KAAK8yE,YAAY7D,cAAcjyE,GAC/B,MAAM22E,EAAc3zE,KAAK8xE,MAAM7yC,SAASjiC,GACxCgD,KAAK+xE,QAAQ/0E,MAAQ22E,EAAYrxC,OACjC,MAAMl9B,EAASpF,KAAK0zE,SAASroE,KAAKrL,KAAK+xE,QAAS,CAAC,GAGjD,OAFA/xE,KAAK8yE,YAAYnD,gBAAgBgE,EAAY9kE,QAC7C7O,KAAK2yE,gBAAgBiB,QACd,CACH/0E,MAAOuG,EACPC,YAAasuE,EAAYtgD,OACzB/tB,aAActF,KAAK+xE,QAAQ1+C,OAEnC,CAEQmgD,mBAAAA,CAAoBjzE,EAAoC6yD,GAC5D,OAAQroC,IACJ,IAAK/qB,KAAKyyE,cAAe,CACrB,MAAMrsE,EAAY,CAAE7F,SACpBP,KAAKw6D,MAAM7zD,KAAKP,GACZ7F,IAAUgxE,KACVnrE,EAAKvH,MAAQ,G,CAGrB,IAAIuG,EACJ,IACIA,EAASguD,EAAeroC,E,CAC1B,MAAOtlB,GACLL,OAASrJ,C,CAKb,OAHKiE,KAAKyyE,oBAA4B12E,IAAXqJ,IACvBA,EAASpF,KAAK0vE,aAEXtqE,CAAM,CAErB,CAEAgpD,OAAAA,CAAQ14C,EAAa9R,EAAsB4a,GACvC,MAAM7R,EAAQ3M,KAAK+xE,QAAQ8B,YAAYn+D,EAAK9R,GAC5C,IAAK5D,KAAKyyE,eAAiBzyE,KAAK8zE,aAAannE,GAAQ,CACjD,MAAM4iE,EAAWvvE,KAAK8yE,YAAYxD,cAAc3iE,EAAO6R,IACjD,WAAEu1D,EAAU,WAAEC,GAAeh0E,KAAKi0E,cAAcz1D,GAChD4/C,EAAUp+D,KAAKo+D,QACrB,GAAI2V,EAAY,CACZ,MAAMG,EAAiBliE,GAAUwM,GAAW7R,EAAMmuB,MAAQ96B,KAAKmzE,UAAUgB,QAAQxnE,EAAMmuB,MAAOy0C,GAC9FvvE,KAAKqkB,OAAO0vD,EAAWK,SAAUL,EAAWv1D,QAAS01D,EAAgB3E,EAAUyE,E,MAC5E,GAAIxC,GAAepT,GAAU,CAChC,IAAIl5D,EAAOyH,EAAMmuB,MACZ9oB,GAAUwM,KACXtZ,EAAOlF,KAAKmzE,UAAUgB,QAAQjvE,EAAMqqE,GAAUvrE,YAElDo6D,EAAQv/D,OAASqG,C,EAG7B,CAQQ4uE,YAAAA,CAAannE,GACjB,OAAQA,EAAMk2C,uBAAyBjH,MAAMjvC,EAAMquB,cAA2C,kBAApBruB,EAAMk2B,YAA2B+Y,MAAMjvC,EAAMk2B,UAC3H,CAEAoR,OAAAA,CAAQv+B,EAAa3Y,EAAkByhB,EAA0BuM,GAC7D,IAAIroB,EACC1C,KAAKyyE,gBACN/vE,EAAU1C,KAAK8yE,YAAY3D,mBAAmB3wD,IAElD,MAAM61D,EAAgBr0E,KAAK+xE,QAAQuC,YAAY5+D,EAAK3Y,EAAMguB,IACrD/qB,KAAKyyE,eAAiB/vE,GAAWA,EAAQ5G,OAAS,GACnDkE,KAAKu0E,yBAAyBF,EAAe71D,EAAS9b,EAE9D,CAEQ6xE,wBAAAA,CAAyBnvE,EAAaoZ,EAA0B9b,GACpE,MAAM,WAAEqxE,EAAU,WAAEC,GAAeh0E,KAAKi0E,cAAcz1D,GACtD,GAAIu1D,EACA/zE,KAAKqkB,OAAO0vD,EAAWK,SAAUL,EAAWv1D,QAASpZ,EAAQ1C,EAASsxE,QACnE,IAAKD,EAAY,CAMpB,MAAM3V,EAAUp+D,KAAKo+D,QACrB,GAAIoT,GAAepT,GACfA,EAAQv/D,OAASuG,EAAOpB,gBACrB,GAAsB,kBAAXoB,GAAuBA,EAAQ,CAC7C,MAAMovE,EAAapvE,EAAO7E,MACpBkiB,EAASziB,KAAKy0E,sBAAsBrvE,EAAQg5D,GAC9CoW,IACA/xD,EAAOliB,MAAQi0E,GAEnB,MAAME,EAAUjyD,EAChBziB,KAAKw6D,MAAMnuD,MACXrM,KAAKw6D,MAAM7zD,KAAK+tE,E,EAG5B,CAEAx0D,MAAAA,CAAO3f,EAAe2f,GAClB,IAAKlgB,KAAKyyE,cAAe,CACrB,IAAIrxC,EAAOphC,KAAKo+D,QAIhB,IAAKh9B,EAAKhtB,UAAY8L,EAAO1B,SAAW0B,EAAOk0D,SAAU,CACrDhzC,EAAOphC,KAAK0vE,WAAU,GACtB,MAAMlxD,EAAU4iB,EAAKhtB,SAASoK,QAC9Bxe,KAAK8yE,YAAY3D,mBAAmB3wD,E,CAExC,MAAMk2D,EAAU,CAAEn0E,SAClBP,KAAKw6D,MAAMnuD,MACXrM,KAAKw6D,MAAM7zD,KAAK+tE,GACZx0D,EAAO1B,SAAW0B,EAAOk0D,UACzBp0E,KAAKqkB,OAAOnE,EAAOk0D,SAAUl0D,EAAO1B,QAAS4iB,EAAMA,EAAKhtB,UAAU,E,CAG9E,CAEAs7D,SAAAA,GAAoB,IAAVrjE,IAAGxQ,UAAAC,OAAA,QAAAC,IAAAF,UAAA,KAAAA,UAAA,GACT,GAAImE,KAAKyyE,cACL,OAEJ,MAAM5sE,EAAM7F,KAAKo+D,QAMjB,OALAtrD,GAAuBjN,GACvB7F,KAAK8yE,YAAYpD,UAAU7pE,GACvBwG,GACArM,KAAKw6D,MAAMnuD,MAEXmlE,GAAe3rE,GACR7F,KAAKmzE,UAAUgB,QAAQtuE,EAAIhH,MAAOgH,EAAIuO,WhFnDnD,SAAoCpV,EAA2BoH,GACjE,MAAMuuE,EAAe31E,EAAW0B,gBAAgB0F,EAAK7F,OAC/Cq0E,EAAcxuE,EACpB,IAAK,MAAM5F,KAAYm0E,EAAa/zE,gBAEF7E,IAA1ByE,EAASK,mBAA6D9E,IAA/B64E,EAAYp0E,EAAStD,QAC5D03E,EAAYp0E,EAAStD,MAAQoX,GAAiB9T,EAASK,cAGnE,CgF4CYg0E,CAA0B70E,KAAKozE,cAAevtE,GAE3CA,EACX,CAEQouE,aAAAA,CAAcz1D,GAClB,IAAKxe,KAAK+yE,cAAclvE,IAAI2a,GAAU,CAClC,MAAMu1D,EAAa3gE,GAAmBoL,EAAShN,IAC/CxR,KAAK+yE,cAAcjoE,IAAI0T,EAAS,CAC5Bu1D,WAAYA,EACZC,aAAYD,GAAapiE,GAAiBoiE,EAAWvyD,W,CAG7D,OAAOxhB,KAAK+yE,cAAc1zD,IAAIb,EAClC,CAEQ6F,MAAAA,CAAO+vD,EAAkB51D,EAAiB3f,EAAgB6D,EAAkBsxE,GAChF,MAAMnuE,EAAM7F,KAAKo+D,QACjB,IAAIr/D,EAMJ,OAJIA,EADAi1E,GAA+B,kBAAVn1E,EACdmB,KAAKgzE,OAAO8B,eAAejvE,EAAK2Y,EAAS9b,EAAS7D,GAElDA,EAEHu1E,GACJ,IAAK,IACDvuE,EAAI2Y,GAAWzf,EACf,MAEJ,IAAK,KACD8G,EAAI2Y,IAAW,EACf,MAEJ,IAAK,KACI3X,MAAMC,QAAQjB,EAAI2Y,MACnB3Y,EAAI2Y,GAAW,IAEnB3Y,EAAI2Y,GAAS7X,KAAK5H,GAG9B,CAEQ01E,qBAAAA,CAAsB71E,EAAage,GACvC,IAAK,MAAO1f,EAAM63E,KAAkBr2E,OAAOqU,QAAQ6J,GAAS,CACxD,MAAMo4D,EAAWp2E,EAAO1B,QACPnB,IAAbi5E,EACAp2E,EAAO1B,GAAQ63E,EACRluE,MAAMC,QAAQkuE,IAAanuE,MAAMC,QAAQiuE,KAChDA,EAAcpuE,QAAQquE,GACtBp2E,EAAO1B,GAAQ63E,E,CAGvB,OAAOn2E,CACX,CAEA,oBAAIgiD,GACA,OAAO5gD,KAAK+xE,QAAQnxB,gBACxB,EASE,MAAgBq0B,GAElBzxC,yBAAAA,CAA0B//B,GAMtB,OAAO8/B,GAA2BC,0BAA0B//B,EAChE,CAEAogC,6BAAAA,CAA8BpgC,GAI1B,OAAO8/B,GAA2BM,8BAA8BpgC,EACpE,CAEAsgC,uBAAAA,CAAwBtgC,GAOpB,OAAO8/B,GAA2BQ,wBAAwBtgC,EAC9D,CAEAmhC,qBAAAA,CAAsBnhC,GAOlB,OAAO8/B,GAA2BqB,sBAAsBnhC,EAC5D,EAIE,MAAOyxE,WAA0CD,GAE1CzxC,yBAAAA,CAAyB9iB,GAKjC,IALkC,SAAE+iB,EAAQ,OAAEC,GAK9ChjB,EACG,MAAMkjB,EAAcH,EAAS1f,MACvB,IAAM0f,EAAS1f,MAAQ,IACvB0f,EAASvmC,KAAKw0E,SAAS,OAAM,YAAArxE,OACbojC,EAASvmC,KAAK0Z,UAAU,EAAG6sB,EAASvmC,KAAKpB,OAAS,GAAE,uBAAAuE,OAC9CojC,EAASvmC,KAAI,KACzC,MAAO,aAAPmD,OAAoBujC,EAAW,gBAAAvjC,OAAgBqjC,EAAO5I,MAAK,KAC/D,CAES+I,6BAAAA,CAA6BljB,GAGrC,IAHsC,eAAEmjB,GAGxCnjB,EACG,MAAO,oCAAPtgB,OAA4CyjC,EAAehJ,MAAK,KACpE,EASE,MAAOq6C,WAAgCxD,GAA7Cx2E,WAAAA,G,oBAEY,KAAAmnC,OAAmB,GAEnB,KAAA8yC,aAAkC,GAClC,KAAAC,iBAAsC,GACtC,KAAAC,eAAiB,EACjB,KAAAC,UAAY,CAkGxB,CAhGIr1D,MAAAA,GACI,CAGJwvD,SAAAA,GAGA,CAEA1qE,KAAAA,CAAMhI,GACFgD,KAAKw1E,aACL,MAAMlzC,EAAStiC,KAAK8xE,MAAM7yC,SAASjiC,GAKnC,OAJAgD,KAAKsiC,OAASA,EAAOA,OACrBtiC,KAAK+xE,QAAQ/0E,MAAQ,IAAIgD,KAAKsiC,QAC9BtiC,KAAK0zE,SAASroE,KAAKrL,KAAK+xE,QAAS,CAAC,GAClC/xE,KAAK2yE,gBAAgBiB,QACd,CACHtxC,OAAQtiC,KAAKsiC,OACb8yC,aAAc,IAAIp1E,KAAKq1E,kBACvBI,WAAYz1E,KAAKs1E,eAEzB,CAEAv4E,IAAAA,CAAKA,EAAkBytD,GACnB,MAAM8oB,EAAatzE,KAAK+xE,QAAQwB,YAAY9B,GAAe10E,EAAKG,MAAO8C,KAAKwzE,oBAAoBhpB,GAAMipB,KAAKzzE,OAI3G,OAHIjD,EAAK4gB,QACL3d,KAAK0zE,SAAWJ,GAEbA,CACX,CAEQkC,UAAAA,GACJx1E,KAAKo1E,aAAe,GACpBp1E,KAAKq1E,iBAAmB,GACxBr1E,KAAKs1E,eAAiB,EACtBt1E,KAAKu1E,UAAY,CACrB,CAEQ/B,mBAAAA,CAAoBpgB,GACxB,OAAQroC,IACJ,MAAMpgB,EAAO3K,KAAK01E,gBAClB,IACItiB,EAAeroC,E,CACjB,QACE/qB,KAAK21E,eAAehrE,E,EAGhC,CAEQirE,wBAAAA,GACJ51E,KAAKo1E,aAAalb,OAAOl6D,KAAKu1E,UAClC,CAEAG,aAAAA,GACI,MAAM/qE,EAAO3K,KAAKo1E,aAAat5E,OAE/B,OADAkE,KAAKu1E,UAAY5qE,EACVA,CACX,CAEAgrE,cAAAA,CAAehrE,GACX3K,KAAK41E,2BACL51E,KAAKu1E,UAAY5qE,CACrB,CAEAyjD,OAAAA,CAAQ14C,EAAa9R,EAAsB4a,GACvCxe,KAAK+xE,QAAQ8B,YAAYn+D,EAAK9R,GACzB5D,KAAKyyE,gBACNzyE,KAAKq1E,iBAAmB,IAAIr1E,KAAKo1E,aAAc52D,GAC/Cxe,KAAKs1E,eAAiBt1E,KAAKi9B,QAAU,EAE7C,CAEAgX,OAAAA,CAAQv+B,EAAa3Y,EAAkByhB,EAA0BuM,GAC7D/qB,KAAK61E,OAAOr3D,GACZxe,KAAK+xE,QAAQuC,YAAY5+D,EAAK3Y,EAAMguB,GACpC/qB,KAAK81E,MAAMt3D,EACf,CAEAq3D,MAAAA,CAAOztE,GACEpI,KAAKyyE,eACNzyE,KAAKo1E,aAAazuE,KAAKyB,EAE/B,CAEA0tE,KAAAA,CAAM1tE,GACF,IAAKpI,KAAKyyE,cAAe,CACrB,MAAM1pE,EAAQ/I,KAAKo1E,aAAaxzD,YAAYxZ,GACxCW,GAAS,GACT/I,KAAKo1E,aAAalb,OAAOnxD,E,CAGrC,CAEA,WAAIk0B,GACA,OAAQj9B,KAAK+xE,QAAgB90C,OACjC,EAGJ,MAAM84C,GAA+B,CACjCt6C,iBAAiB,EACjB+jB,qBAAsB,OACtBhkB,iBAAiB,EACjBF,qBAAsB,IAAI45C,IAO9B,MAAMlD,WAA0Bxb,GAK5Br7D,WAAAA,CAAYmnC,EAAyB5G,GACjC,MAAMs6C,EAAsBt6C,GAAU,iBAAkBA,EACxDtgC,MAAMknC,EAAM5jC,OAAA2lB,OAAA3lB,OAAA2lB,OAAA3lB,OAAA2lB,OAAA,GACL0xD,IAAa,CAChB70B,kBAAmB80B,EACb,IAAIp8B,GAAqB,CAAE9M,aAAcpR,EAAOoR,eAChD,IAAIkuB,KACPt/B,GAEX,CAEA,gBAAIg3C,GACA,OAAO1yE,KAAK40D,eAChB,CAEA2e,WAAAA,CAAYr2E,EAAcstD,GACtB,OAAOxqD,KAAKmzD,KAAKj2D,EAAMstD,EAC3B,CAEAqoB,gBAAAA,GACI7yE,KAAKggD,qBACT,CAEA6zB,WAAAA,CAAYn+D,EAAa9R,GACrB,OAAO5D,KAAKouD,QAAQ14C,EAAK9R,EAC7B,CAEA0wE,WAAAA,CAAY5+D,EAAa3Y,EAAkBguB,GACvC,OAAO/qB,KAAKi0C,QAAQv+B,EAAK3Y,EAAM,CAC3BuwD,KAAM,CAACviC,IAEf,CAEAqnD,MAAAA,CAAO18D,EAAay8D,GAChBnyE,KAAKu0C,GAAG7+B,EAAKy8D,EACjB,CAEAG,UAAAA,CAAW58D,EAAa28D,GACpBryE,KAAKk0C,OAAOx+B,EAAK28D,EACrB,CAEAE,QAAAA,CAAS78D,EAAa28D,GAClBryE,KAAKs0C,KAAK5+B,EAAK28D,EACnB,CAEAG,cAAAA,CAAe98D,EAAa28D,GACxBryE,KAAKo0C,WAAW1+B,EAAK28D,EACzB,EC3iBE,SAAU4D,GAAmC34D,EAAkB/hB,EAAW+mC,GAS5E,OAGJ,SAAoB4zC,EAA8B54D,GAC9C,MAAM64D,EAAY94D,GAAqBC,GAAS,GAC1C84D,EAAchsE,EAAOkT,EAAQ/Z,OAAO6F,OAAOqH,GAAcrH,QAAOrM,GAAQo5E,EAAUtyE,IAAI9G,KAC5F,IAAK,MAAMA,KAAQq5E,EAAa,CAC5B,MAAMj6B,EAAGz9C,OAAA2lB,OAAA3lB,OAAA2lB,OAAA,GACF6xD,GAAa,CAChB9nB,QAAS,EACToK,SAAU,EACVvkB,QAAS,EACTK,KAAM,EACNC,GAAI,IAER4H,EAAI54C,MAAMuH,IACN/N,EAAKG,KACLg5E,EAAc36E,OAAOwB,KAAKA,EAAMs5E,GAAal6B,EAAKp/C,EAAK4iB,a,CAGnE,CArBI22D,CANqC,CACjC/6E,SACA+mC,SACA/+B,MAJU,IAAI8E,IAKdmV,UAAW,IAAInV,KAEOiV,GACnB/hB,CACX,CAqBA,SAAS86E,GAAal6B,EAAkB/zC,GAA6C,IAC7EmuE,EAD0DC,EAAW36E,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAEzE,GAAImW,GAAU5J,GACVmuE,EA+NR,SAAsBp6B,EAAkBz9B,GACpC,MAAMhJ,EAAMymC,EAAIiS,UACVzhD,EAAQwvC,EAAI7Z,OAAO5jB,EAAQ7f,OACjC,IAAK8N,EACD,MAAM,IAAIlM,MAAM,qCAAuCie,EAAQ7f,OAEnE,MAAO,IAAMs9C,EAAI5gD,OAAO6yD,QAAQ14C,EAAK/I,EAAO+R,EAChD,CAtOiB+3D,CAAat6B,EAAK/zC,QACxB,GAAIgJ,GAAShJ,GAChBmuE,EAsBR,SAAqBp6B,EAAkBj8B,GACnC,MAAMD,EAAaD,GAAYE,GAC/B,MAAO,IAAMi8B,EAAI5gD,OAAO2kB,OAAOD,EAAYC,EAC/C,CAzBiBw2D,CAAYv6B,EAAK/zC,QACvB,GAAIoJ,GAAapJ,GACpBmuE,EAASF,GAAal6B,EAAK/zC,EAAQoZ,eAChC,GAAI7P,GAAiBvJ,GACxBmuE,EAASI,GAAoBx6B,EAAK/zC,QAC/B,GAAIgK,GAAWhK,GAClBmuE,EAqBR,SAAuBp6B,EAAkBy6B,GACrC,MAAM75E,EAAO65E,EAAS75E,KAAKmhB,IAC3B,GAAIzN,EAAa1T,GAAO,CACpB,MAAM2Y,EAAMymC,EAAIlI,UACVhrC,EAAY2tE,EAAS/6E,UAAUC,OAAS,EAatD,SAAgCiB,EAAkB85E,GAC9C,MAAMvpC,EAAaupC,EAAUrxE,KAAI8D,GAAKwtE,GAAextE,EAAEzK,SACvD,OAAQksB,IACJ,MAAMgsD,EAAiB,CAAC,EACxB,IAAK,IAAIvsE,EAAI,EAAGA,EAAI8iC,EAAWxxC,OAAQ0O,IAAK,CACxC,MAAMwsE,EAAaj6E,EAAKgtE,WAAWv/D,GAC7BvB,EAAYqkC,EAAW9iC,GAC7BusE,EAASC,EAAW95E,MAAQ+L,EAAU8hB,E,CAE1C,OAAOgsD,CAAQ,CAEvB,CAxB0DE,CAAuBl6E,EAAM65E,EAAS/6E,WAAa,KAAM,CAAG,GAC9G,OAAQkvB,GAASoxB,EAAI5gD,OAAO04C,QAAQv+B,EAAKwhE,GAAQ/6B,EAAKp/C,GAAO65E,EAAU3tE,EAAU8hB,G,CAC9E,GAAIha,GAAehU,GAAO,CAC7B,MAAM2Y,EAAMymC,EAAIiS,UACVmoB,EAASY,GAASh7B,EAAKp/C,EAAKG,MAClC,MAAO,IAAMi/C,EAAI5gD,OAAO6yD,QAAQ14C,EAAK6gE,EAAQK,E,CAC1C,IAAK75E,EACR,MAAM,IAAImS,EAAkB0nE,EAASxiE,SAAU,wBAAF/T,OAA0Bu2E,EAASr2E,QAEhF4O,GAER,CApCiBioE,CAAcj7B,EAAK/zC,QACzB,GAAIkJ,GAAelJ,GACtBmuE,EA4ER,SAA2Bp6B,EAAkBr7B,GACzC,GAAqC,IAAjCA,EAAaC,SAASjlB,OACtB,OAAOu6E,GAAal6B,EAAKr7B,EAAaC,SAAS,IAC5C,CACH,MAAMs2D,EAA8B,GAEpC,IAAK,MAAMjvE,KAAW0Y,EAAaC,SAAU,CACzC,MAAMu2D,EAAqC,CAGvCp4B,IAAKm3B,GAAal6B,EAAK/zC,GAAS,IAE9Bia,EAAQk1D,GAAkBnvE,GAC5Bia,IACAi1D,EAAiB/pC,KAAOupC,GAAez0D,IAE3Cg1D,EAAQ1wE,KAAK2wE,E,CAGjB,MAAM5hE,EAAMymC,EAAI5H,KAChB,OAAQxpB,GAASoxB,EAAI5gD,OAAOulB,aAAapL,EAAK2hE,EAAQ7xE,KAAI+wE,IACtD,MAAMrtD,EAAuB,CACzBg2B,IAAKA,IAAMq3B,EAAOr3B,IAAIn0B,IAEpB0wC,EAAO8a,EAAOhpC,KAIpB,OAHIkuB,IACAvyC,EAAIqkB,KAAO,IAAMkuB,EAAK1wC,IAEnB7B,CAAG,I,CAGtB,CA3GiBsuD,CAAkBr7B,EAAK/zC,QAC7B,GAAIsK,GAAiBtK,GACxBmuE,EA2GR,SAA6Bp6B,EAAkBlkC,GAC3C,GAA8B,IAA1BA,EAAM8I,SAASjlB,OACf,OAAOu6E,GAAal6B,EAAKlkC,EAAM8I,SAAS,IAE5C,MAAMs2D,EAA8B,GAEpC,IAAK,MAAMjvE,KAAW6P,EAAM8I,SAAU,CAClC,MAAMu2D,EAAqC,CAGvCp4B,IAAKm3B,GAAal6B,EAAK/zC,GAAS,IAE9Bia,EAAQk1D,GAAkBnvE,GAC5Bia,IACAi1D,EAAiB/pC,KAAOupC,GAAez0D,IAE3Cg1D,EAAQ1wE,KAAK2wE,E,CAGjB,MAAMG,EAAQt7B,EAAI5H,KAEZmjC,EAASA,CAAC/hE,EAAkBgiE,KAC9B,MAAMC,EAAUD,EAAQ/E,eAAejtE,KAAK,KAC5C,MAAO,UAAPtF,OAAiBsV,EAAQ,KAAAtV,OAAIu3E,EAAO,EAElC92D,EAAwBiK,GAASoxB,EAAI5gD,OAAOulB,aAAa22D,EAAOJ,EAAQ7xE,KAAI,CAAC+wE,EAAQ7gE,KACvF,MAAMwT,EAAuB,CAAEg2B,IAAKA,KAAM,GACpC3jD,EAAS4gD,EAAI5gD,OACnB2tB,EAAIg2B,IAAM,KAEN,GADAq3B,EAAOr3B,IAAIn0B,IACNxvB,EAAOk3E,cAAe,CACvB,MAAMxnE,EAAMysE,EAAOD,EAAOl8E,GACrBA,EAAOo3E,gBAAgBtzD,IAAIpU,IAE5B1P,EAAOo3E,gBAAgB7nE,IAAIG,EAAK,IAEpC,MAAM4sE,EAAat8E,EAAOo3E,gBAAgBtzD,IAAIpU,GACb,qBAAZ,OAAV4sE,QAAU,IAAVA,OAAU,EAAVA,EAAaniE,MAEpBmiE,EAAWniE,IAAO,E,GAI9B,MAAM+lD,EAAO8a,EAAOhpC,KAUpB,OARIrkB,EAAIqkB,KADJkuB,EACW,IAAMA,EAAK1wC,GAEX,KACP,MAAM+sD,EAAsBv8E,EAAOo3E,gBAAgBtzD,IAAIq4D,EAAOD,EAAOl8E,IAErE,QADkC,OAAnBu8E,QAAmB,IAAnBA,OAAmB,EAAnBA,EAAsBpiE,GACzB,EAGbwT,CAAG,KAER6uD,EAAU12D,GAAK86B,EAAKo7B,GAAkBt/D,GAAQ6I,EAAc,KAClE,OAAQiK,IACJgtD,EAAQhtD,GACHoxB,EAAI5gD,OAAOk3E,eACZt2B,EAAI5gD,OAAOo3E,gBAAgBqF,OAAON,EAAOD,EAAOt7B,EAAI5gD,Q,CAGhE,CAzKiB08E,CAAoB97B,EAAK/zC,QAC/B,GAAI0J,GAAQ1J,GACfmuE,EAyKR,SAAoBp6B,EAAkBlkC,GAClC,MAAMo/D,EAAUp/D,EAAM8I,SAASvb,KAAI8D,GAAK+sE,GAAal6B,EAAK7yC,KAC1D,OAAQyhB,GAASssD,EAAQ1zE,SAAQ4yE,GAAUA,EAAOxrD,IACtD,CA5KiBmtD,CAAW/7B,EAAK/zC,OACtB,IlFoXiBrJ,EkFpXFqJ,GlFqXfpJ,GAAWC,WAAWF,EAAM6S,IkFjX/B,MAAM,IAAI1C,EAAkB9G,EAAQgM,SAAU,4BAAF/T,OAA8B+H,EAAQ7H,QAJtD,CAC5B,MAAMmV,EAAMymC,EAAIiS,UAChBmoB,EAASA,IAAMp6B,EAAI5gD,OAAO6yD,QAAQ14C,EAAK2tB,GAAKj7B,E,ElFkX9C,IAAsBrJ,EkF9WxB,OAAOsiB,GAAK86B,EAAKq6B,OAAcz6E,EAAYw7E,GAAkBnvE,GAAUmuE,EAAQnuE,EAAQ4Y,YAC3F,CA0CA,SAAS81D,GAAeqB,GACpB,GlFE0Bp5E,EkFFRo5E,ElFGXn5E,GAAWC,WAAWF,EAAMgR,GkFHL,CAC1B,MAAMqR,EAAO01D,GAAeqB,EAAU/2D,MAChCF,EAAQ41D,GAAeqB,EAAUj3D,OACvC,OAAQ6J,GAAU3J,EAAK2J,IAAS7J,EAAM6J,E,CACnC,GlFfL,SAAwBhsB,GAC1B,OAAOC,GAAWC,WAAWF,EAAM+Q,EACvC,CkFaesoE,CAAcD,GAAY,CACjC,MAAM/2D,EAAO01D,GAAeqB,EAAU/2D,MAChCF,EAAQ41D,GAAeqB,EAAUj3D,OACvC,OAAQ6J,GAAU3J,EAAK2J,IAAS7J,EAAM6J,E,CACnC,GlF6EL,SAAqBhsB,GACvB,OAAOC,GAAWC,WAAWF,EAAMqR,EACvC,CkF/EeioE,CAAWF,GAAY,CAC9B,MAAMt5E,EAAQi4E,GAAeqB,EAAUt5E,OACvC,OAAQksB,IAAUlsB,EAAMksB,E,CACrB,GlF8GL,SAA+BhsB,GACjC,OAAOC,GAAWC,WAAWF,EAAMwR,EACvC,CkFhHe+nE,CAAqBH,GAAY,CACxC,MAAMj7E,EAAOi7E,EAAUzlC,UAAUx0B,IAAKhhB,KACtC,OAAQ6tB,QAAkBhvB,IAATgvB,IAAqC,IAAfA,EAAK7tB,E,CACzC,GlFtCL,SAA2B6B,GAC7B,OAAOC,GAAWC,WAAWF,EAAM8Q,EACvC,CkFoCe0oE,CAAiBJ,GAAY,CACpC,MAAMt5E,EAAQ8I,QAAQwwE,EAAUK,MAChC,MAAO,IAAM35E,C,ClFdf,IAAwBE,EkFgB1BoQ,GACJ,CAwGA,SAASooE,GAAkBnvE,GACvB,GAAI0J,GAAQ1J,GACR,OAAOA,EAAQqwE,cAGvB,CAEA,SAAS9B,GAAoBx6B,EAAkBu8B,GAAsD,IAA5Bl3D,EAAQ3lB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG68E,EAASl3D,SACzF,GAAKA,EAUE,IAAIpP,GAAWoP,IAAa/Q,EAAa+Q,EAASzkB,KAAKmhB,KAAM,CAChE,MAAMxI,EAAMymC,EAAIlI,UAChB,OAAQlpB,GAASoxB,EAAI5gD,OAAO04C,QAAQv+B,EAAKwhE,GAAQ/6B,EAAK36B,EAASzkB,KAAKmhB,KAAoBw6D,EAAU3tD,E,CAC/F,GAAI3Y,GAAWoP,IAAazQ,GAAeyQ,EAASzkB,KAAKmhB,KAAM,CAClE,MAAMxI,EAAMymC,EAAIiS,UACV/tC,EAAe82D,GAASh7B,EAAK36B,EAASzkB,KAAKmhB,IAAIhhB,MACrD,MAAO,IAAMi/C,EAAI5gD,OAAO6yD,QAAQ14C,EAAK2K,EAAcq4D,E,CAChD,GAAI1mE,GAAUwP,GAAW,CAC5B,MAAM9L,EAAMymC,EAAIiS,UACV1vC,EAAUy4D,GAASh7B,EAAK36B,EAAS3iB,OACvC,MAAO,IAAMs9C,EAAI5gD,OAAO6yD,QAAQ14C,EAAKgJ,EAASg6D,E,CAG9C,MAAM,IAAIj4E,MAAM,yC,CAvBL,CACX,IAAKi4E,EAAS/3E,KAAKud,IACf,MAAM,IAAIzd,MAAM,wCAA0Ci4E,EAAS/3E,KAAKoF,UAE5E,MAAMguE,EAAaj1D,GAAmB45D,EAAS/3E,KAAKud,KAC9Cy6D,EAA2B,OAAV5E,QAAU,IAAVA,OAAU,EAAVA,EAAYvyD,SACnC,IAAKm3D,EACD,MAAM,IAAIl4E,MAAM,4CAA8Cuf,GAAY04D,EAAS/3E,KAAKud,MAE5F,OAAOy4D,GAAoBx6B,EAAKu8B,EAAUC,E,CAgBlD,CAWA,SAASt3D,GAAK86B,EAAkB95B,EAA8Bk0D,EAAgBv1D,GAC1E,MAAMy6C,EAAOp5C,GAASy0D,GAAez0D,GAErC,IAAKrB,EAAa,CACd,GAAIy6C,EAAM,CACN,MAAM/lD,EAAMymC,EAAI5H,KAChB,OAAQxpB,GAASoxB,EAAI5gD,OAAOulB,aAAapL,EAAK,CAC1C,CACIwpC,IAAKA,IAAMq3B,EAAOxrD,GAClBwiB,KAAMA,IAAMkuB,EAAK1wC,IAErB,CACIm0B,IAAKY,KACLvS,KAAMA,KAAOkuB,EAAK1wC,K,CAI1B,OAAOwrD,C,CAIf,GAAoB,MAAhBv1D,EAAqB,CACrB,MAAMtL,EAAMymC,EAAI7H,OAChB,OAAQvpB,GAASoxB,EAAI5gD,OAAO+4C,KAAK5+B,EAAK,CAClC+oC,IAAKA,IAAM83B,EAAOxrD,GAClBwiB,KAAMkuB,EAAO,IAAMA,EAAK1wC,QAAQhvB,G,CAEjC,GAAoB,MAAhBilB,EAAqB,CAC5B,MAAMtL,EAAMymC,EAAI7H,OAChB,GAAImnB,EAAM,CACN,MAAMgc,EAAQt7B,EAAI5H,KAKlB,OAAQxpB,GAASoxB,EAAI5gD,OAAOulB,aAAa22D,EAAO,CAC5C,CACIv4B,IAAKA,IAAM/C,EAAI5gD,OAAO64C,WAAW1+B,EAAK,CAClC+oC,IAAKA,IAAM83B,EAAOxrD,KAEtBwiB,KAAMA,IAAMkuB,EAAK1wC,IAErB,CACIm0B,IAAKY,KACLvS,KAAMA,KAAOkuB,EAAK1wC,K,CAI1B,OAAQA,GAASoxB,EAAI5gD,OAAO64C,WAAW1+B,EAAK,CACxC+oC,IAAKA,IAAM83B,EAAOxrD,I,CAGvB,GAAoB,MAAhB/J,EAAqB,CAC5B,MAAMtL,EAAMymC,EAAIqc,WAChB,OAAQztC,GAASoxB,EAAI5gD,OAAOi9D,SAAS9iD,EAAK,CACtC+oC,IAAKA,IAAM83B,EAAOxrD,GAClBwiB,KAAMkuB,EAAO,IAAMA,EAAK1wC,QAAQhvB,G,CAGpCoT,GAER,CAEA,SAAS+nE,GAAQ/6B,EAAoB/zC,GACjC,MAAMlL,EAMV,SAAqBi/C,EAAoB/zC,GACrC,GAAIqI,EAAarI,GACb,OAAOA,EAAQlL,KACZ,GAAIi/C,EAAI3+B,UAAU3Z,IAAIuE,GACzB,OAAO+zC,EAAI3+B,UAAU6B,IAAIjX,GACtB,CACH,IAAIrJ,EAAgBqJ,EAChB0G,EAAkB/P,EAAKkU,WACvB0wB,EAAmBv7B,EAAQ7H,MAC/B,MAAQkQ,EAAa3B,IAAS,CAC1B,GAAIgD,GAAQhD,IAAWwC,GAAexC,IAAW4D,GAAiB5D,GAAS,CAEvE60B,EADc70B,EAAOiS,SAASnY,QAAQ7J,GACrBiF,WAAa,IAAM2/B,C,CAExC5kC,EAAO+P,EACPA,EAASA,EAAOmE,U,CAKpB,OAFA0wB,EADa70B,EACG5R,KAAO,IAAMymC,EAC7BwY,EAAI3+B,UAAU1S,IAAI1C,EAASu7B,GACpBA,C,CAEf,CA5BiBi1C,CAAYz8B,EAAK/zC,GACxBrL,EAAOo/C,EAAI54C,MAAM8b,IAAIniB,GAC3B,IAAKH,EAAM,MAAM,IAAI0D,MAAM,SAADJ,OAAUnD,EAAI,kBACxC,OAAOH,CACX,CA0BA,SAASo6E,GAASh7B,EAAoBj/C,GAClC,MAAMyP,EAAQwvC,EAAI7Z,OAAOplC,GACzB,IAAKyP,EAAO,MAAM,IAAIlM,MAAM,UAADJ,OAAWnD,EAAI,kBAC1C,OAAOyP,CACX,CCtYM,SAAUksE,GAAoBjH,GAChC,MAAMr2E,EASJ,SAA+Bq2E,GACjC,MAAMt0D,EAAUs0D,EAAS1vE,QACnB4vE,EAAQF,EAASr2E,OAAOw0B,MACxBx0B,EAAS,IAAIgJ,GAAcqtE,GACjC,OAAOqE,GAAa34D,EAAS/hB,EAAQu2E,EAAMnyD,WAC/C,CAdmBm5D,CAAqBlH,GAEpC,OADAr2E,EAAO++D,WACA/+D,CACX,CCMM,MAAO4H,GAET41E,WAAAA,CAAYz7D,EAAkB7Z,GAC1B,MAAMu1E,EAAiB5uE,EAAOiT,GAAqBC,GAAS,IACtD9Z,EAA8BxD,KAAKi5E,oBAAoBD,GACvD12C,EAAsBtiC,KAAKsD,mBAAmB01E,EAAgBx1E,EAAgBC,GAYpF,OAVAD,EAAeG,SAAQu1E,IACnB,MAAMnjE,EAAUmjE,EAAcp1E,QACP,kBAAZiS,GAAwBA,GAAW,SAAUA,GAAWyG,GAAazG,GAC5EusB,EAAO6uC,QAAQ+H,GAEf52C,EAAO37B,KAAKuyE,E,IAKb52C,CACX,CAEU22C,mBAAAA,CAAoB11E,GAC1B,OAAOA,EAAM6F,OAAO2H,IAAgB3H,QAAOE,IAAMA,EAAE+pE,WAC9C7tE,KAAIgc,GAAYxhB,KAAKm5E,mBAAmB33D,KAAW1Z,SAC5D,CAEUqxE,kBAAAA,CAAmB33D,GACzB,MAAM5e,EAAQwd,GAAcoB,GACtBzL,EAAU/V,KAAKo5E,sBAAsBx2E,GAAS5C,KAAKq5E,qBAAqBz2E,GAASA,EACjFgB,EAAuB,CACzB1G,KAAMskB,EAAStkB,KACf4G,QAASiS,EACTgc,aAAa,GAMjB,OAJIvQ,EAAS3S,SAETjL,EAAU2tB,MAAQ/U,GAAa5Z,GAASmtB,GAAMyB,QAAU,UAErD5tB,CACX,CAEUw1E,qBAAAA,CAAsBx2E,GAC5B,QAAIA,EAAMsT,MAAMpM,SAAS,SAGdlH,EAAMga,OAAO9S,SAAS,SAAUlH,EAAMga,OAAO9S,SAAS,OAMrE,CAEUuvE,oBAAAA,CAAqBz2E,GAC3B,MAAM02E,EAAc,IAAIv1E,OAAOnB,EAAOA,EAAMsT,MAAQ,KACpD,MAAO,CAAChR,EAAMmI,KACVisE,EAAYn8D,UAAY9P,EAExB,OADmBisE,EAAYx2E,KAAKoC,EACnB,CAEzB,CAEU5B,kBAAAA,CAAmBC,EAA6BC,EAA6BC,GACnF,OAAOF,EAEF6F,OAAOqH,GACP1G,SAAQhN,GAAQgX,GAAkBhX,GAAMqM,OAAO4I,MAC/CpH,UAAStB,GAAKA,EAAEzK,QAAOiJ,UAEvByxE,MAAK,CAACprE,EAAGC,IAAMA,EAAEvP,MAAM/C,OAASqS,EAAEtP,MAAM/C,SACxC0J,KAAIkZ,GAAW1e,KAAKw5E,kBAAkB96D,EAASlb,EAAgBmE,QAAe,OAAPlE,QAAO,IAAPA,OAAO,EAAPA,EAAS7B,mBACzF,CAEU43E,iBAAAA,CAAkB96D,EAAkBlb,EAA6B5B,GACvE,MAAO,CACH1E,KAAMwhB,EAAQ7f,MACdiF,QAAS9D,KAAKy5E,oBAAoB/6D,EAAS9c,GAC3C+vB,WAAY3xB,KAAK05E,cAAch7D,EAASlb,GAEhD,CAEUi2E,mBAAAA,CAAoB/6D,EAAkB9c,GAC5C,OAAOA,EACH,IAAImC,O9E2CV,SAAoC2a,GACtC,OAAO7X,MAAMuE,UAAU5F,IAAI6F,KAAKqT,GAAS1F,GACrC,KAAKC,KAAKD,GAAU,IAAH3Y,OAAO2Y,EAAOsG,eAAajf,OAAG2Y,EAAOE,cAAa,KAAMmD,GAAarD,KACxFrT,KAAK,GACX,C8E/CuBg0E,CAA0Bj7D,EAAQ7f,QAC7C6f,EAAQ7f,KAChB,CAEU66E,aAAAA,CAAch7D,EAAkBlb,GACtC,OAAOA,EAAe+F,QAAO,CAACqwE,EAAyBjtE,KACnD,MAAMoJ,EAAe,OAALpJ,QAAK,IAALA,OAAK,EAALA,EAAO7I,QAIvB,OAHW,OAAPiS,QAAO,IAAPA,OAAO,EAAPA,EAAS6G,SAAUH,GAAe,IAAM1G,EAAQ6G,OAAS,IAAK8B,EAAQ7f,QACtE+6E,EAAWjzE,KAAKgG,GAEbitE,CAAU,GAClB,GACP,EC/FE,MAAOp3E,GAET2xE,OAAAA,CAAQn3E,EAAe0F,GACnB,IAAI8b,EAAuC9b,EAAQ6b,cAInD,GAHI5M,GAAiB6M,KACjBA,E9EkDN,SAAoCk6D,GACtC,GAAIA,EAASl3D,SACT,OAAOk3D,EAASl3D,SACb,GAAIk3D,EAAS/3E,KAAKud,IAAK,CAC1B,MAAM27D,EAAgB/6D,GAAmB45D,EAAS/3E,KAAKud,KACvD,OAAoB,OAAb27D,QAAa,IAAbA,OAAa,EAAbA,EAAer4D,Q,CAG9B,C8E1DsBs4D,CAA0Bt7D,IAEpCpM,GAAWoM,GAAU,CACrB,MAAMzhB,EAAOyhB,EAAQzhB,KAAKmhB,IAC1B,IAAKnhB,EACD,MAAM,IAAI0D,MAAM,2CAEpB,OAAOT,KAAKyC,aAAa1F,EAAMC,EAAO0F,E,CAE1C,OAAO1F,CACX,CAGUyF,YAAAA,CAAa1F,EAAoBC,EAAe0F,G,MACtD,OAAQ3F,EAAKG,KAAKgc,eACd,IAAK,MAAO,OAAOzd,GAAes+E,WAAW/8E,GAC7C,IAAK,SAAU,OAAOvB,GAAeu+E,cAAch9E,GACnD,IAAK,KAAM,OAAOvB,GAAew+E,UAAUj9E,GAE/C,OAAyB,QAAjBmX,E9EoYV,SAAsBpX,G,UACxB,OAAI2gB,GAAmB3gB,GACG,QAAf6kD,EAAS,QAATztC,EAAApX,EAAK4D,YAAI,IAAAwT,OAAA,EAAAA,EAAEjX,YAAI,IAAA0kD,EAAAA,EAAI,SAEnBpiC,GAAeziB,GAAQA,EAAKG,KAAgC,QAAzBg9E,EAAAt6D,GAAoB7iB,UAAK,IAAAm9E,EAAAA,EAAIn9E,EAAKG,IAEpF,C8E1YgBi9E,CAAYp9E,UAAK,IAAAoX,OAAA,EAAAA,EAAEmL,eACvB,IAAK,SAAU,OAAO7jB,GAAe2+E,cAAcp9E,GACnD,IAAK,UAAW,OAAOvB,GAAe4+E,eAAer9E,GACrD,IAAK,SAAU,OAAOvB,GAAe6+E,cAAct9E,GACnD,IAAK,OAAQ,OAAOvB,GAAe8+E,YAAYv9E,GAC/C,QAAS,OAAOA,EAExB,EAGE,IAAWvB,IAAjB,SAAiBA,GAgBb,SAAS++E,EAAuB/lE,GAC5B,OAAQA,GACJ,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,QAAS,OAAOA,EAExB,CAzBgBhZ,EAAAu+E,cAAhB,SAA8Bh9E,GAC1B,IAAIoI,EAAS,GACb,IAAK,IAAIoF,EAAI,EAAGA,EAAIxN,EAAMlB,OAAS,EAAG0O,IAAK,CACvC,MAAM6tB,EAAIr7B,EAAMk+B,OAAO1wB,GACvB,GAAU,OAAN6tB,EAAY,CAEZjzB,GAAUo1E,EADCx9E,EAAMk+B,SAAS1wB,G,MAG1BpF,GAAUizB,C,CAGlB,OAAOjzB,CACX,EAegB3J,EAAAw+E,UAAhB,SAA0Bj9E,GACtB,MAAwB,MAApBA,EAAMk+B,OAAO,GACNl+B,EAAM4Z,UAAU,GAEhB5Z,CAEf,EAEgBvB,EAAAs+E,WAAhB,SAA2B/8E,GACvB,OAAO6c,SAAS7c,EACpB,EAEgBvB,EAAA6+E,cAAhB,SAA8Bt9E,GAC1B,OAAOy9E,OAAOz9E,EAClB,EAEgBvB,EAAA8+E,YAAhB,SAA4Bv9E,GACxB,OAAO,IAAI07B,KAAK17B,EACpB,EAEgBvB,EAAA2+E,cAAhB,SAA8Bp9E,GAC1B,OAAO+mE,OAAO/mE,EAClB,EAEgBvB,EAAA4+E,eAAhB,SAA+Br9E,GAC3B,MAA+B,SAAxBA,EAAMsiB,aACjB,CAEH,CAzDD,CAAiB7jB,KAAAA,GAAc,K,eC/B/B,IAAIi/E,GAAW,EACXC,GAA2B,GAuBxB,MAAMC,GAAqBnzE,OAAO,sBAMnC,SAAUozE,GAAqBp1E,GACjC,OAAOA,IAAQm1E,EACnB,CAaOv2E,eAAey2E,GAAkBnuE,GACpC,GAAIA,IAAUouE,GAAAA,GAAkBC,KAE5B,OAEJ,MAAM5c,EAAU1lC,KAAKuiD,MAKrB,GAJI7c,EAAUsc,IAAYC,KACtBD,GAAWtc,QA/DR,IAAI8c,SAAQC,IAGa,qBAAjBC,aACPC,WAAWF,EAAS,GAEpBC,aAAaD,E,KA4DjBxuE,EAAM2uE,wBACN,MAAMV,EAEd,CAMM,MAAOW,GAAbpgF,WAAAA,GAII,KAAAqgF,QAAU,IAAIN,SAAW,CAACC,EAAStrD,KAC/B7vB,KAAKm7E,QAAWM,IACZN,EAAQM,GACDz7E,MAEXA,KAAK6vB,OAAUpqB,IACXoqB,EAAOpqB,GACAzF,KACV,GAET,ECnGA,MAAMotE,GACFjyE,WAAAA,CAAYopE,EAAK7iE,EAAYkmE,EAAS7gE,GAClC/G,KAAK8tE,KAAOvJ,EACZvkE,KAAK+tE,YAAcrsE,EACnB1B,KAAKguE,SAAWpG,EAChB5nE,KAAKiuE,SAAWlnE,EAChB/G,KAAKkuE,kBAAenyE,CACxB,CACA,OAAIwoE,GACA,OAAOvkE,KAAK8tE,IAChB,CACA,cAAIpsE,GACA,OAAO1B,KAAK+tE,WAChB,CACA,WAAInG,GACA,OAAO5nE,KAAKguE,QAChB,CACAV,OAAAA,CAAQhgE,GACJ,GAAIA,EAAO,CACP,MAAMV,EAAQ5M,KAAKwtE,SAASlgE,EAAMV,OAC5BK,EAAMjN,KAAKwtE,SAASlgE,EAAML,KAChC,OAAOjN,KAAKiuE,SAASr3D,UAAUhK,EAAOK,EAC1C,CACA,OAAOjN,KAAKiuE,QAChB,CACAE,MAAAA,CAAO1G,EAASG,GACZ,IAAK,MAAMD,KAAUF,EACjB,GAAI2F,GAAiBsO,cAAc/T,GAAS,CAExC,MAAMr6D,EAAQquE,GAAmBhU,EAAOr6D,OAElC0tB,EAAch7B,KAAKwtE,SAASlgE,EAAMV,OAClCi2B,EAAY7iC,KAAKwtE,SAASlgE,EAAML,KACtCjN,KAAKiuE,SAAWjuE,KAAKiuE,SAASr3D,UAAU,EAAGokB,GAAe2sC,EAAOziE,KAAOlF,KAAKiuE,SAASr3D,UAAUisB,EAAW7iC,KAAKiuE,SAASnyE,QAEzH,MAAMkR,EAAYuB,KAAKC,IAAIlB,EAAMV,MAAMG,KAAM,GACvCI,EAAUoB,KAAKC,IAAIlB,EAAML,IAAIF,KAAM,GACzC,IAAIuhE,EAActuE,KAAKkuE,aACvB,MAAM0N,EAAmBC,GAAmBlU,EAAOziE,MAAM,EAAO81B,GAChE,GAAI7tB,EAAUH,IAAc4uE,EAAiB9/E,OACzC,IAAK,IAAI0O,EAAI,EAAG4tB,EAAMwjD,EAAiB9/E,OAAQ0O,EAAI4tB,EAAK5tB,IACpD8jE,EAAY9jE,EAAIwC,EAAY,GAAK4uE,EAAiBpxE,QAIlDoxE,EAAiB9/E,OAAS,IAC1BwyE,EAAYpU,OAAOltD,EAAY,EAAGG,EAAUH,KAAc4uE,GAG1D57E,KAAKkuE,aAAeI,EAAcA,EAAYtB,MAAM,EAAGhgE,EAAY,GAAG3M,OAAOu7E,EAAkBtN,EAAYtB,MAAM7/D,EAAU,IAGnI,MAAMygE,EAAOjG,EAAOziE,KAAKpJ,QAAU+mC,EAAY7H,GAC/C,GAAa,IAAT4yC,EACA,IAAK,IAAIpjE,EAAIwC,EAAY,EAAI4uE,EAAiB9/E,OAAQs8B,EAAMk2C,EAAYxyE,OAAQ0O,EAAI4tB,EAAK5tB,IACrF8jE,EAAY9jE,GAAK8jE,EAAY9jE,GAAKojE,CAG9C,KACK,KAAIR,GAAiB0O,OAAOnU,GAK7B,MAAM,IAAIlnE,MAAM,iCAJhBT,KAAKiuE,SAAWtG,EAAOziE,KACvBlF,KAAKkuE,kBAAenyE,CAIxB,CAEJiE,KAAKguE,SAAWpG,CACpB,CACAyG,cAAAA,GAII,YAH0BtyE,IAAtBiE,KAAKkuE,eACLluE,KAAKkuE,aAAe2N,GAAmB77E,KAAKiuE,UAAU,IAEnDjuE,KAAKkuE,YAChB,CACAX,UAAAA,CAAWlgE,GACPA,EAASkB,KAAKC,IAAID,KAAKD,IAAIjB,EAAQrN,KAAKiuE,SAASnyE,QAAS,GAC1D,MAAMwyE,EAActuE,KAAKquE,iBACzB,IAAII,EAAM,EAAGC,EAAOJ,EAAYxyE,OAChC,GAAa,IAAT4yE,EACA,MAAO,CAAE3hE,KAAM,EAAGF,UAAWQ,GAEjC,KAAOohE,EAAMC,GAAM,CACf,MAAMC,EAAMpgE,KAAKyxB,OAAOyuC,EAAMC,GAAQ,GAClCJ,EAAYK,GAAOthE,EACnBqhE,EAAOC,EAGPF,EAAME,EAAM,CAEpB,CAGA,MAAM5hE,EAAO0hE,EAAM,EAEnB,MAAO,CAAE1hE,OAAMF,WADfQ,EAASrN,KAAK+7E,gBAAgB1uE,EAAQihE,EAAYvhE,KACfuhE,EAAYvhE,GACnD,CACAygE,QAAAA,CAAS7G,GACL,MAAM2H,EAActuE,KAAKquE,iBACzB,GAAI1H,EAAS55D,MAAQuhE,EAAYxyE,OAC7B,OAAOkE,KAAKiuE,SAASnyE,OAEpB,GAAI6qE,EAAS55D,KAAO,EACrB,OAAO,EAEX,MAAM6hE,EAAaN,EAAY3H,EAAS55D,MACxC,GAAI45D,EAAS95D,WAAa,EACtB,OAAO+hE,EAEX,MAAMC,EAAkBlI,EAAS55D,KAAO,EAAIuhE,EAAYxyE,OAAUwyE,EAAY3H,EAAS55D,KAAO,GAAK/M,KAAKiuE,SAASnyE,OAC3GuR,EAASkB,KAAKD,IAAIsgE,EAAajI,EAAS95D,UAAWgiE,GACzD,OAAO7uE,KAAK+7E,gBAAgB1uE,EAAQuhE,EACxC,CACAmN,eAAAA,CAAgB1uE,EAAQuhE,GACpB,KAAOvhE,EAASuhE,GAAcoN,GAAMh8E,KAAKiuE,SAASv5D,WAAWrH,EAAS,KAClEA,IAEJ,OAAOA,CACX,CACA,aAAIggE,GACA,OAAOrtE,KAAKquE,iBAAiBvyE,MACjC,CACA,oBAAO4/E,CAActN,GACjB,MAAMpK,EAAYoK,EAClB,YAAqBryE,IAAdioE,GAAyC,OAAdA,GACJ,kBAAnBA,EAAU9+D,WAAyCnJ,IAApBioE,EAAU12D,aACrBvR,IAA1BioE,EAAUiY,aAA8D,kBAA1BjY,EAAUiY,YACjE,CACA,aAAOH,CAAO1N,GACV,MAAMpK,EAAYoK,EAClB,YAAqBryE,IAAdioE,GAAyC,OAAdA,GACJ,kBAAnBA,EAAU9+D,WAAyCnJ,IAApBioE,EAAU12D,YAAiDvR,IAA1BioE,EAAUiY,WACzF,EAEG,IAAIpP,GA8DX,SAASC,GAAUlB,EAAMmB,GACrB,GAAInB,EAAK9vE,QAAU,EAEf,OAAO8vE,EAEX,MAAMhN,EAAKgN,EAAK9vE,OAAS,EAAK,EACxBslB,EAAOwqD,EAAKoB,MAAM,EAAGpO,GACrB19C,EAAQ0qD,EAAKoB,MAAMpO,GACzBkO,GAAU1rD,EAAM2rD,GAChBD,GAAU5rD,EAAO6rD,GACjB,IAAIE,EAAU,EACVC,EAAW,EACX1iE,EAAI,EACR,KAAOyiE,EAAU7rD,EAAKtlB,QAAUoxE,EAAWhsD,EAAMplB,QAAQ,CACrD,MAAMqxE,EAAMJ,EAAQ3rD,EAAK6rD,GAAU/rD,EAAMgsD,IAGrCtB,EAAKphE,KAFL2iE,GAAO,EAEK/rD,EAAK6rD,KAIL/rD,EAAMgsD,IAE1B,CACA,KAAOD,EAAU7rD,EAAKtlB,QAClB8vE,EAAKphE,KAAO4W,EAAK6rD,KAErB,KAAOC,EAAWhsD,EAAMplB,QACpB8vE,EAAKphE,KAAO0W,EAAMgsD,KAEtB,OAAOtB,CACX,CACA,SAASiQ,GAAmB32E,EAAMg3E,GAA+B,IAAhBC,EAAUtgF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EAC1D,MAAMuJ,EAAS82E,EAAgB,CAACC,GAAc,GAC9C,IAAK,IAAI3xE,EAAI,EAAGA,EAAItF,EAAKpJ,OAAQ0O,IAAK,CAClC,MAAMgkE,EAAKtpE,EAAKwP,WAAWlK,GACvBwxE,GAAMxN,KACK,KAAPA,GAA2ChkE,EAAI,EAAItF,EAAKpJ,QAAqC,KAA3BoJ,EAAKwP,WAAWlK,EAAI,IACtFA,IAEJpF,EAAOuB,KAAKw1E,EAAa3xE,EAAI,GAErC,CACA,OAAOpF,CACX,CACA,SAAS42E,GAAMvnE,GACX,OAAgB,KAATA,GAAsD,KAATA,CACxD,CACA,SAASknE,GAAmBruE,GACxB,MAAMV,EAAQU,EAAMV,MACdK,EAAMK,EAAML,IAClB,OAAIL,EAAMG,KAAOE,EAAIF,MAASH,EAAMG,OAASE,EAAIF,MAAQH,EAAMC,UAAYI,EAAIJ,UACpE,CAAED,MAAOK,EAAKA,IAAKL,GAEvBU,CACX,CACA,SAAS8uE,GAAkBjX,GACvB,MAAM73D,EAAQquE,GAAmBxW,EAAS73D,OAC1C,OAAIA,IAAU63D,EAAS73D,MACZ,CAAEm5D,QAAStB,EAASsB,QAASn5D,SAEjC63D,CACX,EA3HA,SAAW0H,GAYPA,EAAaxkB,OAHb,SAAgBkc,EAAK7iE,EAAYkmE,EAAS7gE,GACtC,OAAO,IAAIqmE,GAAiB7I,EAAK7iE,EAAYkmE,EAAS7gE,EAC1D,EAoBA8lE,EAAasB,OATb,SAAgBT,EAAUjG,EAASG,GAC/B,GAAI8F,aAAoBN,GAEpB,OADAM,EAASS,OAAO1G,EAASG,GAClB8F,EAGP,MAAM,IAAIjtE,MAAM,uEAExB,EA6BAosE,EAAaY,WA3Bb,SAAoBC,EAAUxG,GAC1B,MAAMhiE,EAAOwoE,EAASJ,UAChBK,EAAcb,GAAU5F,EAAM1hE,IAAI42E,KAAoB,CAACjuE,EAAGC,KAC5D,MAAMw/D,EAAOz/D,EAAEb,MAAMV,MAAMG,KAAOqB,EAAEd,MAAMV,MAAMG,KAChD,OAAa,IAAT6gE,EACOz/D,EAAEb,MAAMV,MAAMC,UAAYuB,EAAEd,MAAMV,MAAMC,UAE5C+gE,CAAI,IAEf,IAAIC,EAAqB,EACzB,MAAMwO,EAAQ,GACd,IAAK,MAAM/yE,KAAKqkE,EAAa,CACzB,MAAM3yC,EAAc0yC,EAASF,SAASlkE,EAAEgE,MAAMV,OAC9C,GAAIouB,EAAc6yC,EACd,MAAM,IAAIptE,MAAM,oBAEXu6B,EAAc6yC,GACnBwO,EAAM11E,KAAKzB,EAAK0R,UAAUi3D,EAAoB7yC,IAE9C1xB,EAAEm9D,QAAQ3qE,QACVugF,EAAM11E,KAAK2C,EAAEm9D,SAEjBoH,EAAqBH,EAASF,SAASlkE,EAAEgE,MAAML,IACnD,CAEA,OADAovE,EAAM11E,KAAKzB,EAAK+X,OAAO4wD,IAChBwO,EAAM12E,KAAK,GACtB,CAEH,CA5DD,CA4DGknE,KAAiBA,GAAe,CAAC,I,uCC9KpC,SAASvjE,EAAWkkC,GAClB,GAAoB,iBAATA,EACT,MAAM,IAAI1iB,UAAU,mCAAqC+qC,KAAKC,UAAUtoB,GAE5E,CAGA,SAAS8uC,EAAqB9uC,EAAMlkC,GAMlC,IALA,IAIIgzE,EAJAl6D,EAAM,GACN5X,EAAoB,EACpB+xE,GAAa,EACbj8D,EAAO,EAEFk8D,EAAI,EAAGA,GAAKhvC,EAAK1xC,SAAU0gF,EAAG,CACrC,GAAIA,EAAIhvC,EAAK1xC,OACXwgF,EAAO9uC,EAAK94B,WAAW8nE,OACpB,IAAa,KAATF,EACP,MAEAA,EAAO,EAAQ,CACjB,GAAa,KAATA,EAAmB,CACrB,GAAIC,IAAcC,EAAI,GAAc,IAATl8D,QAEpB,GAAIi8D,IAAcC,EAAI,GAAc,IAATl8D,EAAY,CAC5C,GAAI8B,EAAItmB,OAAS,GAA2B,IAAtB0O,GAA8D,KAAnC4X,EAAI1N,WAAW0N,EAAItmB,OAAS,IAAsD,KAAnCsmB,EAAI1N,WAAW0N,EAAItmB,OAAS,GAC1H,GAAIsmB,EAAItmB,OAAS,EAAG,CAClB,IAAIqS,EAAiBiU,EAAIR,YAAY,KACrC,GAAIzT,IAAmBiU,EAAItmB,OAAS,EAAG,EACb,IAApBqS,GACFiU,EAAM,GACN5X,EAAoB,GAGpBA,GADA4X,EAAMA,EAAI4qD,MAAM,EAAG7+D,IACKrS,OAAS,EAAIsmB,EAAIR,YAAY,KAEvD26D,EAAYC,EACZl8D,EAAO,EACP,QACF,CACF,MAAO,GAAmB,IAAf8B,EAAItmB,QAA+B,IAAfsmB,EAAItmB,OAAc,CAC/CsmB,EAAM,GACN5X,EAAoB,EACpB+xE,EAAYC,EACZl8D,EAAO,EACP,QACF,CAEEhX,IACE8Y,EAAItmB,OAAS,EACfsmB,GAAO,MAEPA,EAAM,KACR5X,EAAoB,EAExB,MACM4X,EAAItmB,OAAS,EACfsmB,GAAO,IAAMorB,EAAKw/B,MAAMuP,EAAY,EAAGC,GAEvCp6D,EAAMorB,EAAKw/B,MAAMuP,EAAY,EAAGC,GAClChyE,EAAoBgyE,EAAID,EAAY,EAEtCA,EAAYC,EACZl8D,EAAO,CACT,MAAoB,KAATg8D,IAA+B,IAAVh8D,IAC5BA,EAEFA,GAAQ,CAEZ,CACA,OAAO8B,CACT,CAcA,IAAIA,EAAQ,CAEV+4D,QAAS,WAKP,IAJA,IAEI3tC,EAFAprB,EAAe,GACf5X,GAAA,EAGK+xE,EAAI1gF,UAAUC,OAAS,EAAGygF,IAAM,IAAM/xE,EAAkB+xE,IAAK,CACpE,IAAIj8D,EACAi8D,GAAK,EACPj8D,EAAOzkB,UAAU0gF,SAAA,IAEb/uC,IACFA,EAAM3wB,QAAQ4/D,OAChBn8D,EAAOktB,GAGTlkC,EAAWgX,GAGS,IAAhBA,EAAKxkB,SAITsmB,EAAe9B,EAAO,IAAM8B,EAC5B5X,EAA0C,KAAvB8V,EAAK5L,WAAW,GACrC,CAQA,OAFA0N,EAAek6D,EAAqBl6D,GAAe5X,GAE/CA,EACE4X,EAAatmB,OAAS,EACjB,IAAMsmB,EAEN,IACAA,EAAatmB,OAAS,EACxBsmB,EAEA,GAEX,EAEAs6D,UAAW,SAAmBlvC,GAG5B,GAFAlkC,EAAWkkC,GAES,IAAhBA,EAAK1xC,OAAc,MAAO,IAE9B,IAAIsmB,EAAoC,KAAvBorB,EAAK94B,WAAW,GAC7BlK,EAAyD,KAArCgjC,EAAK94B,WAAW84B,EAAK1xC,OAAS,GAQtD,OAHoB,KAFpB0xC,EAAO8uC,EAAqB9uC,GAAOprB,IAE1BtmB,QAAiBsmB,IAAYorB,EAAO,KACzCA,EAAK1xC,OAAS,GAAK0O,IAAmBgjC,GAAQ,KAE9CprB,EAAmB,IAAMorB,EACtBA,CACT,EAEAmvC,WAAY,SAAoBnvC,GAE9B,OADAlkC,EAAWkkC,GACJA,EAAK1xC,OAAS,GAA4B,KAAvB0xC,EAAK94B,WAAW,EAC5C,EAEA/O,KAAM,WACJ,GAAyB,IAArB9J,UAAUC,OACZ,MAAO,IAET,IADA,IAAI0xC,EACK8uC,EAAI,EAAGA,EAAIzgF,UAAUC,SAAUwgF,EAAG,CACzC,IAAI9xE,EAAM3O,UAAUygF,GACpBhzE,EAAWkB,GACPA,EAAI1O,OAAS,aACX0xC,EACFA,EAAShjC,EAETgjC,GAAU,IAAMhjC,EAEtB,CACA,gBAAIgjC,EACK,IACFprB,EAAMs6D,UAAUlvC,EACzB,EAEAovC,SAAU,SAAkBpvC,EAAM8uC,GAIhC,GAHAhzE,EAAWkkC,GACXlkC,EAAWgzE,GAEP9uC,IAAS8uC,EAAI,MAAO,GAKxB,IAHA9uC,EAAOprB,EAAM+4D,QAAQ3tC,OACrB8uC,EAAKl6D,EAAM+4D,QAAQmB,IAEF,MAAO,GAIxB,IADA,IAAI9xE,EAAY,EACTA,EAAYgjC,EAAK1xC,QACa,KAA/B0xC,EAAK94B,WAAWlK,KADYA,GASlC,IALA,IAAI+xE,EAAU/uC,EAAK1xC,OACfwkB,EAAUi8D,EAAU/xE,EAGpBgyE,EAAU,EACPA,EAAUF,EAAGxgF,QACa,KAA3BwgF,EAAG5nE,WAAW8nE,KADUA,GAW9B,IAPA,IACIruE,EADQmuE,EAAGxgF,OACK0gF,EAGhBnkD,EAAS/X,EAAUnS,EAAQmS,EAAUnS,EACrC0uE,GAAiB,EACjBt8D,EAAI,EACDA,GAAK8X,IAAU9X,EAAG,CACvB,GAAIA,IAAM8X,EAAQ,CAChB,GAAIlqB,EAAQkqB,EAAQ,CAClB,GAAmC,KAA/BikD,EAAG5nE,WAAW8nE,EAAUj8D,GAG1B,OAAO+7D,EAAGtP,MAAMwP,EAAUj8D,EAAI,GACzB,GAAU,IAANA,EAGT,OAAO+7D,EAAGtP,MAAMwP,EAAUj8D,EAE9B,MAAWD,EAAU+X,IACoB,KAAnCmV,EAAK94B,WAAWlK,EAAY+V,GAG9Bs8D,EAAgBt8D,EACD,IAANA,IAGTs8D,EAAgB,IAGpB,KACF,CACA,IAAIC,EAAWtvC,EAAK94B,WAAWlK,EAAY+V,GAE3C,GAAIu8D,IADSR,EAAG5nE,WAAW8nE,EAAUj8D,GAEnC,MACoB,KAAbu8D,IACPD,EAAgBt8D,EACpB,CAEA,IAAIo7C,EAAM,GAGV,IAAKp7C,EAAI/V,EAAYqyE,EAAgB,EAAGt8D,GAAKg8D,IAAWh8D,EAClDA,IAAMg8D,GAAkC,KAAvB/uC,EAAK94B,WAAW6L,KAChB,IAAfo7C,EAAI7/D,OACN6/D,GAAO,KAEPA,GAAO,OAMb,OAAIA,EAAI7/D,OAAS,EACR6/D,EAAM2gB,EAAGtP,MAAMwP,EAAUK,IAEhCL,GAAWK,EACoB,KAA3BP,EAAG5nE,WAAW8nE,MACdA,EACGF,EAAGtP,MAAMwP,GAEpB,EAEAO,UAAW,SAAmBvvC,GAC5B,OAAOA,CACT,EAEAwvC,QAAS,SAAiBxvC,GAExB,GADAlkC,EAAWkkC,GACS,IAAhBA,EAAK1xC,OAAc,MAAO,IAK9B,IAJA,IAAIwgF,EAAO9uC,EAAK94B,WAAW,GACvB0N,EAAmB,KAATk6D,EACV9xE,GAAO,EACP+xE,GAAA,EACKj8D,EAAIktB,EAAK1xC,OAAS,EAAGwkB,GAAK,IAAKA,EAEtC,GAAa,MADbg8D,EAAO9uC,EAAK94B,WAAW4L,KAEnB,IAAKi8D,EAAc,CACjB/xE,EAAM8V,EACN,KACF,OAGFi8D,GAAA,EAIJ,OAAa,IAAT/xE,EAAmB4X,EAAU,IAAM,IACnCA,GAAmB,IAAR5X,EAAkB,KAC1BgjC,EAAKw/B,MAAM,EAAGxiE,EACvB,EAEAyyE,SAAU,SAAkBzvC,EAAM8uC,GAChC,QAAI,IAAAA,GAAoC,iBAARA,EAAkB,MAAM,IAAIxxD,UAAU,mCACtExhB,EAAWkkC,GAEX,IAGIprB,EAHA5X,EAAQ,EACR+xE,GAAO,EACPj8D,GAAA,EAGJ,QAAI,IAAAg8D,GAAqBA,EAAIxgF,OAAS,GAAKwgF,EAAIxgF,QAAU0xC,EAAK1xC,OAAQ,CACpE,GAAIwgF,EAAIxgF,SAAW0xC,EAAK1xC,QAAUwgF,IAAQ9uC,EAAM,MAAO,GACvD,IAAIgvC,EAASF,EAAIxgF,OAAS,EACtBqS,GAAoB,EACxB,IAAKiU,EAAIorB,EAAK1xC,OAAS,EAAGsmB,GAAK,IAAKA,EAAG,CACrC,IAAIiW,EAAOmV,EAAK94B,WAAW0N,GAC3B,GAAa,KAATiW,GAGA,IAAK/X,EAAc,CACjB9V,EAAQ4X,EAAI,EACZ,KACF,OAEwB,IAAtBjU,IAGFmS,GAAA,EACAnS,EAAmBiU,EAAI,GAErBo6D,GAAU,IAERnkD,IAASikD,EAAI5nE,WAAW8nE,IACR,KAAZA,IAGJD,EAAMn6D,IAKRo6D,GAAU,EACVD,EAAMpuE,GAId,CAGA,OADI3D,IAAU+xE,EAAKA,EAAMpuE,GAAmC,IAATouE,IAAYA,EAAM/uC,EAAK1xC,QACnE0xC,EAAKw/B,MAAMxiE,EAAO+xE,EAC3B,CACE,IAAKn6D,EAAIorB,EAAK1xC,OAAS,EAAGsmB,GAAK,IAAKA,EAClC,GAA2B,KAAvBorB,EAAK94B,WAAW0N,IAGhB,IAAK9B,EAAc,CACjB9V,EAAQ4X,EAAI,EACZ,KACF,OACkB,IAATm6D,IAGXj8D,GAAA,EACAi8D,EAAMn6D,EAAI,GAId,OAAa,IAATm6D,EAAmB,GAChB/uC,EAAKw/B,MAAMxiE,EAAO+xE,EAE7B,EAEAW,QAAS,SAAiB1vC,GACxBlkC,EAAWkkC,GAQX,IAPA,IAAI8uC,GAAY,EACZl6D,EAAY,EACZ5X,GAAO,EACP+xE,GAAA,EAGAj8D,EAAc,EACTk8D,EAAIhvC,EAAK1xC,OAAS,EAAG0gF,GAAK,IAAKA,EAAG,CACzC,IAAIruE,EAAOq/B,EAAK94B,WAAW8nE,GAC3B,GAAa,KAATruE,GASS,IAAT3D,IAGF+xE,GAAA,EACA/xE,EAAMgyE,EAAI,GAEC,KAATruE,GAEkB,IAAdmuE,EACFA,EAAWE,EACY,IAAhBl8D,IACPA,EAAc,IACK,IAAdg8D,IAGTh8D,GAAe,QArBb,IAAKi8D,EAAc,CACjBn6D,EAAYo6D,EAAI,EAChB,KACF,CAoBN,CAEA,OAAkB,IAAdF,IAA4B,IAAT9xE,GAEH,IAAhB8V,GAEgB,IAAhBA,GAAqBg8D,IAAa9xE,EAAM,GAAK8xE,IAAal6D,EAAY,EACjE,GAEForB,EAAKw/B,MAAMsP,EAAU9xE,EAC9B,EAEA2yE,OAAQ,SAAgB3vC,GACtB,GAAmB,OAAfA,GAA6C,iBAAfA,EAChC,MAAM,IAAI1iB,UAAU,0EAA4E0iB,GAElG,OAvVJ,SAAiBA,EAAKlkC,GACpB,IAAIgzE,EAAMhzE,EAAW8zE,KAAO9zE,EAAW0C,KACnCoW,EAAO9Y,EAAW+zE,OAAS/zE,EAAWpM,MAAQ,KAAOoM,EAAWg0E,KAAO,IAC3E,OAAKhB,EAGDA,IAAQhzE,EAAW0C,KACdswE,EAAMl6D,EAERk6D,EA8UU,IA9UEl6D,EALVA,CAMX,CAVA,CAuVmB,EAAKorB,EACtB,EAEAxoC,MAAO,SAAewoC,GACpBlkC,EAAWkkC,GAEX,IAAI8uC,EAAM,CAAEtwE,KAAM,GAAIoxE,IAAK,GAAIC,KAAM,GAAIC,IAAK,GAAIpgF,KAAM,IACxD,GAAoB,IAAhBswC,EAAK1xC,OAAc,OAAOwgF,EAC9B,IAEIl6D,EAFA5X,EAAOgjC,EAAK94B,WAAW,GACvB6nE,EAAsB,KAAT/xE,EAEb+xE,GACFD,EAAItwE,KAAO,IACXoW,EAAQ,GAERA,EAAQ,EAaV,IAXA,IAAI9B,GAAY,EACZk8D,EAAY,EACZruE,GAAO,EACPkqB,GAAA,EACAwkD,EAAIrvC,EAAK1xC,OAAS,EAIlBykB,EAAc,EAGXs8D,GAAKz6D,IAASy6D,EAEnB,GAAa,MADbryE,EAAOgjC,EAAK94B,WAAWmoE,KAUV,IAAT1uE,IAGFkqB,GAAA,EACAlqB,EAAM0uE,EAAI,GAEC,KAATryE,GAEkB,IAAd8V,EAAiBA,EAAWu8D,EAA2B,IAAhBt8D,IAAmBA,EAAc,IACrD,IAAdD,IAGXC,GAAe,QAlBb,IAAK8X,EAAc,CACjBmkD,EAAYK,EAAI,EAChB,KACF,CAwCN,OArBkB,IAAdv8D,IAA4B,IAATnS,GAEP,IAAhBoS,GAEgB,IAAhBA,GAAqBD,IAAanS,EAAM,GAAKmS,IAAak8D,EAAY,GACvD,IAATruE,IACiCmuE,EAAIe,KAAOf,EAAIp/E,KAAhC,IAAds/E,GAAmBD,EAAkC/uC,EAAKw/B,MAAM,EAAG7+D,GAAgCq/B,EAAKw/B,MAAMwP,EAAWruE,KAG7G,IAAdquE,GAAmBD,GACrBD,EAAIp/E,KAAOswC,EAAKw/B,MAAM,EAAG1sD,GACzBg8D,EAAIe,KAAO7vC,EAAKw/B,MAAM,EAAG7+D,KAEzBmuE,EAAIp/E,KAAOswC,EAAKw/B,MAAMwP,EAAWl8D,GACjCg8D,EAAIe,KAAO7vC,EAAKw/B,MAAMwP,EAAWruE,IAEnCmuE,EAAIgB,IAAM9vC,EAAKw/B,MAAM1sD,EAAUnS,IAG7BquE,EAAY,EAAGF,EAAIc,IAAM5vC,EAAKw/B,MAAM,EAAGwP,EAAY,GAAYD,IAAYD,EAAIc,IAAM,KAElFd,CACT,EAEA1jB,IAAK,IACL2kB,UAAW,IACXC,MAAO,KACPC,MAAO,MAGTr7D,EAAMq7D,MAAQr7D,EAEdorB,EAAOkwC,QAAUt7D,CAAAA,GC/gBb9Y,EAA2B,CAAC,EAGhC,SAASgzE,EAAoBl6D,GAE5B,IAAI5X,EAAelB,EAAyB8Y,GAC5C,QAAI,IAAA5X,EACH,OAAOA,EAAakzE,QAGrB,IAAInB,EAASjzE,EAAyB8Y,GAAY,CAGjDs7D,QAAS,CAAC,GAOX,OAHAlwC,EAAoBprB,GAAUm6D,EAAQA,EAAOmB,QAASpB,GAG/CC,EAAOmB,OACf,CCrBApB,EAAoB7f,EAAI,CAACjvB,EAASlkC,KACjC,IAAI,IAAI8Y,KAAO9Y,EACXgzE,EAAoBC,EAAEjzE,EAAY8Y,KAASk6D,EAAoBC,EAAE/uC,EAASprB,IAC5E1jB,OAAOC,eAAe6uC,EAASprB,EAAK,CAAE45B,YAAA,EAAkB38B,IAAK/V,EAAW8Y,IAE1E,ECNDk6D,EAAoBC,EAAI,CAAC/uC,EAAKlkC,IAAU5K,OAAO0M,UAAUmP,eAAelP,KAAKmiC,EAAKlkC,GCClFgzE,EAAoBA,EAAK9uC,IACH,oBAAX/lC,QAA0BA,OAAOk2E,aAC1Cj/E,OAAOC,eAAe6uC,EAAS/lC,OAAOk2E,YAAa,CAAE9+E,MAAO,WAE7DH,OAAOC,eAAe6uC,EAAS,aAAc,CAAE3uC,OAAA,GAAc,E,eCQvD,IAAI2uC,EAEX,GAAI,EAAJ,Y,wBAAuB,iBAAZ3wB,QACV2wB,EAAiC,UAArB3wB,QAAQ+gE,cACd,GAAyB,iBAAdC,UAAwB,CACzC,IAAIv0E,EAAYu0E,UAAUC,UAC1BtwC,EAAYlkC,EAAUV,QAAQ,YAAc,C,CCV7C,MAAMU,EAAiB,iBACjBkB,EAAoB,MACpB+xE,EAAoB,QAE1B,SAASj8D,EAAaktB,EAAU8uC,GAG/B,IAAK9uC,EAAIuwC,QAAUzB,EAClB,MAAM,IAAI77E,MAAA,2DAAAJ,OAAiEmtC,EAAIwwC,UAAA,cAAA39E,OAAsBmtC,EAAIpqB,KAAA,eAAA/iB,OAAkBmtC,EAAIywC,MAAA,kBAAA59E,OAAsBmtC,EAAI6lC,SAAA,OAK1J,GAAI7lC,EAAIuwC,SAAWz0E,EAAe2P,KAAKu0B,EAAIuwC,QAC1C,MAAM,IAAIt9E,MAAM,mDAQjB,GAAI+sC,EAAIpqB,KACP,GAAIoqB,EAAIwwC,WACP,IAAKxzE,EAAkByO,KAAKu0B,EAAIpqB,MAC/B,MAAM,IAAI3iB,MAAM,iJAGjB,GAAI87E,EAAkBtjE,KAAKu0B,EAAIpqB,MAC9B,MAAM,IAAI3iB,MAAM,4HAIpB,CAkCA,MAAM+7E,EAAS,GACTruE,EAAS,IACTkqB,EAAU,+DAkBT,MAAMwkD,EAEZ,YAAAqB,CAAa1wC,GACZ,OAAIA,aAAiBqvC,KAGhBrvC,GAGoC,iBAArBA,EAAOwwC,WACU,iBAApBxwC,EAAO6lC,UACS,iBAAhB7lC,EAAOpqB,MACU,iBAAjBoqB,EAAOywC,OACW,iBAAlBzwC,EAAOuwC,QACW,iBAAlBvwC,EAAO2wC,QACS,mBAAhB3wC,EAAO4wC,MACa,mBAApB5wC,EAAOxpC,QACzB,CA0CA7I,WAAAA,CAAsBqyC,EAAsClkC,EAAoBgzE,EAAel6D,EAAgB5X,GAAsC,IAAnB+xE,EAAA1gF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,IAAmBwiF,EAAAA,GAAAA,GAAA,uBAAAA,EAAAA,GAAAA,GAAA,0BAAAA,EAAAA,GAAAA,GAAA,qBAAAA,EAAAA,GAAAA,GAAA,sBAAAA,EAAAA,GAAAA,GAAA,wBAExH,iBAAjB7wC,GACVxtC,KAAK+9E,OAASvwC,EAAauwC,QAAUvB,EACrCx8E,KAAKg+E,UAAYxwC,EAAawwC,WAAaxB,EAC3Cx8E,KAAKojB,KAAOoqB,EAAapqB,MAAQo5D,EACjCx8E,KAAKi+E,MAAQzwC,EAAaywC,OAASzB,EACnCx8E,KAAKqzE,SAAW7lC,EAAa6lC,UAAYmJ,IAKzCx8E,KAAK+9E,OAvHR,SAAoBvwC,EAAgBlkC,GACnC,OAAKkkC,GAAWlkC,EAGTkkC,EAFC,MAGT,CALA,CAuH4BA,EAAc+uC,GACvCv8E,KAAKg+E,UAAY10E,GAAakzE,EAC9Bx8E,KAAKojB,KAjHR,SAA8BoqB,EAAgBlkC,GAM7C,OAAQkkC,GACP,IAAK,QACL,IAAK,OACL,IAAK,OACClkC,EAEMA,EAAK,KAAO6E,IACtB7E,EAAO6E,EAAS7E,GAFhBA,EAAO6E,EAMV,OAAO7E,CACR,CAlBA,CAiHoCtJ,KAAK+9E,OAAQzB,GAAQE,GACtDx8E,KAAKi+E,MAAQ77D,GAASo6D,EACtBx8E,KAAKqzE,SAAW7oE,GAAYgyE,EAE5Bl8D,EAAatgB,KAAMu8E,GAErB,CA4BA,UAAA4B,GAIC,OAAOG,EAAYt+E,MAAM,EAC1B,CAIAo+E,KAAK5wC,GAEJ,IAAKA,EACJ,OAAOxtC,KAGR,IAAI+9E,OAAEz0E,EAAM00E,UAAE1B,EAASl5D,KAAEhB,EAAI67D,MAAEzzE,EAAK6oE,SAAEkJ,GAAa/uC,EA2BnD,gBA1BIlkC,EACHA,EAAStJ,KAAK+9E,OACO,OAAXz0E,IACVA,EAASkzE,QAAA,IAENF,EACHA,EAAYt8E,KAAKg+E,UACO,OAAd1B,IACVA,EAAYE,QAAA,IAETp6D,EACHA,EAAOpiB,KAAKojB,KACO,OAAThB,IACVA,EAAOo6D,QAAA,IAEJhyE,EACHA,EAAQxK,KAAKi+E,MACO,OAAVzzE,IACVA,EAAQgyE,QAAA,IAELD,EACHA,EAAWv8E,KAAKqzE,SACO,OAAbkJ,IACVA,EAAWC,GAGRlzE,IAAWtJ,KAAK+9E,QAChBzB,IAAct8E,KAAKg+E,WACnB57D,IAASpiB,KAAKojB,MACd5Y,IAAUxK,KAAKi+E,OACf1B,IAAav8E,KAAKqzE,SAEdrzE,KAGD,IAAI88E,EAAIxzE,EAAQgzE,EAAWl6D,EAAM5X,EAAO+xE,EAChD,CAUA,YAAAv3E,CAAawoC,GAAkC,IAAnBlkC,EAAAzN,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAC3B,MAAMygF,EAAQjkD,EAAQv1B,KAAK0qC,GAC3B,OAAK8uC,EAGE,IAAIQ,EACVR,EAAM,IAAME,EACZ+B,EAAcjC,EAAM,IAAME,GAC1B+B,EAAcjC,EAAM,IAAME,GAC1B+B,EAAcjC,EAAM,IAAME,GAC1B+B,EAAcjC,EAAM,IAAME,GAC1BlzE,GARO,IAAIwzE,EAAIN,EAAQA,EAAQA,EAAQA,EAAQA,EAUjD,CAuBA,WAAAgC,CAAYl1E,GAEX,IAAIgzE,EAAYE,EAWhB,GANIhvC,IACHlkC,EAAOA,EAAKnM,QAAQ,MAAOgR,IAKxB7E,EAAK,KAAO6E,GAAU7E,EAAK,KAAO6E,EAAQ,CAC7C,MAAMq/B,EAAMlkC,EAAKV,QAAQuF,EAAQ,IACpB,IAATq/B,GACH8uC,EAAYhzE,EAAKsN,UAAU,GAC3BtN,EAAO6E,IAEPmuE,EAAYhzE,EAAKsN,UAAU,EAAG42B,GAC9BlkC,EAAOA,EAAKsN,UAAU42B,IAAQr/B,E,CAIhC,OAAO,IAAI2uE,EAAI,OAAQR,EAAWhzE,EAAMkzE,EAAQA,EACjD,CAEA,WAAAljE,CAAYk0B,GACX,MAAMlkC,EAAS,IAAIwzE,EAClBtvC,EAAWuwC,OACXvwC,EAAWwwC,UACXxwC,EAAWpqB,KACXoqB,EAAWywC,MACXzwC,EAAW6lC,UAGZ,OADA/yD,EAAahX,GAAA,GACNA,CACR,CAeAtF,QAAAA,GACC,OAAOy6E,EAAaz+E,KADZnE,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAET,CAEA6iF,MAAAA,GACC,OAAO1+E,IACR,CAMA,aAAA2+E,CAAcnxC,GACb,GAAKA,EAEE,IAAIA,aAAgBqvC,EAC1B,OAAOrvC,EACD,CACN,MAAMlkC,EAAS,IAAIwzE,EAAItvC,GAGvB,OAFAlkC,EAAOs1E,WAAwBpxC,EAAMqxC,SACrCv1E,EAAOw1E,QAAqBtxC,EAAMuxC,OAASx+D,EAA4BitB,EAAM2wC,OAAS,KAC/E70E,C,EAPP,OAAYkkC,CASd,EAkBD,MAAMjtB,EAAiBitB,EAAY,OAAI,EAGvC,MAAMsvC,UAAYD,EAAA1hF,WAAAA,GAAA,SAAAU,YAAAwiF,EAAAA,GAAAA,GAAA,kBAEW,OAAAA,EAAAA,GAAAA,GAAA,eACH,MAEzB,UAAAF,GAIC,OAHKn+E,KAAK8+E,UACT9+E,KAAK8+E,QAAUR,EAAYt+E,MAAM,IAE3BA,KAAK8+E,OACb,CAES96E,QAAAA,GACR,OADiBnI,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAQT4iF,EAAaz+E,MAAM,IANrBA,KAAK4+E,aACT5+E,KAAK4+E,WAAaH,EAAaz+E,MAAM,IAE/BA,KAAK4+E,WAKd,CAESF,MAAAA,GACR,MAAMlxC,EAAgB,CACrBwxC,KAAM,GA0BP,OAvBIh/E,KAAK8+E,UACRtxC,EAAI2wC,OAASn+E,KAAK8+E,QAClBtxC,EAAIuxC,KAAOx+D,GAERvgB,KAAK4+E,aACRpxC,EAAIqxC,SAAW7+E,KAAK4+E,YAGjB5+E,KAAKojB,OACRoqB,EAAIpqB,KAAOpjB,KAAKojB,MAEbpjB,KAAK+9E,SACRvwC,EAAIuwC,OAAS/9E,KAAK+9E,QAEf/9E,KAAKg+E,YACRxwC,EAAIwwC,UAAYh+E,KAAKg+E,WAElBh+E,KAAKi+E,QACRzwC,EAAIywC,MAAQj+E,KAAKi+E,OAEdj+E,KAAKqzE,WACR7lC,EAAI6lC,SAAWrzE,KAAKqzE,UAEd7lC,CACR,EAID,MAAMmuB,EAAwC,CAC7C,GAAkB,MAClB,GAAkB,MAClB,GAAyB,MACzB,GAAiB,MACjB,GAA8B,MAC9B,GAA+B,MAC/B,GAAmB,MAEnB,GAA4B,MAC5B,GAAuB,MACvB,GAAsB,MACtB,GAAwB,MACxB,GAAsB,MACtB,GAAuB,MACvB,GAAqB,MACrB,GAAiB,MACjB,GAAkB,MAClB,GAAsB,MACtB,GAAmB,MAEnB,GAAkB,OAGnB,SAASc,EAAuBjvB,EAAsBlkC,EAAiBgzE,GACtE,IAAIl6D,EACA5X,GAAmB,EAEvB,IAAK,IAAI+xE,EAAM,EAAGA,EAAM/uC,EAAa1xC,OAAQygF,IAAO,CACnD,MAAMj8D,EAAOktB,EAAa94B,WAAW6nE,GAGrC,GACEj8D,GAAQ,IAAcA,GAAQ,KAC3BA,GAAQ,IAAcA,GAAQ,IAC9BA,GAAQ,IAAmBA,GAAQ,IAC3B,KAATA,GACS,KAATA,GACS,KAATA,GACS,MAATA,GACChX,GAAmB,KAATgX,GACVg8D,GAAwB,KAATh8D,GACfg8D,GAAwB,KAATh8D,GACfg8D,GAAwB,KAATh8D,GAGM,IAArB9V,IACH4X,GAAO68D,mBAAmBzxC,EAAa52B,UAAUpM,EAAiB+xE,IAClE/xE,GAAmB,YAGhB4X,IACHA,GAAOorB,EAAatS,OAAOqhD,QAGtB,UAEFn6D,IACHA,EAAMorB,EAAavwB,OAAO,EAAGs/D,IAI9B,MAAMjzE,EAAUqyD,EAAYr7C,QAAA,IACxBhX,IAGsB,IAArBkB,IACH4X,GAAO68D,mBAAmBzxC,EAAa52B,UAAUpM,EAAiB+xE,IAClE/xE,GAAmB,GAIpB4X,GAAO9Y,IAEwB,IAArBkB,IAEVA,EAAkB+xE,E,EASrB,OAJyB,IAArB/xE,IACH4X,GAAO68D,mBAAmBzxC,EAAa52B,UAAUpM,UAAA,IAG3C4X,EAAoBA,EAAMorB,CAClC,CAEA,SAASoxB,EAA0BpxB,GAClC,IAAIlkC,EACJ,IAAK,IAAIgzE,EAAM,EAAGA,EAAM9uC,EAAK1xC,OAAQwgF,IAAO,CAC3C,MAAMl6D,EAAOorB,EAAK94B,WAAW4nE,GAChB,KAATl6D,GAAmC,KAATA,QAAA,IACzB9Y,IACHA,EAAMkkC,EAAKvwB,OAAO,EAAGq/D,IAEtBhzE,GAAOqyD,EAAYv5C,SAAA,IAEf9Y,IACHA,GAAOkkC,EAAK8uC,G,CAIf,YAAO,IAAAhzE,EAAoBA,EAAMkkC,CAClC,CAKO,SAAS8wC,EAAYh1E,EAAUgzE,GAErC,IAAIl6D,EAsBJ,OAnBCA,EAFG9Y,EAAI00E,WAAa10E,EAAI8Z,KAAKtnB,OAAS,GAAoB,SAAfwN,EAAIy0E,OAAA,KAAA19E,OAElCiJ,EAAI00E,WAAA39E,OAAYiJ,EAAI8Z,MAEN,KAA3B9Z,EAAI8Z,KAAK1O,WAAW,KAChBpL,EAAI8Z,KAAK1O,WAAW,IAAM,IAAcpL,EAAI8Z,KAAK1O,WAAW,IAAM,IAAcpL,EAAI8Z,KAAK1O,WAAW,IAAM,IAAcpL,EAAI8Z,KAAK1O,WAAW,IAAM,MACxH,KAA3BpL,EAAI8Z,KAAK1O,WAAW,GAElB4nE,EAIIhzE,EAAI8Z,KAAKnG,OAAO,GAFhB3T,EAAI8Z,KAAK,GAAG9D,cAAgBhW,EAAI8Z,KAAKnG,OAAO,GAM7C3T,EAAI8Z,KAEToqB,IACHprB,EAAQA,EAAMjlB,QAAQ,MAAO,OAEvBilB,CACR,CAKA,SAASq8D,EAAajxC,EAAUlkC,GAE/B,MAAMgzE,EAAWhzE,EAEds1D,EADAnC,EAGH,IAAIr6C,EAAM,IACN27D,OAAEvzE,EAAMwzE,UAAEzB,EAASn5D,KAAE9C,EAAI29D,MAAEzB,EAAKnJ,SAAEh7C,GAAamV,EASnD,GARIhjC,IACH4X,GAAO5X,EACP4X,GAAO,MAEJm6D,GAAwB,SAAX/xE,KAChB4X,GAAOjU,EACPiU,GAAOjU,GAEJouE,EAAW,CACd,IAAI/uC,EAAM+uC,EAAU3zE,QAAQ,KAC5B,IAAa,IAAT4kC,EAAY,CAEf,MAAMlkC,EAAWizE,EAAUt/D,OAAO,EAAGuwB,GACrC+uC,EAAYA,EAAUt/D,OAAOuwB,EAAM,GACnCA,EAAMlkC,EAASsY,YAAY,MACd,IAAT4rB,EACHprB,GAAOk6D,EAAQhzE,GAAA,GAAU,IAGzB8Y,GAAOk6D,EAAQhzE,EAAS2T,OAAO,EAAGuwB,IAAA,GAAM,GACxCprB,GAAO,IACPA,GAAOk6D,EAAQhzE,EAAS2T,OAAOuwB,EAAM,IAAI,OAE1CprB,GAAO,G,CAERm6D,EAAYA,EAAUj9D,cACtBkuB,EAAM+uC,EAAU36D,YAAY,MACf,IAAT4rB,EACHprB,GAAOk6D,EAAQC,GAAA,GAAW,IAG1Bn6D,GAAOk6D,EAAQC,EAAUt/D,OAAO,EAAGuwB,IAAA,GAAM,GACzCprB,GAAOm6D,EAAUt/D,OAAOuwB,G,CAG1B,GAAIltB,EAAM,CAET,GAAIA,EAAKxkB,QAAU,GAA4B,KAAvBwkB,EAAK5L,WAAW,IAAgD,KAAvB4L,EAAK5L,WAAW,GAAuB,CACvG,MAAM84B,EAAOltB,EAAK5L,WAAW,GACzB84B,GAAQ,IAAcA,GAAQ,KACjCltB,EAAA,IAAAjgB,OAAW6b,OAAOC,aAAaqxB,EAAO,SAAAntC,OAAOigB,EAAKrD,OAAO,I,MAEpD,GAAIqD,EAAKxkB,QAAU,GAA4B,KAAvBwkB,EAAK5L,WAAW,GAAuB,CACrE,MAAM84B,EAAOltB,EAAK5L,WAAW,GACzB84B,GAAQ,IAAcA,GAAQ,KACjCltB,EAAA,GAAAjgB,OAAU6b,OAAOC,aAAaqxB,EAAO,SAAAntC,OAAOigB,EAAKrD,OAAO,I,CAI1DmF,GAAOk6D,EAAQh8D,GAAA,GAAM,E,CAUtB,OARIk8D,IACHp6D,GAAO,IACPA,GAAOk6D,EAAQE,GAAA,GAAO,IAEnBnkD,IACHjW,GAAO,IACPA,GAAQ9Y,EAAgE+uB,EAAjDokC,EAAuBpkC,GAAA,GAAU,IAElDjW,CACR,CAIA,SAASmC,EAA2BipB,GACnC,IACC,OAAO0xC,mBAAmB1xC,E,CACzB,MAAA2xC,GACD,OAAI3xC,EAAI1xC,OAAS,EACT0xC,EAAIvwB,OAAO,EAAG,GAAKsH,EAA2BipB,EAAIvwB,OAAO,IAEzDuwB,C,CAGV,CAEA,MAAMp/B,EAAiB,8BAEvB,SAASmwE,EAAc/wC,GACtB,OAAKA,EAAI3qC,MAAMuL,GAGRo/B,EAAIrwC,QAAQiR,GAAiBo/B,GAAUjpB,EAA2BipB,KAFjEA,CAGT,C,aCjqBA,MAAM4xC,EAAYC,EAAA5B,OAAkB4B,EAC9BjtD,EAAQ,IAEP,IAAUktD,GAAjB,SAAiB9xC,GAeGA,EAAA+xC,SAAhB,SAAyB/xC,GAAa,QAAAhiC,EAAA3P,UAAAC,OAAAwN,EAAA,IAAAzC,MAAA2E,EAAA,EAAAA,EAAA,KAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAApC,EAAAoC,EAAA,GAAA7P,UAAA6P,GAClC,OAAO8hC,EAAI4wC,KAAK,CAAEh7D,KAAMg8D,EAAUz5E,KAAK6nC,EAAIpqB,QAAS9Z,IACxD,EAgBgBkkC,EAAAgyC,YAAhB,SAA4BhyC,GACxB,IAAI8uC,EAAO9uC,EAAIpqB,KACXhB,GAAA,EACAk6D,EAAK,KAAOlqD,IACZkqD,EAAOlqD,EAAQkqD,EACfl6D,GAAA,GAEJ,QAAA4oC,EAAAnvD,UAAAC,OAPqCwN,EAAA,IAAAzC,MAAAmkD,EAAA,EAAAA,EAAA,KAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAA3hD,EAAA2hD,EAAA,GAAApvD,UAAAovD,GAOrC,IAAIzgD,EAAe40E,EAAUjE,QAAQmB,KAAShzE,GAI9C,OAHI8Y,GAAc5X,EAAa,KAAO4nB,IAAUob,EAAIwwC,YAChDxzE,EAAeA,EAAaoM,UAAU,IAEnC42B,EAAI4wC,KAAK,CAAEh7D,KAAM5Y,GAC5B,EAUgBgjC,EAAAwvC,QAAhB,SAAwBxvC,GACpB,GAAwB,IAApBA,EAAIpqB,KAAKtnB,QAAgB0xC,EAAIpqB,OAASgP,EACtC,OAAOob,EAEX,IAAIlkC,EAAO81E,EAAUpC,QAAQxvC,EAAIpqB,MAIjC,OAHoB,IAAhB9Z,EAAKxN,QAAuC,KAAvBwN,EAAKoL,WAAW,KACrCpL,EAAO,IAEJkkC,EAAI4wC,KAAK,CAAEh7D,KAAA9Z,GACtB,EAUgBkkC,EAAAyvC,SAAhB,SAAyBzvC,GACrB,OAAO4xC,EAAUnC,SAASzvC,EAAIpqB,KAClC,EAUgBoqB,EAAA0vC,QAAhB,SAAwB1vC,GACpB,OAAO4xC,EAAUlC,QAAQ1vC,EAAIpqB,KACjC,CACH,CAzFD,CAAiBk8D,IAAAA,EAAK,I,wCCJhB,IAAWG,GC2CLC,ID3CZ,SAAiBD,GAEAA,EAAAxC,SAAW0C,GAAM1C,SACjBwC,EAAAzC,QAAU2C,GAAM3C,QAChByC,EAAAvC,QAAUyC,GAAMzC,QAChBuC,EAAAF,SAAWI,GAAMJ,SACjBE,EAAAD,YAAcG,GAAMH,YAEjBC,EAAAG,OAAhB,SAAuBzxE,EAAkBC,GACrC,OAAQ,OAADD,QAAC,IAADA,OAAC,EAADA,EAAGnK,eAAgB,OAADoK,QAAC,IAADA,OAAC,EAADA,EAAGpK,WAChC,EAEgBy7E,EAAA7C,SAAhB,SAAyBtjE,EAAoB9L,GACzC,MAAMqyE,EAA2B,kBAATvmE,EAAoBA,EAAOA,EAAK8J,KAClD08D,EAAuB,kBAAPtyE,EAAkBA,EAAKA,EAAG4V,KAC1C28D,EAAYF,EAASG,MAAM,KAAK52E,QAAOE,GAAKA,EAAExN,OAAS,IACvDmkF,EAAUH,EAAOE,MAAM,KAAK52E,QAAOE,GAAKA,EAAExN,OAAS,IACzD,IAAI0O,EAAI,EACR,KAAOA,EAAIu1E,EAAUjkF,QACbikF,EAAUv1E,KAAOy1E,EAAQz1E,GADJA,KAO7B,MAFiB,MAAM01E,OAAOH,EAAUjkF,OAAS0O,GAClCy1E,EAAQjT,MAAMxiE,GAAG7E,KAAK,IAEzC,CAEH,CA5BD,CAAiB85E,KAAAA,GAAQ,KC2CzB,SAAYC,GAKRA,EAAAA,EAAA,qBAMAA,EAAAA,EAAA,mBAKAA,EAAAA,EAAA,mCAQAA,EAAAA,EAAA,mCAKAA,EAAAA,EAAA,mBAMAA,EAAAA,EAAA,yCAKAA,EAAAA,EAAA,wBACH,CAzCD,CAAYA,KAAAA,GAAa,KA8GnB,MAAOS,GAMThlF,WAAAA,CAAYy2E,GACR5xE,KAAKogF,gBAAkBxO,EAASp1E,gBAChCwD,KAAKqgF,cAAgBzO,EAAS0O,UAAUC,cACxCvgF,KAAKwgF,mBAAqB5O,EAAS0O,UAAUG,kBACjD,CAEA,aAAMC,CAAqCnc,GAAoD,IAA1Coc,EAAiB9kF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KACvF,MAAMj0E,QAAgB/G,KAAKwgF,mBAAmBI,SAASrc,GACvD,OAAOvkE,KAAK6gF,YAAetc,EAAKx9D,EAAS45E,EAC7C,CAIAG,gBAAAA,CAA8C7Z,EAA4B1C,EAAWoc,GAEjF,OADApc,EAAS,OAAHA,QAAG,IAAHA,EAAAA,EAAOvF,GAAIh6D,MAAMiiE,EAAa1C,KAChCoc,EACO3gF,KAAK6gF,YAAetc,EAAK0C,EAAc0Z,GAEvC3gF,KAAKqoD,OAAUkc,EAAK0C,EAEnC,CAIA8Z,UAAAA,CAAwC77E,EAAcq/D,EAAUoc,GAC5D,OAAIA,EACO3gF,KAAK6gF,YAAetc,EAAKr/D,EAAMy7E,GAE/B3gF,KAAKqoD,OAAUkc,EAAKr/D,EAEnC,CAEA87E,SAAAA,CAAuCC,EAAU1c,GAC7C,OAAOvkE,KAAKqoD,OAAUkc,EAAK,CAAE2c,OAAQD,GACzC,CAEU54B,MAAAA,CAAoCkc,EAAUx9D,GACpD,GAAuB,kBAAZA,EAAsB,CAC7B,MAAMo6E,EAAcnhF,KAAKgF,MAASu/D,EAAKx9D,GACvC,OAAO/G,KAAKohF,sBAAyBD,EAAa5c,OAAKxoE,EAAWgL,E,CAE/D,GAAI,WAAYA,EAAS,CAC5B,MAAMo6E,EAAc,CAAEtiF,MAAOkI,EAAQm6E,OAAQ57E,aAAc,GAAID,YAAa,IAC5E,OAAOrF,KAAKohF,sBAAyBD,EAAa5c,E,CAE/C,CACH,MAAM4c,EAAcnhF,KAAKgF,MAASu/D,EAAKx9D,EAAQumE,WAC/C,OAAOttE,KAAKohF,sBAAsBD,EAAa5c,EAAKx9D,E,CAE5D,CAEU,iBAAM85E,CAAyCtc,EAAUx9D,EAAgCs6E,GAC/F,GAAuB,kBAAZt6E,EAAsB,CAC7B,MAAMo6E,QAAoBnhF,KAAKshF,WAAc/c,EAAKx9D,EAASs6E,GAC3D,OAAOrhF,KAAKohF,sBAAyBD,EAAa5c,OAAKxoE,EAAWgL,E,CAC/D,CACH,MAAMo6E,QAAoBnhF,KAAKshF,WAAc/c,EAAKx9D,EAAQumE,UAAW+T,GACrE,OAAOrhF,KAAKohF,sBAAsBD,EAAa5c,EAAKx9D,E,CAE5D,CAaUq6E,qBAAAA,CAAmDD,EAA6B5c,EAAU0C,EAA6B/hE,GAC7H,IAAIwoE,EACJ,GAAIzG,EACAyG,EAAW,CACPyT,cACA5c,MACAh9D,MAAOm4E,GAAc6B,OACrBtO,WAAY,GACZhM,oBAED,CACH,MAAMua,EAAqBxhF,KAAKyhF,yBAAyBld,EAAKr/D,GAC9DwoE,EAAW,CACPyT,cACA5c,MACAh9D,MAAOm4E,GAAc6B,OACrBtO,WAAY,GACZ,gBAAIhM,GACA,OAAOua,GACX,E,CAIR,OADCL,EAAYtiF,MAA2B4U,UAAYi6D,EAC7CA,CACX,CAEA,YAAMS,CAAoCT,EAAuCiT,G,QAE7E,MAAMe,EAA6C,QAAnCvtE,EAAAu5D,EAASyT,YAAYtiF,MAAMuV,gBAAQ,IAAAD,OAAA,EAAAA,EAAEnI,KAAK9E,SACpD+/D,EAAiC,QAAlBrlB,EAAA5hD,KAAKqgF,qBAAa,IAAAz+B,OAAA,EAAAA,EAAEviC,IAAIquD,EAASnJ,IAAIvgE,YACpDkB,EAAO+hE,EAAeA,EAAaqG,gBAAkBttE,KAAKwgF,mBAAmBI,SAASlT,EAASnJ,KAErG,GAAI0C,EACAvoE,OAAOC,eACH+uE,EACA,eACA,CACI7uE,MAAOooE,QAGZ,CACH,MAAMua,EAAqBxhF,KAAKyhF,yBAAyB/T,EAASnJ,IAAKr/D,GACvExG,OAAOC,eACH+uE,EACA,eACA,CACIruD,IAAKmiE,G,CAYjB,OALIE,IAAYx8E,IACZwoE,EAASyT,kBAAoBnhF,KAAKshF,WAAW5T,EAASnJ,IAAKr/D,EAAMy7E,GAChEjT,EAASyT,YAAYtiF,MAA2B4U,UAAYi6D,GAEjEA,EAASnmE,MAAQm4E,GAAc6B,OACxB7T,CACX,CAEU1oE,KAAAA,CAAyBu/D,EAAUr/D,GAEzC,OADiBlF,KAAKogF,gBAAgBuB,YAAYpd,GAClChpE,OAAOgJ,cAAcS,MAASE,EAClD,CAEUo8E,UAAAA,CAA8B/c,EAAUr/D,EAAcy7E,GAE5D,OADiB3gF,KAAKogF,gBAAgBuB,YAAYpd,GAClChpE,OAAOqmF,YAAY58E,MAASE,EAAMy7E,EACtD,CAEUc,wBAAAA,CAAyBld,EAAUr/D,GACzC,MAAMk7E,EAAkBpgF,KAAKogF,gBAC7B,IAAIyB,EACJ,MAAO,IACW,OAAPA,QAAO,IAAPA,EAAAA,EAAAA,EAAYhV,GAAaxkB,OAC5Bkc,EAAIvgE,WAAYo8E,EAAgBuB,YAAYpd,GAAKpiE,iBAAiBT,WAAY,EAAO,OAAJwD,QAAI,IAAJA,EAAAA,EAAQ,GAGrG,EAuEE,MAAO48E,GAMT3mF,WAAAA,CAAYy2E,GAFO,KAAAmQ,YAA4C,IAAI15E,IAG/DrI,KAAKgiF,uBAAyBpQ,EAAS0O,UAAU2B,sBACrD,CAEA,OAAIC,GACA,OAAO93E,EAAOpK,KAAK+hF,YAAYj7D,SACnC,CAEAq7D,WAAAA,CAAYzU,GACR,MAAM0U,EAAY1U,EAASnJ,IAAIvgE,WAC/B,GAAIhE,KAAK+hF,YAAYl+E,IAAIu+E,GACrB,MAAM,IAAI3hF,MAAM,4BAADJ,OAA6B+hF,EAAS,0BAEzDpiF,KAAK+hF,YAAYj3E,IAAIs3E,EAAW1U,EACpC,CAEAp6D,WAAAA,CAAYixD,GACR,MAAM6d,EAAY7d,EAAIvgE,WACtB,OAAOhE,KAAK+hF,YAAY1iE,IAAI+iE,EAChC,CAEA,yBAAMC,CAAoB9d,EAAUoc,GAChC,IAAIjT,EAAW1tE,KAAKsT,YAAYixD,GAChC,OAAImJ,IAGJA,QAAiB1tE,KAAKgiF,uBAAuBtB,QAAQnc,EAAKoc,GAC1D3gF,KAAKmiF,YAAYzU,GACVA,EACX,CAIA4U,cAAAA,CAAe/d,EAAUr/D,EAAcy7E,GACnC,GAAIA,EACA,OAAO3gF,KAAKgiF,uBAAuBjB,WAAW77E,EAAMq/D,EAAKoc,GAAmB4B,MAAK7U,IAC7E1tE,KAAKmiF,YAAYzU,GACVA,KAER,CACH,MAAMA,EAAW1tE,KAAKgiF,uBAAuBjB,WAAW77E,EAAMq/D,GAE9D,OADAvkE,KAAKmiF,YAAYzU,GACVA,C,CAEf,CAEA8U,WAAAA,CAAYje,GACR,OAAOvkE,KAAK+hF,YAAYl+E,IAAI0gE,EAAIvgE,WACpC,CAEAy+E,kBAAAA,CAAmBle,GACf,MAAM6d,EAAY7d,EAAIvgE,WAChB0+E,EAAa1iF,KAAK+hF,YAAY1iE,IAAI+iE,GAOxC,OANIM,IACAA,EAAWn7E,MAAQm4E,GAAciD,QACjCD,EAAWE,uBAAoB7mF,EAC/B2mF,EAAWzP,WAAa,GACxByP,EAAWrX,iBAActvE,GAEtB2mF,CACX,CAEAG,cAAAA,CAAete,GACX,MAAM6d,EAAY7d,EAAIvgE,WAChB0+E,EAAa1iF,KAAK+hF,YAAY1iE,IAAI+iE,GAKxC,OAJIM,IACAA,EAAWn7E,MAAQm4E,GAAciD,QACjC3iF,KAAK+hF,YAAY/J,OAAOoK,IAErBM,CACX,ECzYE,MAAOI,GAMT3nF,WAAAA,CAAYy2E,GACR5xE,KAAKhB,WAAa4yE,EAAS31E,OAAOgG,cAClCjC,KAAK+iF,iBAAmB,IAAMnR,EAAS31E,OAAOqkF,UAAU0C,iBACxDhjF,KAAKijF,cAAgBrR,EAASqB,WAAWiQ,cACzCljF,KAAKmjF,eAAiBvR,EAAS0O,UAAU8C,cAC7C,CAEA,UAAMC,CAAK3V,GAA+D,IAApC2T,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KAClE,IAAK,MAAM50E,KAAQ4N,GAAU05D,EAASyT,YAAYtiF,aACxCi8E,GAAkBuG,GACxBhtE,GAAiBjO,GAAMzC,SAAQua,GAAOle,KAAKsjF,OAAOplE,EAAKwvD,IAE/D,CAEU4V,MAAAA,CAAOnjF,EAAwButE,GACrC,MAAMxvD,EAAM/d,EAAQ8F,UAEpB,QAAiBlK,IAAbmiB,EAAIwC,KACJ,IACI,MAAM+8B,EAAcz9C,KAAKujF,aAAapjF,GACtC,GAAI6F,EAAey3C,GACfv/B,EAAIwC,KAAO+8B,OAGX,GADAv/B,EAAIslE,iBAAmB/lC,EACnBz9C,KAAK+iF,mBAAmBP,YAAY/kC,EAAYgmC,aAAc,CAE9D,MAAMC,EAAa1jF,KAAK2jF,YAAYlmC,GACpCv/B,EAAIwC,KAAiB,OAAVgjE,QAAU,IAAVA,EAAAA,EAAc1jF,KAAK4jF,mBAAmBzjF,EAASs9C,E,EAGpE,MAAOh4C,GACLyY,EAAIwC,KAAIhiB,OAAA2lB,OAAA3lB,OAAA2lB,OAAA,GACDlkB,GAAO,CACVuF,QAAS,mDAAFrF,OAAqD6d,EAAInY,SAAQ,OAAA1F,OAAMoF,I,CAK1FioE,EAASuF,WAAWtsE,KAAKuX,EAC7B,CAEA2lE,MAAAA,CAAOnW,GACH,IAAK,MAAMxvD,KAAOwvD,EAASuF,kBACf/0D,EAAyBwC,YACzBxC,EAAyBslE,iBAErC9V,EAASuF,WAAa,EAC1B,CAEAsQ,YAAAA,CAAapjF,GACT,MACMs9C,EADQz9C,KAAKijF,cAAca,SAAS3jF,GAChB4jF,WAAW5jF,EAAQ8F,UAAUF,UACvD,OAAkB,OAAX03C,QAAW,IAAXA,EAAAA,EAAez9C,KAAK4jF,mBAAmBzjF,EAClD,CAEA20E,cAAAA,CAAe1uE,EAAe5F,EAAkBwjF,EAA8BC,GAG1E,MAAMjR,EAAShzE,KACTiG,EAA8B,CAChCi+E,SAAUF,EACVj+E,SAAUk+E,EAEV,OAAI/lE,G,MtG9CqBrY,EsG+CrB,GAAID,EAAU5F,KAAK0gB,MAEf,OAAO1gB,KAAK0gB,KACT,GtGjDG,kBADW7a,EsGkDW7F,KAAKwjF,mBtGjDP,OAAR39E,GACiB,kBAApCA,EAA2B3I,MACS,kBAApC2I,EAA2BlF,MACS,kBAApCkF,EAA2Bud,KsG8C0B,CAEpD,MAAMsgE,EAAa1Q,EAAO2Q,YAAY3jF,KAAKwjF,kBAC3CxjF,KAAK0gB,KAAiB,OAAVgjE,QAAU,IAAVA,EAAAA,EACR1Q,EAAO4Q,mBAAmB,CAAE39E,YAAW3F,UAAW8F,EAAM5F,YAAYR,KAAKwjF,iB,MAC1E,QAAkBznF,IAAdiE,KAAK0gB,KAAoB,CAEhC,MAAMyjE,EAAUnR,EAAOoR,cAAc,CAAEn+E,YAAW3F,UAAW8F,EAAM5F,aACnE,GAAI2jF,EAAQ73D,OAAShZ,GAAYlN,GAAMmB,MAAQm4E,GAAc2E,eAEzD,OAEJrkF,KAAK0gB,KAAmB,QAAZvM,EAAAgwE,EAAQ/9E,YAAI,IAAA+N,EAAAA,EAAIgwE,EAAQ73D,MACpCtsB,KAAKwjF,iBAAmBW,EAAQG,K,CAEpC,OAAO1+E,EAAU5F,KAAK0gB,MAAQ1gB,KAAK0gB,UAAO3kB,CAC9C,EACA,oBAAIwoF,GACA,OAAOvkF,KAAKwjF,gBAChB,EACA,SAAIl3D,GACA,OAAOtmB,EAAehG,KAAK0gB,MAAQ1gB,KAAK0gB,UAAO3kB,CACnD,GAEJ,OAAOkK,CACX,CAEUm+E,aAAAA,CAAcjkF,GACpB,IACI,MAAMs9C,EAAcz9C,KAAKujF,aAAapjF,GACtC,GAAI6F,EAAey3C,GACf,MAAO,CAAEnxB,MAAOmxB,GAEpB,MAAMimC,EAAa1jF,KAAK2jF,YAAYlmC,GACpC,OAAIimC,EACO,CAAEt9E,KAAMs9E,EAAYY,MAAO7mC,GAG3B,CACH6mC,MAAO7mC,EACPnxB,MACItsB,KAAK4jF,mBAAmBzjF,EAASs9C,G,CAG/C,MAAOh4C,GACL,MAAO,CACH6mB,MAAK5tB,OAAA2lB,OAAA3lB,OAAA2lB,OAAA,GACElkB,GAAO,CACVuF,QAAS,mDAAFrF,OAAqDF,EAAQ8F,UAAUF,SAAQ,OAAA1F,OAAMoF,K,CAI5G,CAEUk+E,WAAAA,CAAYa,GAClB,GAAIA,EAAgBp+E,KAChB,OAAOo+E,EAAgBp+E,KAE3B,MAAMq+E,EAAMzkF,KAAK+iF,mBAAmBzvE,YAAYkxE,EAAgBf,aAChE,OAAKgB,EAGEzkF,KAAKmjF,eAAeuB,WAAWD,EAAItD,YAAYtiF,MAAO2lF,EAAgBphE,WAH7E,CAIJ,CAEUwgE,kBAAAA,CAAmBzjF,EAAwBwkF,GAGjD,MAAMjX,EAAWp6D,GAAYnT,EAAQG,WACjCotE,EAASnmE,MAAQm4E,GAAc2E,gBAC/Bh4D,QAAQG,KAAK,gFAADnsB,OAAiFqtE,EAASnJ,IAAG,OAE7G,MAAMqgB,EAAgB5kF,KAAKhB,WAAWkB,iBAAiBC,GACvD,OAAAzB,OAAA2lB,OAAA3lB,OAAA2lB,OAAA,GACOlkB,GAAO,CACVuF,QAAS,kCAAFrF,OAAoCukF,EAAa,YAAAvkF,OAAWF,EAAQ8F,UAAUF,SAAQ,MAC7F4+E,qBAER,EChME,MAAOE,GACTC,OAAAA,CAAQ1+E,GACJ,GAtBF,SAAkBA,GACpB,MAA8C,kBAA/BA,EAAsBlJ,IACzC,CAoBY6nF,CAAQ3+E,GACR,OAAOA,EAAKlJ,IAGpB,CAEA8nF,WAAAA,CAAY5+E,GACR,OAAO+X,GAAoB/X,EAAKgO,SAAU,OAC9C,ECsBE,MAAO6wE,GAKT9pF,WAAAA,CAAYy2E,GACR5xE,KAAKklF,aAAetT,EAASqB,WAAWkS,aACxCnlF,KAAK+I,MAAQ6oE,EAAS31E,OAAOqkF,UAAU8E,aACvCplF,KAAKqlF,YAAczT,EAAS0O,UAAU8C,cAC1C,CAEAkC,eAAAA,CAAgBC,GACZ,GAAIA,EAAe,CACf,MAAMxR,E7F4IZ,SAAyBrxE,G,MAC3B,MAAMuR,EAAUvR,EAAQuR,QAGxB,KAAOA,KAA6B,QAAjBE,EAAAzR,EAAQpC,iBAAS,IAAA6T,OAAA,EAAAA,EAAEF,UAAS,CAC3C,MAAM8/D,EAAa3gE,GAAmB1Q,EAAQ6b,cAAeb,IAC7D,GAAIq2D,EACA,OAAOA,EAEXrxE,EAAUA,EAAQpC,S,CAG1B,C6FxJ+BklF,CAAeD,GAC5BE,EAAWF,EAActxE,QAC/B,GAAI8/D,GAAc0R,EAAU,CACxB,MAAMx/E,EAAaw/E,EAA4B1R,EAAWv1D,SAE1D,GAAI1Y,EAAYG,GACZ,OAAOA,EAAUiY,IACd,GAAIrX,MAAMC,QAAQb,GACrB,IAAK,MAAMiY,KAAOjY,EACd,GAAIH,EAAYoY,IAAQA,EAAIgmE,UACrBhmE,EAAIgmE,SAAS72E,QAAUk4E,EAAcl4E,QACrC6Q,EAAIgmE,SAASj3E,KAAOs4E,EAAct4E,IACrC,OAAOiR,EAAIA,G,CAK3B,GAAIunE,EAAU,CACV,MAAMC,EAAW1lF,KAAKklF,aAAaF,YAAYS,GAE/C,GAAIC,IAAaA,IAAaH,GtG5DxC,SAAsBt2E,EAAgBH,GACxC,KAAOG,EAAM3O,WAET,IADA2O,EAAQA,EAAM3O,aACAwO,EACV,OAAO,EAGf,OAAO,CACX,CsGoD+D62E,CAAYJ,EAAeG,IACtE,OAAOD,C,EAKvB,CAEAG,mBAAAA,CAAoBL,GAChB,MAAMtxE,EAAUjU,KAAKslF,gBAAgBC,GACrC,GAAW,OAAPtxE,QAAO,IAAPA,OAAO,EAAPA,EAASG,SAAU,CACnB,MAAMyxE,EAAa7lF,KAAKklF,aAAaF,YAAY/wE,GACjD,OAAiB,OAAV4xE,QAAU,IAAVA,EAAAA,EAAc5xE,EAAQG,Q,CAGrC,CAEA0xE,cAAAA,CAAeD,EAAqBpiF,GAChC,MAAMsiF,EAA+B,GACrC,GAAItiF,EAAQuiF,mBAAoB,CAC5B,MAAM9nE,EAAMle,KAAKimF,mBAAmBJ,GAChC3nE,GACA6nE,EAAKp/E,KAAKuX,E,CAGlB,IAAIgoE,EAAkBlmF,KAAK+I,MAAMo9E,kBAAkBN,EAAY7lF,KAAKqlF,YAAYe,eAAeP,IAK/F,OAJIpiF,EAAQggF,cACRyC,EAAkBA,EAAgB98E,QAAO8U,GAAOuhE,GAASG,OAAO1hE,EAAImoE,UAAW5iF,EAAQggF,gBAE3FsC,EAAKp/E,QAAQu/E,GACN97E,EAAO27E,EAClB,CAEUE,kBAAAA,CAAmBJ,GACzB,MAAMH,EAAW1lF,KAAKklF,aAAaF,YAAYa,GAC/C,GAAIH,EAAU,CACV,MAAMjB,EAAMnxE,GAAYuyE,GAClBziE,EAAOpjB,KAAKqlF,YAAYe,eAAeP,GAC7C,MAAO,CACHQ,UAAW5B,EAAIlgB,IACf+hB,WAAYljE,EACZqhD,UAAWggB,EAAIlgB,IACfhuB,WAAYnzB,EACZmjE,QAASn5E,EAAkBs4E,GAC3Bc,OAAO,E,CAInB,ECtIE,MAAOC,GAMTtrF,WAAAA,CAAY4lB,GACR,GALI,KAAAvb,IAAM,IAAI6C,IAKV0Y,EACA,IAAK,MAAO9V,EAAKpM,KAAUkiB,EACvB/gB,KAAK+K,IAAIE,EAAKpM,EAG1B,CAKA,QAAI8L,GACA,OAAO4B,EAAU2B,IAAI9D,EAAOpK,KAAKwF,IAAIshB,UAAUthB,KAAI2I,GAAKA,EAAErS,SAC9D,CAKA83E,KAAAA,GACI5zE,KAAKwF,IAAIouE,OACb,CAUAoE,OAAO/sE,EAAQpM,GACX,QAAc9C,IAAV8C,EACA,OAAOmB,KAAKwF,IAAIwyE,OAAO/sE,GACpB,CACH,MAAM6b,EAAS9mB,KAAKwF,IAAI6Z,IAAIpU,GAC5B,GAAI6b,EAAQ,CACR,MAAM/d,EAAQ+d,EAAOle,QAAQ/J,GAC7B,GAAIkK,GAAS,EAMT,OALsB,IAAlB+d,EAAOhrB,OACPkE,KAAKwF,IAAIwyE,OAAO/sE,GAEhB6b,EAAOozC,OAAOnxD,EAAO,IAElB,C,CAGf,OAAO,C,CAEf,CASAsW,GAAAA,CAAIpU,G,MACA,OAAwB,QAAjBkJ,EAAAnU,KAAKwF,IAAI6Z,IAAIpU,UAAI,IAAAkJ,EAAAA,EAAI,EAChC,CAOAtQ,GAAAA,CAAIoH,EAAQpM,GACR,QAAc9C,IAAV8C,EACA,OAAOmB,KAAKwF,IAAI3B,IAAIoH,GACjB,CACH,MAAM6b,EAAS9mB,KAAKwF,IAAI6Z,IAAIpU,GAC5B,QAAI6b,GACOA,EAAOle,QAAQ/J,IAAU,C,CAI5C,CAKAkM,GAAAA,CAAIE,EAAQpM,GAMR,OALImB,KAAKwF,IAAI3B,IAAIoH,GACbjL,KAAKwF,IAAI6Z,IAAIpU,GAAMtE,KAAK9H,GAExBmB,KAAKwF,IAAIsF,IAAIG,EAAK,CAACpM,IAEhBmB,IACX,CAKA0mF,MAAAA,CAAOz7E,EAAQ6b,GAMX,OALI9mB,KAAKwF,IAAI3B,IAAIoH,GACbjL,KAAKwF,IAAI6Z,IAAIpU,GAAMtE,QAAQmgB,GAE3B9mB,KAAKwF,IAAIsF,IAAIG,EAAKpE,MAAMyS,KAAKwN,IAE1B9mB,IACX,CAKA2D,OAAAA,CAAQwF,GACJnJ,KAAKwF,IAAI7B,SAAQ,CAACmI,EAAOb,IACrBa,EAAMnI,SAAQ9E,GAASsK,EAAWtK,EAAOoM,EAAKjL,SAEtD,CAKA,CAACyH,OAAOH,YACJ,OAAOtH,KAAK+S,UAAUzL,UAC1B,CAKAyL,OAAAA,GACI,OAAO3I,EAAOpK,KAAKwF,IAAIuN,WAClBhJ,SAAQ2W,IAAA,IAAEzV,EAAKa,GAAM4U,EAAA,OAAK5U,EAAMtG,KAAI3G,GAAS,CAACoM,EAAKpM,IAAiB,GAC7E,CAKA8U,IAAAA,GACI,OAAOvJ,EAAOpK,KAAKwF,IAAImO,OAC3B,CAKAmT,MAAAA,GACI,OAAO1c,EAAOpK,KAAKwF,IAAIshB,UAAU5c,MACrC,CAKAy8E,mBAAAA,GACI,OAAOv8E,EAAOpK,KAAKwF,IAAIuN,UAC3B,EAIE,MAAO6zE,GAKT,QAAIj8E,GACA,OAAO3K,KAAKwF,IAAImF,IACpB,CAIAxP,WAAAA,CAAY4lB,GACR,GAVI,KAAAvb,IAAM,IAAI6C,IACV,KAAAw+E,QAAU,IAAIx+E,IASd0Y,EACA,IAAK,MAAO9V,EAAKpM,KAAUkiB,EACvB/gB,KAAK8K,IAAIG,EAAKpM,EAG1B,CAEA+0E,KAAAA,GACI5zE,KAAKwF,IAAIouE,QACT5zE,KAAK6mF,QAAQjT,OACjB,CAEA9oE,GAAAA,CAAIG,EAAQpM,GAGR,OAFAmB,KAAKwF,IAAIsF,IAAIG,EAAKpM,GAClBmB,KAAK6mF,QAAQ/7E,IAAIjM,EAAOoM,GACjBjL,IACX,CAEAqf,GAAAA,CAAIpU,GACA,OAAOjL,KAAKwF,IAAI6Z,IAAIpU,EACxB,CAEA67E,MAAAA,CAAOjoF,GACH,OAAOmB,KAAK6mF,QAAQxnE,IAAIxgB,EAC5B,CAEAm5E,OAAO/sE,GACH,MAAMpM,EAAQmB,KAAKwF,IAAI6Z,IAAIpU,GAC3B,YAAclP,IAAV8C,IACAmB,KAAKwF,IAAIwyE,OAAO/sE,GAChBjL,KAAK6mF,QAAQ7O,OAAOn5E,IACb,EAGf,ECpJE,MAAOkoF,GAKT5rF,WAAAA,CAAYy2E,GACR5xE,KAAKklF,aAAetT,EAASqB,WAAWkS,aACxCnlF,KAAKgnF,aAAepV,EAAS0O,UAAU2G,0BAC3C,CAEA,oBAAMC,CAAexZ,GAA+D,IAApC2T,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KAC5E,OAAOh7E,KAAKmnF,sBAAsBzZ,EAASyT,YAAYtiF,MAAO6uE,OAAU3xE,EAAWslF,EACvF,CAcA,2BAAM8F,CAAsBC,EAAqB1Z,GAA4J,IAAxHzhE,EAAApQ,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAiD6X,GAAgB2tE,EAAAxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAiCk/E,GAAAA,GAAkBC,KACrM,MAAM0C,EAAgC,GAEtC19E,KAAKqnF,WAAWD,EAAY1J,EAAShQ,GACrC,IAAK,MAAMtnE,KAAQ6F,EAASm7E,SAClBtM,GAAkBuG,GACxBrhF,KAAKqnF,WAAWjhF,EAAMs3E,EAAShQ,GAEnC,OAAOgQ,CACX,CAMU2J,UAAAA,CAAWjhF,EAAes3E,EAA+BhQ,GAC/D,MAAMxwE,EAAO8C,KAAKklF,aAAaJ,QAAQ1+E,GACnClJ,GACAwgF,EAAQ/2E,KAAK3G,KAAKgnF,aAAaM,kBAAkBlhF,EAAMlJ,EAAMwwE,GAErE,CAEA,wBAAM6Z,CAAmB7Z,GAA+D,IAApC2T,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KAChF,MAAMznE,EAAWm6D,EAASyT,YAAYtiF,MAChC2oF,EAAS,IAAIf,GAEnB,IAAK,MAAMrgF,KAAQ2N,GAAkBR,SAC3BunE,GAAkBuG,GACxBrhF,KAAKynF,YAAYrhF,EAAMsnE,EAAU8Z,GAErC,OAAOA,CACX,CAOUC,WAAAA,CAAYrhF,EAAesnE,EAA2B8Z,GAC5D,MAAMlnF,EAAY8F,EAAK6M,WACvB,GAAI3S,EAAW,CACX,MAAMpD,EAAO8C,KAAKklF,aAAaJ,QAAQ1+E,GACnClJ,GACAsqF,EAAOz8E,IAAIzK,EAAWN,KAAKgnF,aAAaM,kBAAkBlhF,EAAMlJ,EAAMwwE,G,CAGlF,EChGE,MAAOga,GAKTvsF,WAAAA,CAAY4lB,EAAsC4mE,EAAoBlkF,G,MAClEzD,KAAK+gB,SAAWA,EAChB/gB,KAAK2nF,WAAaA,EAClB3nF,KAAK4B,gBAA0C,QAAxBuS,EAAO,OAAP1Q,QAAO,IAAPA,OAAO,EAAPA,EAAS7B,uBAAe,IAAAuS,GAAAA,CACnD,CAEAyzE,cAAAA,GACI,OAAI5nF,KAAK2nF,WACE3nF,KAAK+gB,SAAS1gB,OAAOL,KAAK2nF,WAAWC,kBAErC5nF,KAAK+gB,QAEpB,CAEAgjE,UAAAA,CAAW7mF,GACP,MAAMspF,EAAQxmF,KAAK4B,gBACb5B,KAAK+gB,SAASnX,MAAKN,GAAKA,EAAEpM,KAAKoiB,gBAAkBpiB,EAAKoiB,gBACtDtf,KAAK+gB,SAASnX,MAAKN,GAAKA,EAAEpM,OAASA,IACzC,OAAIspF,IAGAxmF,KAAK2nF,WACE3nF,KAAK2nF,WAAW5D,WAAW7mF,QADtC,EAIJ,EAGE,MAAO2qF,GAKT1sF,WAAAA,CAAY4lB,EAAwC4mE,EAAoBlkF,G,MACpEzD,KAAK+gB,SAAW,IAAI1Y,IACpBrI,KAAK4B,gBAA0C,QAAxBuS,EAAO,OAAP1Q,QAAO,IAAPA,OAAO,EAAPA,EAAS7B,uBAAe,IAAAuS,GAAAA,EAC/C,IAAK,MAAM/L,KAAW2Y,EAAU,CAC5B,MAAM7jB,EAAO8C,KAAK4B,gBACZwG,EAAQlL,KAAKoiB,cACblX,EAAQlL,KACd8C,KAAK+gB,SAASjW,IAAI5N,EAAMkL,E,CAE5BpI,KAAK2nF,WAAaA,CACtB,CAEA5D,UAAAA,CAAW7mF,GACP,MAAM4qF,EAAY9nF,KAAK4B,gBAAkB1E,EAAKoiB,cAAgBpiB,EACxDspF,EAAQxmF,KAAK+gB,SAAS1B,IAAIyoE,GAChC,OAAItB,IAGAxmF,KAAK2nF,WACE3nF,KAAK2nF,WAAW5D,WAAW7mF,QADtC,EAIJ,CAEA0qF,cAAAA,GACI,IAAIG,EAAgB39E,EAAOpK,KAAK+gB,SAAS+F,UAIzC,OAHI9mB,KAAK2nF,aACLI,EAAgBA,EAAc1nF,OAAOL,KAAK2nF,WAAWC,mBAElDG,CACX,ECnGE,MAAgBC,GAAtB7sF,WAAAA,GAEc,KAAA8sF,UAA0B,GAC1B,KAAAC,YAAa,CAoB3B,CAlBIC,SAAAA,CAAUC,GACNpoF,KAAKioF,UAAUthF,KAAKyhF,EACxB,CAEAC,OAAAA,GACIroF,KAAKsoF,kBACLtoF,KAAK4zE,QACL5zE,KAAKkoF,YAAa,EAClBloF,KAAKioF,UAAUtkF,SAAQykF,GAAcA,EAAWC,WACpD,CAEUC,eAAAA,GACN,GAAItoF,KAAKkoF,WACL,MAAM,IAAIznF,MAAM,uCAExB,EAKE,MAAO8nF,WAA0BP,GAAvC7sF,WAAAA,G,oBACuB,KAAA8jB,MAAQ,IAAI5W,GAoCnC,CAlCIxE,GAAAA,CAAIoH,GAEA,OADAjL,KAAKsoF,kBACEtoF,KAAKif,MAAMpb,IAAIoH,EAC1B,CAEAH,GAAAA,CAAIG,EAAQpM,GACRmB,KAAKsoF,kBACLtoF,KAAKif,MAAMnU,IAAIG,EAAKpM,EACxB,CAIAwgB,GAAAA,CAAIpU,EAAQu9E,GAER,GADAxoF,KAAKsoF,kBACDtoF,KAAKif,MAAMpb,IAAIoH,GACf,OAAOjL,KAAKif,MAAMI,IAAIpU,GACnB,GAAIu9E,EAAU,CACjB,MAAM3pF,EAAQ2pF,IAEd,OADAxoF,KAAKif,MAAMnU,IAAIG,EAAKpM,GACbA,C,CAIf,CAEAm5E,OAAO/sE,GAEH,OADAjL,KAAKsoF,kBACEtoF,KAAKif,MAAM+4D,OAAO/sE,EAC7B,CAEA2oE,KAAAA,GACI5zE,KAAKsoF,kBACLtoF,KAAKif,MAAM20D,OACf,EAGE,MAAO6U,WAAgET,GAKzE7sF,WAAAA,CAAYg4E,GACR/3E,QAJa,KAAA6jB,MAAQ,IAAI5W,IAKzBrI,KAAKmzE,UAAqB,OAATA,QAAS,IAATA,EAAAA,EAAct0E,GAASA,CAC5C,CAEAgF,GAAAA,CAAI6kF,EAAqBz9E,GAErB,OADAjL,KAAKsoF,kBACEtoF,KAAK2oF,gBAAgBD,GAAY7kF,IAAIoH,EAChD,CAEAH,GAAAA,CAAI49E,EAAqBz9E,EAAUpM,GAC/BmB,KAAKsoF,kBACLtoF,KAAK2oF,gBAAgBD,GAAY59E,IAAIG,EAAKpM,EAC9C,CAIAwgB,GAAAA,CAAIqpE,EAAqBz9E,EAAUu9E,GAC/BxoF,KAAKsoF,kBACL,MAAMM,EAAe5oF,KAAK2oF,gBAAgBD,GAC1C,GAAIE,EAAa/kF,IAAIoH,GACjB,OAAO29E,EAAavpE,IAAIpU,GACrB,GAAIu9E,EAAU,CACjB,MAAM3pF,EAAQ2pF,IAEd,OADAI,EAAa99E,IAAIG,EAAKpM,GACfA,C,CAIf,CAEAm5E,OAAO0Q,EAAqBz9E,GAExB,OADAjL,KAAKsoF,kBACEtoF,KAAK2oF,gBAAgBD,GAAY1Q,OAAO/sE,EACnD,CAIA2oE,KAAAA,CAAM8U,GAEF,GADA1oF,KAAKsoF,kBACDI,EAAY,CACZ,MAAMhqB,EAAS1+D,KAAKmzE,UAAUuV,GAC9B1oF,KAAKif,MAAM+4D,OAAOtZ,E,MAElB1+D,KAAKif,MAAM20D,OAEnB,CAEU+U,eAAAA,CAAgBD,GACtB,MAAMhqB,EAAS1+D,KAAKmzE,UAAUuV,GAC9B,IAAIG,EAAgB7oF,KAAKif,MAAMI,IAAIq/C,GAKnC,OAJKmqB,IACDA,EAAgB,IAAIxgF,IACpBrI,KAAKif,MAAMnU,IAAI4zD,EAAQmqB,IAEpBA,CACX,EAuBE,MAAOC,WAA6BP,GACtCptF,WAAAA,CAAY4tF,GACR3tF,QACA4E,KAAKmoF,UAAUY,EAAezI,UAAU0I,gBAAgBC,UAAS,KAC7DjpF,KAAK4zE,OAAO,IAEpB,ECnIE,MAAOsV,GAST/tF,WAAAA,CAAYy2E,GACR5xE,KAAKhB,WAAa4yE,EAAS31E,OAAOgG,cAClCjC,KAAKklF,aAAetT,EAASqB,WAAWkS,aACxCnlF,KAAKgnF,aAAepV,EAAS0O,UAAU2G,2BACvCjnF,KAAKmpF,aAAevX,EAAS31E,OAAOqkF,UAAU8E,aAC9CplF,KAAKopF,iBAAmB,IAAIN,GAA8BlX,EAAS31E,OACvE,CAEA6nF,QAAAA,CAASloF,GACL,MAAM4rF,EAA4C,GAC5C5C,EAAgB5kF,KAAKhB,WAAWkB,iBAAiBtE,GAEjDytF,EAAc/1E,GAAY1X,EAAQ0E,WAAWsiF,kBACnD,GAAIyG,EAAa,CACb,IAAIC,EAAmC1tF,EAAQ0E,UAC/C,EAAG,CACC,MAAMipF,EAAkBF,EAAYhqE,IAAIiqE,GACpCC,EAAgBztF,OAAS,GACzB0rF,EAAO7gF,KAAKyD,EAAOm/E,GAAiBngF,QAChCogF,GAAQxpF,KAAKhB,WAAWiB,UAAUupF,EAAK7oF,KAAMikF,MAErD0E,EAAcA,EAAYr2E,U,OACrBq2E,E,CAGb,IAAIlkF,EAAgBpF,KAAKypF,eAAe7E,EAAehpF,GACvD,IAAK,IAAI4O,EAAIg9E,EAAO1rF,OAAS,EAAG0O,GAAK,EAAGA,IACpCpF,EAASpF,KAAK0pF,YAAYlC,EAAOh9E,GAAIpF,GAEzC,OAAOA,CACX,CAKUskF,WAAAA,CAAY3oE,EAAwC4mE,EAAoBlkF,GAC9E,OAAO,IAAIikF,GAAYt9E,EAAO2W,GAAW4mE,EAAYlkF,EACzD,CAMUkmF,mBAAAA,CAAoB5oE,EAA6B4mE,EAAoBlkF,GAC3E,MAAM6c,EAAIlW,EAAO2W,GAAUvb,KAAI8D,IAC3B,MAAMpM,EAAO8C,KAAKklF,aAAaJ,QAAQx7E,GACvC,GAAIpM,EACA,OAAO8C,KAAKgnF,aAAaM,kBAAkBh+E,EAAGpM,EAElC,IACjBmM,cACH,OAAO,IAAIq+E,GAAYpnE,EAAGqnE,EAAYlkF,EAC1C,CAKUgmF,cAAAA,CAAe7E,EAAuBgF,GAC5C,OAAO5pF,KAAKopF,iBAAiB/pE,IAAIulE,GAAe,IAAM,IAAIiD,GAAS7nF,KAAKmpF,aAAaU,YAAYjF,KACrG,ECGJ,SAASkF,GAAwBjkF,GAC7B,MAAsB,kBAARA,KAAsBA,IAAQ,SAAUA,GAAO,WAAYA,EAC7E,CAEM,MAAOkkF,GAaT5uF,WAAAA,CAAYy2E,GAVZ,KAAAoY,iBAAmB,IAAI3mF,IAAI,CAAC,aAAc,qBAAsB,kBAAmB,YAAa,aAW5FrD,KAAK+iF,iBAAmBnR,EAAS31E,OAAOqkF,UAAU0C,iBAClDhjF,KAAKmjF,eAAiBvR,EAAS0O,UAAU8C,eACzCpjF,KAAKklF,aAAetT,EAASqB,WAAWkS,aACxCnlF,KAAKiqF,gBAAkBrY,EAAS9H,cAAcogB,eAClD,CAEAC,SAAAA,CAAU/jF,GAAiD,IAAlC3C,EAAA5H,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAgC,CAAC,EACtD,MAAMuuF,EAA0B,OAAP3mF,QAAO,IAAPA,OAAO,EAAPA,EAAS4mF,SAC5BC,EAAkBA,CAACr/E,EAAapM,IAAmBmB,KAAKqqF,SAASp/E,EAAKpM,EAAO4E,GAC7E4mF,EAAWD,EAAmB,CAACn/E,EAAapM,IAAmBurF,EAAiBn/E,EAAKpM,EAAOyrF,GAAmBA,EAErH,IAEI,OADAtqF,KAAKuqF,gBAAkBj3E,GAAYlN,GAC5ByvD,KAAKC,UAAU1vD,EAAMikF,EAAiB,OAAP5mF,QAAO,IAAPA,OAAO,EAAPA,EAAS+mF,M,CACjD,QACExqF,KAAKuqF,qBAAkBxuF,C,CAE/B,CAEA0uF,WAAAA,CAAyC1jF,GAAqD,IAApCtD,EAAA5H,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAkC,CAAC,EACzF,MAAMmQ,EAAO6pD,KAAK7wD,MAAM+B,GAExB,OADA/G,KAAK0qF,SAAS1+E,EAAMA,EAAMvI,GACnBuI,CACX,CAEUq+E,QAAAA,CAASp/E,EAAapM,EAAc6hB,GAAoF,IAAlF,QAAEujE,EAAO,WAAE0G,EAAU,YAAEC,EAAW,SAAEC,EAAQ,aAAEC,GAAoCpqE,E,YAC9H,IAAI1gB,KAAKgqF,iBAAiBnmF,IAAIoH,GAA9B,CAEO,GAAInF,EAAYjH,GAAQ,CAC3B,MAAMksF,EAAWlsF,EAAMqf,IACjBnY,EAAWk+E,EAAUplF,EAAMkH,cAAWhK,EAC5C,GAAIgvF,EAAU,CACV,MAAMC,EAAiB13E,GAAYy3E,GACnC,IAAItmB,EAAY,GACZzkE,KAAKuqF,iBAAmBvqF,KAAKuqF,kBAAoBS,IAE7CvmB,EADAqmB,EACYA,EAAaE,EAAezmB,IAAK1lE,GAEjCmsF,EAAezmB,IAAIvgE,YAGvC,MAAMuyC,EAAav2C,KAAKmjF,eAAeiD,eAAe2E,GACtD,MAAO,CACHE,KAAM,GAAF5qF,OAAKokE,EAAS,KAAApkE,OAAIk2C,GACtBxwC,W,CAGJ,MAAO,CACHmlF,OAA4B,QAApBtpC,EAAW,QAAXztC,EAAAtV,EAAMytB,aAAK,IAAAnY,OAAA,EAAAA,EAAEzO,eAAO,IAAAk8C,EAAAA,EAAI,8BAChC77C,W,CAGL,GAAIH,EAAU/G,GAAQ,CACzB,IAAIoV,EAYJ,GAXI22E,IACA32E,EAAUjU,KAAKmrF,kCAAiCzsF,OAAA2lB,OAAC,CAAC,EAAIxlB,IAChDoM,IAAOpM,EAAM4U,aAAqB,OAAPQ,QAAO,IAAPA,OAAO,EAAPA,EAASm3E,eAEtCn3E,EAAQm3E,YAAYC,YAAkC,QAApBnR,EAAAl6E,KAAKuqF,uBAAe,IAAArQ,OAAA,EAAAA,EAAE3V,IAAIvgE,aAGhE2mF,IAAe1/E,IACR,OAAPgJ,QAAO,IAAPA,IAAAA,EAAOvV,OAAA2lB,OAAA,GAAUxlB,IACjBoV,EAAQq3E,YAA4B,QAAdC,EAAA1sF,EAAMuV,gBAAQ,IAAAm3E,OAAA,EAAAA,EAAErmF,MAEtC2lF,EAAU,CACH,OAAP52E,QAAO,IAAPA,IAAAA,EAAOvV,OAAA2lB,OAAA,GAAUxlB,IACjB,MAAM2sF,EAAUxrF,KAAKiqF,gBAAgBwB,WAAW5sF,GAC5C2sF,IACCv3E,EAA+By3E,SAAWF,EAAQruF,QAAQ,MAAO,I,CAG1E,OAAc,OAAP8W,QAAO,IAAPA,EAAAA,EAAWpV,C,CAElB,OAAOA,C,CAEf,CAEUssF,iCAAAA,CAAkC/kF,GACxC,MAAMulF,EAA4EjpF,IAAW,CACzF2K,OAAQ3K,EAAQ2K,OAChBJ,IAAKvK,EAAQuK,IACbnR,OAAQ4G,EAAQ5G,OAChBwR,MAAO5K,EAAQ4K,QAGnB,GAAIlH,EAAKgO,SAAU,CACf,MACMw3E,GADaxlF,EAAKglF,YAAcO,EAAsBvlF,EAAKgO,WACCw3E,YAAc,CAAC,EASjF,OAPAltF,OAAOiV,KAAKvN,GAAMgD,QAAO6B,IAAQA,EAAI+H,WAAW,OAAMrP,SAAQsH,IAC1D,MAAM4gF,EnG9GhB,SAA+BzlF,EAA2B5F,GAC5D,OAAK4F,GAAS5F,EAGP6d,GAA6BjY,EAAM5F,EAAU4F,EAAK6N,SAAS,GAFvD,EAGf,CmGyG4C63E,CAAqB1lF,EAAKgO,SAAUnJ,GAAKzF,IAAImmF,GACtC,IAA/BE,EAAoB/vF,SACpB8vF,EAAY3gF,GAAO4gF,E,IAIpBzlF,C,CAGf,CAEUskF,QAAAA,CAAStkF,EAAsB4F,EAAevI,EAAiCnD,EAAqByrF,EAA4BC,GACtI,IAAK,MAAOC,EAAcltF,KAASL,OAAOqU,QAAQ3M,GAC9C,GAAIS,MAAMC,QAAQ/H,GACd,IAAK,IAAIgK,EAAQ,EAAGA,EAAQhK,EAAKjD,OAAQiN,IAAS,CAC9C,MAAMX,EAAUrJ,EAAKgK,GACjB+gF,GAAwB1hF,GACxBrJ,EAAKgK,GAAS/I,KAAKksF,gBAAgB9lF,EAAM6lF,EAAcjgF,EAAM5D,EAAS3E,GAC/DmC,EAAUwC,IACjBpI,KAAK0qF,SAAStiF,EAA2B4D,EAAMvI,EAAS2C,EAAM6lF,EAAcljF,E,MAG7E+gF,GAAwB/qF,GAC/BqH,EAAK6lF,GAAgBjsF,KAAKksF,gBAAgB9lF,EAAM6lF,EAAcjgF,EAAMjN,EAAM0E,GACnEmC,EAAU7G,IACjBiB,KAAK0qF,SAAS3rF,EAAwBiN,EAAMvI,EAAS2C,EAAM6lF,GAGnE,MAAME,EAAU/lF,EAChB+lF,EAAQl5E,WAAa3S,EACrB6rF,EAAQj5E,mBAAqB64E,EAC7BI,EAAQh5E,gBAAkB64E,CAC9B,CAEUE,eAAAA,CAAgB5rF,EAAoBE,EAAkBwL,EAAe/F,EAAkCxC,GAC7G,IAAIwgF,EAAUh+E,EAAUF,SACpBumB,EAAQrmB,EAAUilF,OACtB,GAAIjlF,EAAUglF,KAAM,CAChB,MAAM/sE,EAAMle,KAAKosF,WAAWpgF,EAAM/F,EAAUglF,KAAMxnF,EAAQqnF,cAC1D,GAAIllF,EAAUsY,GAIV,OAHK+lE,IACDA,EAAUjkF,KAAKklF,aAAaJ,QAAQ5mE,IAEjC,CACHnY,SAAiB,OAAPk+E,QAAO,IAAPA,EAAAA,EAAW,GACrB/lE,OAGJoO,EAAQpO,C,CAGhB,GAAIoO,EAAO,CACP,MAAMpO,EAA0B,CAC5BnY,SAAiB,OAAPk+E,QAAO,IAAPA,EAAAA,EAAW,IAQzB,OANA/lE,EAAIoO,MAAQ,CACRhsB,YACAE,WACAkF,QAAS4mB,EACTrmB,UAAWiY,GAERA,C,CAIf,CAEUkuE,UAAAA,CAAWpgF,EAAeu4D,EAAaumB,GAC7C,IACI,MAAMuB,EAAgB9nB,EAAI37D,QAAQ,KAClC,GAAsB,IAAlByjF,EAAqB,CACrB,MAAMjmF,EAAOpG,KAAKmjF,eAAeuB,WAAW14E,EAAMu4D,EAAI3tD,UAAU,IAChE,OAAKxQ,GACM,2BAA6Bm+D,C,CAI5C,GAAI8nB,EAAgB,EAAG,CACnB,MAAM5I,EAAcqH,EAAeA,EAAavmB,GAAOvF,GAAIh6D,MAAMu/D,GAC3DmJ,EAAW1tE,KAAK+iF,iBAAiBzvE,YAAYmwE,GACnD,OAAK/V,EAGEA,EAASyT,YAAYtiF,MAFjB,oCAAsC0lE,C,CAIrD,MAAMkf,EAAcqH,EAAeA,EAAavmB,EAAI3tD,UAAU,EAAGy1E,IAAkBrtB,GAAIh6D,MAAMu/D,EAAI3tD,UAAU,EAAGy1E,IACxG3e,EAAW1tE,KAAK+iF,iBAAiBzvE,YAAYmwE,GACnD,IAAK/V,EACD,MAAO,oCAAsCnJ,EAEjD,GAAI8nB,IAAkB9nB,EAAIzoE,OAAS,EAC/B,OAAO4xE,EAASyT,YAAYtiF,MAEhC,MAAMuH,EAAOpG,KAAKmjF,eAAeuB,WAAWhX,EAASyT,YAAYtiF,MAAO0lE,EAAI3tD,UAAUy1E,EAAgB,IACtG,OAAKjmF,GACM,0BAA4Bm+D,C,CAGzC,MAAO9+D,GACL,OAAOyW,OAAOzW,E,CAEtB,ECvRE,MAAO6mF,GAKT7vF,QAAAA,CAASmtE,GACL,GAAK5pE,KAAKusF,WAAcvsF,KAAKwF,IAA7B,CAKA,IAAKxF,KAAKwF,MACNxF,KAAKwF,IAAM,CAAC,EACRxF,KAAKusF,WAAW,CAEhB,IAAK,MAAMjP,KAAOt9E,KAAKusF,UAAUpqF,iBAAiBR,eAC9C3B,KAAKwF,IAAI83E,GAAOt9E,KAAKusF,UAEzBvsF,KAAKusF,eAAYxwF,C,CAIzB,IAAK,MAAMuhF,KAAO1T,EAASznE,iBAAiBR,oBAClB5F,IAAlBiE,KAAKwF,IAAI83E,IAAsBt9E,KAAKwF,IAAI83E,KAAS1T,GACjDv9C,QAAQG,KAAK,sBAADnsB,OAAuBi9E,EAAG,2DAAAj9E,OAA0DupE,EAASznE,iBAAiBT,WAAU,OAExI1B,KAAKwF,IAAI83E,GAAO1T,C,MAlBhB5pE,KAAKusF,UAAY3iB,CAoBzB,CAEA+X,WAAAA,CAAYpd,GACR,QAAuBxoE,IAAnBiE,KAAKusF,UACL,OAAOvsF,KAAKusF,UAEhB,QAAiBxwF,IAAbiE,KAAKwF,IACL,MAAM,IAAI/E,MAAM,yFAEpB,MAAM68E,EAAMmC,GAASvC,QAAQ3Y,GACvBqN,EAAW5xE,KAAKwF,IAAI83E,GAC1B,IAAK1L,EACD,MAAM,IAAInxE,MAAM,gEAADJ,OAAiEi9E,EAAG,OAEvF,OAAO1L,CACX,CAEA,OAAIsQ,GACA,YAAuBnmF,IAAnBiE,KAAKusF,UACE,CAACvsF,KAAKusF,gBAEAxwF,IAAbiE,KAAKwF,IACE9G,OAAOooB,OAAO9mB,KAAKwF,KAEvB,EACX,ECjCE,SAAUgnF,GAAel/D,GAC3B,MAAO,CAAEA,OACb,CAqCM,IAAWm/D,GCyJAC,GCnOAC,IF0EjB,SAAiBF,GACAA,EAAAvK,IAAqC,CAAC,OAAQ,OAAQ,WACtE,CAFD,CAAiBuK,KAAAA,GAAkB,KAY7B,MAAOG,GAITzxF,WAAAA,CAAYy2E,GAHK,KAAA7+D,QAAU,IAAI0zE,GAI3BzmF,KAAKhB,WAAa4yE,EAAS31E,OAAOgG,aACtC,CAUAxF,QAAAA,CAAYowF,GAAoH,IAAjFC,EAAAjxF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAsCmE,KAAM+sF,EAAAlxF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAA+B,OACtH,GAAiB,aAAbkxF,EACA,MAAM,IAAItsF,MAAM,6EAEpB,IAAK,MAAOE,EAAM6tE,KAAO9vE,OAAOqU,QAAQ85E,GAAe,CACnD,MAAMG,EAAYxe,EAClB,GAAI3nE,MAAMC,QAAQkmF,GACd,IAAK,MAAMle,KAASke,EAAW,CAC3B,MAAMrvE,EAA8B,CAChCmxD,MAAO9uE,KAAKitF,wBAAwBne,EAAOge,GAC3CC,YAEJ/sF,KAAKktF,SAASvsF,EAAMgd,E,MAErB,GAAyB,oBAAdqvE,EAA0B,CACxC,MAAMrvE,EAA8B,CAChCmxD,MAAO9uE,KAAKitF,wBAAwBD,EAAWF,GAC/CC,YAEJ/sF,KAAKktF,SAASvsF,EAAMgd,E,EAGhC,CAEUsvE,uBAAAA,CAAwBne,EAAwBge,GACtD,OAAOzoF,MAAO+B,EAAM8d,EAAQm9D,KACxB,UACUvS,EAAMzjE,KAAKyhF,EAAS1mF,EAAM8d,EAAQm9D,E,CAC1C,MAAO57E,GACL,GAAIo1E,GAAqBp1E,GACrB,MAAMA,EAEV4mB,QAAQC,MAAM,uCAAwC7mB,GACtD,MAAMC,EAAUD,aAAehF,MAAQgF,EAAIC,QAAUwW,OAAOzW,GACxDA,aAAehF,OAASgF,EAAI+0D,OAC5BnuC,QAAQC,MAAM7mB,EAAI+0D,OAEtBt2C,EAAO,QAAS,wCAA0Cxe,EAAS,CAAEU,Q,EAGjF,CAEU8mF,QAAAA,CAASvsF,EAAcgd,GAC7B,GAAa,YAAThd,EAIJ,IAAK,MAAMb,KAAWE,KAAKhB,WAAWuH,eAAe5F,GACjDX,KAAK+S,QAAQhI,IAAIjL,EAAS6d,QAJ1B3d,KAAK+S,QAAQhI,IAAI,UAAW4S,EAMpC,CAEAwvE,SAAAA,CAAUxsF,EAAc+4B,GACpB,IAAI0zD,EAAShjF,EAAOpK,KAAK+S,QAAQsM,IAAI1e,IAChCN,OAAOL,KAAK+S,QAAQsM,IAAI,YAI7B,OAHIqa,IACA0zD,EAASA,EAAOhkF,QAAOuU,GAAS+b,EAAW5vB,SAAS6T,EAAMovE,aAEvDK,EAAO5nF,KAAImY,GAASA,EAAMmxD,OACrC,ECnIE,MAAOue,GAKTlyF,WAAAA,CAAYy2E,GACR5xE,KAAKstF,mBAAqB1b,EAAS2b,WAAWX,mBAC9C5sF,KAAKwtF,SAAW5b,EAASzvE,gBAC7B,CAEA,sBAAMsrF,CAAiB/f,GAAgG,IAArEjqE,EAAA5H,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAA6B,CAAC,EAAGwlF,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KAC/G,MAAMmG,EAAczT,EAASyT,YACvB9V,EAA4B,GAIlC,SAFMyP,GAAkBuG,IAEnB59E,EAAQi2B,YAAcj2B,EAAQi2B,WAAW5vB,SAAS,YAAa,CAEhE,GADA9J,KAAK0tF,oBAAoBvM,EAAa9V,EAAa5nE,GAC/CA,EAAQkqF,uBAAyBtiB,EAAYniE,MAAKuzD,IAAI,IAAAtoD,EAAC,OAAM,QAANA,EAAAsoD,EAAEmP,YAAI,IAAAz3D,OAAA,EAAAA,EAAEmZ,QAASo/D,GAAkBkB,WAAW,IACrG,OAAOviB,EAIX,GADArrE,KAAK6tF,qBAAqB1M,EAAa9V,EAAa5nE,GAChDA,EAAQqqF,wBAA0BziB,EAAYniE,MAAKuzD,IAAI,IAAAtoD,EAAC,OAAM,QAANA,EAAAsoD,EAAEmP,YAAI,IAAAz3D,OAAA,EAAAA,EAAEmZ,QAASo/D,GAAkBqB,YAAY,IACvG,OAAO1iB,EAIX,GADArrE,KAAKguF,qBAAqBtgB,EAAUrC,EAAa5nE,GAC7CA,EAAQwqF,wBAA0B5iB,EAAYniE,MAAKuzD,IAAI,IAAAtoD,EAAC,OAAM,QAANA,EAAAsoD,EAAEmP,YAAI,IAAAz3D,OAAA,EAAAA,EAAEmZ,QAASo/D,GAAkBwB,YAAY,IACvG,OAAO7iB,C,CAKf,IACIA,EAAY1kE,cAAc3G,KAAKmuF,YAAYhN,EAAYtiF,MAAO4E,EAAS49E,G,CACzE,MAAO57E,GACL,GAAIo1E,GAAqBp1E,GACrB,MAAMA,EAEV4mB,QAAQC,MAAM,uCAAwC7mB,E,CAK1D,aAFMq1E,GAAkBuG,GAEjBhW,CACX,CAEUqiB,mBAAAA,CAAoBvM,EAA0B9V,EAA2B+iB,GAC/E,IAAK,MAAMC,KAAclN,EAAY97E,YAAa,CAC9C,MAAMipF,EAAyB,CAC3BloB,SAAUmoB,GAAqB,SAC/BjhF,MAAO,CACHV,MAAO,CACHG,KAAMshF,EAAWthF,KAAQ,EACzBF,UAAWwhF,EAAWpzD,OAAU,GAEpChuB,IAAK,CACDF,KAAMshF,EAAWthF,KAAQ,EACzBF,UAAWwhF,EAAWpzD,OAAUozD,EAAWvyF,OAAS,IAG5D4J,QAAS2oF,EAAW3oF,QACpBkmE,KAAM4gB,GAAeE,GAAkBkB,aACvChxE,OAAQ5c,KAAKwuF,aAEjBnjB,EAAY1kE,KAAK2nF,E,CAEzB,CAEUT,oBAAAA,CAAqB1M,EAA0B9V,EAA2B+iB,GAChF,IAAK,MAAMK,KAAetN,EAAY77E,aAAc,CAChD,IAAIgI,EAIJ,GAAIsuC,MAAM6yC,EAAY9hF,MAAMquB,cAGxB,GAAI,kBAAmByzD,EAAa,CAChC,MAAM9hF,EAAS8hF,EAAyCz2C,cACxD,GAAK4D,MAAMjvC,EAAMquB,aAGV,CAGH,MAAM2rC,EAAqB,CAAE55D,KAAM,EAAGF,UAAW,GACjDS,EAAQ,CAAEV,MAAO+5D,EAAU15D,IAAK05D,E,KAPL,CAC3B,MAAMA,EAAqB,CAAE55D,KAAMJ,EAAMQ,QAAW,EAAGN,UAAWF,EAAMO,WACxEI,EAAQ,CAAEV,MAAO+5D,EAAU15D,IAAK05D,E,QASxCr5D,EAAQZ,EAAa+hF,EAAY9hF,OAErC,GAAIW,EAAO,CACP,MAAMghF,EAAyB,CAC3BloB,SAAUmoB,GAAqB,SAC/BjhF,QACA5H,QAAS+oF,EAAY/oF,QACrBkmE,KAAM4gB,GAAeE,GAAkBqB,cACvCnxE,OAAQ5c,KAAKwuF,aAEjBnjB,EAAY1kE,KAAK2nF,E,EAG7B,CAEUN,oBAAAA,CAAqBtgB,EAA2BrC,EAA2B+iB,GACjF,IAAK,MAAMnoF,KAAaynE,EAASuF,WAAY,CACzC,MAAMyb,EAAezoF,EAAUqmB,MAC/B,GAAIoiE,EAAc,CACd,MAAMtqF,EAAwC,CAC1CgC,KAAMsoF,EAAapuF,UACnBE,SAAUkuF,EAAaluF,SACvBuI,MAAO2lF,EAAa3lF,MACpB6iE,KAAM,CACFt+C,KAAMo/D,GAAkBwB,aACxBS,cAAeD,EAAapuF,UAAUC,MACtCC,SAAUkuF,EAAaluF,SACvByjF,QAASyK,EAAazoF,UAAUF,WAGxCslE,EAAY1kE,KAAK3G,KAAK4uF,aAAa,QAASF,EAAahpF,QAAStB,G,EAG9E,CAEU,iBAAM+pF,CAAY56E,EAAmB9P,GAAgE,IAApC49E,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KACvG,MAAM6T,EAAgC,GAChCC,EAA+BA,CAAoB1oB,EAAiD1gE,EAAiBtB,KACvHyqF,EAAgBloF,KAAK3G,KAAK4uF,aAAaxoB,EAAU1gE,EAAStB,GAAM,EAUpE,aAPM82E,QAAQgH,IAAIluE,GAAUT,GAAU/N,KAAInB,gBAChCy2E,GAAkBuG,GACxB,MAAM+L,EAASptF,KAAKstF,mBAAmBH,UAAU/mF,EAAK7F,MAAOkD,EAAQi2B,YACrE,IAAK,MAAMo1C,KAASse,QACVte,EAAM1oE,EAAM0oF,EAAUzN,E,KAG7BwN,CACX,CAEUD,YAAAA,CAAgCxoB,EAAiD1gE,EAAiBtB,GACxG,MAAO,CACHsB,UACA4H,MAAOyhF,GAAmB3qF,GAC1BgiE,SAAUmoB,GAAqBnoB,GAC/B94C,KAAMlpB,EAAKkpB,KACXg5C,gBAAiBliE,EAAKkiE,gBACtBmE,KAAMrmE,EAAKqmE,KACXpE,mBAAoBjiE,EAAKiiE,mBACzBuF,KAAMxnE,EAAKwnE,KACXhvD,OAAQ5c,KAAKwuF,YAErB,CAEUA,SAAAA,GACN,OAAOxuF,KAAKwtF,SAAS9rF,UACzB,EAGE,SAAUqtF,GAAsC3qF,GAClD,GAAIA,EAAKkJ,MACL,OAAOlJ,EAAKkJ,MAEhB,IAAI5K,EAOJ,MAN6B,kBAAlB0B,EAAK5D,SACZkC,EAAUyb,GAAoB/Z,EAAKgC,KAAKgO,SAAUhQ,EAAK5D,SAAU4D,EAAK2E,OACvC,kBAAjB3E,EAAKsa,UACnBhc,EtGlDF,SAA6B0D,EAA2BsY,EAAiB3V,GAC3E,IAAK3C,EACD,OAEJ,MAAMgY,EAAQK,GAA4BrY,EAAMsY,EAAa,OAAJtY,QAAI,IAAJA,OAAI,EAAJA,EAAM6N,SAC/D,OAAqB,IAAjBmK,EAAMtiB,OAQHsiB,EAJHrV,OADUhN,IAAVgN,EACQwF,KAAKC,IAAI,EAAGD,KAAKD,IAAIvF,EAAOqV,EAAMtiB,OAAS,IAE3C,QANZ,CASJ,CsGoCkBkzF,CAAmB5qF,EAAKgC,KAAKgO,SAAUhQ,EAAKsa,QAASta,EAAK2E,QAEjE,OAAPrG,QAAO,IAAPA,IAAAA,EAAY0B,EAAKgC,KAAKgO,UACjB1R,EAMEA,EAAQ4K,MALJ,CACHV,MAAO,CAAEG,KAAM,EAAGF,UAAW,GAC7BI,IAAK,CAAEF,KAAM,EAAGF,UAAW,GAIvC,CAEM,SAAU0hF,GAAqBnoB,GACjC,OAAQA,GACJ,IAAK,QACD,OAAO,EACX,IAAK,UACD,OAAO,EACX,IAAK,OACD,OAAO,EACX,IAAK,OACD,OAAO,EACX,QACI,MAAM,IAAI3lE,MAAM,gCAAkC2lE,GAE9D,EAEA,SAAiBsmB,GACAA,EAAAkB,YAAc,eACdlB,EAAAqB,aAAe,gBACfrB,EAAAwB,aAAe,eAC/B,CAJD,CAAiBxB,KAAAA,GAAiB,KEjN5B,MAAOuC,GAKT9zF,WAAAA,CAAYy2E,GACR5xE,KAAKmjF,eAAiBvR,EAAS0O,UAAU8C,eACzCpjF,KAAKklF,aAAetT,EAASqB,WAAWkS,YAC5C,CAEAmC,iBAAAA,CAAkBlhF,EAAelJ,GAAuE,IAA7CwwE,EAAA7xE,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAA4ByX,GAAYlN,GAC3F,OAAJlJ,QAAI,IAAJA,IAAAA,EAAS8C,KAAKklF,aAAaJ,QAAQ1+E,IACnC,MAAMgd,EAAOpjB,KAAKmjF,eAAeiD,eAAehgF,GAChD,IAAKlJ,EACD,MAAM,IAAIuD,MAAM,gBAADJ,OAAiB+iB,EAAI,kBAExC,IAAI8rE,EACJ,MAAMC,EAAoBA,KAAK,IAAAh7E,EAAA,OAAgB,OAAf+6E,QAAe,IAAfA,EAAAA,EAAAA,EAAoB9hF,EAAqD,QAAnC+G,EAAAnU,KAAKklF,aAAaF,YAAY5+E,UAAK,IAAA+N,EAAAA,EAAI/N,EAAKgO,SAAS,EAC3H,MAAO,CACHhO,OACAlJ,OACA,eAAIkyF,GACA,OAAOD,GACX,EACAE,iBAAkBjiF,EAAkBhH,EAAKgO,UACzCzT,KAAMyF,EAAK7F,MACXkjF,YAAa/V,EAASnJ,IACtBnhD,OAER,EAuCE,MAAOksE,GAITn0F,WAAAA,CAAYy2E,GACR5xE,KAAKqlF,YAAczT,EAAS0O,UAAU8C,cAC1C,CAEA,wBAAMmM,CAAmB7hB,GAA+D,IAApC2T,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KAChF,MAAMsJ,EAAgC,GAChC/wE,EAAWm6D,EAASyT,YAAYtiF,MACtC,IAAK,MAAMoV,KAAWD,GAAUT,SACtBunE,GAAkBuG,GACxBhtE,GAAiBJ,GAAS7K,QAAOjJ,IAAY6F,EAAe7F,KAAUwD,SAAQxD,IAE1E,MAAMs9C,EAAcz9C,KAAKsnF,kBAAkBnnF,GACvCs9C,GACA6mC,EAAM39E,KAAK82C,E,IAIvB,OAAO6mC,CACX,CAEUgD,iBAAAA,CAAkBnnF,GACxB,MAAMqvF,EAAkBrvF,EAAQ8F,UAAUs+E,iBACpCkL,EAAatvF,EAAQ8F,UAAUi+E,SACrC,IAAKsL,IAAoBC,EACrB,OAEJ,MAAMC,EAASp8E,GAAYnT,EAAQG,WAAWikE,IAC9C,MAAO,CACH8hB,UAAWqJ,EACXpJ,WAAYtmF,KAAKqlF,YAAYe,eAAejmF,EAAQG,WACpDmkE,UAAW+qB,EAAgB/L,YAC3BltC,WAAYi5C,EAAgBpsE,KAC5BmjE,QAASn5E,EAAkBqiF,GAC3BjJ,MAAO/G,GAASG,OAAO4P,EAAgB/L,YAAaiM,GAE5D,EC9GE,MAAOC,GAAbx0F,WAAAA,GACc,KAAAy0F,iBAAmB,IACnB,KAAAC,eAAiB,GAuC/B,CArCIzJ,cAAAA,CAAehgF,GACX,GAAIA,EAAK6M,WAAY,CACjB,MAAM68E,EAAgB9vF,KAAKomF,eAAehgF,EAAK6M,YACzC88E,EAAa/vF,KAAKgwF,eAAe5pF,GAEvC,OADiB0pF,EAAgB9vF,KAAK4vF,iBAAmBG,C,CAG7D,MAAO,EACX,CAEUC,cAAAA,CAActvE,GAAiD,IAAhD,mBAAExN,EAAkB,gBAAEC,GAA0BuN,EACrE,IAAKxN,EACD,MAAM,IAAIzS,MAAM,6CAEpB,YAAwB1E,IAApBoX,EACOD,EAAqBlT,KAAK6vF,eAAiB18E,EAE/CD,CACX,CAEAwxE,UAAAA,CAAwCt+E,EAAegd,GAEnD,OADiBA,EAAK48D,MAAMhgF,KAAK4vF,kBACjBrmF,QAAO,CAACE,EAAewmF,KACnC,IAAKxmF,GAAyC,IAAxBwmF,EAAan0F,OAC/B,OAAO2N,EAEX,MAAMymF,EAAgBD,EAAarnF,QAAQ5I,KAAK6vF,gBAChD,GAAIK,EAAgB,EAAG,CACnB,MAAM1vF,EAAWyvF,EAAar5E,UAAU,EAAGs5E,GACrCr8E,EAAagG,SAASo2E,EAAar5E,UAAUs5E,EAAgB,IAC7DpkF,EAASrC,EAAuDjJ,GACtE,OAAY,OAALsL,QAAK,IAALA,OAAK,EAALA,EAAQ+H,E,CAEnB,OAAQpK,EAAqDwmF,EAAa,GAC3E7pF,EACP,ECjBE,MAAO+pF,GAOTh1F,WAAAA,CAAYy2E,GAJO,KAAAwe,OAAS,IAAI7U,GACtB,KAAA8U,SAAgD,CAAC,EACjD,KAAAC,iBAAkB,EAGxBtwF,KAAKogF,gBAAkBxO,EAASp1E,eACpC,CAEA,SAAI+zF,GACA,OAAOvwF,KAAKowF,OAAO5U,OACvB,CAEA35B,UAAAA,CAAW2uC,G,QACPxwF,KAAKswF,gBAA8D,QAA5C1uC,EAA6B,QAA7BztC,EAAAq8E,EAAOC,aAAanQ,iBAAS,IAAAnsE,OAAA,EAAAA,EAAEu8E,qBAAa,IAAA9uC,GAAAA,CACvE,CAEA,iBAAM+uC,CAAYH,GACd,GAAIxwF,KAAKswF,gBAAiB,CACtB,GAAIE,EAAO/zF,SAAU,CAIjB,MAAMm0F,EAAY5wF,KAAKogF,gBAAgB8B,IACvCsO,EAAO/zF,SAAS,CAEZo0F,QAASD,EAAUprF,KAAIsrF,GAAQ9wF,KAAK+wF,cAAcD,EAAK3uF,iBAAiBT,e,CAIhF,GAAI8uF,EAAOQ,mBAAoB,CAG3B,MAAMC,EAAiBjxF,KAAKogF,gBAAgB8B,IAAI18E,KAAIsrF,IAAQ,CAExDD,QAAS7wF,KAAK+wF,cAAcD,EAAK3uF,iBAAiBT,gBAIhD24D,QAAgBm2B,EAAOQ,mBAAmBC,GAChDA,EAAettF,SAAQ,CAACutF,EAAMx7E,KAC1B1V,KAAKmxF,2BAA2BD,EAAKL,QAAUx2B,EAAQ3kD,GAAK,G,EAIxE1V,KAAKowF,OAAOjV,SAChB,CAQAiW,mBAAAA,CAAoBzpB,GACXA,EAAO0oB,UAGZ3xF,OAAOiV,KAAKg0D,EAAO0oB,UAAU1sF,SAAQktF,IACjC7wF,KAAKmxF,2BAA2BN,EAASlpB,EAAO0oB,SAASQ,GAAS,GAE1E,CAEUM,0BAAAA,CAA2BN,EAAiBH,GAClD1wF,KAAKqwF,SAASQ,GAAWH,CAC7B,CAQA,sBAAMW,CAAiBznB,EAAkB8mB,SAC/B1wF,KAAKuwF,MAEX,MAAMe,EAActxF,KAAK+wF,cAAcnnB,GACvC,GAAI5pE,KAAKqwF,SAASiB,GACd,OAAOtxF,KAAKqwF,SAASiB,GAAaZ,EAE1C,CAEUK,aAAAA,CAAcrvF,GACpB,MAAO,GAAPrB,OAAUqB,EACd,GH3HJ,SAAiBirF,GAGGA,EAAAtkC,OAAhB,SAAuBgqB,GACnB,MAAO,CACHgW,QAAShkF,eAAkBguE,IAEnC,CACH,CARD,CAAiBsa,KAAAA,GAAU,KIuFrB,MAAO4E,GAmBTp2F,WAAAA,CAAYy2E,GAjBZ,KAAA4f,mBAAmC,CAE/BjE,WAAY,CACR7zD,WAAY,CAAC,WAAY,UAQd,KAAA+3D,gBAA4C,GAC5C,KAAAC,oBAAsB,IAAIjL,GAC1B,KAAAkL,WAAa,IAAItpF,IACjB,KAAAupF,qBAAuB,IAAIvpF,IACpC,KAAAwpF,aAAenS,GAAciD,QAGnC3iF,KAAK+iF,iBAAmBnR,EAAS0O,UAAU0C,iBAC3ChjF,KAAKgiF,uBAAyBpQ,EAAS0O,UAAU2B,uBACjDjiF,KAAKmpF,aAAevX,EAAS0O,UAAU8E,aACvCplF,KAAKogF,gBAAkBxO,EAASp1E,eACpC,CAEA,WAAMs1F,CAAyBC,GAAsG,IAAhEtuF,EAAA5H,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAwB,CAAC,EAAGwlF,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,K,QAC7H,IAAK,MAAMtN,KAAYqkB,EAAW,CAC9B,MAAM9mF,EAAMyiE,EAASnJ,IAAIvgE,WACzB,GAAI0pE,EAASnmE,QAAUm4E,GAAcsS,WACjC,GAAkC,mBAAvBvuF,EAAQ8pF,YAA4B9pF,EAAQ8pF,WAEnD7f,EAASnmE,MAAQm4E,GAAcuS,kBAC/BvkB,EAASrC,iBAActvE,EACvBiE,KAAK2xF,WAAW3Z,OAAO/sE,QACpB,GAAkC,kBAAvBxH,EAAQ8pF,WAAyB,CAC/C,MAAMoE,EAAa3xF,KAAK2xF,WAAWtyE,IAAIpU,GACjCinF,EAAuC,QAAlB/9E,EAAU,OAAVw9E,QAAU,IAAVA,OAAU,EAAVA,EAAYvsF,cAAM,IAAA+O,OAAA,EAAAA,EAAEg+E,iBAC/C,GAAID,EAAoB,CAGpB,MACMx4D,GAD6C,QAA7BkoB,EAAAn+C,EAAQ8pF,WAAW7zD,kBAAU,IAAAkoB,EAAAA,EAAI6qC,GAAmBvK,KACzC94E,QAAOivB,IAAM65D,EAAmBpoF,SAASuuB,KACtEqB,EAAW59B,OAAS,IACpBkE,KAAK2xF,WAAW7mF,IAAIG,EAAK,CACrBmnF,WAAW,EACX3uF,QAAS,CACL8pF,WAAU7uF,OAAA2lB,OAAA3lB,OAAA2lB,OAAA,GACH5gB,EAAQ8pF,YAAU,CACrB7zD,gBAGRt0B,OAAQusF,EAAWvsF,SAEvBsoE,EAASnmE,MAAQm4E,GAAcuS,kB,QAM3CjyF,KAAK2xF,WAAW3Z,OAAO/sE,E,CAG/BjL,KAAK6xF,aAAenS,GAAciD,cAC5B3iF,KAAKqyF,WAAWN,EAAUvsF,KAAI8D,GAAKA,EAAEi7D,MAAM,UAC3CvkE,KAAKsyF,eAAeP,EAAWtuF,EAAS49E,EAClD,CAEA,YAAMlT,CAAOokB,EAAgBC,GAAoD,IAApCnR,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KACzEh7E,KAAK6xF,aAAenS,GAAciD,QAElC,IAAK,MAAM8P,KAAcD,EACrBxyF,KAAK+iF,iBAAiBF,eAAe4P,GACrCzyF,KAAK2xF,WAAW3Z,OAAOya,EAAWzuF,YAClChE,KAAKmpF,aAAauJ,OAAOD,GAG7B,IAAK,MAAME,KAAcJ,EAAS,CAE9B,IADoBvyF,KAAK+iF,iBAAiBN,mBAAmBkQ,GAC3C,CAId,MAAMC,EAAc5yF,KAAKgiF,uBAAuBhB,UAAU,CAAEzgF,MAAO,WAAaoyF,GAChFC,EAAYrrF,MAAQm4E,GAAciD,QAClC3iF,KAAK+iF,iBAAiBZ,YAAYyQ,E,CAEtC5yF,KAAK2xF,WAAW3Z,OAAO2a,EAAW3uF,W,CAGtC,MAAM6uF,EAAiBzoF,EAAOmoF,GAASlyF,OAAOmyF,GAAShtF,KAAI++D,GAAOA,EAAIvgE,aAAY+D,QAClF/H,KAAK+iF,iBAAiBb,IACjB94E,QAAOq7E,IAAQoO,EAAehvF,IAAI4gF,EAAIlgB,IAAIvgE,aAAehE,KAAK8yF,aAAarO,EAAKoO,KAChFlvF,SAAQ8gF,IACUzkF,KAAKogF,gBAAgBuB,YAAY8C,EAAIlgB,KAAK0O,WAAWC,OAC7D2Q,OAAOY,GACdA,EAAIl9E,MAAQgH,KAAKD,IAAIm2E,EAAIl9E,MAAOm4E,GAAc2E,gBAC9CI,EAAIpZ,iBAActvE,CAAS,UAG7BiE,KAAKqyF,WAAWE,EAASC,SAEzB1X,GAAkBuG,GAGxB,MAAM0R,EAAmB/yF,KAAK+iF,iBAAiBb,IAC1C94E,QAAOq7E,I,MAEJ,OAAAA,EAAIl9E,MAAQm4E,GAAcsT,UAEiB,QAAvC7+E,EAAAnU,KAAK2xF,WAAWtyE,IAAIolE,EAAIlgB,IAAIvgE,mBAAW,IAAAmQ,OAAA,EAAAA,EAAEi+E,UAAS,IAEzDtqF,gBACC9H,KAAKsyF,eAAeS,EAAkB/yF,KAAKwxF,mBAAoBnQ,EACzE,CAEU,gBAAMgR,CAAWE,EAAgBC,SACjCtX,QAAQgH,IAAIliF,KAAKyxF,gBAAgBjsF,KAAIytF,GAAYA,EAASV,EAASC,KAC7E,CAKUM,YAAAA,CAAaplB,EAA2BwlB,GAE9C,QAAIxlB,EAASuF,WAAW/pE,MAAKgV,QAAqBniB,IAAdmiB,EAAIoO,SAIjCtsB,KAAKmpF,aAAagK,WAAWzlB,EAAUwlB,EAClD,CAEAjK,QAAAA,CAAS5W,GAEL,OADAryE,KAAKyxF,gBAAgB9qF,KAAK0rE,GACnBsa,GAAWtkC,QAAO,KACrB,MAAMt/C,EAAQ/I,KAAKyxF,gBAAgB7oF,QAAQypE,GACvCtpE,GAAS,GACT/I,KAAKyxF,gBAAgBv3B,OAAOnxD,EAAO,E,GAG/C,CAMU,oBAAMupF,CAAeP,EAA8BtuF,EAAuB49E,GAChFrhF,KAAKozF,aAAarB,EAAWtuF,SAEvBzD,KAAKqzF,cAActB,EAAWrS,GAAc6B,OAAQF,GAAaoD,GACnEzkF,KAAKgiF,uBAAuB7T,OAAOsW,EAAKpD,WAGtCrhF,KAAKqzF,cAActB,EAAWrS,GAAc4T,eAAgBjS,GAAaoD,GAC3EzkF,KAAKmpF,aAAaoK,cAAc9O,EAAKpD,WAGnCrhF,KAAKqzF,cAActB,EAAWrS,GAAc2E,eAAgBhD,GAAah9E,UAC3E,MAAMmvF,EAAmBxzF,KAAKogF,gBAAgBuB,YAAY8C,EAAIlgB,KAAK0O,WAAWwgB,iBAC9EhP,EAAI7B,wBAA0B4Q,EAAiBjM,mBAAmB9C,EAAKpD,EAAY,UAGjFrhF,KAAKqzF,cAActB,EAAWrS,GAAcsT,OAAQ3R,GAAaoD,GACpDzkF,KAAKogF,gBAAgBuB,YAAY8C,EAAIlgB,KAAK0O,WAAWC,OACtDmQ,KAAKoB,EAAKpD,WAGtBrhF,KAAKqzF,cAActB,EAAWrS,GAAcuS,kBAAmB5Q,GAAaoD,GAC9EzkF,KAAKmpF,aAAauK,iBAAiBjP,EAAKpD,KAG5C,MAAMsS,EAAgB5B,EAAU3oF,QAAOq7E,GAAOzkF,KAAK4zF,eAAenP,WAC5DzkF,KAAKqzF,cAAcM,EAAejU,GAAcsS,UAAW3Q,GAAaoD,GAC1EzkF,KAAK85C,SAAS2qC,EAAKpD,KAIvB,IAAK,MAAMoD,KAAOsN,EAAW,CACzB,MAAMxqF,EAAQvH,KAAK2xF,WAAWtyE,IAAIolE,EAAIlgB,IAAIvgE,YACtCuD,IACAA,EAAM6qF,WAAY,E,CAG9B,CAEUgB,YAAAA,CAAarB,EAA8BtuF,GACjD,IAAK,MAAMghF,KAAOsN,EAAW,CACzB,MAAM9mF,EAAMw5E,EAAIlgB,IAAIvgE,WACduD,EAAQvH,KAAK2xF,WAAWtyE,IAAIpU,GAI7B1D,IAASA,EAAM6qF,WAChBpyF,KAAK2xF,WAAW7mF,IAAIG,EAAK,CACrBmnF,WAAW,EACX3uF,UACA2B,OAAa,OAALmC,QAAK,IAALA,OAAK,EAALA,EAAOnC,Q,CAI/B,CAEU,mBAAMiuF,CAActB,EAA8B8B,EAA4BxS,EACpFhP,GACA,MAAMyhB,EAAW/B,EAAU3oF,QAAOE,GAAKA,EAAE/B,MAAQssF,IACjD,IAAK,MAAMnmB,KAAYomB,QACbhZ,GAAkBuG,SAClBhP,EAAS3E,GACfA,EAASnmE,MAAQssF,QAEf7zF,KAAK+zF,iBAAiBD,EAAUD,EAAaxS,GACnDrhF,KAAK6xF,aAAegC,CACxB,CAEAG,YAAAA,CAAaH,EAA4BxhB,GAErC,OADAryE,KAAK0xF,oBAAoB3mF,IAAI8oF,EAAaxhB,GACnCsa,GAAWtkC,QAAO,KACrBroD,KAAK0xF,oBAAoB1Z,OAAO6b,EAAaxhB,EAAS,GAE9D,CAIA4hB,SAAAA,CAAU1sF,EAAsB2sF,EAAsC7S,GAClE,IAAI9c,EAOJ,GANI2vB,GAAc,SAAUA,EACxB3vB,EAAM2vB,EAEN7S,EAAc6S,EAEP,OAAX7S,QAAW,IAAXA,IAAAA,EAAgBtG,GAAAA,GAAkBC,MAC9BzW,EAAK,CACL,MAAMmJ,EAAW1tE,KAAK+iF,iBAAiBzvE,YAAYixD,GACnD,GAAImJ,GAAYA,EAASnmE,MAAQA,EAC7B,OAAO2zE,QAAQC,QAAQ5W,E,CAG/B,OAAIvkE,KAAK6xF,cAAgBtqF,EACd2zE,QAAQC,aAAQp/E,GAChBslF,EAAY/F,wBACZJ,QAAQrrD,OAAO+qD,IAEnB,IAAIM,SAAQ,CAACC,EAAStrD,KACzB,MAAMskE,EAAkBn0F,KAAKg0F,aAAazsF,GAAO,KAG7C,GAFA4sF,EAAgB9L,UAChB+L,EAAiB/L,UACb9jB,EAAK,CACL,MAAMmJ,EAAW1tE,KAAK+iF,iBAAiBzvE,YAAYixD,GACnD4W,EAAgB,OAARzN,QAAQ,IAARA,OAAQ,EAARA,EAAUnJ,I,MAElB4W,OAAQp/E,E,IAGVq4F,EAAmB/S,EAAagT,yBAAwB,KAC1DF,EAAgB9L,UAChB+L,EAAiB/L,UACjBx4D,EAAO+qD,GAAmB,GAC5B,GAEV,CAEU,sBAAMmZ,CAAiBhC,EAA8BxqF,EAAsB85E,GACjF,GAAyB,IAArB0Q,EAAUj2F,OAEV,OAEJ,MAAMw4F,EAAYt0F,KAAK0xF,oBAAoBryE,IAAI9X,GAC/C,IAAK,MAAM0rF,KAAYqB,QACbxZ,GAAkBuG,SAClB4R,EAASlB,EAAW1Q,EAElC,CAOUuS,cAAAA,CAAelmB,GACrB,OAAO/lE,QAAQ3H,KAAKu0F,gBAAgB7mB,GAAU6f,WAClD,CAMU,cAAMzzC,CAAS4zB,EAA2B2T,G,QAChD,MAAMmT,EAAYx0F,KAAKogF,gBAAgBuB,YAAYjU,EAASnJ,KAAKgpB,WAAWb,kBACtE+H,EAAoBz0F,KAAKu0F,gBAAgB7mB,GAAU6f,WACnD9pF,EAAuC,kBAAtBgxF,EAAiCA,OAAoB14F,EACtEsvE,QAAoBmpB,EAAU/G,iBAAiB/f,EAAUjqE,EAAS49E,GACpE3T,EAASrC,YACTqC,EAASrC,YAAY1kE,QAAQ0kE,GAE7BqC,EAASrC,YAAcA,EAI3B,MAAM9jE,EAAQvH,KAAK2xF,WAAWtyE,IAAIquD,EAASnJ,IAAIvgE,YAC/C,GAAIuD,EAAO,CACK,QAAZ4M,EAAA5M,EAAMnC,cAAM,IAAA+O,IAAZ5M,EAAMnC,OAAW,CAAC,GAClB,MAAMy0B,EAAmC,QAAnB+nB,EAAO,OAAPn+C,QAAO,IAAPA,OAAO,EAAPA,EAASi2B,kBAAU,IAAAkoB,EAAAA,EAAI6qC,GAAmBvK,IAC5D36E,EAAMnC,OAAO+sF,iBACb5qF,EAAMnC,OAAO+sF,iBAAiBxrF,QAAQkzB,GAEtCtyB,EAAMnC,OAAO+sF,iBAAmB,IAAIt4D,E,CAGhD,CAEU06D,eAAAA,CAAgB7mB,G,QACtB,OAA4D,QAArD9rB,EAA4C,QAA5CztC,EAAAnU,KAAK2xF,WAAWtyE,IAAIquD,EAASnJ,IAAIvgE,mBAAW,IAAAmQ,OAAA,EAAAA,EAAE1Q,eAAO,IAAAm+C,EAAAA,EAAI,CAAC,CACrE,EChVE,MAAO8yC,GAuBTv5F,WAAAA,CAAYy2E,GAbO,KAAA+iB,YAAc,IAAItsF,IAKlB,KAAAusF,kBAAoB,IAAInM,GAMxB,KAAAoM,eAAiB,IAAIxsF,IAGpCrI,KAAK+xF,UAAYngB,EAAS0O,UAAU0C,iBACpChjF,KAAKogF,gBAAkBxO,EAASp1E,gBAChCwD,KAAKozE,cAAgBxB,EAAS3vE,aAClC,CAEAkkF,iBAAAA,CAAkBN,EAAqBiP,GACnC,MAAMC,EAAezhF,GAAYuyE,GAAYthB,IACvCn/D,EAAiC,GAQvC,OAPApF,KAAK60F,eAAelxF,SAAQqxF,IACxBA,EAAQrxF,SAAQsxF,IACRxV,GAASG,OAAOqV,EAASxwB,UAAWswB,IAAiBE,EAAS1+C,aAAeu+C,GAC7E1vF,EAAOuB,KAAKsuF,E,GAElB,IAEC7qF,EAAOhF,EAClB,CAEAykF,WAAAA,CAAYqL,EAAmBC,GAC3B,IAAIC,EAAehrF,EAAOpK,KAAK20F,YAAYhhF,QAI3C,OAHIwhF,IACAC,EAAeA,EAAahsF,QAAOm7D,IAAQ4wB,GAAQA,EAAKtxF,IAAI0gE,MAEzD6wB,EACF5vF,KAAI++D,GAAOvkE,KAAKq1F,oBAAoB9wB,EAAK2wB,KACzChrF,MACT,CAEUmrF,mBAAAA,CAAoB9wB,EAAa2wB,G,MACvC,IAAKA,EACD,OAAgC,QAAzB/gF,EAAAnU,KAAK20F,YAAYt1E,IAAIklD,UAAI,IAAApwD,EAAAA,EAAI,GAExC,MAAM6yE,EAAehnF,KAAK40F,kBAAkBv1E,IAAIklD,EAAK2wB,GAAU,K,MAE3D,OADqD,QAAzB/gF,EAAAnU,KAAK20F,YAAYt1E,IAAIklD,UAAI,IAAApwD,EAAAA,EAAI,IAC9B/K,QAAOE,GAAKtJ,KAAKozE,cAAcnzE,UAAUqJ,EAAE3I,KAAMu0F,IAAU,IAE1F,OAAOlO,CACX,CAEA0L,MAAAA,CAAOnuB,GACH,MAAM6d,EAAY7d,EAAIvgE,WACtBhE,KAAK20F,YAAY3c,OAAOoK,GACxBpiF,KAAK40F,kBAAkBhhB,MAAMwO,GAC7BpiF,KAAK60F,eAAe7c,OAAOoK,EAC/B,CAEA,mBAAMmR,CAAc7lB,GAA+D,IAApC2T,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KAC3E,MAAMpJ,EAAW5xE,KAAKogF,gBAAgBuB,YAAYjU,EAASnJ,KACrDmZ,QAAgB9L,EAASqB,WAAWwgB,iBAAiBvM,eAAexZ,EAAU2T,GAC9E9c,EAAMmJ,EAASnJ,IAAIvgE,WACzBhE,KAAK20F,YAAY7pF,IAAIy5D,EAAKmZ,GAC1B19E,KAAK40F,kBAAkBhhB,MAAMrP,EACjC,CAEA,sBAAMmvB,CAAiBhmB,GAA+D,IAApC2T,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KAC9E,MAAMpJ,EAAW5xE,KAAKogF,gBAAgBuB,YAAYjU,EAASnJ,KACrD+wB,QAAkB1jB,EAAS0O,UAAUiV,6BAA6BhG,mBAAmB7hB,EAAU2T,GACrGrhF,KAAK60F,eAAe/pF,IAAI4iE,EAASnJ,IAAIvgE,WAAYsxF,EACrD,CAEAnC,UAAAA,CAAWzlB,EAA2BwlB,GAClC,MAAMjgB,EAAajzE,KAAK60F,eAAex1E,IAAIquD,EAASnJ,IAAIvgE,YACxD,QAAKivE,GAGEA,EAAW/pE,MAAKgV,IAAQA,EAAIsoE,OAAS0M,EAAYrvF,IAAIqa,EAAIumD,UAAUzgE,aAC9E,ECjHE,MAAOwxF,GAYTr6F,WAAAA,CAAYy2E,GAVZ,KAAA6jB,oBAAoC,CAAC,EAOlB,KAAArF,OAAS,IAAI7U,GAI5Bv7E,KAAKogF,gBAAkBxO,EAASp1E,gBAChCwD,KAAK+iF,iBAAmBnR,EAAS0O,UAAU0C,iBAC3ChjF,KAAK01F,gBAAkB9jB,EAAS0O,UAAU0I,gBAC1ChpF,KAAKwgF,mBAAqB5O,EAAS0O,UAAUG,mBAC7CzgF,KAAK21F,MAAQ/jB,EAAS0O,UAAUsV,aACpC,CAEA,SAAIrF,GACA,OAAOvwF,KAAKowF,OAAO5U,OACvB,CAEA35B,UAAAA,CAAW2uC,G,MACPxwF,KAAK61F,QAAiC,QAAvB1hF,EAAAq8E,EAAOsF,wBAAgB,IAAA3hF,EAAAA,OAAIpY,CAC9C,CAEA40F,WAAAA,CAAYoF,GAGR,OAAO/1F,KAAK21F,MAAMK,OAAMrpF,IAAQ,IAAAwH,EAAC,OAAAnU,KAAKi2F,oBAAgC,QAAZ9hF,EAAAnU,KAAK61F,eAAO,IAAA1hF,EAAAA,EAAI,GAAIxH,EAAM,GACxF,CAEA,yBAAMspF,CAAoBJ,GAAgE,IAApCxU,EAAWxlF,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAGk/E,GAAAA,GAAkBC,KAClF,MAAM+W,QAAkB/xF,KAAKk2F,eAAeL,SAGtC/a,GAAkBuG,SAClBrhF,KAAK01F,gBAAgB5D,MAAMC,EAAW/xF,KAAKy1F,oBAAqBpU,EAC1E,CAMU,oBAAM6U,CAAeL,GAC3B,MAAMl0F,EAAiB3B,KAAKogF,gBAAgB8B,IAAIn4E,SAAQT,GAAKA,EAAEnH,iBAAiBR,iBAC1EowF,EAA+B,GAC/BoE,EAAazoB,IACfqkB,EAAUprF,KAAK+mE,GACV1tE,KAAK+iF,iBAAiBP,YAAY9U,EAASnJ,MAC5CvkE,KAAK+iF,iBAAiBZ,YAAYzU,E,EAY1C,aANM1tE,KAAKo2F,wBAAwBP,EAASM,SACtCjb,QAAQgH,IACV2T,EAAQrwF,KAAI6wF,GAAM,CAACA,EAAIr2F,KAAKs2F,cAAcD,MACrC7wF,KAAInB,SAAerE,KAAKu2F,kBAAkB54E,EAAOhc,EAAgBw0F,MAE1En2F,KAAKowF,OAAOjV,UACL4W,CACX,CAOUqE,uBAAAA,CAAwBI,EAA6BC,GAC3D,OAAOvb,QAAQC,SACnB,CAOUmb,aAAAA,CAAcI,GACpB,OAAO13B,GAAIh6D,MAAM0xF,EAAgBnyB,IACrC,CAMU,oBAAMgyB,CAAeG,EAAkCC,EAAiBh1F,EAA0Bw0F,GACxG,MAAMpvF,QAAgB/G,KAAKwgF,mBAAmBoW,cAAcD,SACtDzb,QAAQgH,IAAIn7E,EAAQvB,KAAInB,UAC1B,GAAIrE,KAAK62F,aAAaH,EAAiB/4E,EAAOhc,GAC1C,GAAIgc,EAAMm5E,kBACA92F,KAAKu2F,eAAeG,EAAiB/4E,EAAM4mD,IAAK5iE,EAAgBw0F,QACnE,GAAIx4E,EAAMo5E,OAAQ,CACrB,MAAMrpB,QAAiB1tE,KAAK+iF,iBAAiBV,oBAAoB1kE,EAAM4mD,KACvE4xB,EAAUzoB,E,KAI1B,CAKUmpB,YAAAA,CAAaG,EAAmCr5E,EAAuBhc,GAC7E,MAAMzE,EAAOuiF,GAASxC,SAASt/D,EAAM4mD,KACrC,GAAIrnE,EAAK8V,WAAW,KAChB,OAAO,EAEX,GAAI2K,EAAMm5E,YACN,MAAgB,iBAAT55F,GAAoC,QAATA,EAC/B,GAAIygB,EAAMo5E,OAAQ,CACrB,MAAM7Z,EAAUuC,GAASvC,QAAQv/D,EAAM4mD,KACvC,OAAO5iE,EAAemI,SAASozE,E,CAEnC,OAAO,CACX,ECpJE,MAAO+Z,GAKT97F,WAAAA,CAAYy2E,GACR,MAAMtvC,EAASsvC,EAASr2E,OAAOC,aAAau9E,YAAYnH,EAAS1vE,QAAS,CACtEN,gBAAiBgwE,EAASzvE,iBAAiBP,kBAE/C5B,KAAK0D,WAAa1D,KAAKk3F,sBAAsB50D,GAC7C,MAAM60D,EAAcC,GAAsB90D,GAAU5jC,OAAOooB,OAAOwb,GAAUA,EAC5EtiC,KAAKq3F,gBAAkB,IAAIC,GAAgBH,EAAa,CACpD3nE,iBAAkB,QAE1B,CAEA,cAAI7P,GACA,OAAO3f,KAAK0D,UAChB,CAEAu7B,QAAAA,CAAS/5B,G,MACL,MAAMqyF,EAAmBv3F,KAAKq3F,gBAAgBp4D,SAAS/5B,GACvD,MAAO,CACHo9B,OAAQi1D,EAAiBj1D,OACzBjP,OAAQkkE,EAAiBlkE,OACzBxkB,OAAsC,QAA9BsF,EAAAojF,EAAiBr3D,OAAOrxB,cAAM,IAAAsF,EAAAA,EAAI,GAElD,CAEU+iF,qBAAAA,CAAsBne,GAC5B,GAAIqe,GAAsBre,GAAc,OAAOA,EAC/C,MAAMz2C,EAASk1D,GAA4Bze,GAAer6E,OAAOooB,OAAOiyD,EAAYxhD,OAAOrtB,OAAS6uE,EAC9F0e,EAA2B,CAAC,EAElC,OADAn1D,EAAO3+B,SAAQgJ,GAAS8qF,EAAI9qF,EAAMzP,MAAQyP,IACnC8qF,CACX,EAaE,SAAUD,GAA4Bx1C,GACxC,OAAOA,GAAmB,UAAWA,GAAmB,gBAAiBA,CAC7E,CAKM,SAAUo1C,GAAsBp1C,GAClC,OAfE,SAA2BA,GAC7B,OAAOn7C,MAAMC,QAAQk7C,KAAgD,IAA3BA,EAAgBlmD,QAAgB,SAAUkmD,EAAgB,GACxG,CAaY01C,CAAiB11C,KAAqBw1C,GAA4Bx1C,EAC9E,CCiBM,SAAU21C,GAAWvxF,EAAwBwG,EAAsCnJ,GACrF,IAAIm0F,EACAjxB,EACgB,kBAATvgE,GACPugE,EAAW/5D,EACXgrF,EAAOn0F,IAEPkjE,EAAWvgE,EAAKkH,MAAMV,MACtBgrF,EAAOhrF,GAEN+5D,IACDA,EAAWxH,GAAS9W,OAAO,EAAG,IAGlC,MAGM/lB,EAkDV,SAAkB1mC,G,UACd,MAAM0mC,EAAuB,GAC7B,IAAIu1D,EAAcj8F,EAAQ+qE,SAAS55D,KAC/B+qF,EAAmBl8F,EAAQ+qE,SAAS95D,UACxC,IAAK,IAAIrC,EAAI,EAAGA,EAAI5O,EAAQm8F,MAAMj8F,OAAQ0O,IAAK,CAC3C,MAAMjC,EAAc,IAANiC,EACR42B,EAAO52B,IAAM5O,EAAQm8F,MAAMj8F,OAAS,EAC1C,IAAIiR,EAAOnR,EAAQm8F,MAAMvtF,GACrBzB,EAAQ,EAEZ,GAAIR,GAAS3M,EAAQ6H,QAAQmJ,MAAO,CAChC,MAAM/J,EAA6B,QAArBsR,EAAAvY,EAAQ6H,QAAQmJ,aAAK,IAAAuH,OAAA,EAAAA,EAAErR,KAAKiK,GACtClK,IACAkG,EAAQlG,EAAMkG,MAAQlG,EAAM,GAAG/G,O,KAEhC,CACH,MAAM+G,EAA4B,QAApB++C,EAAAhmD,EAAQ6H,QAAQsJ,YAAI,IAAA60C,OAAA,EAAAA,EAAE9+C,KAAKiK,GACrClK,IACAkG,EAAQlG,EAAMkG,MAAQlG,EAAM,GAAG/G,O,CAGvC,GAAIslC,EAAM,CACN,MAAMv+B,EAA2B,QAAnBq3E,EAAAt+E,EAAQ6H,QAAQwJ,WAAG,IAAAitE,OAAA,EAAAA,EAAEp3E,KAAKiK,GACpClK,IACAkK,EAAOA,EAAK6J,UAAU,EAAG/T,EAAMkG,O,CAIvCgE,EAAOA,EAAK6J,UAAU,EAAGohF,GAAcjrF,IAGvC,GAFsBkrF,GAAelrF,EAAMhE,IAEtBgE,EAAKjR,QAEtB,GAAIwmC,EAAOxmC,OAAS,EAAG,CACnB,MAAM6qE,EAAWxH,GAAS9W,OAAOwvC,EAAaC,GAC9Cx1D,EAAO37B,KAAK,CACRhG,KAAM,QACNoG,QAAS,GACTuG,MAAO8xD,GAAM/W,OAAOse,EAAUA,I,MAGnC,CACHuxB,GAAS/6E,UAAYpU,EACrB,MAAMovF,EAAWD,GAASp1F,KAAKiK,GAC/B,GAAIorF,EAAU,CACV,MAAMC,EAAYD,EAAS,GACrBt5F,EAAQs5F,EAAS,GACjBvrF,EAAQuyD,GAAS9W,OAAOwvC,EAAaC,EAAmB/uF,GACxDkE,EAAMkyD,GAAS9W,OAAOwvC,EAAaC,EAAmB/uF,EAAQqvF,EAAUt8F,QAC9EwmC,EAAO37B,KAAK,CACRhG,KAAM,MACNoG,QAASlI,EACTyO,MAAO8xD,GAAM/W,OAAOz7C,EAAOK,KAE/BlE,GAASqvF,EAAUt8F,OACnBiN,EAAQkvF,GAAelrF,EAAMhE,E,CAGjC,GAAIA,EAAQgE,EAAKjR,OAAQ,CACrB,MAAMo5C,EAAOnoC,EAAK6J,UAAU7N,GACtBsvF,EAAmBxxF,MAAMyS,KAAK47B,EAAKojD,SAASC,KAClDj2D,EAAO37B,QAAQ6xF,GAAkBH,EAAkBnjD,EAAM2iD,EAAaC,EAAmB/uF,G,EAIjG8uF,IACAC,EAAmB,C,CAIvB,GAAIx1D,EAAOxmC,OAAS,GAAwC,UAAnCwmC,EAAOA,EAAOxmC,OAAS,GAAG6E,KAC/C,OAAO2hC,EAAO0qC,MAAM,GAAI,GAG5B,OAAO1qC,CACX,CA7HmBrD,CAAS,CACpB84D,MAJUU,GAASryF,GAKnBugE,WACAljE,QALsBi1F,GAAiBd,KAQ3C,OA2NJ,SAA2Bh8F,G,YACvB,MAAM+8F,EAA0Bx5B,GAAS9W,OAAOzsD,EAAQ+qE,SAAS55D,KAAMnR,EAAQ+qE,SAAS95D,WACxF,GAA8B,IAA1BjR,EAAQ0mC,OAAOxmC,OACf,OAAO,IAAI88F,GAAiB,GAAIx5B,GAAM/W,OAAOswC,EAAeA,IAEhE,MAAM53E,EAA2B,GACjC,KAAOnlB,EAAQmN,MAAQnN,EAAQ0mC,OAAOxmC,QAAQ,CAC1C,MAAMsM,EAAUywF,GAAkBj9F,EAASmlB,EAASA,EAASjlB,OAAS,IAClEsM,GACA2Y,EAASpa,KAAKyB,E,CAGtB,MAAMwE,EAAgC,QAAxBg1C,EAAW,QAAXztC,EAAA4M,EAAS,UAAE,IAAA5M,OAAA,EAAAA,EAAE7G,MAAMV,aAAK,IAAAg1C,EAAAA,EAAI+2C,EACpC1rF,EAA8C,QAAxCs+E,EAA6B,QAA7BrR,EAAAn5D,EAASA,EAASjlB,OAAS,UAAE,IAAAo+E,OAAA,EAAAA,EAAE5sE,MAAML,WAAG,IAAAs+E,EAAAA,EAAIoN,EACxD,OAAO,IAAIC,GAAiB73E,EAAUq+C,GAAM/W,OAAOz7C,EAAOK,GAC9D,CA1OW6rF,CAAkB,CACrB/vF,MAAO,EACPu5B,SACAqkC,YAER,CAiBA,SAAS8xB,GAASryF,GACd,IAAIW,EAAU,GAEVA,EADgB,kBAATX,EACGA,EAEAA,EAAKlB,KAGnB,OADc6B,EAAQi5E,MAAMvkE,GAEhC,CAUA,MAAMy8E,GAAW,2+iBACXK,GAAiB,uojBA+EvB,SAASC,GAAkB/tB,EAA0B19D,EAAcgsF,EAAmBC,GAClF,MAAM12D,EAAuB,GAE7B,GAAoB,IAAhBmoC,EAAK3uE,OAAc,CACnB,MAAM8Q,EAAQuyD,GAAS9W,OAAO0wC,EAAWC,GACnC/rF,EAAMkyD,GAAS9W,OAAO0wC,EAAWC,EAAiBjsF,EAAKjR,QAC7DwmC,EAAO37B,KAAK,CACRhG,KAAM,OACNoG,QAASgG,EACTO,MAAO8xD,GAAM/W,OAAOz7C,EAAOK,I,KAE5B,CACH,IAAIkQ,EAAY,EAChB,IAAK,MAAMta,KAAS4nE,EAAM,CACtB,MAAMwuB,EAAap2F,EAAMkG,MACnBmwF,EAAensF,EAAK6J,UAAUuG,EAAW87E,GAC3CC,EAAap9F,OAAS,GACtBwmC,EAAO37B,KAAK,CACRhG,KAAM,OACNoG,QAASgG,EAAK6J,UAAUuG,EAAW87E,GACnC3rF,MAAO8xD,GAAM/W,OACT8W,GAAS9W,OAAO0wC,EAAW57E,EAAY67E,GACvC75B,GAAS9W,OAAO0wC,EAAWE,EAAaD,MAIpD,IAAI3rF,EAAS6rF,EAAap9F,OAAS,EACnC,MAAMq9F,EAAUt2F,EAAM,GAUtB,GATAy/B,EAAO37B,KAAK,CACRhG,KAAM,aACNoG,QAASoyF,EACT7rF,MAAO8xD,GAAM/W,OACT8W,GAAS9W,OAAO0wC,EAAW57E,EAAY9P,EAAS2rF,GAChD75B,GAAS9W,OAAO0wC,EAAW57E,EAAY9P,EAAS8rF,EAAQr9F,OAASk9F,MAGzE3rF,GAAU8rF,EAAQr9F,OACG,IAAjB+G,EAAM/G,OAAc,CACpBuR,GAAUxK,EAAM,GAAG/G,OACnB,MAAM+C,EAAQgE,EAAM,GACpBy/B,EAAO37B,KAAK,CACRhG,KAAM,OACNoG,QAASlI,EACTyO,MAAO8xD,GAAM/W,OACT8W,GAAS9W,OAAO0wC,EAAW57E,EAAY9P,EAAS2rF,GAChD75B,GAAS9W,OAAO0wC,EAAW57E,EAAY9P,EAASxO,EAAM/C,OAASk9F,K,MAIvE12D,EAAO37B,KAAK,CACRhG,KAAM,OACNoG,QAAS,GACTuG,MAAO8xD,GAAM/W,OACT8W,GAAS9W,OAAO0wC,EAAW57E,EAAY9P,EAAS2rF,GAChD75B,GAAS9W,OAAO0wC,EAAW57E,EAAY9P,EAAS2rF,MAI5D77E,EAAY87E,EAAap2F,EAAM,GAAG/G,M,CAEtC,MAAMs9F,EAAarsF,EAAK6J,UAAUuG,GAC9Bi8E,EAAWt9F,OAAS,GACpBwmC,EAAO37B,KAAK,CACRhG,KAAM,OACNoG,QAASqyF,EACT9rF,MAAO8xD,GAAM/W,OACT8W,GAAS9W,OAAO0wC,EAAW57E,EAAY67E,GACvC75B,GAAS9W,OAAO0wC,EAAW57E,EAAY67E,EAAiBI,EAAWt9F,U,CAMnF,OAAOwmC,CACX,CAEA,MAAM+2D,GAAqB,KACrBC,GAAqB,OAE3B,SAASrB,GAAelrF,EAAchE,GAClC,MAAMlG,EAAQkK,EAAK6J,UAAU7N,GAAOlG,MAAMw2F,IAC1C,OAAIx2F,EACOkG,EAAQlG,EAAMkG,MAEdgE,EAAKjR,MAEpB,CAEA,SAASk8F,GAAcjrF,GACnB,MAAMlK,EAAQkK,EAAKlK,MAAMy2F,IACzB,GAAIz2F,GAAgC,kBAAhBA,EAAMkG,MACtB,OAAOlG,EAAMkG,KAGrB,CAqBA,SAAS8vF,GAAkBj9F,EAAuBwlC,GAC9C,MAAM55B,EAAO5L,EAAQ0mC,OAAO1mC,EAAQmN,OACpC,MAAkB,QAAdvB,EAAK7G,KACE44F,GAAc39F,GAAS,GACT,SAAd4L,EAAK7G,MAAiC,eAAd6G,EAAK7G,KAC7B64F,GAAe59F,IAQ9B,SAAyB+Q,EAAmBvE,GACxC,GAAIA,EAAS,CACT,MAAM2E,EAAO,IAAI0sF,GAAc,GAAI9sF,EAAMW,OACrC,YAAalF,EACbA,EAAQsxF,QAAQ/yF,KAAKoG,GAErB3E,EAAQrB,QAAQ2yF,QAAQ/yF,KAAKoG,E,CAGzC,CAfQ4sF,CAAgBnyF,EAAM45B,QACtBxlC,EAAQmN,QAGhB,CAaA,SAASywF,GAAe59F,GACpB,IAAI+Q,EAAQ/Q,EAAQ0mC,OAAO1mC,EAAQmN,OACnC,MAAM6wF,EAAajtF,EACnB,IAAIktF,EAAYltF,EAChB,MAAMorF,EAAuB,GAC7B,KAAOprF,GAAwB,UAAfA,EAAMhM,MAAmC,QAAfgM,EAAMhM,MAC5Co3F,EAAMpxF,KAAKmzF,GAAiBl+F,IAC5Bi+F,EAAYltF,EACZA,EAAQ/Q,EAAQ0mC,OAAO1mC,EAAQmN,OAEnC,OAAO,IAAIgxF,GAAchC,EAAO34B,GAAM/W,OAAOuxC,EAAWtsF,MAAMV,MAAOitF,EAAUvsF,MAAML,KACzF,CAEA,SAAS6sF,GAAiBl+F,GAEtB,MAAmB,eADLA,EAAQ0mC,OAAO1mC,EAAQmN,OAC3BpI,KACC44F,GAAc39F,GAAS,GAEvBo+F,GAAep+F,EAE9B,CAEA,SAAS29F,GAAc39F,EAAuBq+F,GAC1C,MAAMC,EAAWt+F,EAAQ0mC,OAAO1mC,EAAQmN,SAClC7L,EAAOg9F,EAASnzF,QAAQ6P,UAAU,GAClCg3B,EAAYhyC,EAAQ0mC,OAAO1mC,EAAQmN,OACzC,GAAwB,UAAX,OAAT6kC,QAAS,IAATA,OAAS,EAATA,EAAWjtC,MAAiB,CAC5B,GAAIs5F,EAAQ,CACR,MAAME,EAAUH,GAAep+F,GAC/B,OAAO,IAAIw+F,GACPl9F,EACA,IAAI68F,GAAc,CAACI,GAAUA,EAAQ7sF,OACrC2sF,EACA76B,GAAM/W,OAAO6xC,EAAS5sF,MAAMV,MAAOutF,EAAQ7sF,MAAML,K,CAElD,CACH,MAAM40E,EAAU2X,GAAe59F,GAC/B,OAAO,IAAIw+F,GACPl9F,EACA2kF,EACAoY,EACA76B,GAAM/W,OAAO6xC,EAAS5sF,MAAMV,MAAOi1E,EAAQv0E,MAAML,K,EAGtD,CACH,MAAMK,EAAQ4sF,EAAS5sF,MACvB,OAAO,IAAI8sF,GAAal9F,EAAM,IAAI68F,GAAc,GAAIzsF,GAAQ2sF,EAAQ3sF,E,CAE5E,CAEA,SAAS0sF,GAAep+F,GACpB,MAAM+Q,EAAQ/Q,EAAQ0mC,OAAO1mC,EAAQmN,SACrC,OAAO,IAAI0wF,GAAc9sF,EAAM5F,QAAS4F,EAAMW,MAClD,CAoBA,SAASorF,GAAiBj1F,GACtB,IAAKA,EACD,OAAOi1F,GAAiB,CACpB9rF,MAAO,MACPK,IAAK,KACLF,KAAM,MAGd,MAAM,MAAEH,EAAK,IAAEK,EAAG,KAAEF,GAAStJ,EAC7B,MAAO,CACHmJ,MAAOytF,GAAgBztF,GAAO,GAC9BK,IAAKotF,GAAgBptF,GAAK,GAC1BF,KAAMstF,GAAgBttF,GAAM,GAEpC,CAEA,SAASstF,GAAgBnmD,EAAqCtnC,GAC1D,GAAsB,kBAAXsnC,GAAyC,kBAAXA,EAAqB,CAC1D,MAAMomD,EAA4B,kBAAXpmD,EAAsB73B,GAAa63B,GAAUA,EAAOt3B,OAC3E,OAAIhQ,EACO,IAAI7I,OAAO,QAAD1D,OAASi6F,IAEnB,IAAIv2F,OAAO,OAAD1D,OAAQi6F,EAAO,S,CAGpC,OAAOpmD,CAEf,CAEA,MAAM0kD,GAKFz9F,WAAAA,CAAY4lB,EAA0BzT,GAClCtN,KAAK+gB,SAAWA,EAChB/gB,KAAKsN,MAAQA,CACjB,CAEAitF,MAAAA,CAAOr9F,GACH,OAAO8C,KAAKw6F,aAAa5wF,MAAKN,GAAKA,EAAEpM,OAASA,GAClD,CAEAu9F,OAAAA,CAAQv9F,GACJ,OAAO8C,KAAKw6F,aAAapxF,QAAOE,GAAKA,EAAEpM,OAASA,GACpD,CAEQs9F,UAAAA,GACJ,OAAOx6F,KAAK+gB,SAAS3X,QAAQE,GAAqB,SAAUA,GAChE,CAEAtF,QAAAA,GACI,IAAInF,EAAQ,GACZ,IAAK,MAAMuJ,KAAWpI,KAAK+gB,SACvB,GAAqB,IAAjBliB,EAAM/C,OACN+C,EAAQuJ,EAAQpE,eACb,CACH,MAAMkB,EAAOkD,EAAQpE,WACrBnF,GAAS67F,GAAa77F,GAASqG,C,CAGvC,OAAOrG,EAAMzB,MACjB,CAEAu9F,UAAAA,CAAWl3F,GACP,IAAI5E,EAAQ,GACZ,IAAK,MAAMuJ,KAAWpI,KAAK+gB,SACvB,GAAqB,IAAjBliB,EAAM/C,OACN+C,EAAQuJ,EAAQuyF,WAAWl3F,OACxB,CACH,MAAMyB,EAAOkD,EAAQuyF,WAAWl3F,GAChC5E,GAAS67F,GAAa77F,GAASqG,C,CAGvC,OAAOrG,EAAMzB,MACjB,EAGJ,MAAMg9F,GAMFj/F,WAAAA,CAAY+B,EAAc6J,EAAyBkzF,EAAiB3sF,GAChEtN,KAAK9C,KAAOA,EACZ8C,KAAK+G,QAAUA,EACf/G,KAAKi6F,OAASA,EACdj6F,KAAKsN,MAAQA,CACjB,CAEAtJ,QAAAA,GACI,IAAIkB,EAAO,IAAH7E,OAAOL,KAAK9C,MACpB,MAAM6J,EAAU/G,KAAK+G,QAAQ/C,WAM7B,OALoC,IAAhChE,KAAK+G,QAAQ2yF,QAAQ59F,OACrBoJ,EAAO,GAAH7E,OAAM6E,EAAI,KAAA7E,OAAI0G,GACX/G,KAAK+G,QAAQ2yF,QAAQ59F,OAAS,IACrCoJ,EAAO,GAAH7E,OAAM6E,EAAI,MAAA7E,OAAK0G,IAEnB/G,KAAKi6F,OAEE,IAAP55F,OAAW6E,EAAI,KAERA,CAEf,CAEAy1F,UAAAA,CAAWl3F,G,QACP,OAAiC,QAA1Bm+C,EAAkB,QAAlBztC,EAAO,OAAP1Q,QAAO,IAAPA,OAAO,EAAPA,EAASm3F,iBAAS,IAAAzmF,OAAA,EAAAA,EAAA9I,KAAA5H,EAAGzD,aAAK,IAAA4hD,EAAAA,EAAI5hD,KAAK66F,kBAAkBp3F,EAChE,CAEQo3F,iBAAAA,CAAkBp3F,GACtB,MAAMsD,EAAU/G,KAAK+G,QAAQ4zF,WAAWl3F,GACxC,GAAIzD,KAAKi6F,OAAQ,CACb,MAAMa,EA4BlB,SAAyBC,EAAah0F,EAAiBtD,G,QACnD,GAAY,cAARs3F,GAA+B,aAARA,GAA8B,SAARA,EAAgB,CAC7D,MAAMhyF,EAAQhC,EAAQ6B,QAAQ,KAC9B,IAAIoyF,EAAUj0F,EACd,GAAIgC,EAAQ,EAAG,CACX,MAAMkyF,EAAehD,GAAelxF,EAASgC,GAC7CiyF,EAAUj0F,EAAQ6P,UAAUqkF,GAC5Bl0F,EAAUA,EAAQ6P,UAAU,EAAG7N,E,EAEvB,aAARgyF,GAA+B,SAARA,GAAmC,SAAjBt3F,EAAQ4/E,QAEjD2X,EAAU,IAAH36F,OAAQ26F,EAAO,MAE1B,MAAME,EAAqD,QAAtCt5C,EAAkB,QAAlBztC,EAAA1Q,EAAQ03F,kBAAU,IAAAhnF,OAAA,EAAAA,EAAA9I,KAAA5H,EAAGsD,EAASi0F,UAAQ,IAAAp5C,EAAAA,EAMnE,SAA2B76C,EAAiBi0F,GACxC,IAEI,OADAh8B,GAAIh6D,MAAM+B,GAAS,GACZ,IAAP1G,OAAW26F,EAAO,MAAA36F,OAAK0G,EAAO,I,CAChC,MAAAoN,GACE,OAAOpN,C,CAEf,CAbuEq0F,CAAkBr0F,EAASi0F,GAC1F,OAAOE,C,CAEX,MACJ,CA7C6BG,CAAgBr7F,KAAK9C,KAAM6J,EAAgB,OAAPtD,QAAO,IAAPA,EAAAA,EAAW,CAAC,GACjE,GAAwB,kBAAbq3F,EACP,OAAOA,C,CAGf,IAAIQ,EAAS,GACQ,YAAV,OAAP73F,QAAO,IAAPA,OAAO,EAAPA,EAASs3F,WAAqCh/F,KAAV,OAAP0H,QAAO,IAAPA,OAAO,EAAPA,EAASs3F,KACtCO,EAAS,IACe,UAAV,OAAP73F,QAAO,IAAPA,OAAO,EAAPA,EAASs3F,KAChBO,EAAS,KACe,iBAAV,OAAP73F,QAAO,IAAPA,OAAO,EAAPA,EAASs3F,OAChBO,EAAS,OAEb,IAAIp2F,EAAO,GAAH7E,OAAMi7F,EAAM,KAAAj7F,OAAIL,KAAK9C,MAAImD,OAAGi7F,GAMpC,OALoC,IAAhCt7F,KAAK+G,QAAQ2yF,QAAQ59F,OACrBoJ,EAAO,GAAH7E,OAAM6E,EAAI,YAAA7E,OAAM0G,GACb/G,KAAK+G,QAAQ2yF,QAAQ59F,OAAS,IACrCoJ,EAAO,GAAH7E,OAAM6E,EAAI,MAAA7E,OAAK0G,IAEnB/G,KAAKi6F,OAEE,IAAP55F,OAAW6E,EAAI,KAERA,CAEf,EA+BJ,MAAM60F,GAIF5+F,WAAAA,CAAY48F,EAAsBzqF,GAC9BtN,KAAK05F,QAAU3B,EACf/3F,KAAKsN,MAAQA,CACjB,CAEAtJ,QAAAA,GACI,IAAIkB,EAAO,GACX,IAAK,IAAIsF,EAAI,EAAGA,EAAIxK,KAAK05F,QAAQ59F,OAAQ0O,IAAK,CAC1C,MAAMyvF,EAASj6F,KAAK05F,QAAQlvF,GACtBhD,EAAOxH,KAAK05F,QAAQlvF,EAAI,GAC9BtF,GAAQ+0F,EAAOj2F,WACXwD,GAAQA,EAAK8F,MAAMV,MAAMG,KAAOktF,EAAO3sF,MAAMV,MAAMG,OACnD7H,GAAQ,K,CAGhB,OAAOA,CACX,CAEAy1F,UAAAA,CAAWl3F,GACP,IAAIyB,EAAO,GACX,IAAK,IAAIsF,EAAI,EAAGA,EAAIxK,KAAK05F,QAAQ59F,OAAQ0O,IAAK,CAC1C,MAAMyvF,EAASj6F,KAAK05F,QAAQlvF,GACtBhD,EAAOxH,KAAK05F,QAAQlvF,EAAI,GAC9BtF,GAAQ+0F,EAAOU,WAAWl3F,GACtB+D,GAAQA,EAAK8F,MAAMV,MAAMG,KAAOktF,EAAO3sF,MAAMV,MAAMG,OACnD7H,GAAQ,K,CAGhB,OAAOA,CACX,EAGJ,MAAMu0F,GAIFt+F,WAAAA,CAAY+J,EAAcoI,GACtBtN,KAAKkF,KAAOA,EACZlF,KAAKsN,MAAQA,CACjB,CAEAtJ,QAAAA,GACI,OAAOhE,KAAKkF,IAChB,CACAy1F,UAAAA,GACI,OAAO36F,KAAKkF,IAChB,EAIJ,SAASw1F,GAAax1F,GAClB,OAAIA,EAAKwsE,SAAS,MACP,KAEA,MAEf,CCxpBM,MAAO6pB,GAKTpgG,WAAAA,CAAYy2E,GACR5xE,KAAKmpF,aAAevX,EAAS31E,OAAOqkF,UAAU8E,aAC9CplF,KAAKiqF,gBAAkBrY,EAAS9H,cAAcogB,eAClD,CAEAsR,gBAAAA,CAAiBp1F,GACb,MAAMolF,EAAUxrF,KAAKiqF,gBAAgBwB,WAAWrlF,GAChD,GAAIolF,GDgGN,SAAkBplF,EAAwB3C,GAC5C,MAAMg4F,EAAoB/C,GAAiBj1F,GACrCs0F,EAAQU,GAASryF,GACvB,GAAqB,IAAjB2xF,EAAMj8F,OACN,OAAO,EAGX,MAAMyM,EAAQwvF,EAAM,GACd32D,EAAO22D,EAAMA,EAAMj8F,OAAS,GAC5B4/F,EAAaD,EAAkB7uF,MAC/B+uF,EAAYF,EAAkBxuF,IAEpC,OAAOtF,QAAkB,OAAV+zF,QAAU,IAAVA,OAAU,EAAVA,EAAY54F,KAAKyF,KAAWZ,QAAiB,OAATg0F,QAAS,IAATA,OAAS,EAATA,EAAW74F,KAAKs+B,GACvE,CC7GuBw6D,CAAQpQ,GAAU,CAE7B,OADoBmM,GAAWnM,GACZmP,WAAW,CAC1BQ,WAAYA,CAAC9X,EAAM2X,IACRh7F,KAAK67F,0BAA0Bz1F,EAAMi9E,EAAM2X,GAEtDJ,UAAYG,GACD/6F,KAAK87F,yBAAyB11F,EAAM20F,I,CAK3D,CAEUc,yBAAAA,CAA0Bz1F,EAAelJ,EAAc89F,G,MAC7D,MAAMv9C,EAA0D,QAA5CtpC,EAAAnU,KAAK+7F,4BAA4B31F,EAAMlJ,UAAK,IAAAiX,EAAAA,EAAInU,KAAKg8F,sBAAsB51F,EAAMlJ,GACrG,GAAIugD,GAAeA,EAAY2xC,YAAa,CACxC,MAAMriF,EAAO0wC,EAAY2xC,YAAY9hF,MAAMV,MAAMG,KAAO,EAClDF,EAAY4wC,EAAY2xC,YAAY9hF,MAAMV,MAAMC,UAAY,EAC5D03D,EAAM9mB,EAAYgmC,YAAYrF,KAAK,CAAE/K,SAAU,IAAFhzE,OAAM0M,EAAI,KAAA1M,OAAIwM,KACjE,MAAO,IAAPxM,OAAW26F,EAAO,MAAA36F,OAAKkkE,EAAIvgE,WAAU,I,CAI7C,CAEU83F,wBAAAA,CAAyBG,EAAgBC,GAGnD,CAEUH,2BAAAA,CAA4B31F,EAAelJ,GACjD,MACMmsF,EADW/1E,GAAYlN,GACAw8E,kBAC7B,IAAKyG,EACD,OAEJ,IAAIC,EAAmCljF,EACvC,EAAG,CACC,MACMq3C,EADkB4rC,EAAYhqE,IAAIiqE,GACJ1/E,MAAKN,GAAKA,EAAEpM,OAASA,IACzD,GAAIugD,EACA,OAAOA,EAEX6rC,EAAcA,EAAYr2E,U,OACrBq2E,EAGb,CAEU0S,qBAAAA,CAAsB51F,EAAelJ,GAE3C,OADoB8C,KAAKmpF,aAAaU,cAAcjgF,MAAKN,GAAKA,EAAEpM,OAASA,GAE7E,ECnEE,MAAOi/F,GAEThhG,WAAAA,CAAYy2E,GACR5xE,KAAKo8F,cAAgB,IAAMxqB,EAASr2E,OAAO8gG,aAC/C,CACA5Q,UAAAA,CAAWrlF,G,MACP,OdwBF,SAA+BA,GACjC,MAAwD,kBAAzCA,EAA4BslF,QAC/C,Cc1BW4Q,CAAqBl2F,GACbA,EAAKslF,SAEiE,QAA1Ev3E,EAAAzF,EAAgBtI,EAAKgO,SAAUpU,KAAKo8F,gBAAgBG,8BAAsB,IAAApoF,OAAA,EAAAA,EAAEjP,IACvF,E,ICbaojE,G,QCUX,MAAOk0B,GAITrhG,WAAAA,CAAYy2E,GACR5xE,KAAKy8F,WAAa7qB,EAASr2E,OAAOgJ,aACtC,CAEAS,KAAAA,CAAyBE,GACrB,OAAOg2E,QAAQC,QAAQn7E,KAAKy8F,WAAWz3F,MAASE,GACpD,ECME,MAAOw3F,GAAbvhG,WAAAA,GAEY,KAAAwhG,oBAAsB,IAAIC,GAAAA,GAC1B,KAAAC,WAA0B,GAC1B,KAAAC,UAAyB,GACzB,KAAAl1F,MAAO,CA6DnB,CA3DIouF,KAAAA,CAAM91E,GACFlgB,KAAK+8F,cACL,MAAMC,EAAc,IAAIJ,GAAAA,GAExB,OADA58F,KAAK28F,oBAAsBK,EACpBh9F,KAAKi9F,QAAQj9F,KAAK68F,WAAY38E,EAAQ88E,EAAYrwF,MAC7D,CAEAuwF,IAAAA,CAAQh9E,GACJ,OAAOlgB,KAAKi9F,QAAQj9F,KAAK88F,UAAW58E,EACxC,CAEQ+8E,OAAAA,CAAkBE,EAAoBj9E,EAAuBygE,GACjE,MAAMyc,EAAW,IAAI7hB,GACf59D,EAAmB,CACrBuC,SACAk9E,WACAzc,kBAAoC,OAAjBA,QAAiB,IAAjBA,EAAAA,EAAqB5F,GAAAA,GAAkBC,MAI9D,OAFAmiB,EAAMx2F,KAAKgX,GACX3d,KAAKq9F,uBACED,EAAS5hB,OACpB,CAEQ,0BAAM6hB,GACV,IAAKr9F,KAAK4H,KACN,OAEJ,MAAMmL,EAAuB,GAC7B,GAAI/S,KAAK68F,WAAW/gG,OAAS,EAEzBiX,EAAQpM,KAAK3G,KAAK68F,WAAWS,aAC1B,MAAIt9F,KAAK88F,UAAUhhG,OAAS,GAI/B,OAFAiX,EAAQpM,QAAQ3G,KAAK88F,UAAU5iC,OAAO,EAAGl6D,KAAK88F,UAAUhhG,Q,CAI5DkE,KAAK4H,MAAO,QACNszE,QAAQgH,IAAInvE,EAAQvN,KAAInB,UAAkD,IAA3C,OAAE6b,EAAM,SAAEk9E,EAAQ,kBAAEzc,GAAmBjgE,EACxE,IAEI,MAAMtb,QAAe81E,QAAQC,UAAUoH,MAAK,IAAMriE,EAAOygE,KACzDyc,EAASjiB,QAAQ/1E,E,CACnB,MAAOK,GACDo1E,GAAqBp1E,GAErB23F,EAASjiB,aAAQp/E,GAEjBqhG,EAASvtE,OAAOpqB,E,MAI5BzF,KAAK4H,MAAO,EACZ5H,KAAKq9F,sBACT,CAEAN,WAAAA,GACI/8F,KAAK28F,oBAAoBY,QAC7B,EClEE,MAAOC,GASTriG,WAAAA,CAAYy2E,GAHO,KAAA6rB,oBAAsB,IAAI7W,GAC1B,KAAA8W,eAAiB,IAAI9W,GAGpC5mF,KAAKsd,QAAUs0D,EAAS1vE,QACxBlC,KAAK8xE,MAAQF,EAASr2E,OAAOw0B,MAC7B/vB,KAAKgzE,OAASpB,EAASqB,WAAWC,MACtC,CAEAyqB,SAAAA,CAAUv4F,GACN,MAAO,CAGHC,YAAaD,EAAOC,YAAYG,KAAI8D,GAAK5K,OAAA2lB,OAAC,CAAC,EAAI/a,KAC/ChE,aAAcF,EAAOE,aAAaE,KAAI8D,GAAK5K,OAAA2lB,OAAC,CAAC,EAAI/a,KACjDzK,MAAOmB,KAAK49F,iBAAiBx4F,EAAOvG,MAAOmB,KAAK69F,wBAAwBz4F,EAAOvG,QAEvF,CAEUg/F,uBAAAA,CAAwBz3F,GAC9B,MAAM03F,EAAW,IAAIz1F,IACf01F,EAAW,IAAI11F,IACrB,IAAK,MAAM4L,KAAWD,GAAU5N,GAC5B03F,EAAShzF,IAAImJ,EAAS,CAAC,GAE3B,GAAI7N,EAAKgO,SACL,IAAK,MAAM1R,KAAW+J,EAAUrG,EAAKgO,UACjC2pF,EAASjzF,IAAIpI,EAAS,CAAC,GAG/B,MAAO,CACHo7F,WACAC,WAER,CAEUH,gBAAAA,CAAiBx3F,EAAexK,GACtC,MAAMiK,EAAMjK,EAAQkiG,SAASz+E,IAAIjZ,GACjCP,EAAItF,MAAQ6F,EAAK7F,MACjBsF,EAAIsN,gBAAkB/M,EAAK+M,gBAC3BtN,EAAIqN,mBAAqB9M,EAAK8M,wBACRnX,IAAlBqK,EAAKgO,WACLvO,EAAIuO,SAAWpU,KAAKg+F,iBAAiB53F,EAAKgO,SAAUxY,IAExD,IAAK,MAAOsB,EAAM2B,KAAUH,OAAOqU,QAAQ3M,GACvC,IAAIlJ,EAAK8V,WAAW,KAGpB,GAAInM,MAAMC,QAAQjI,GAAQ,CACtB,MAAMo/F,EAAa,GACnBp4F,EAAI3I,GAAQ+gG,EACZ,IAAK,MAAMl/F,KAAQF,EACX+G,EAAU7G,GACVk/F,EAAIt3F,KAAK3G,KAAK49F,iBAAiB7+F,EAAMnD,IAC9BkK,EAAY/G,GACnBk/F,EAAIt3F,KAAK3G,KAAKk+F,mBAAmBn/F,EAAMnD,IAEvCqiG,EAAIt3F,KAAK5H,E,MAGV6G,EAAU/G,GACjBgH,EAAI3I,GAAQ8C,KAAK49F,iBAAiB/+F,EAAOjD,GAClCkK,EAAYjH,GACnBgH,EAAI3I,GAAQ8C,KAAKk+F,mBAAmBr/F,EAAOjD,QAC1BG,IAAV8C,IACPgH,EAAI3I,GAAQ2B,GAGpB,OAAOgH,CACX,CAEUq4F,kBAAAA,CAAmBj4F,EAAsBrK,GAC/C,MAAMiK,EAA+B,CAAC,EAKtC,OAJAA,EAAIE,SAAWE,EAAUF,SACrBE,EAAUi+E,WACVr+E,EAAIq+E,SAAWtoF,EAAQmiG,SAAS1+E,IAAIpZ,EAAUi+E,WAE3Cr+E,CACX,CAEUm4F,gBAAAA,CAAiB53F,EAAexK,GACtC,MAAM8G,EAAU9G,EAAQmiG,SAAS1+E,IAAIjZ,GAoBrC,OAnBIa,EAAcb,GACd1D,EAAQwE,SAAWd,EAAKc,SAGxBxE,EAAQ6b,cAAgBve,KAAKm+F,oBAAoB/3F,EAAKmY,eAE1D7b,EAAQmM,OAASzI,EAAKyI,OACtBnM,EAAQuR,QAAUrY,EAAQkiG,SAASz+E,IAAIjZ,EAAK6N,SACxCrN,EAAmBR,GACnB1D,EAAQqE,QAAUX,EAAKW,QAAQvB,KAAIyJ,GAASjP,KAAKg+F,iBAAiB/uF,EAAOrT,KAClEoL,EAAcZ,KACrB1D,EAAQkB,UAAYwC,EAAKxC,UAAU1G,KACnCwF,EAAQ2K,OAASjH,EAAKiH,OACtB3K,EAAQ5G,OAASsK,EAAKtK,OACtB4G,EAAQsK,UAAY5G,EAAKkH,MAAMV,MAAMG,KACrCrK,EAAQoK,YAAc1G,EAAKkH,MAAMV,MAAMC,UACvCnK,EAAQyK,QAAU/G,EAAKkH,MAAML,IAAIF,KACjCrK,EAAQwK,UAAY9G,EAAKkH,MAAML,IAAIJ,WAEhCnK,CACX,CAEA07F,OAAAA,CAAqCh5F,GACjC,MAAMgB,EAAOhB,EAAOvG,MACdjD,EAAUoE,KAAKq+F,uBAAuBj4F,GAI5C,MAHI,aAAcA,GACdpG,KAAKs+F,eAAel4F,EAAKgO,SAAUxY,GAEhC,CACHyJ,YAAaD,EAAOC,YACpBC,aAAcF,EAAOE,aACrBzG,MAAOmB,KAAKu+F,eAAen4F,EAAMxK,GAEzC,CAEUyiG,sBAAAA,CAAuBj4F,GAC7B,MAAM03F,EAAW,IAAIz1F,IACf01F,EAAW,IAAI11F,IACrB,IAAK,MAAM4L,KAAWD,GAAU5N,GAC5B03F,EAAShzF,IAAImJ,EAAS,CAAC,GAE3B,IAAIjI,EACJ,GAAI5F,EAAKgO,SACL,IAAK,MAAM1R,KAAW+J,EAAUrG,EAAKgO,UAAW,CAC5C,IAAIy2C,EACA,aAAcnoD,GACdmoD,EAAM,IAAIqkB,GAAgBxsE,EAAQwE,UAClC8E,EAAO6+C,GACA,YAAanoD,EACpBmoD,EAAM,IAAIwkB,GACH,cAAe3sE,IACtBmoD,EAAM7qD,KAAKw+F,mBAAmB97F,IAE9BmoD,IACAkzC,EAASjzF,IAAIpI,EAASmoD,GACtBA,EAAI7+C,KAAOA,E,CAIvB,MAAO,CACH8xF,WACAC,WAER,CAEUQ,cAAAA,CAAen4F,EAAWxK,GAChC,MAAMqY,EAAUrY,EAAQkiG,SAASz+E,IAAIjZ,GACrC6N,EAAQ1T,MAAQ6F,EAAK7F,MACrB0T,EAAQd,gBAAkB/M,EAAK+M,gBAC/Bc,EAAQf,mBAAqB9M,EAAK8M,mBAC9B9M,EAAKgO,WACLH,EAAQG,SAAWxY,EAAQmiG,SAAS1+E,IAAIjZ,EAAKgO,WAEjD,IAAK,MAAOlX,EAAM2B,KAAUH,OAAOqU,QAAQ3M,GACvC,IAAIlJ,EAAK8V,WAAW,KAGpB,GAAInM,MAAMC,QAAQjI,GAAQ,CACtB,MAAMo/F,EAAiB,GACvBhqF,EAAQ/W,GAAQ+gG,EAChB,IAAK,MAAMl/F,KAAQF,EACX+G,EAAU7G,GACVk/F,EAAIt3F,KAAK3G,KAAKy+F,UAAUz+F,KAAKu+F,eAAex/F,EAAMnD,GAAUqY,IACrDnO,EAAY/G,GACnBk/F,EAAIt3F,KAAK3G,KAAK0+F,iBAAiB3/F,EAAMkV,EAAS/W,EAAMtB,IAEpDqiG,EAAIt3F,KAAK5H,E,MAGV6G,EAAU/G,GACjBoV,EAAQ/W,GAAQ8C,KAAKy+F,UAAUz+F,KAAKu+F,eAAe1/F,EAAOjD,GAAUqY,GAC7DnO,EAAYjH,GACnBoV,EAAQ/W,GAAQ8C,KAAK0+F,iBAAiB7/F,EAAOoV,EAAS/W,EAAMtB,QAC3CG,IAAV8C,IACPoV,EAAQ/W,GAAQ2B,GAGxB,OAAOoV,CACX,CAEUwqF,SAAAA,CAAUr4F,EAAW0I,GAE3B,OADA1I,EAAK6M,WAAanE,EACX1I,CACX,CAEUs4F,gBAAAA,CAAiBz4F,EAAgBG,EAAelJ,EAActB,GACpE,OAAOoE,KAAKgzE,OAAO8B,eAAe1uE,EAAMlJ,EAAMtB,EAAQmiG,SAAS1+E,IAAIpZ,EAAUi+E,UAAYj+E,EAAUF,SACvG,CAEUu4F,cAAAA,CAAe57F,EAAc9G,GAAgC,IAAP+iG,EAAG9iG,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EAClE,MAAM+iG,EAAahjG,EAAQmiG,SAAS1+E,IAAI3c,GAKxC,GAJqC,kBAA1BA,EAAQ6b,gBACfqgF,EAAWrgF,cAAgBve,KAAK6+F,kBAAkBn8F,EAAQ6b,gBAE9DqgF,EAAW3qF,QAAUrY,EAAQkiG,SAASz+E,IAAI3c,EAAQuR,SAC9CrN,EAAmBg4F,GACnB,IAAK,MAAM3vF,KAASvM,EAAQqE,QAAS,CACjC,MAAM+3F,EAAW9+F,KAAKs+F,eAAervF,EAAOrT,EAAS+iG,KACrDC,EAAW73F,QAAQJ,KAAKm4F,E,CAGhC,OAAOF,CACX,CAEUJ,kBAAAA,CAAmB97F,GACzB,MAAMkB,EAAY5D,KAAK++F,aAAar8F,EAAQkB,WACtCyJ,EAAS3K,EAAQ2K,OACjBvR,EAAS4G,EAAQ5G,OACjBkR,EAAYtK,EAAQsK,UACpBF,EAAcpK,EAAQoK,YACtBK,EAAUzK,EAAQyK,QAClBD,EAAYxK,EAAQwK,UACpB2B,EAASnM,EAAQmM,OAiBvB,OAhBa,IAAI2gE,GACbniE,EACAvR,EACA,CACI8Q,MAAO,CACHG,KAAMC,EACNH,UAAWC,GAEfG,IAAK,CACDF,KAAMI,EACNN,UAAWK,IAGnBtJ,EACAiL,EAGR,CAEUkwF,YAAAA,CAAa7hG,GACnB,OAAO8C,KAAK8xE,MAAMnyD,WAAWziB,EACjC,CAEUihG,mBAAAA,CAAoB/3F,GAI1B,OAHsC,IAAlCpG,KAAKy9F,oBAAoB9yF,MACzB3K,KAAKg/F,4BAEFh/F,KAAKy9F,oBAAoBp+E,IAAIjZ,EACxC,CAEUy4F,iBAAAA,CAAkBI,GACc,IAAlCj/F,KAAKy9F,oBAAoB9yF,MACzB3K,KAAKg/F,4BAET,MAAM52F,EAAUpI,KAAKy9F,oBAAoB3W,OAAOmY,GAChD,GAAI72F,EACA,OAAOA,EAEP,MAAM,IAAI3H,MAAM,+BAAiCw+F,EAEzD,CAEUD,yBAAAA,GACN,IAAIC,EAAK,EACT,IAAK,MAAM72F,KAAW4L,GAAUhU,KAAKsd,S5HxOXve,E4HyOAqJ,E5HxOvBpJ,GAAWC,WAAWF,EAAM2Q,I4HyOvB1P,KAAKy9F,oBAAoB3yF,IAAI1C,EAAS62F,K5H1OhD,IAA4BlgG,C4H6O9B,EC3QE,SAAUzC,GAAwBV,GACpC,MAAO,CACHkuE,cAAe,CACXogB,gBAAkBtY,GAAa,IAAIuqB,GAAuBvqB,GAC1DstB,sBAAwBttB,GAAa,IAAI2pB,GAA2B3pB,IAExEr2E,OAAQ,CACJqmF,YAAchQ,GAAa,IAAI4qB,GAAmB5qB,GAClDyqB,cAAgBzqB,GC9BtB,SAA8BA,GAChC,MAAMruE,EAAkB,GAClB+Z,EAAUs0D,EAAS1vE,QACzB,IAAK,MAAMnF,KAAQugB,EAAQ/Z,MACnBwN,GAAehU,KvH8DOsjB,EuH9DoBtjB,GvH+D9B8R,SAAWuR,GAAcC,GAAcpH,KAAK,MuH/DLqD,GAAmB8D,GAAcrjB,KACpFwG,EAAMoD,KAAK5J,EAAKG,MvH6DtB,IAA4BmjB,EuH1D9B,MAAO,CACHk8E,sBAAuBh5F,EACvB47F,WAAY1wF,EAEpB,CDkByC2wF,CAAoBxtB,GACjDrtE,cAAgBqtE,GAAaiH,GAAoBjH,GACjDytB,iBAAmBztB,GEjDzB,SAAiCA,GACnC,MAAMt0D,EAAUs0D,EAAS1vE,QACnB4vE,EAAQF,EAASr2E,OAAOw0B,MACxBx0B,EAAS,IAAI45E,GAAwBvD,GAG3C,OAFAqE,GAAa34D,EAAS/hB,EAAQu2E,EAAMnyD,YACpCpkB,EAAO++D,WACA/+D,CACX,CF0C4C+jG,CAAuB1tB,GACvDn2E,eAAgBA,IAAM,IAAI+G,GAC1BhH,aAAcA,IAAM,IAAI2H,GACxB4sB,MAAQ6hD,GAAa,IAAIqlB,GAAarlB,GACtCM,2BAA4BA,IAAM,IAAIgD,IAE1CoL,UAAW,CACP8C,eAAgBA,IAAM,IAAIuM,GAC1B1I,2BAA6BrV,GAAa,IAAIqd,GAAkCrd,GAChF2jB,6BAA+B3jB,GAAa,IAAI0d,GAAoC1d,IAExFqB,WAAY,CACRC,OAAStB,GAAa,IAAIkR,GAAclR,GACxCuT,aAAcA,IAAM,IAAIN,GACxB3B,cAAgBtR,GAAa,IAAIsX,GAAqBtX,GACtD6hB,iBAAmB7hB,GAAa,IAAImV,GAAwBnV,GAC5D2tB,WAAa3tB,GAAa,IAAIqT,GAAkBrT,IAEpD4tB,WAAY,CACRC,SAAW7tB,GAAa,IAAI4rB,GAAgB5rB,GAC5C8tB,eAAiB9tB,GAAa,IAAImY,GAAsBnY,IAE5D2b,WAAY,CACRb,kBAAoB9a,GAAa,IAAIyb,GAAyBzb,GAC9Dgb,mBAAqBhb,GAAa,IAAIgb,GAAmBhb,IAE7D31E,OAAQA,IAAML,EAAQK,OAE9B,CAoBM,SAAUE,GAA8BP,GAC1C,MAAO,CACHY,gBAAiBA,IAAM,IAAI8vF,GAC3BhM,UAAW,CACP0C,iBAAmBpR,GAAa,IAAIkQ,GAAwBlQ,GAC5DqQ,uBAAyBrQ,GAAa,IAAIuO,GAA8BvO,GACxEoX,gBAAkBpX,GAAa,IAAI2f,GAAuB3f,GAC1DwT,aAAexT,GAAa,IAAI8iB,GAAoB9iB,GACpD+tB,iBAAmB/tB,GAAa,IAAI4jB,GAAwB5jB,GAC5D6O,mBAAqB7O,GAAah2E,EAAQ4kF,mBAAmB5O,GAC7DgkB,cAAeA,IAAM,IAAI8G,GACzBkD,sBAAwBhuB,GAAa,IAAIue,GAA6Bve,IAGlF,CJ1EM,SAAU11E,GACZ2jG,EAAwBC,EAAyBC,EAAyBC,EAAyBC,EAAyBC,EAAyBC,EAAyBC,EAAyBC,GAGvM,OAAOC,GADQ,CAACT,EAASC,EAASC,EAASC,EAASC,EAASC,EAASC,EAASC,EAASC,GAAS92F,OAAOg3F,GAAQ,CAAC,GAErH,EA/BA,SAAiBj4B,GACAA,EAAAk4B,MAAQ,CAA4BC,EAAmBC,IAAuBH,GAAOA,GAAO,CAAC,EAAGE,GAAKC,EACrH,CAFD,CAAiBp4B,KAAAA,GAAM,KAiCvB,MAAMq4B,GAAUl5F,OAAO,WAmBvB,SAAS64F,GAAcM,EAAsBC,GACzC,MAAMC,EAAa,IAAIC,MAAM,CAAC,EAAU,CACpCC,eAAgBA,KAAM,EACtB3hF,IAAKA,CAACxZ,EAAKod,IAASg+E,GAASp7F,EAAKod,EAAM29E,EAAQC,GAAYC,GAC5DvqC,yBAA0BA,CAAC1wD,EAAKod,KAAUg+E,GAASp7F,EAAKod,EAAM29E,EAAQC,GAAYC,GAAQpiG,OAAO63D,yBAAyB1wD,EAAKod,IAC/Hpf,IAAKA,CAACuL,EAAG6T,IAASA,KAAQ29E,EAC1BM,QAASA,IAAM,IAAIC,QAAQD,QAAQN,GAASD,MAGhD,OADAG,EAAMH,KAAW,EACVG,CACX,CAMA,MAAMM,GAAgB35F,SActB,SAASw5F,GAAep7F,EAAUod,EAAgC29E,EAAsBC,GACpF,GAAI59E,KAAQpd,EAAK,CACb,GAAIA,EAAIod,aAAiBxiB,MACrB,MAAM,IAAIA,MAAM,mFAAoF,CAAC4gG,MAAOx7F,EAAIod,KAEpH,GAAIpd,EAAIod,KAAUm+E,GACd,MAAM,IAAI3gG,MAAM,gCAAkCyb,OAAO+G,GAAQ,8FAErE,OAAOpd,EAAIod,E,CACR,GAAIA,KAAQ29E,EAAQ,CACvB,MAAM/hG,EAA+D+hG,EAAO39E,GAC5Epd,EAAIod,GAAQm+E,GACZ,IACIv7F,EAAIod,GAA0B,oBAAVpkB,EAAwBA,EAAMgiG,GAAYP,GAAQzhG,EAAOgiG,E,CAC/E,MAAOv0E,GAEL,MADAzmB,EAAIod,GAAQqJ,aAAiB7rB,MAAQ6rB,OAAQvwB,EACvCuwB,C,CAEV,OAAOzmB,EAAIod,E,CAInB,CASA,SAASs9E,GAAO3hG,EAAqBge,GACjC,GAAIA,EACA,IAAK,MAAO3R,EAAKq2F,KAAW5iG,OAAOqU,QAAQ6J,GACvC,QAAe7gB,IAAXulG,EAAsB,CACtB,MAAMC,EAAS3iG,EAAOqM,GAElBrM,EAAOqM,GADI,OAAXs2F,GAA8B,OAAXD,GAAqC,kBAAXC,GAAyC,kBAAXD,EAC7Df,GAAOgB,EAAQD,GAEfA,C,CAK9B,OAAO1iG,CACX,COpHM,MAAO4iG,GAET5gB,QAAAA,GACI,MAAM,IAAIngF,MAAM,+BACpB,CAEA,mBAAMm2F,GACF,MAAO,EACX,EAIG,MAAM56F,GAAkB,CAC3BwkF,mBAAoBA,IAAM,IAAIghB,IC9B5BC,GAAgF,CAClFv/F,QAASA,KAAyC,EAClDC,iBAAkBA,KAAA,CACdP,iBAAiB,EACjBD,eAAgB,CAAC,YACjBD,WAAY,aAIdggG,GAAkG,CACpGz/F,cAAeA,IAAM,IAAIyb,IAoBvB,SAAU1c,GAAoB2gG,G,MAChC,MAAM/vB,EAlBV,WACI,MAAM31E,EAASC,GACXC,GAA8BH,IAC9B0lG,IAEEpkF,EAAUphB,GACZI,GAAwB,CAAEL,WAC1BwlG,IAGJ,OADAxlG,EAAOO,gBAAgBC,SAAS6gB,GACzBA,CACX,CAOqBskF,GACX3tF,EAAU29D,EAAS4tB,WAAWE,eAAejV,YAAYkX,GAE/D,OADA/vB,EAAS31E,OAAOqkF,UAAU2B,uBAAuBjB,UAAU/sE,EAAS+qD,GAAIh6D,MAAM,YAAD3E,OAAyB,QAAZ8T,EAAAF,EAAQ/W,YAAI,IAAAiX,EAAAA,EAAI,UAAS,cAC5GF,CACX,C,gDCnBA,QAnBA,SAAsBnI,EAAOqf,EAAUC,GAIrC,IAHA,IAAIriB,GAAS,EACTjN,EAASgQ,EAAMhQ,SAEViN,EAAQjN,GAAQ,CACvB,IAAI+C,EAAQiN,EAAM/C,GACdq1D,EAAUjzC,EAAStsB,GAEvB,GAAe,MAAXu/D,SAAiCriE,IAAb6vB,EACfwyC,IAAYA,KAAYyjC,EAAAA,EAAAA,GAASzjC,GAClChzC,EAAWgzC,EAASxyC,IAE1B,IAAIA,EAAWwyC,EACXh5D,EAASvG,CAEjB,CACA,OAAOuG,CACT,C,kCChBA,QAJA,SAAgBvG,EAAOyJ,GACrB,OAAOzJ,EAAQyJ,CACjB,C,0DCUA,QAVA,SAAiBqD,EAAYwf,GAC3B,IAAIpiB,GAAS,EACT3D,GAASud,EAAAA,EAAAA,GAAYhX,GAAc9E,MAAM8E,EAAW7P,QAAU,GAKlE,OAHA0qB,EAAAA,EAAAA,GAAS7a,GAAY,SAAS9M,EAAOoM,EAAKU,GACxCvG,IAAS2D,GAASoiB,EAAStsB,EAAOoM,EAAKU,EACzC,IACOvG,CACT,C,iGC+BA,QAlCA,SAAiBqd,EAAQW,EAAMvkB,EAAOijG,GACpC,KAAK13C,EAAAA,EAAAA,GAAS3nC,GACZ,OAAOA,EAST,IALA,IAAI1Z,GAAS,EACTjN,GAHJsnB,GAAO2+E,EAAAA,EAAAA,GAAS3+E,EAAMX,IAGJ3mB,OACdqhB,EAAYrhB,EAAS,EACrBuK,EAASoc,EAEI,MAAVpc,KAAoB0C,EAAQjN,GAAQ,CACzC,IAAImP,GAAM+2F,EAAAA,EAAAA,GAAM5+E,EAAKra,IACjBisE,EAAWn2E,EAEf,GAAY,cAARoM,GAA+B,gBAARA,GAAiC,cAARA,EAClD,OAAOwX,EAGT,GAAI1Z,GAASoU,EAAW,CACtB,IAAI8kF,EAAW57F,EAAO4E,QAELlP,KADjBi5E,EAAW8sB,EAAaA,EAAWG,EAAUh3F,EAAK5E,QAAUtK,KAE1Di5E,GAAW5qB,EAAAA,EAAAA,GAAS63C,GAChBA,GACCC,EAAAA,EAAAA,GAAQ9+E,EAAKra,EAAQ,IAAM,GAAK,CAAC,EAE1C,EACA8Z,EAAAA,EAAAA,GAAYxc,EAAQ4E,EAAK+pE,GACzB3uE,EAASA,EAAO4E,EAClB,CACA,OAAOwX,CACT,ECnBA,QAhBA,SAAoBA,EAAQ0/E,EAAOl5F,GAKjC,IAJA,IAAIF,GAAS,EACTjN,EAASqmG,EAAMrmG,OACfsJ,EAAS,CAAC,IAEL2D,EAAQjN,GAAQ,CACvB,IAAIsnB,EAAO++E,EAAMp5F,GACblK,GAAQujG,EAAAA,EAAAA,GAAQ3/E,EAAQW,GAExBna,EAAUpK,EAAOukB,IACnBi/E,EAAQj9F,GAAQ28F,EAAAA,EAAAA,GAAS3+E,EAAMX,GAAS5jB,EAE5C,CACA,OAAOuG,CACT,C,gDCQA,QAJA,SAAevG,GACb,OAAOyjG,EAAAA,EAAAA,GAAUzjG,EA7BM,EA8BzB,C,8EC3BI0jG,EAAc7jG,OAAO0M,UAGrBmP,EAAiBgoF,EAAYhoF,eAsDjC,SA/BeuR,EAAAA,EAAAA,IAAS,SAASrJ,EAAQ+/E,GACvC//E,EAAS/jB,OAAO+jB,GAEhB,IAAI1Z,GAAS,EACTjN,EAAS0mG,EAAQ1mG,OACjBumB,EAAQvmB,EAAS,EAAI0mG,EAAQ,QAAKzmG,EAMtC,IAJIsmB,IAASuE,EAAAA,EAAAA,GAAe47E,EAAQ,GAAIA,EAAQ,GAAIngF,KAClDvmB,EAAS,KAGFiN,EAAQjN,GAMf,IALA,IAAI8gB,EAAS4lF,EAAQz5F,GACjB+Z,GAAQ2/E,EAAAA,EAAAA,GAAO7lF,GACf8lF,GAAc,EACdC,EAAc7/E,EAAMhnB,SAEf4mG,EAAaC,GAAa,CACjC,IAAI13F,EAAM6X,EAAM4/E,GACZ7jG,EAAQ4jB,EAAOxX,SAELlP,IAAV8C,IACC+jG,EAAAA,EAAAA,GAAG/jG,EAAO0jG,EAAYt3F,MAAUsP,EAAelP,KAAKoX,EAAQxX,MAC/DwX,EAAOxX,GAAO2R,EAAO3R,GAEzB,CAGF,OAAOwX,CACT,G,kECrCA,QAbA,SAAoBogF,GAClB,OAAO,SAASl3F,EAAY1C,EAAWH,GACrC,IAAIg6F,EAAWpkG,OAAOiN,GACtB,KAAKgX,EAAAA,EAAAA,GAAYhX,GAAa,CAC5B,IAAIwf,GAAWjI,EAAAA,EAAAA,GAAaja,EAAW,GACvC0C,GAAagI,EAAAA,EAAAA,GAAKhI,GAClB1C,EAAY,SAASgC,GAAO,OAAOkgB,EAAS23E,EAAS73F,GAAMA,EAAK63F,EAAW,CAC7E,CACA,IAAI/5F,EAAQ85F,EAAcl3F,EAAY1C,EAAWH,GACjD,OAAOC,GAAS,EAAI+5F,EAAS33E,EAAWxf,EAAW5C,GAASA,QAAShN,CACvE,CACF,E,wBCjBI8qB,EAAYtY,KAAKC,ICoCrB,QAFWu0F,GDGX,SAAmBj3F,EAAO7C,EAAWH,GACnC,IAAIhN,EAAkB,MAATgQ,EAAgB,EAAIA,EAAMhQ,OACvC,IAAKA,EACH,OAAQ,EAEV,IAAIiN,EAAqB,MAAbD,EAAoB,GAAIwZ,EAAAA,EAAAA,GAAUxZ,GAI9C,OAHIC,EAAQ,IACVA,EAAQ8d,EAAU/qB,EAASiN,EAAO,KAE7Bi6F,EAAAA,EAAAA,GAAcl3F,GAAOoX,EAAAA,EAAAA,GAAaja,EAAW,GAAIF,EAC1D,G,gDE/BA,QALA,SAAiB+C,GAEf,OADsB,MAATA,EAAgB,EAAIA,EAAMhQ,SACvBmwB,EAAAA,EAAAA,GAAYngB,EAAO,GAAK,EAC1C,C,iCClBA,IAGIyO,EAHc7b,OAAO0M,UAGQmP,eAcjC,QAJA,SAAiBkI,EAAQxX,GACvB,OAAiB,MAAVwX,GAAkBlI,EAAelP,KAAKoX,EAAQxX,EACvD,E,cCkBA,QAJA,SAAawX,EAAQW,GACnB,OAAiB,MAAVX,IAAkBwgF,EAAAA,EAAAA,GAAQxgF,EAAQW,EAAM8/E,EACjD,C,oECHA,QALA,SAAkBrkG,GAChB,MAAuB,iBAATA,KACViI,EAAAA,EAAAA,GAAQjI,KAAUwkB,EAAAA,EAAAA,GAAaxkB,IArBrB,oBAqB+BykB,EAAAA,EAAAA,GAAWzkB,EAC1D,C,kCCRA,QALA,SAAciN,GACZ,IAAIhQ,EAAkB,MAATgQ,EAAgB,EAAIA,EAAMhQ,OACvC,OAAOA,EAASgQ,EAAMhQ,EAAS,QAAKC,CACtC,C,4ECmCA,QALA,SAAa4P,EAAYwf,GAEvB,QADWrkB,EAAAA,EAAAA,GAAQ6E,GAAcoX,EAAAA,EAAWogF,EAAAA,GAChCx3F,GAAYuX,EAAAA,EAAAA,GAAaiI,EAAU,GACjD,C,oECtBA,QANA,SAAarf,GACX,OAAQA,GAASA,EAAMhQ,QACnBsnG,EAAAA,EAAAA,GAAat3F,EAAO8xB,EAAAA,EAAUylE,EAAAA,QAC9BtnG,CACN,C,kCCzBA,IAAIunG,EAAe,KAiBnB,QAPA,SAAyB9+B,GAGvB,IAFA,IAAIz7D,EAAQy7D,EAAO1oE,OAEZiN,KAAWu6F,EAAarqF,KAAKurD,EAAOtpC,OAAOnyB,MAClD,OAAOA,CACT,ECbA,IAAIw6F,EAAc,OAelB,QANA,SAAkB/+B,GAChB,OAAOA,EACHA,EAAOwI,MAAM,EAAGw2B,EAAgBh/B,GAAU,GAAGrnE,QAAQomG,EAAa,IAClE/+B,CACN,E,wBCRIi/B,EAAa,qBAGbC,EAAa,aAGbC,EAAY,cAGZC,EAAe/pF,SA8CnB,QArBA,SAAkBhb,GAChB,GAAoB,iBAATA,EACT,OAAOA,EAET,IAAIgjG,EAAAA,EAAAA,GAAShjG,GACX,OA1CM,IA4CR,IAAIurD,EAAAA,EAAAA,GAASvrD,GAAQ,CACnB,IAAIyJ,EAAgC,mBAAjBzJ,EAAMglG,QAAwBhlG,EAAMglG,UAAYhlG,EACnEA,GAAQurD,EAAAA,EAAAA,GAAS9hD,GAAUA,EAAQ,GAAMA,CAC3C,CACA,GAAoB,iBAATzJ,EACT,OAAiB,IAAVA,EAAcA,GAASA,EAEhCA,EAAQilG,EAASjlG,GACjB,IAAIklG,EAAWL,EAAWzqF,KAAKpa,GAC/B,OAAQklG,GAAYJ,EAAU1qF,KAAKpa,GAC/B+kG,EAAa/kG,EAAMmuE,MAAM,GAAI+2B,EAAW,EAAI,GAC3CN,EAAWxqF,KAAKpa,GAvDb,KAuD6BA,CACvC,EC1DA,IAAImlG,EAAW,IAsCf,QAZA,SAAkBnlG,GAChB,OAAKA,GAGLA,EAAQolG,EAASplG,MACHmlG,GAAYnlG,KAAU,IA9BpB,uBA+BFA,EAAQ,GAAK,EAAI,GAGxBA,IAAUA,EAAQA,EAAQ,EAPd,IAAVA,EAAcA,EAAQ,CAQjC,C,gDCJA,QAPA,SAAmBA,GACjB,IAAIuG,GAAS8+F,EAAAA,EAAAA,GAASrlG,GAClBslG,EAAY/+F,EAAS,EAEzB,OAAOA,IAAWA,EAAU++F,EAAY/+F,EAAS++F,EAAY/+F,EAAU,CACzE,C,iBC3BAs4E,EAAQ,GAA0BA,EAAQ,QAAoB,EAC9D,MAAM0mB,EAAQC,EAAQ,MAChBpgC,EAAKogC,EAAQ,MACbC,EAAWD,EAAQ,MACzB,IAAItpB,GACJ,SAAWA,GACPA,EAAkBC,KAAOt8E,OAAO6M,OAAO,CACnC+vE,yBAAyB,EACzB+Y,wBAAyBiQ,EAASp7B,MAAM8R,OAE5CD,EAAkBwpB,UAAY7lG,OAAO6M,OAAO,CACxC+vE,yBAAyB,EACzB+Y,wBAAyBiQ,EAASp7B,MAAM8R,OAQ5CD,EAAkBjgB,GANlB,SAAYj8D,GACR,MAAMmlE,EAAYnlE,EAClB,OAAOmlE,IAAcA,IAAc+W,EAAkBC,MAC9ChX,IAAc+W,EAAkBwpB,WAC/BtgC,EAAG6C,QAAQ9C,EAAUsX,4BAA8BtX,EAAUqwB,wBACzE,CAEH,CAhBD,CAgBGtZ,IAAsB2C,EAAQ,GAAoB3C,EAAoB,CAAC,IAC1E,MAAMypB,EAAgB9lG,OAAO6M,QAAO,SAAU8mE,EAAUz2E,GACpD,MAAM08D,GAAS,EAAI8rC,EAAMK,WAAWhsE,MAAM4iD,WAAWhJ,EAASoB,KAAK73E,GAAU,GAC7E,MAAO,CAAEysF,OAAAA,GAAY/vB,EAAO+vB,SAAW,EAC3C,IACA,MAAMqc,EACFvpG,WAAAA,GACI6E,KAAK2kG,cAAe,CACxB,CACApH,MAAAA,GACSv9F,KAAK2kG,eACN3kG,KAAK2kG,cAAe,EAChB3kG,KAAK4kG,WACL5kG,KAAK4kG,SAASC,UAAK9oG,GACnBiE,KAAKqoF,WAGjB,CACA,2BAAI/M,GACA,OAAOt7E,KAAK2kG,YAChB,CACA,2BAAItQ,GACA,OAAIr0F,KAAK2kG,aACEH,GAENxkG,KAAK4kG,WACN5kG,KAAK4kG,SAAW,IAAIN,EAASQ,SAE1B9kG,KAAK4kG,SAASx2B,MACzB,CACAia,OAAAA,GACQroF,KAAK4kG,WACL5kG,KAAK4kG,SAASvc,UACdroF,KAAK4kG,cAAW7oG,EAExB,EAiCJ2hF,EAAQ,GA/BR,MACI,SAAI/wE,GAMA,OALK3M,KAAK+kG,SAGN/kG,KAAK+kG,OAAS,IAAIL,GAEf1kG,KAAK+kG,MAChB,CACAxH,MAAAA,GACSv9F,KAAK+kG,OAON/kG,KAAK+kG,OAAOxH,SAHZv9F,KAAK+kG,OAAShqB,EAAkBwpB,SAKxC,CACAlc,OAAAA,GACSroF,KAAK+kG,OAID/kG,KAAK+kG,kBAAkBL,GAE5B1kG,KAAK+kG,OAAO1c,UAJZroF,KAAK+kG,OAAShqB,EAAkBC,IAMxC,E,iBCxFJt8E,OAAOC,eAAe++E,EAAS,aAAc,CAAE7+E,OAAO,IACtD6+E,EAAQonB,QAAUpnB,EAAQxU,WAAQ,EAClC,MAAMk7B,EAAQC,EAAQ,MACtB,IAAIn7B,GACJ,SAAWA,GACP,MAAM87B,EAAc,CAAE3c,OAAAA,GAAY,GAClCnf,EAAM8R,KAAO,WAAc,OAAOgqB,CAAa,CAClD,CAHD,CAGG97B,IAAUwU,EAAQxU,MAAQA,EAAQ,CAAC,IACtC,MAAM+7B,EACFl6F,GAAAA,CAAIsnE,GAAkC,IAAxBz2E,EAAOC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,KAAMqpG,EAAMrpG,UAAAC,OAAA,EAAAD,UAAA,QAAAE,EAC3BiE,KAAKmlG,aACNnlG,KAAKmlG,WAAa,GAClBnlG,KAAKolG,UAAY,IAErBplG,KAAKmlG,WAAWx+F,KAAK0rE,GACrBryE,KAAKolG,UAAUz+F,KAAK/K,GAChBiL,MAAMC,QAAQo+F,IACdA,EAAOv+F,KAAK,CAAE0hF,QAASA,IAAMroF,KAAK0yF,OAAOrgB,EAAUz2E,IAE3D,CACA82F,MAAAA,CAAOrgB,GAA0B,IAAhBz2E,EAAOC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,KACvB,IAAKmE,KAAKmlG,WACN,OAEJ,IAAIE,GAAoC,EACxC,IAAK,IAAI76F,EAAI,EAAG4tB,EAAMp4B,KAAKmlG,WAAWrpG,OAAQ0O,EAAI4tB,EAAK5tB,IACnD,GAAIxK,KAAKmlG,WAAW36F,KAAO6nE,EAAU,CACjC,GAAIryE,KAAKolG,UAAU56F,KAAO5O,EAItB,OAFAoE,KAAKmlG,WAAWjrC,OAAO1vD,EAAG,QAC1BxK,KAAKolG,UAAUlrC,OAAO1vD,EAAG,GAIzB66F,GAAoC,CAE5C,CAEJ,GAAIA,EACA,MAAM,IAAI5kG,MAAM,oFAExB,CACA6kG,MAAAA,GACI,IAAKtlG,KAAKmlG,WACN,MAAO,GAEX,MAAMh4B,EAAM,GAAI6f,EAAYhtF,KAAKmlG,WAAWn4B,MAAM,GAAIu4B,EAAWvlG,KAAKolG,UAAUp4B,MAAM,GAAG,QAAAxhE,EAAA3P,UAAAC,OAJnFivB,EAAI,IAAAlkB,MAAA2E,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAJqf,EAAIrf,GAAA7P,UAAA6P,GAKV,IAAK,IAAIlB,EAAI,EAAG4tB,EAAM40D,EAAUlxF,OAAQ0O,EAAI4tB,EAAK5tB,IAC7C,IACI2iE,EAAIxmE,KAAKqmF,EAAUxiF,GAAGwgB,MAAMu6E,EAAS/6F,GAAIugB,GAC7C,CACA,MAAOzhB,IAEH,EAAI86F,EAAMK,WAAWp4E,QAAQC,MAAMhjB,EACvC,CAEJ,OAAO6jE,CACX,CACAzlE,OAAAA,GACI,OAAQ1H,KAAKmlG,YAAyC,IAA3BnlG,KAAKmlG,WAAWrpG,MAC/C,CACAusF,OAAAA,GACIroF,KAAKmlG,gBAAappG,EAClBiE,KAAKolG,eAAYrpG,CACrB,EAEJ,MAAM+oG,EACF3pG,WAAAA,CAAYizF,GACRpuF,KAAKouF,SAAWA,CACpB,CAKA,SAAIhgB,GA6BA,OA5BKpuE,KAAKwlG,SACNxlG,KAAKwlG,OAAS,CAACvS,EAAUwS,EAAUC,KAC1B1lG,KAAKmlG,aACNnlG,KAAKmlG,WAAa,IAAIF,GAEtBjlG,KAAKouF,UAAYpuF,KAAKouF,SAASuX,oBAAsB3lG,KAAKmlG,WAAWz9F,WACrE1H,KAAKouF,SAASuX,mBAAmB3lG,MAErCA,KAAKmlG,WAAWp6F,IAAIkoF,EAAUwS,GAC9B,MAAMrgG,EAAS,CACXijF,QAASA,KACAroF,KAAKmlG,aAIVnlG,KAAKmlG,WAAWzS,OAAOO,EAAUwS,GACjCrgG,EAAOijF,QAAUyc,EAAQc,MACrB5lG,KAAKouF,UAAYpuF,KAAKouF,SAASyX,sBAAwB7lG,KAAKmlG,WAAWz9F,WACvE1H,KAAKouF,SAASyX,qBAAqB7lG,MACvC,GAMR,OAHI6G,MAAMC,QAAQ4+F,IACdA,EAAY/+F,KAAKvB,GAEdA,CAAM,GAGdpF,KAAKwlG,MAChB,CAKAX,IAAAA,CAAKz2B,GACGpuE,KAAKmlG,YACLnlG,KAAKmlG,WAAWG,OAAOj6F,KAAKrL,KAAKmlG,WAAY/2B,EAErD,CACAia,OAAAA,GACQroF,KAAKmlG,aACLnlG,KAAKmlG,WAAW9c,UAChBroF,KAAKmlG,gBAAappG,EAE1B,EAEJ2hF,EAAQonB,QAAUA,EAClBA,EAAQc,MAAQ,WAAc,C,eCpH9B,SAASphC,EAAO3lE,GACZ,MAAwB,kBAAVA,GAAsBA,aAAiBqd,MACzD,CAcA,SAASpQ,EAAMjN,GACX,OAAOgI,MAAMC,QAAQjI,EACzB,CAxBAH,OAAOC,eAAe++E,EAAS,aAAc,CAAE7+E,OAAO,IACtD6+E,EAAQooB,YAAcpoB,EAAQ5xE,MAAQ4xE,EAAQj3D,KAAOi3D,EAAQpxD,MAAQoxD,EAAQ9jE,OAAS8jE,EAAQlZ,OAASkZ,EAAQ5W,aAAU,EAIzH4W,EAAQ5W,QAHR,SAAiBjoE,GACb,OAAiB,IAAVA,IAA4B,IAAVA,CAC7B,EAKA6+E,EAAQlZ,OAASA,EAIjBkZ,EAAQ9jE,OAHR,SAAgB/a,GACZ,MAAwB,kBAAVA,GAAsBA,aAAiBklE,MACzD,EAKA2Z,EAAQpxD,MAHR,SAAeztB,GACX,OAAOA,aAAiB4B,KAC5B,EAKAi9E,EAAQj3D,KAHR,SAAc5nB,GACV,MAAwB,oBAAVA,CAClB,EAKA6+E,EAAQ5xE,MAAQA,EAIhB4xE,EAAQooB,YAHR,SAAqBjnG,GACjB,OAAOiN,EAAMjN,IAAUA,EAAMmK,OAAM+8F,GAAQvhC,EAAOuhC,IACtD,C,eC3BA,IAAIC,EACJ,SAASC,IACL,QAAalqG,IAATiqG,EACA,MAAM,IAAIvlG,MAAM,0CAEpB,OAAOulG,CACX,CAPAtnG,OAAOC,eAAe++E,EAAS,aAAc,CAAE7+E,OAAO,IAQtD,SAAWonG,GAOPA,EAAIC,QANJ,SAAiBC,GACb,QAAYpqG,IAARoqG,EACA,MAAM,IAAI1lG,MAAM,yCAEpBulG,EAAOG,CACX,CAEH,CARD,CAQGF,IAAQA,EAAM,CAAC,IAClBvoB,EAAAA,QAAkBuoB,C","sources":["../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-4YFB5VUC.mjs","../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-BI6EQKOQ.mjs","../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-EQFLFMNE.mjs","../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-FF7BQXOH.mjs","../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-NCMFTTUW.mjs","../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-Y27MQZ3U.mjs","../node_modules/@mermaid-js/parser/dist/mermaid-parser.core.mjs","../node_modules/langium/src/syntax-tree.ts","../node_modules/langium/src/utils/stream.ts","../node_modules/langium/src/utils/cst-utils.ts","../node_modules/langium/src/utils/errors.ts","../node_modules/langium/src/languages/generated/ast.ts","../node_modules/langium/src/utils/ast-utils.ts","../node_modules/@chevrotain/regexp-to-ast/src/utils.ts","../node_modules/@chevrotain/regexp-to-ast/src/character-classes.ts","../node_modules/@chevrotain/regexp-to-ast/src/regexp-parser.ts","../node_modules/@chevrotain/regexp-to-ast/src/base-regexp-visitor.ts","../node_modules/langium/src/utils/regexp-utils.ts","../node_modules/langium/src/utils/grammar-utils.ts","../node_modules/@chevrotain/utils/src/to-fast-properties.ts","../node_modules/lodash-es/_baseSlice.js","../node_modules/lodash-es/drop.js","../node_modules/lodash-es/assign.js","../node_modules/lodash-es/pickBy.js","../node_modules/lodash-es/_baseIsRegExp.js","../node_modules/lodash-es/isRegExp.js","../node_modules/@chevrotain/gast/src/model.ts","../node_modules/@chevrotain/gast/src/visitor.ts","../node_modules/lodash-es/_baseSome.js","../node_modules/lodash-es/some.js","../node_modules/lodash-es/includes.js","../node_modules/lodash-es/_arrayEvery.js","../node_modules/lodash-es/_baseEvery.js","../node_modules/lodash-es/every.js","../node_modules/@chevrotain/gast/src/helpers.ts","../node_modules/chevrotain/src/parse/grammar/rest.ts","../node_modules/lodash-es/uniq.js","../node_modules/chevrotain/src/parse/grammar/first.ts","../node_modules/chevrotain/src/parse/constants.ts","../node_modules/chevrotain/src/parse/grammar/follow.ts","../node_modules/lodash-es/negate.js","../node_modules/lodash-es/reject.js","../node_modules/lodash-es/indexOf.js","../node_modules/lodash-es/_baseDifference.js","../node_modules/lodash-es/difference.js","../node_modules/lodash-es/compact.js","../node_modules/lodash-es/head.js","../node_modules/@chevrotain/utils/src/print.ts","../node_modules/chevrotain/src/scan/reg_exp_parser.ts","../node_modules/chevrotain/src/scan/reg_exp.ts","../node_modules/chevrotain/src/scan/lexer.ts","../node_modules/@chevrotain/utils/src/timer.ts","../node_modules/chevrotain/src/scan/tokens.ts","../node_modules/chevrotain/src/scan/lexer_errors_public.ts","../node_modules/chevrotain/src/scan/lexer_public.ts","../node_modules/chevrotain/src/scan/tokens_public.ts","../node_modules/chevrotain/src/parse/errors_public.ts","../node_modules/chevrotain/src/parse/grammar/resolver.ts","../node_modules/lodash-es/flatMap.js","../node_modules/lodash-es/_arrayAggregator.js","../node_modules/lodash-es/_baseAggregator.js","../node_modules/lodash-es/_createAggregator.js","../node_modules/lodash-es/groupBy.js","../node_modules/lodash-es/dropRight.js","../node_modules/chevrotain/src/parse/grammar/interpreter.ts","../node_modules/chevrotain/src/parse/grammar/lookahead.ts","../node_modules/chevrotain/src/parse/grammar/checks.ts","../node_modules/chevrotain/src/parse/grammar/gast/gast_resolver_public.ts","../node_modules/chevrotain/src/parse/exceptions_public.ts","../node_modules/chevrotain/src/parse/parser/traits/recoverable.ts","../node_modules/chevrotain/src/parse/grammar/keys.ts","../node_modules/chevrotain/src/parse/grammar/llk_lookahead.ts","../node_modules/chevrotain/src/parse/parser/traits/looksahead.ts","../node_modules/chevrotain/src/parse/cst/cst.ts","../node_modules/chevrotain/src/lang/lang_extensions.ts","../node_modules/chevrotain/src/parse/cst/cst_visitor.ts","../node_modules/chevrotain/src/parse/parser/traits/gast_recorder.ts","../node_modules/chevrotain/src/parse/parser/parser.ts","../node_modules/chevrotain/src/parse/parser/utils/apply_mixins.ts","../node_modules/chevrotain/src/parse/parser/traits/tree_builder.ts","../node_modules/chevrotain/src/parse/parser/traits/lexer_adapter.ts","../node_modules/chevrotain/src/parse/parser/traits/recognizer_engine.ts","../node_modules/chevrotain/src/parse/parser/traits/recognizer_api.ts","../node_modules/chevrotain/src/parse/parser/traits/error_handler.ts","../node_modules/chevrotain/src/parse/parser/traits/context_assist.ts","../node_modules/chevrotain/src/parse/parser/traits/perf_tracer.ts","../node_modules/chevrotain-allstar/src/atn.ts","../node_modules/chevrotain-allstar/src/dfa.ts","../node_modules/lodash-es/uniqBy.js","../node_modules/chevrotain-allstar/src/all-star-lookahead.ts","../node_modules/vscode-languageserver-types/lib/esm/main.js","../node_modules/langium/src/parser/cst-node-builder.ts","../node_modules/langium/src/parser/langium-parser.ts","../node_modules/langium/src/parser/parser-builder-base.ts","../node_modules/langium/src/parser/langium-parser-builder.ts","../node_modules/langium/src/parser/token-builder.ts","../node_modules/langium/src/parser/value-converter.ts","../node_modules/langium/src/utils/promise-utils.ts","../node_modules/vscode-languageserver-textdocument/lib/esm/main.js","../LIB/node_modules/path-browserify/index.js","../LIB/webpack/bootstrap","../LIB/webpack/runtime/define property getters","../LIB/webpack/runtime/hasOwnProperty shorthand","../LIB/webpack/runtime/make namespace object","../LIB/src/platform.ts","../LIB/src/uri.ts","../LIB/src/utils.ts","../node_modules/langium/src/utils/uri-utils.ts","../node_modules/langium/src/workspace/documents.ts","../node_modules/langium/src/references/linker.ts","../node_modules/langium/src/references/name-provider.ts","../node_modules/langium/src/references/references.ts","../node_modules/langium/src/utils/collections.ts","../node_modules/langium/src/references/scope-computation.ts","../node_modules/langium/src/references/scope.ts","../node_modules/langium/src/utils/caching.ts","../node_modules/langium/src/references/scope-provider.ts","../node_modules/langium/src/serializer/json-serializer.ts","../node_modules/langium/src/service-registry.ts","../node_modules/langium/src/validation/validation-registry.ts","../node_modules/langium/src/validation/document-validator.ts","../node_modules/langium/src/utils/disposable.ts","../node_modules/langium/src/workspace/ast-descriptions.ts","../node_modules/langium/src/workspace/ast-node-locator.ts","../node_modules/langium/src/workspace/configuration.ts","../node_modules/langium/src/workspace/document-builder.ts","../node_modules/langium/src/workspace/index-manager.ts","../node_modules/langium/src/workspace/workspace-manager.ts","../node_modules/langium/src/parser/lexer.ts","../node_modules/langium/src/documentation/jsdoc.ts","../node_modules/langium/src/documentation/documentation-provider.ts","../node_modules/langium/src/documentation/comment-provider.ts","../node_modules/langium/src/dependency-injection.ts","../node_modules/langium/src/parser/async-parser.ts","../node_modules/langium/src/workspace/workspace-lock.ts","../node_modules/langium/src/serializer/hydrator.ts","../node_modules/langium/src/default-module.ts","../node_modules/langium/src/languages/grammar-config.ts","../node_modules/langium/src/parser/completion-parser-builder.ts","../node_modules/langium/src/workspace/file-system-provider.ts","../node_modules/langium/src/utils/grammar-loader.ts","../node_modules/lodash-es/_baseExtremum.js","../node_modules/lodash-es/_baseLt.js","../node_modules/lodash-es/_baseMap.js","../node_modules/lodash-es/_baseSet.js","../node_modules/lodash-es/_basePickBy.js","../node_modules/lodash-es/clone.js","../node_modules/lodash-es/defaults.js","../node_modules/lodash-es/_createFind.js","../node_modules/lodash-es/findIndex.js","../node_modules/lodash-es/find.js","../node_modules/lodash-es/flatten.js","../node_modules/lodash-es/_baseHas.js","../node_modules/lodash-es/has.js","../node_modules/lodash-es/isString.js","../node_modules/lodash-es/last.js","../node_modules/lodash-es/map.js","../node_modules/lodash-es/min.js","../node_modules/lodash-es/_trimmedEndIndex.js","../node_modules/lodash-es/_baseTrim.js","../node_modules/lodash-es/toNumber.js","../node_modules/lodash-es/toFinite.js","../node_modules/lodash-es/toInteger.js","../node_modules/vscode-jsonrpc/lib/common/cancellation.js","../node_modules/vscode-jsonrpc/lib/common/events.js","../node_modules/vscode-jsonrpc/lib/common/is.js","../node_modules/vscode-jsonrpc/lib/common/ral.js"],"sourcesContent":["import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  InfoGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-Y27MQZ3U.mjs\";\n\n// src/language/info/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/info/tokenBuilder.ts\nvar InfoTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"InfoTokenBuilder\");\n  }\n  constructor() {\n    super([\"info\", \"showInfo\"]);\n  }\n};\n\n// src/language/info/module.ts\nvar InfoModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new InfoTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createInfoServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Info = inject(\n    createDefaultCoreModule({ shared }),\n    InfoGeneratedModule,\n    InfoModule\n  );\n  shared.ServiceRegistry.register(Info);\n  return { shared, Info };\n}\n__name(createInfoServices, \"createInfoServices\");\n\nexport {\n  InfoModule,\n  createInfoServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  MermaidGeneratedSharedModule,\n  PieGeneratedModule,\n  __name\n} from \"./chunk-Y27MQZ3U.mjs\";\n\n// src/language/pie/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/pie/tokenBuilder.ts\nvar PieTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"PieTokenBuilder\");\n  }\n  constructor() {\n    super([\"pie\", \"showData\"]);\n  }\n};\n\n// src/language/pie/valueConverter.ts\nvar PieValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"PieValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name !== \"PIE_SECTION_LABEL\") {\n      return void 0;\n    }\n    return input.replace(/\"/g, \"\").trim();\n  }\n};\n\n// src/language/pie/module.ts\nvar PieModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new PieTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new PieValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createPieServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Pie = inject(\n    createDefaultCoreModule({ shared }),\n    PieGeneratedModule,\n    PieModule\n  );\n  shared.ServiceRegistry.register(Pie);\n  return { shared, Pie };\n}\n__name(createPieServices, \"createPieServices\");\n\nexport {\n  PieModule,\n  createPieServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  MermaidGeneratedSharedModule,\n  PacketGeneratedModule,\n  __name\n} from \"./chunk-Y27MQZ3U.mjs\";\n\n// src/language/packet/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/packet/tokenBuilder.ts\nvar PacketTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"PacketTokenBuilder\");\n  }\n  constructor() {\n    super([\"packet-beta\"]);\n  }\n};\n\n// src/language/packet/module.ts\nvar PacketModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new PacketTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createPacketServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Packet = inject(\n    createDefaultCoreModule({ shared }),\n    PacketGeneratedModule,\n    PacketModule\n  );\n  shared.ServiceRegistry.register(Packet);\n  return { shared, Packet };\n}\n__name(createPacketServices, \"createPacketServices\");\n\nexport {\n  PacketModule,\n  createPacketServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  ArchitectureGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-Y27MQZ3U.mjs\";\n\n// src/language/architecture/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/architecture/tokenBuilder.ts\nvar ArchitectureTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"ArchitectureTokenBuilder\");\n  }\n  constructor() {\n    super([\"architecture\"]);\n  }\n};\n\n// src/language/architecture/valueConverter.ts\nvar ArchitectureValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"ArchitectureValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name === \"ARCH_ICON\") {\n      return input.replace(/[()]/g, \"\").trim();\n    } else if (rule.name === \"ARCH_TEXT_ICON\") {\n      return input.replace(/[\"()]/g, \"\");\n    } else if (rule.name === \"ARCH_TITLE\") {\n      return input.replace(/[[\\]]/g, \"\").trim();\n    }\n    return void 0;\n  }\n};\n\n// src/language/architecture/module.ts\nvar ArchitectureModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new ArchitectureTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new ArchitectureValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createArchitectureServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Architecture = inject(\n    createDefaultCoreModule({ shared }),\n    ArchitectureGeneratedModule,\n    ArchitectureModule\n  );\n  shared.ServiceRegistry.register(Architecture);\n  return { shared, Architecture };\n}\n__name(createArchitectureServices, \"createArchitectureServices\");\n\nexport {\n  ArchitectureModule,\n  createArchitectureServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  GitGraphGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-Y27MQZ3U.mjs\";\n\n// src/language/gitGraph/module.ts\nimport {\n  inject,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  EmptyFileSystem\n} from \"langium\";\n\n// src/language/gitGraph/tokenBuilder.ts\nvar GitGraphTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"GitGraphTokenBuilder\");\n  }\n  constructor() {\n    super([\"gitGraph\"]);\n  }\n};\n\n// src/language/gitGraph/module.ts\nvar GitGraphModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new GitGraphTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createGitGraphServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const GitGraph = inject(\n    createDefaultCoreModule({ shared }),\n    GitGraphGeneratedModule,\n    GitGraphModule\n  );\n  shared.ServiceRegistry.register(GitGraph);\n  return { shared, GitGraph };\n}\n__name(createGitGraphServices, \"createGitGraphServices\");\n\nexport {\n  GitGraphModule,\n  createGitGraphServices\n};\n","var __defProp = Object.defineProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\n\n// src/language/generated/ast.ts\nimport { AbstractAstReflection } from \"langium\";\nvar Statement = \"Statement\";\nvar Architecture = \"Architecture\";\nfunction isArchitecture(item) {\n  return reflection.isInstance(item, Architecture);\n}\n__name(isArchitecture, \"isArchitecture\");\nvar Branch = \"Branch\";\nfunction isBranch(item) {\n  return reflection.isInstance(item, Branch);\n}\n__name(isBranch, \"isBranch\");\nvar Checkout = \"Checkout\";\nvar CherryPicking = \"CherryPicking\";\nvar Commit = \"Commit\";\nfunction isCommit(item) {\n  return reflection.isInstance(item, Commit);\n}\n__name(isCommit, \"isCommit\");\nvar Common = \"Common\";\nfunction isCommon(item) {\n  return reflection.isInstance(item, Common);\n}\n__name(isCommon, \"isCommon\");\nvar GitGraph = \"GitGraph\";\nfunction isGitGraph(item) {\n  return reflection.isInstance(item, GitGraph);\n}\n__name(isGitGraph, \"isGitGraph\");\nvar Info = \"Info\";\nfunction isInfo(item) {\n  return reflection.isInstance(item, Info);\n}\n__name(isInfo, \"isInfo\");\nvar Merge = \"Merge\";\nfunction isMerge(item) {\n  return reflection.isInstance(item, Merge);\n}\n__name(isMerge, \"isMerge\");\nvar Packet = \"Packet\";\nfunction isPacket(item) {\n  return reflection.isInstance(item, Packet);\n}\n__name(isPacket, \"isPacket\");\nvar PacketBlock = \"PacketBlock\";\nfunction isPacketBlock(item) {\n  return reflection.isInstance(item, PacketBlock);\n}\n__name(isPacketBlock, \"isPacketBlock\");\nvar Pie = \"Pie\";\nfunction isPie(item) {\n  return reflection.isInstance(item, Pie);\n}\n__name(isPie, \"isPie\");\nvar PieSection = \"PieSection\";\nfunction isPieSection(item) {\n  return reflection.isInstance(item, PieSection);\n}\n__name(isPieSection, \"isPieSection\");\nvar Direction = \"Direction\";\nvar MermaidAstReflection = class extends AbstractAstReflection {\n  static {\n    __name(this, \"MermaidAstReflection\");\n  }\n  getAllTypes() {\n    return [\"Architecture\", \"Branch\", \"Checkout\", \"CherryPicking\", \"Commit\", \"Common\", \"Direction\", \"Edge\", \"GitGraph\", \"Group\", \"Info\", \"Junction\", \"Merge\", \"Packet\", \"PacketBlock\", \"Pie\", \"PieSection\", \"Service\", \"Statement\"];\n  }\n  computeIsSubtype(subtype, supertype) {\n    switch (subtype) {\n      case Branch:\n      case Checkout:\n      case CherryPicking:\n      case Commit:\n      case Merge: {\n        return this.isSubtype(Statement, supertype);\n      }\n      case Direction: {\n        return this.isSubtype(GitGraph, supertype);\n      }\n      default: {\n        return false;\n      }\n    }\n  }\n  getReferenceType(refInfo) {\n    const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\n    switch (referenceId) {\n      default: {\n        throw new Error(`${referenceId} is not a valid reference id.`);\n      }\n    }\n  }\n  getTypeMetaData(type) {\n    switch (type) {\n      case \"Architecture\": {\n        return {\n          name: \"Architecture\",\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"edges\", defaultValue: [] },\n            { name: \"groups\", defaultValue: [] },\n            { name: \"junctions\", defaultValue: [] },\n            { name: \"services\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case \"Branch\": {\n        return {\n          name: \"Branch\",\n          properties: [\n            { name: \"name\" },\n            { name: \"order\" }\n          ]\n        };\n      }\n      case \"Checkout\": {\n        return {\n          name: \"Checkout\",\n          properties: [\n            { name: \"branch\" }\n          ]\n        };\n      }\n      case \"CherryPicking\": {\n        return {\n          name: \"CherryPicking\",\n          properties: [\n            { name: \"id\" },\n            { name: \"parent\" },\n            { name: \"tags\", defaultValue: [] }\n          ]\n        };\n      }\n      case \"Commit\": {\n        return {\n          name: \"Commit\",\n          properties: [\n            { name: \"id\" },\n            { name: \"message\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case \"Common\": {\n        return {\n          name: \"Common\",\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case \"Edge\": {\n        return {\n          name: \"Edge\",\n          properties: [\n            { name: \"lhsDir\" },\n            { name: \"lhsGroup\", defaultValue: false },\n            { name: \"lhsId\" },\n            { name: \"lhsInto\", defaultValue: false },\n            { name: \"rhsDir\" },\n            { name: \"rhsGroup\", defaultValue: false },\n            { name: \"rhsId\" },\n            { name: \"rhsInto\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case \"GitGraph\": {\n        return {\n          name: \"GitGraph\",\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case \"Group\": {\n        return {\n          name: \"Group\",\n          properties: [\n            { name: \"icon\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case \"Info\": {\n        return {\n          name: \"Info\",\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case \"Junction\": {\n        return {\n          name: \"Junction\",\n          properties: [\n            { name: \"id\" },\n            { name: \"in\" }\n          ]\n        };\n      }\n      case \"Merge\": {\n        return {\n          name: \"Merge\",\n          properties: [\n            { name: \"branch\" },\n            { name: \"id\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case \"Packet\": {\n        return {\n          name: \"Packet\",\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"blocks\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case \"PacketBlock\": {\n        return {\n          name: \"PacketBlock\",\n          properties: [\n            { name: \"end\" },\n            { name: \"label\" },\n            { name: \"start\" }\n          ]\n        };\n      }\n      case \"Pie\": {\n        return {\n          name: \"Pie\",\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"sections\", defaultValue: [] },\n            { name: \"showData\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case \"PieSection\": {\n        return {\n          name: \"PieSection\",\n          properties: [\n            { name: \"label\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case \"Service\": {\n        return {\n          name: \"Service\",\n          properties: [\n            { name: \"icon\" },\n            { name: \"iconText\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case \"Direction\": {\n        return {\n          name: \"Direction\",\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"dir\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      default: {\n        return {\n          name: type,\n          properties: []\n        };\n      }\n    }\n  }\n};\nvar reflection = new MermaidAstReflection();\n\n// src/language/generated/grammar.ts\nimport { loadGrammarFromJson } from \"langium\";\nvar loadedInfoGrammar;\nvar InfoGrammar = /* @__PURE__ */ __name(() => loadedInfoGrammar ?? (loadedInfoGrammar = loadGrammarFromJson('{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Info\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"name\":\"Info\",\"entry\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"info\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"showInfo\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"*\"}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"TitleAndAccessibilities\",\"fragment\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"fragment\":true,\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}')), \"InfoGrammar\");\nvar loadedPacketGrammar;\nvar PacketGrammar = /* @__PURE__ */ __name(() => loadedPacketGrammar ?? (loadedPacketGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Packet\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"name\":\"Packet\",\"entry\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"packet-beta\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"blocks\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"Assignment\",\"feature\":\"blocks\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"+\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PacketBlock\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"start\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"end\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"name\":\"TitleAndAccessibilities\",\"fragment\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"fragment\":true,\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}`)), \"PacketGrammar\");\nvar loadedPieGrammar;\nvar PieGrammar = /* @__PURE__ */ __name(() => loadedPieGrammar ?? (loadedPieGrammar = loadGrammarFromJson('{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Pie\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"name\":\"Pie\",\"entry\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"pie\"},{\"$type\":\"Assignment\",\"feature\":\"showData\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showData\"},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"sections\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"Assignment\",\"feature\":\"sections\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"+\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PieSection\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"PIE_SECTION_LABEL\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]+\\\\\"/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"PIE_SECTION_VALUE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/(0|[1-9][0-9]*)(\\\\\\\\.[0-9]+)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"name\":\"TitleAndAccessibilities\",\"fragment\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"fragment\":true,\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}')), \"PieGrammar\");\nvar loadedArchitectureGrammar;\nvar ArchitectureGrammar = /* @__PURE__ */ __name(() => loadedArchitectureGrammar ?? (loadedArchitectureGrammar = loadGrammarFromJson('{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Architecture\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"name\":\"Architecture\",\"entry\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"architecture-beta\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"*\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Statement\",\"fragment\":true,\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"groups\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"services\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"junctions\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"edges\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"LeftPort\",\"fragment\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"lhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"RightPort\",\"fragment\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"rhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Arrow\",\"fragment\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"lhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"--\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"-\"}]}]},{\"$type\":\"Assignment\",\"feature\":\"rhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Group\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"group\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Service\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"service\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"iconText\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Junction\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"junction\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Edge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"lhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"lhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"rhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"rhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_DIRECTION\",\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"L\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"R\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"T\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"B\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_ID\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]+/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_TEXT_ICON\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\(\\\\\"[^\\\\\"]+\\\\\"\\\\\\\\)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_ICON\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\([\\\\\\\\w-:]+\\\\\\\\)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\[[\\\\\\\\w ]+\\\\\\\\]/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_GROUP\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\{group\\\\\\\\}/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_INTO\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/<|>/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"name\":\"TitleAndAccessibilities\",\"fragment\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"fragment\":true,\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}')), \"ArchitectureGrammar\");\nvar loadedGitGraphGrammar;\nvar GitGraphGrammar = /* @__PURE__ */ __name(() => loadedGitGraphGrammar ?? (loadedGitGraphGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"GitGraph\",\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"rules\":[{\"$type\":\"ParserRule\",\"name\":\"TitleAndAccessibilities\",\"fragment\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"fragment\":true,\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false},{\"$type\":\"ParserRule\",\"name\":\"GitGraph\",\"entry\":true,\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Keyword\",\"value\":\":\"}]},{\"$type\":\"Keyword\",\"value\":\"gitGraph:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@0\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"statements\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Direction\",\"definition\":{\"$type\":\"Assignment\",\"feature\":\"dir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"LR\"},{\"$type\":\"Keyword\",\"value\":\"TB\"},{\"$type\":\"Keyword\",\"value\":\"BT\"}]}},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Commit\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"commit\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"msg:\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"message\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Branch\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"branch\"},{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"order:\"},{\"$type\":\"Assignment\",\"feature\":\"order\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Merge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"merge\"},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Checkout\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"checkout\"},{\"$type\":\"Keyword\",\"value\":\"switch\"}]},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"CherryPicking\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"cherry-pick\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"parent:\"},{\"$type\":\"Assignment\",\"feature\":\"parent\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+(?=\\\\\\\\s)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\w([-\\\\\\\\./\\\\\\\\w]*[-\\\\\\\\w])?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"imports\":[],\"types\":[],\"usedGrammars\":[]}`)), \"GitGraphGrammar\");\n\n// src/language/generated/module.ts\nvar InfoLanguageMetaData = {\n  languageId: \"info\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false\n};\nvar PacketLanguageMetaData = {\n  languageId: \"packet\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false\n};\nvar PieLanguageMetaData = {\n  languageId: \"pie\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false\n};\nvar ArchitectureLanguageMetaData = {\n  languageId: \"architecture\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false\n};\nvar GitGraphLanguageMetaData = {\n  languageId: \"gitGraph\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false\n};\nvar MermaidGeneratedSharedModule = {\n  AstReflection: /* @__PURE__ */ __name(() => new MermaidAstReflection(), \"AstReflection\")\n};\nvar InfoGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => InfoGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => InfoLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PacketGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PacketGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PacketLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PieGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PieGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PieLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar ArchitectureGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => ArchitectureGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => ArchitectureLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar GitGraphGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => GitGraphGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => GitGraphLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\n\n// src/language/common/valueConverter.ts\nimport { DefaultValueConverter } from \"langium\";\n\n// src/language/common/matcher.ts\nvar accessibilityDescrRegex = /accDescr(?:[\\t ]*:([^\\n\\r]*)|\\s*{([^}]*)})/;\nvar accessibilityTitleRegex = /accTitle[\\t ]*:([^\\n\\r]*)/;\nvar titleRegex = /title([\\t ][^\\n\\r]*|)/;\n\n// src/language/common/valueConverter.ts\nvar rulesRegexes = {\n  ACC_DESCR: accessibilityDescrRegex,\n  ACC_TITLE: accessibilityTitleRegex,\n  TITLE: titleRegex\n};\nvar AbstractMermaidValueConverter = class extends DefaultValueConverter {\n  static {\n    __name(this, \"AbstractMermaidValueConverter\");\n  }\n  runConverter(rule, input, cstNode) {\n    let value = this.runCommonConverter(rule, input, cstNode);\n    if (value === void 0) {\n      value = this.runCustomConverter(rule, input, cstNode);\n    }\n    if (value === void 0) {\n      return super.runConverter(rule, input, cstNode);\n    }\n    return value;\n  }\n  runCommonConverter(rule, input, _cstNode) {\n    const regex = rulesRegexes[rule.name];\n    if (regex === void 0) {\n      return void 0;\n    }\n    const match = regex.exec(input);\n    if (match === null) {\n      return void 0;\n    }\n    if (match[1] !== void 0) {\n      return match[1].trim().replace(/[\\t ]{2,}/gm, \" \");\n    }\n    if (match[2] !== void 0) {\n      return match[2].replace(/^\\s*/gm, \"\").replace(/\\s+$/gm, \"\").replace(/[\\t ]{2,}/gm, \" \").replace(/[\\n\\r]{2,}/gm, \"\\n\");\n    }\n    return void 0;\n  }\n};\nvar CommonValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"CommonValueConverter\");\n  }\n  runCustomConverter(_rule, _input, _cstNode) {\n    return void 0;\n  }\n};\n\n// src/language/common/tokenBuilder.ts\nimport { DefaultTokenBuilder } from \"langium\";\nvar AbstractMermaidTokenBuilder = class extends DefaultTokenBuilder {\n  static {\n    __name(this, \"AbstractMermaidTokenBuilder\");\n  }\n  constructor(keywords) {\n    super();\n    this.keywords = new Set(keywords);\n  }\n  buildKeywordTokens(rules, terminalTokens, options) {\n    const tokenTypes = super.buildKeywordTokens(rules, terminalTokens, options);\n    tokenTypes.forEach((tokenType) => {\n      if (this.keywords.has(tokenType.name) && tokenType.PATTERN !== void 0) {\n        tokenType.PATTERN = new RegExp(tokenType.PATTERN.toString() + \"(?:(?=%%)|(?!\\\\S))\");\n      }\n    });\n    return tokenTypes;\n  }\n};\nvar CommonTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"CommonTokenBuilder\");\n  }\n};\n\nexport {\n  __name,\n  Statement,\n  Architecture,\n  isArchitecture,\n  Branch,\n  isBranch,\n  Commit,\n  isCommit,\n  isCommon,\n  GitGraph,\n  isGitGraph,\n  Info,\n  isInfo,\n  Merge,\n  isMerge,\n  Packet,\n  isPacket,\n  PacketBlock,\n  isPacketBlock,\n  Pie,\n  isPie,\n  PieSection,\n  isPieSection,\n  MermaidGeneratedSharedModule,\n  InfoGeneratedModule,\n  PacketGeneratedModule,\n  PieGeneratedModule,\n  ArchitectureGeneratedModule,\n  GitGraphGeneratedModule,\n  AbstractMermaidValueConverter,\n  CommonValueConverter,\n  AbstractMermaidTokenBuilder,\n  CommonTokenBuilder\n};\n","import {\n  GitGraphModule,\n  createGitGraphServices\n} from \"./chunks/mermaid-parser.core/chunk-NCMFTTUW.mjs\";\nimport {\n  InfoModule,\n  createInfoServices\n} from \"./chunks/mermaid-parser.core/chunk-4YFB5VUC.mjs\";\nimport {\n  PacketModule,\n  createPacketServices\n} from \"./chunks/mermaid-parser.core/chunk-EQFLFMNE.mjs\";\nimport {\n  PieModule,\n  createPieServices\n} from \"./chunks/mermaid-parser.core/chunk-BI6EQKOQ.mjs\";\nimport {\n  ArchitectureModule,\n  createArchitectureServices\n} from \"./chunks/mermaid-parser.core/chunk-FF7BQXOH.mjs\";\nimport {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  Architecture,\n  ArchitectureGeneratedModule,\n  Branch,\n  Commit,\n  CommonTokenBuilder,\n  CommonValueConverter,\n  GitGraph,\n  GitGraphGeneratedModule,\n  Info,\n  InfoGeneratedModule,\n  Merge,\n  MermaidGeneratedSharedModule,\n  Packet,\n  PacketBlock,\n  PacketGeneratedModule,\n  Pie,\n  PieGeneratedModule,\n  PieSection,\n  Statement,\n  __name,\n  isArchitecture,\n  isBranch,\n  isCommit,\n  isCommon,\n  isGitGraph,\n  isInfo,\n  isMerge,\n  isPacket,\n  isPacketBlock,\n  isPie,\n  isPieSection\n} from \"./chunks/mermaid-parser.core/chunk-Y27MQZ3U.mjs\";\n\n// src/parse.ts\nvar parsers = {};\nvar initializers = {\n  info: /* @__PURE__ */ __name(async () => {\n    const { createInfoServices: createInfoServices2 } = await import(\"./chunks/mermaid-parser.core/info-46DW6VJ7.mjs\");\n    const parser = createInfoServices2().Info.parser.LangiumParser;\n    parsers.info = parser;\n  }, \"info\"),\n  packet: /* @__PURE__ */ __name(async () => {\n    const { createPacketServices: createPacketServices2 } = await import(\"./chunks/mermaid-parser.core/packet-W2GHVCYJ.mjs\");\n    const parser = createPacketServices2().Packet.parser.LangiumParser;\n    parsers.packet = parser;\n  }, \"packet\"),\n  pie: /* @__PURE__ */ __name(async () => {\n    const { createPieServices: createPieServices2 } = await import(\"./chunks/mermaid-parser.core/pie-BEWT4RHE.mjs\");\n    const parser = createPieServices2().Pie.parser.LangiumParser;\n    parsers.pie = parser;\n  }, \"pie\"),\n  architecture: /* @__PURE__ */ __name(async () => {\n    const { createArchitectureServices: createArchitectureServices2 } = await import(\"./chunks/mermaid-parser.core/architecture-I3QFYML2.mjs\");\n    const parser = createArchitectureServices2().Architecture.parser.LangiumParser;\n    parsers.architecture = parser;\n  }, \"architecture\"),\n  gitGraph: /* @__PURE__ */ __name(async () => {\n    const { createGitGraphServices: createGitGraphServices2 } = await import(\"./chunks/mermaid-parser.core/gitGraph-YCYPL57B.mjs\");\n    const parser = createGitGraphServices2().GitGraph.parser.LangiumParser;\n    parsers.gitGraph = parser;\n  }, \"gitGraph\")\n};\nasync function parse(diagramType, text) {\n  const initializer = initializers[diagramType];\n  if (!initializer) {\n    throw new Error(`Unknown diagram type: ${diagramType}`);\n  }\n  if (!parsers[diagramType]) {\n    await initializer();\n  }\n  const parser = parsers[diagramType];\n  const result = parser.parse(text);\n  if (result.lexerErrors.length > 0 || result.parserErrors.length > 0) {\n    throw new MermaidParseError(result);\n  }\n  return result.value;\n}\n__name(parse, \"parse\");\nvar MermaidParseError = class extends Error {\n  constructor(result) {\n    const lexerErrors = result.lexerErrors.map((err) => err.message).join(\"\\n\");\n    const parserErrors = result.parserErrors.map((err) => err.message).join(\"\\n\");\n    super(`Parsing failed: ${lexerErrors} ${parserErrors}`);\n    this.result = result;\n  }\n  static {\n    __name(this, \"MermaidParseError\");\n  }\n};\nexport {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  Architecture,\n  ArchitectureGeneratedModule,\n  ArchitectureModule,\n  Branch,\n  Commit,\n  CommonTokenBuilder,\n  CommonValueConverter,\n  GitGraph,\n  GitGraphGeneratedModule,\n  GitGraphModule,\n  Info,\n  InfoGeneratedModule,\n  InfoModule,\n  Merge,\n  MermaidGeneratedSharedModule,\n  MermaidParseError,\n  Packet,\n  PacketBlock,\n  PacketGeneratedModule,\n  PacketModule,\n  Pie,\n  PieGeneratedModule,\n  PieModule,\n  PieSection,\n  Statement,\n  createArchitectureServices,\n  createGitGraphServices,\n  createInfoServices,\n  createPacketServices,\n  createPieServices,\n  isArchitecture,\n  isBranch,\n  isCommit,\n  isCommon,\n  isGitGraph,\n  isInfo,\n  isMerge,\n  isPacket,\n  isPacketBlock,\n  isPie,\n  isPieSection,\n  parse\n};\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { TokenType } from 'chevrotain';\nimport type { URI } from './utils/uri-utils.js';\nimport type { AbstractElement } from './languages/generated/ast.js';\nimport type { DocumentSegment, LangiumDocument } from './workspace/documents.js';\n\n/**\n * A node in the Abstract Syntax Tree (AST).\n */\nexport interface AstNode {\n    /** Every AST node has a type corresponding to what was specified in the grammar declaration. */\n    readonly $type: string;\n    /** The container node in the AST; every node except the root node has a container. */\n    readonly $container?: AstNode;\n    /** The property of the `$container` node that contains this node. This is either a direct reference or an array. */\n    readonly $containerProperty?: string;\n    /** In case `$containerProperty` is an array, the array index is stored here. */\n    readonly $containerIndex?: number;\n    /** The Concrete Syntax Tree (CST) node of the text range from which this node was parsed. */\n    readonly $cstNode?: CstNode;\n    /** The document containing the AST; only the root node has a direct reference to the document. */\n    readonly $document?: LangiumDocument;\n}\n\nexport function isAstNode(obj: unknown): obj is AstNode {\n    return typeof obj === 'object' && obj !== null && typeof (obj as AstNode).$type === 'string';\n}\n\nexport interface GenericAstNode extends AstNode {\n    [key: string]: unknown\n}\n\ntype SpecificNodeProperties<N extends AstNode> = keyof Omit<N, keyof AstNode | number | symbol>;\n\n/**\n * The property names of a given AST node type.\n */\nexport type Properties<N extends AstNode> = SpecificNodeProperties<N> extends never ? string : SpecificNodeProperties<N>\n\n/**\n * A cross-reference in the AST. Cross-references may or may not be successfully resolved.\n */\nexport interface Reference<T extends AstNode = AstNode> {\n    /**\n     * The target AST node of this reference. Accessing this property may trigger cross-reference\n     * resolution by the `Linker` in case it has not been done yet. If the reference cannot be resolved,\n     * the value is `undefined`.\n     */\n    readonly ref?: T;\n\n    /** If any problem occurred while resolving the reference, it is described by this property. */\n    readonly error?: LinkingError;\n    /** The CST node from which the reference was parsed */\n    readonly $refNode?: CstNode;\n    /** The actual text used to look up in the surrounding scope */\n    readonly $refText: string;\n    /** The node description for the AstNode returned by `ref`  */\n    readonly $nodeDescription?: AstNodeDescription;\n}\n\nexport function isReference(obj: unknown): obj is Reference {\n    return typeof obj === 'object' && obj !== null && typeof (obj as Reference).$refText === 'string';\n}\n\nexport type ResolvedReference<T extends AstNode = AstNode> = Reference<T> & {\n    readonly ref: T;\n}\n\n/**\n * A description of an AST node is used when constructing scopes and looking up cross-reference targets.\n */\nexport interface AstNodeDescription {\n    /** The target node; should be present only for local references (linking to the same document). */\n    node?: AstNode;\n    /**\n     * The document segment that represents the range of the name of the AST node.\n     */\n    nameSegment?: DocumentSegment;\n    /**\n     * The document segment that represents the full range of the AST node.\n     */\n    selectionSegment?: DocumentSegment;\n    /** `$type` property value of the AST node */\n    type: string;\n    /** Name of the AST node; this is usually determined by the `NameProvider` service. */\n    name: string;\n    /** URI to the document containing the AST node */\n    documentUri: URI;\n    /** Navigation path inside the document */\n    path: string;\n}\n\nexport function isAstNodeDescription(obj: unknown): obj is AstNodeDescription {\n    return typeof obj === 'object' && obj !== null\n        && typeof (obj as AstNodeDescription).name === 'string'\n        && typeof (obj as AstNodeDescription).type === 'string'\n        && typeof (obj as AstNodeDescription).path === 'string';\n}\n\n/**\n * Information about a cross-reference. This is used when traversing references in an AST or to describe\n * unresolved references.\n */\nexport interface ReferenceInfo {\n    reference: Reference\n    container: AstNode\n    property: string\n    index?: number\n}\n\n/**\n * Used to collect information when the `Linker` service fails to resolve a cross-reference.\n */\nexport interface LinkingError extends ReferenceInfo {\n    message: string;\n    targetDescription?: AstNodeDescription;\n}\n\nexport function isLinkingError(obj: unknown): obj is LinkingError {\n    return typeof obj === 'object' && obj !== null\n        && isAstNode((obj as LinkingError).container)\n        && isReference((obj as LinkingError).reference)\n        && typeof (obj as LinkingError).message === 'string';\n}\n\n/**\n * Service used for generic access to the structure of the AST. This service is shared between\n * all involved languages, so it operates on the superset of types of these languages.\n */\nexport interface AstReflection {\n    getAllTypes(): string[]\n    getAllSubTypes(type: string): string[]\n    getReferenceType(refInfo: ReferenceInfo): string\n    getTypeMetaData(type: string): TypeMetaData\n    isInstance(node: unknown, type: string): boolean\n    isSubtype(subtype: string, supertype: string): boolean\n}\n\n/**\n * An abstract implementation of the {@link AstReflection} interface.\n * Serves to cache subtype computation results to improve performance throughout different parts of Langium.\n */\nexport abstract class AbstractAstReflection implements AstReflection {\n\n    protected subtypes: Record<string, Record<string, boolean | undefined>> = {};\n    protected allSubtypes: Record<string, string[] | undefined> = {};\n\n    abstract getAllTypes(): string[];\n    abstract getReferenceType(refInfo: ReferenceInfo): string;\n    abstract getTypeMetaData(type: string): TypeMetaData;\n    protected abstract computeIsSubtype(subtype: string, supertype: string): boolean;\n\n    isInstance(node: unknown, type: string): boolean {\n        return isAstNode(node) && this.isSubtype(node.$type, type);\n    }\n\n    isSubtype(subtype: string, supertype: string): boolean {\n        if (subtype === supertype) {\n            return true;\n        }\n        let nested = this.subtypes[subtype];\n        if (!nested) {\n            nested = this.subtypes[subtype] = {};\n        }\n        const existing = nested[supertype];\n        if (existing !== undefined) {\n            return existing;\n        } else {\n            const result = this.computeIsSubtype(subtype, supertype);\n            nested[supertype] = result;\n            return result;\n        }\n    }\n\n    getAllSubTypes(type: string): string[] {\n        const existing = this.allSubtypes[type];\n        if (existing) {\n            return existing;\n        } else {\n            const allTypes = this.getAllTypes();\n            const types: string[] = [];\n            for (const possibleSubType of allTypes) {\n                if (this.isSubtype(possibleSubType, type)) {\n                    types.push(possibleSubType);\n                }\n            }\n            this.allSubtypes[type] = types;\n            return types;\n        }\n    }\n}\n\n/**\n * Represents runtime meta data about a meta model type.\n */\nexport interface TypeMetaData {\n    /** The name of this meta model type. Corresponds to the `AstNode.$type` value. */\n    name: string\n    /** A list of properties. They can contain default values for their respective property in the AST. */\n    properties: TypeProperty[]\n}\n\n/**\n * Describes the meta data of a property of an AST node.\n *\n * The optional `defaultValue` indicates that the property is mandatory in the AST node.\n * For example, if an AST node contains an array, but no elements of this array have been parsed, we still expect an empty array instead of `undefined`.\n */\nexport interface TypeProperty {\n    name: string\n    defaultValue?: PropertyType\n}\n\n/**\n * Represents a default value for an AST property.\n */\nexport type PropertyType = number | string | boolean | PropertyType[];\n\n/**\n * A node in the Concrete Syntax Tree (CST).\n */\nexport interface CstNode extends DocumentSegment {\n    /** The container node in the CST */\n    readonly container?: CompositeCstNode;\n    /** @deprecated use `container` instead. */\n    readonly parent?: CompositeCstNode;\n    /** The actual text */\n    readonly text: string;\n    /** The root CST node */\n    readonly root: RootCstNode;\n    /** The grammar element from which this node was parsed */\n    readonly grammarSource: AbstractElement;\n    /** @deprecated use `grammarSource` instead. */\n    readonly feature: AbstractElement;\n    /** The AST node created from this CST node */\n    readonly astNode: AstNode;\n    /** @deprecated use `astNode` instead. */\n    readonly element: AstNode;\n    /** Whether the token is hidden, i.e. not explicitly part of the containing grammar rule */\n    readonly hidden: boolean;\n}\n\n/**\n * A composite CST node contains other nodes, but no directly associated token.\n */\nexport interface CompositeCstNode extends CstNode {\n    readonly content: CstNode[];\n    /** @deprecated use `content` instead. */\n    readonly children: CstNode[];\n}\n\nexport function isCompositeCstNode(node: unknown): node is CompositeCstNode {\n    return typeof node === 'object' && node !== null && Array.isArray((node as CompositeCstNode).content);\n}\n\n/**\n * A leaf CST node corresponds to a token in the input token stream.\n */\nexport interface LeafCstNode extends CstNode {\n    readonly tokenType: TokenType;\n}\n\nexport function isLeafCstNode(node: unknown): node is LeafCstNode {\n    return typeof node === 'object' && node !== null && typeof (node as LeafCstNode).tokenType === 'object';\n}\n\nexport interface RootCstNode extends CompositeCstNode {\n    readonly fullText: string\n}\n\nexport function isRootCstNode(node: unknown): node is RootCstNode {\n    return isCompositeCstNode(node) && typeof (node as RootCstNode).fullText === 'string';\n}\n\n/**\n * Returns a type to have only properties names (!) of a type T whose property value is of a certain type K.\n */\ntype ExtractKeysOfValueType<T, K> = { [I in keyof T]: T[I] extends K ? I : never }[keyof T];\n\n/**\n * Returns the property names (!) of an AstNode that are cross-references.\n * Meant to be used during cross-reference resolution in combination with `assertUnreachable(context.property)`.\n */\nexport type CrossReferencesOfAstNodeType<N extends AstNode> = (\n    ExtractKeysOfValueType<N, Reference|undefined>\n    | ExtractKeysOfValueType<N, Array<Reference|undefined>|undefined>\n// eslint-disable-next-line @typescript-eslint/ban-types\n) & {};\n\n/**\n * Represents the enumeration-like type, that lists all AstNode types of your grammar.\n */\nexport type AstTypeList<T> = Record<keyof T, AstNode>;\n\n/**\n * Returns all types that contain cross-references, A is meant to be the interface `XXXAstType` fromm your generated `ast.ts` file.\n * Meant to be used during cross-reference resolution in combination with `assertUnreachable(context.container)`.\n */\nexport type AstNodeTypesWithCrossReferences<A extends AstTypeList<A>> = {\n    [T in keyof A]: CrossReferencesOfAstNodeType<A[T]> extends never ? never : A[T]\n}[keyof A];\n\nexport type Mutable<T> = {\n    -readonly [P in keyof T]: T[P]\n};\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\n/**\n * A stream is a read-only sequence of values. While the contents of an array can be accessed\n * both sequentially and randomly (via index), a stream allows only sequential access.\n *\n * The advantage of this is that a stream can be evaluated lazily, so it does not require\n * to store intermediate values. This can boost performance when a large sequence is\n * processed via filtering, mapping etc. and accessed at most once. However, lazy\n * evaluation means that all processing is repeated when you access the sequence multiple\n * times; in such a case, it may be better to store the resulting sequence into an array.\n */\nexport interface Stream<T> extends Iterable<T> {\n\n    /**\n     * Returns an iterator for this stream. This is the same as calling the `Symbol.iterator` function property.\n     */\n    iterator(): IterableIterator<T>;\n\n    /**\n     * Determines whether this stream contains no elements.\n     */\n    isEmpty(): boolean;\n\n    /**\n     * Determines the number of elements in this stream.\n     */\n    count(): number;\n\n    /**\n     * Collects all elements of this stream into an array.\n     */\n    toArray(): T[];\n\n    /**\n     * Collects all elements of this stream into a Set.\n     */\n    toSet(): Set<T>;\n\n    /**\n     * Collects all elements of this stream into a Map, applying the provided functions to determine keys and values.\n     *\n     * @param keyFn The function to derive map keys. If omitted, the stream elements are used as keys.\n     * @param valueFn The function to derive map values. If omitted, the stream elements are used as values.\n     */\n    toMap<K = T, V = T>(keyFn?: (e: T) => K, valueFn?: (e: T) => V): Map<K, V>;\n\n    /**\n     * Returns a string representation of a stream.\n     */\n    toString(): string;\n\n    /**\n     * Combines two streams by returning a new stream that yields all elements of this stream and the other stream.\n     *\n     * @param other Stream to be concatenated with this one.\n     */\n    concat<T2>(other: Iterable<T2>): Stream<T | T2>;\n\n    /**\n     * Adds all elements of the stream into a string, separated by the specified separator string.\n     *\n     * @param separator A string used to separate one element of the stream from the next in the resulting string.\n     *        If omitted, the steam elements are separated with a comma.\n     */\n    join(separator?: string): string\n\n    /**\n     * Returns the index of the first occurrence of a value in the stream, or -1 if it is not present.\n     *\n     * @param searchElement The value to locate in the array.\n     * @param fromIndex The stream index at which to begin the search. If fromIndex is omitted, the search\n     *        starts at index 0.\n     */\n    indexOf(searchElement: T, fromIndex?: number): number;\n\n    /**\n     * Determines whether all members of the stream satisfy the specified test.\n     *\n     * @param predicate This method calls the predicate function for each element in the stream until the\n     *        predicate returns a value which is coercible to the Boolean value `false`, or until the end\n     *        of the stream.\n     */\n    every<S extends T>(predicate: (value: T) => value is S): this is Stream<S>;\n    every(predicate: (value: T) => unknown): boolean;\n\n    /**\n     * Determines whether any member of the stream satisfies the specified test.\n     *\n     * @param predicate This method calls the predicate function for each element in the stream until the\n     *        predicate returns a value which is coercible to the Boolean value `true`, or until the end\n     *        of the stream.\n     */\n    some(predicate: (value: T) => unknown): boolean;\n\n    /**\n     * Performs the specified action for each element in the stream.\n     *\n     * @param callbackfn Function called once for each element in the stream.\n     */\n    forEach(callbackfn: (value: T, index: number) => void): void;\n\n    /**\n     * Returns a stream that yields the results of calling the specified callback function on each element\n     * of the stream. The function is called when the resulting stream elements are actually accessed, so\n     * accessing the resulting stream multiple times means the function is also called multiple times for\n     * each element of the stream.\n     *\n     * @param callbackfn Lazily evaluated function mapping stream elements.\n     */\n    map<U>(callbackfn: (value: T) => U): Stream<U>;\n\n    /**\n     * Returns the elements of the stream that meet the condition specified in a callback function.\n     * The function is called when the resulting stream elements are actually accessed, so accessing the\n     * resulting stream multiple times means the function is also called multiple times for each element\n     * of the stream.\n     *\n     * @param predicate Lazily evaluated function checking a condition on stream elements.\n     */\n    filter<S extends T>(predicate: (value: T) => value is S): Stream<S>;\n    filter(predicate: (value: T) => unknown): Stream<T>;\n\n    /**\n     * Returns the elements of the stream that are _non-nullable_, which means they are neither `undefined`\n     * nor `null`.\n     */\n    nonNullable(): Stream<NonNullable<T>>;\n\n    /**\n     * Calls the specified callback function for all elements in the stream. The return value of the\n     * callback function is the accumulated result, and is provided as an argument in the next call to\n     * the callback function.\n     *\n     * @param callbackfn This method calls the function once for each element in the stream, providing\n     *        the previous and current values of the reduction.\n     * @param initialValue If specified, `initialValue` is used as the initial value to start the\n     *        accumulation. The first call to the function provides this value as an argument instead\n     *        of a stream value.\n     */\n    reduce(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\n    reduce<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\n\n    /**\n     * Calls the specified callback function for all elements in the stream, in descending order.\n     * The return value of the callback function is the accumulated result, and is provided as an\n     * argument in the next call to the callback function.\n     *\n     * @param callbackfn This method calls the function once for each element in the stream, providing\n     *        the previous and current values of the reduction.\n     * @param initialValue If specified, `initialValue` is used as the initial value to start the\n     *        accumulation. The first call to the function provides this value as an argument instead\n     *        of an array value.\n     */\n    reduceRight(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\n    reduceRight<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\n\n    /**\n     * Returns the value of the first element in the stream that meets the condition, or `undefined`\n     * if there is no such element.\n     *\n     * @param predicate This method calls `predicate` once for each element of the stream, in ascending\n     *        order, until it finds one where `predicate` returns a value which is coercible to the\n     *        Boolean value `true`.\n     */\n    find<S extends T>(predicate: (value: T) => value is S): S | undefined;\n    find(predicate: (value: T) => unknown): T | undefined;\n\n    /**\n     * Returns the index of the first element in the stream that meets the condition, or `-1`\n     * if there is no such element.\n     *\n     * @param predicate This method calls `predicate` once for each element of the stream, in ascending\n     *        order, until it finds one where `predicate` returns a value which is coercible to the\n     *        Boolean value `true`.\n     */\n    findIndex(predicate: (value: T) => unknown): number;\n\n    /**\n     * Determines whether the stream includes a certain element, returning `true` or `false` as appropriate.\n     *\n     * @param searchElement The element to search for.\n     */\n    includes(searchElement: T): boolean;\n\n    /**\n     * Calls a defined callback function on each element of the stream and then flattens the result into\n     * a new stream. This is identical to a `map` followed by `flat` with depth 1.\n     *\n     * @param callbackfn Lazily evaluated function mapping stream elements.\n     */\n    flatMap<U>(callbackfn: (value: T) => U | Iterable<U>): Stream<U>;\n\n    /**\n     * Returns a new stream with all sub-stream or sub-array elements concatenated into it recursively up\n     * to the specified depth.\n     *\n     * @param depth The maximum recursion depth. Defaults to 1.\n     */\n    flat<D extends number = 1>(depth?: D): FlatStream<T, D>;\n\n    /**\n     * Returns the first element in the stream, or `undefined` if the stream is empty.\n     */\n    head(): T | undefined;\n\n    /**\n     * Returns a stream that skips the first `skipCount` elements from this stream.\n     *\n     * @param skipCount The number of elements to skip. If this is larger than the number of elements in\n     *        the stream, an empty stream is returned. Defaults to 1.\n     */\n    tail(skipCount?: number): Stream<T>;\n\n    /**\n     * Returns a stream consisting of the elements of this stream, truncated to be no longer than `maxSize`\n     * in length.\n     *\n     * @param maxSize The number of elements the stream should be limited to\n     */\n    limit(maxSize: number): Stream<T>;\n\n    /**\n     * Returns a stream containing only the distinct elements from this stream.\n     * Equality is determined with the same rules as a standard `Set`.\n     *\n     * @param by A function returning the key used to check equality with a previous stream element.\n     *        If omitted, the stream elements themselves are used for comparison.\n     */\n    distinct<Key = T>(by?: (element: T) => Key): Stream<T>;\n\n    /**\n     * Returns a stream that contains all elements that don't exist in the {@link other} iterable.\n     * Equality is determined with the same rules as a standard `Set`.\n     * @param other The elements that should be exluded from this stream.\n     * @param key A function returning the key used to check quality.\n     *        If omitted, the stream elements themselves are used for comparison.\n     */\n    exclude<Key = T>(other: Iterable<T>, key?: (element: T) => Key): Stream<T>;\n\n}\n\nexport type FlatStream<T, Depth extends number> = {\n    'done': Stream<T>,\n    'recur': T extends Iterable<infer Content>\n        ? FlatStream<Content, MinusOne<Depth>>\n        : Stream<T>\n}[Depth extends 0 ? 'done' : 'recur'];\n\nexport type MinusOne<N extends number> = [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20][N];\n\n/**\n * The default implementation of `Stream` works with two input functions:\n *  - The first function creates the initial state of an iteration.\n *  - The second function gets the current state as argument and returns an `IteratorResult`.\n */\nexport class StreamImpl<S, T> implements Stream<T> {\n    protected readonly startFn: () => S;\n    protected readonly nextFn: (state: S) => IteratorResult<T>;\n\n    constructor(startFn: () => S, nextFn: (state: S) => IteratorResult<T, undefined>) {\n        this.startFn = startFn;\n        this.nextFn = nextFn;\n    }\n\n    iterator(): IterableIterator<T> {\n        const iterator = {\n            state: this.startFn(),\n            next: () => this.nextFn(iterator.state),\n            [Symbol.iterator]: () => iterator\n        };\n        return iterator;\n    }\n\n    [Symbol.iterator](): Iterator<T> {\n        return this.iterator();\n    }\n\n    isEmpty(): boolean {\n        const iterator = this.iterator();\n        return Boolean(iterator.next().done);\n    }\n\n    count(): number {\n        const iterator = this.iterator();\n        let count = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            count++;\n            next = iterator.next();\n        }\n        return count;\n    }\n\n    toArray(): T[] {\n        const result: T[] = [];\n        const iterator = this.iterator();\n        let next: IteratorResult<T>;\n        do {\n            next = iterator.next();\n            if (next.value !== undefined) {\n                result.push(next.value);\n            }\n        } while (!next.done);\n        return result;\n    }\n\n    toSet(): Set<T> {\n        return new Set(this);\n    }\n\n    toMap<K = T, V = T>(keyFn?: (e: T) => K, valueFn?: (e: T) => V): Map<K, V> {\n        const entryStream = this.map(element => <[K, V]>[\n            keyFn ? keyFn(element) : element,\n            valueFn ? valueFn(element) : element\n        ]);\n        return new Map(entryStream);\n    }\n\n    toString(): string {\n        return this.join();\n    }\n\n    concat<T2>(other: Iterable<T2>): Stream<T | T2> {\n        const iterator = other[Symbol.iterator]();\n        return new StreamImpl<{ first: S, firstDone: boolean }, T | T2>(\n            () => ({ first: this.startFn(), firstDone: false }),\n            state => {\n                let result: IteratorResult<T | T2>;\n                if (!state.firstDone) {\n                    do {\n                        result = this.nextFn(state.first);\n                        if (!result.done) {\n                            return result;\n                        }\n                    } while (!result.done);\n                    state.firstDone = true;\n                }\n                do {\n                    result = iterator.next();\n                    if (!result.done) {\n                        return result;\n                    }\n                } while (!result.done);\n                return DONE_RESULT;\n            }\n        );\n    }\n\n    join(separator = ','): string {\n        const iterator = this.iterator();\n        let value = '';\n        let result: IteratorResult<T>;\n        let addSeparator = false;\n        do {\n            result = iterator.next();\n            if (!result.done) {\n                if (addSeparator) {\n                    value += separator;\n                }\n                value += toString(result.value);\n            }\n            addSeparator = true;\n        } while (!result.done);\n        return value;\n    }\n\n    indexOf(searchElement: T, fromIndex = 0): number {\n        const iterator = this.iterator();\n        let index = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            if (index >= fromIndex && next.value === searchElement) {\n                return index;\n            }\n            next = iterator.next();\n            index++;\n        }\n        return -1;\n    }\n\n    // In the following definition the '& this' part in the return type is important\n    // _and_ the order within 'Stream<U> & this' is crucial!\n    // Otherwise Typescript would infer the type of 'this' as 'StreamImpl<S, T> & Stream<U>'\n    // (or '<subClass of StreamImpl<S, T> & Stream<U>') and usages like\n    // ```\n    //  const stream = new StreamImpl(...);\n    //  ... stream.every(<typeGuard>) & stream....\n    // ```\n    // cannot benefit from '<typeGuard>', as Typescript would priorize the signatures\n    // of 'StreamImpl<S, T>' (i.e. those of 'Stream<T>') over those of 'Stream<U>'.\n    // With the order of 'Stream<U> & this' the signatures of 'Stream<U>' get precedence.\n    every<U extends T>(predicate: (value: T) => value is U): this is Stream<U> & this;\n    every(predicate: (value: T) => unknown): boolean;\n    every(predicate: (value: T) => unknown): boolean {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (!predicate(next.value)) {\n                return false;\n            }\n            next = iterator.next();\n        }\n        return true;\n    }\n\n    some(predicate: (value: T) => unknown): boolean {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (predicate(next.value)) {\n                return true;\n            }\n            next = iterator.next();\n        }\n        return false;\n    }\n\n    forEach(callbackfn: (value: T, index: number) => void): void {\n        const iterator = this.iterator();\n        let index = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            callbackfn(next.value, index);\n            next = iterator.next();\n            index++;\n        }\n    }\n\n    map<U>(callbackfn: (value: T) => U): Stream<U> {\n        return new StreamImpl<S, U>(\n            this.startFn,\n            (state) => {\n                const { done, value } = this.nextFn(state);\n                if (done) {\n                    return DONE_RESULT;\n                } else {\n                    return { done: false, value: callbackfn(value) };\n                }\n            }\n        );\n    }\n\n    // for remarks on the return type definition refer to 'every<U extends T>(...)'\n    filter<U extends T>(predicate: (value: T) => value is U): Stream<U> & this;\n    filter(predicate: (value: T) => unknown): Stream<T> & this;\n    filter(predicate: (value: T) => unknown): Stream<T> {\n        return new StreamImpl<S, T>(\n            this.startFn,\n            state => {\n                let result: IteratorResult<T>;\n                do {\n                    result = this.nextFn(state);\n                    if (!result.done && predicate(result.value)) {\n                        return result;\n                    }\n                } while (!result.done);\n                return DONE_RESULT;\n            }\n        );\n    }\n\n    nonNullable(): Stream<NonNullable<T>> {\n        return this.filter(e => e !== undefined && e !== null) as Stream<NonNullable<T>>;\n    }\n\n    reduce(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\n    reduce<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\n    reduce<U>(callbackfn: (previousValue: U | T, currentValue: T) => U, initialValue?: U): U | T | undefined {\n        const iterator = this.iterator();\n        let previousValue: U | T | undefined = initialValue;\n        let next = iterator.next();\n        while (!next.done) {\n            if (previousValue === undefined) {\n                previousValue = next.value;\n            } else {\n                previousValue = callbackfn(previousValue, next.value);\n            }\n            next = iterator.next();\n        }\n        return previousValue;\n    }\n\n    reduceRight(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\n    reduceRight<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\n    reduceRight<U>(callbackfn: (previousValue: U | T, currentValue: T) => U, initialValue?: U): U | T | undefined {\n        return this.recursiveReduce(this.iterator(), callbackfn, initialValue);\n    }\n\n    protected recursiveReduce<U>(iterator: Iterator<T>, callbackfn: (previousValue: U | T, currentValue: T) => U, initialValue?: U): U | T | undefined {\n        const next = iterator.next();\n        if (next.done) {\n            return initialValue;\n        }\n        const previousValue = this.recursiveReduce(iterator, callbackfn, initialValue);\n        if (previousValue === undefined) {\n            return next.value;\n        }\n        return callbackfn(previousValue, next.value);\n    }\n\n    find<S extends T>(predicate: (value: T) => value is S): S | undefined;\n    find(predicate: (value: T) => unknown): T | undefined;\n    find(predicate: (value: T) => unknown): T | undefined {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (predicate(next.value)) {\n                return next.value;\n            }\n            next = iterator.next();\n        }\n        return undefined;\n    }\n\n    findIndex(predicate: (value: T) => unknown): number {\n        const iterator = this.iterator();\n        let index = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            if (predicate(next.value)) {\n                return index;\n            }\n            next = iterator.next();\n            index++;\n        }\n        return -1;\n    }\n\n    includes(searchElement: T): boolean {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (next.value === searchElement) {\n                return true;\n            }\n            next = iterator.next();\n        }\n        return false;\n    }\n\n    flatMap<U>(callbackfn: (value: T) => U | Iterable<U>): Stream<U> {\n        type FlatMapState = { this: S, iterator?: Iterator<U, undefined> }\n        return new StreamImpl<FlatMapState, U>(\n            () => ({ this: this.startFn() }),\n            (state) => {\n                do {\n                    if (state.iterator) {\n                        const next = state.iterator.next();\n                        if (next.done) {\n                            state.iterator = undefined;\n                        } else {\n                            return next;\n                        }\n                    }\n                    const { done, value } = this.nextFn(state.this);\n                    if (!done) {\n                        const mapped = callbackfn(value);\n                        if (isIterable(mapped)) {\n                            state.iterator = mapped[Symbol.iterator]();\n                        } else {\n                            return { done: false, value: mapped };\n                        }\n                    }\n                } while (state.iterator);\n                return DONE_RESULT;\n            }\n        );\n    }\n\n    flat<D extends number = 1>(depth?: D): FlatStream<T, D> {\n        if (depth === undefined) {\n            depth = 1 as D;\n        }\n        if (depth <= 0) {\n            return this as unknown as FlatStream<T, D>;\n        }\n        const stream = depth > 1 ? this.flat(depth - 1) as unknown as StreamImpl<S, T> : this;\n        type FlatMapState = { this: S, iterator?: Iterator<T, undefined> }\n        return new StreamImpl<FlatMapState, T>(\n            () => ({ this: stream.startFn() }),\n            (state) => {\n                do {\n                    if (state.iterator) {\n                        const next = state.iterator.next();\n                        if (next.done) {\n                            state.iterator = undefined;\n                        } else {\n                            return next;\n                        }\n                    }\n                    const { done, value } = stream.nextFn(state.this);\n                    if (!done) {\n                        if (isIterable(value)) {\n                            state.iterator = value[Symbol.iterator]() as Iterator<T>;\n                        } else {\n                            return { done: false, value: value };\n                        }\n                    }\n                } while (state.iterator);\n                return DONE_RESULT;\n            }\n        ) as unknown as FlatStream<T, D>;\n    }\n\n    head(): T | undefined {\n        const iterator = this.iterator();\n        const result = iterator.next();\n        if (result.done) {\n            return undefined;\n        }\n        return result.value;\n    }\n\n    tail(skipCount = 1): Stream<T> {\n        return new StreamImpl<S, T>(\n            () => {\n                const state = this.startFn();\n                for (let i = 0; i < skipCount; i++) {\n                    const next = this.nextFn(state);\n                    if (next.done) {\n                        return state;\n                    }\n                }\n                return state;\n            },\n            this.nextFn\n        );\n    }\n\n    limit(maxSize: number): Stream<T> {\n        return new StreamImpl<{ size: number, state: S }, T>(\n            () => ({ size: 0, state: this.startFn() }),\n            state => {\n                state.size++;\n                if (state.size > maxSize) {\n                    return DONE_RESULT;\n                }\n                return this.nextFn(state.state);\n            }\n        );\n    }\n\n    distinct<Key = T>(by?: (element: T) => Key): Stream<T> {\n        const set = new Set<T | Key>();\n        return this.filter(e => {\n            const value = by ? by(e) : e;\n            if (set.has(value)) {\n                return false;\n            } else {\n                set.add(value);\n                return true;\n            }\n        });\n    }\n\n    exclude<Key = T>(other: Iterable<T>, key?: (element: T) => Key): Stream<T> {\n        const otherKeySet = new Set<Key | T>();\n        for (const item of other) {\n            const value = key ? key(item) : item;\n            otherKeySet.add(value);\n        }\n        return this.filter(e => {\n            const ownKey = key ? key(e) : e;\n            return !otherKeySet.has(ownKey);\n        });\n    }\n}\n\nfunction toString(item: unknown): string {\n    if (typeof item === 'string') {\n        return item as string;\n    }\n    if (typeof item === 'undefined') {\n        return 'undefined';\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    if (typeof (item as any).toString === 'function') {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        return (item as any).toString();\n    }\n    return Object.prototype.toString.call(item);\n}\n\nfunction isIterable<T>(obj: unknown): obj is Iterable<T> {\n    return !!obj && typeof (obj as Iterable<T>)[Symbol.iterator] === 'function';\n}\n\n/**\n * An empty stream of any type.\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nexport const EMPTY_STREAM: Stream<any> = new StreamImpl<undefined, any>(() => undefined, () => DONE_RESULT);\n\n/**\n * Use this `IteratorResult` when implementing a `StreamImpl` to indicate that there are no more elements in the stream.\n */\nexport const DONE_RESULT: IteratorReturnResult<undefined> = Object.freeze({ done: true, value: undefined });\n\n/**\n * Create a stream from one or more iterables or array-likes.\n */\nexport function stream<T>(...collections: Array<Iterable<T> | ArrayLike<T>>): Stream<T> {\n    if (collections.length === 1) {\n        const collection = collections[0];\n        if (collection instanceof StreamImpl) {\n            return collection as Stream<T>;\n        }\n        if (isIterable(collection)) {\n            return new StreamImpl<Iterator<T, undefined>, T>(\n                () => collection[Symbol.iterator](),\n                (iterator) => iterator.next()\n            );\n        }\n        if (typeof collection.length === 'number') {\n            return new StreamImpl<{ index: number }, T>(\n                () => ({ index: 0 }),\n                (state) => {\n                    if (state.index < collection.length) {\n                        return { done: false, value: collection[state.index++] };\n                    } else {\n                        return DONE_RESULT;\n                    }\n                }\n            );\n        }\n    }\n    if (collections.length > 1) {\n        type State = { collIndex: number, iterator?: Iterator<T, undefined>, array?: ArrayLike<T>, arrIndex: number };\n        return new StreamImpl<State, T>(\n            () => ({ collIndex: 0, arrIndex: 0 }),\n            (state) => {\n                do {\n                    if (state.iterator) {\n                        const next = state.iterator.next();\n                        if (!next.done) {\n                            return next;\n                        }\n                        state.iterator = undefined;\n                    }\n                    if (state.array) {\n                        if (state.arrIndex < state.array.length) {\n                            return { done: false, value: state.array[state.arrIndex++] };\n                        }\n                        state.array = undefined;\n                        state.arrIndex = 0;\n                    }\n                    if (state.collIndex < collections.length) {\n                        const collection = collections[state.collIndex++];\n                        if (isIterable(collection)) {\n                            state.iterator = collection[Symbol.iterator]();\n                        } else if (collection && typeof collection.length === 'number') {\n                            state.array = collection;\n                        }\n                    }\n                } while (state.iterator || state.array || state.collIndex < collections.length);\n                return DONE_RESULT;\n            }\n        );\n    }\n    return EMPTY_STREAM;\n}\n\n/**\n * A tree iterator adds the ability to prune the current iteration.\n */\nexport interface TreeIterator<T> extends IterableIterator<T> {\n    /**\n     * Skip the whole subtree below the last returned element. The iteration continues as if that\n     * element had no children.\n     */\n    prune(): void\n}\n\n/**\n * A tree stream is used to stream the elements of a tree, for example an AST or CST.\n */\nexport interface TreeStream<T> extends Stream<T> {\n    iterator(): TreeIterator<T>\n}\n\n/**\n * The default implementation of `TreeStream` takes a root element and a function that computes the\n * children of its argument. Whether the root node included in the stream is controlled with the\n * `includeRoot` option, which defaults to `false`.\n */\nexport class TreeStreamImpl<T>\n    extends StreamImpl<{ iterators: Array<Iterator<T>>, pruned: boolean }, T>\n    implements TreeStream<T> {\n\n    constructor(root: T, children: (node: T) => Iterable<T>, options?: { includeRoot?: boolean }) {\n        super(\n            () => ({\n                iterators: options?.includeRoot ? [[root][Symbol.iterator]()] : [children(root)[Symbol.iterator]()],\n                pruned: false\n            }),\n            state => {\n                if (state.pruned) {\n                    state.iterators.pop();\n                    state.pruned = false;\n                }\n                while (state.iterators.length > 0) {\n                    const iterator = state.iterators[state.iterators.length - 1];\n                    const next = iterator.next();\n                    if (next.done) {\n                        state.iterators.pop();\n                    } else {\n                        state.iterators.push(children(next.value)[Symbol.iterator]());\n                        return next;\n                    }\n                }\n                return DONE_RESULT;\n            }\n        );\n    }\n\n    override iterator(): TreeIterator<T> {\n        const iterator = {\n            state: this.startFn(),\n            next: () => this.nextFn(iterator.state),\n            prune: () => {\n                iterator.state.pruned = true;\n            },\n            [Symbol.iterator]: () => iterator\n        };\n        return iterator;\n    }\n}\n\n/**\n * A set of utility functions that reduce a stream to a single value.\n */\nexport namespace Reduction {\n\n    /**\n     * Compute the sum of a number stream.\n     */\n    export function sum(stream: Stream<number>): number {\n        return stream.reduce((a, b) => a + b, 0);\n    }\n\n    /**\n     * Compute the product of a number stream.\n     */\n    export function product(stream: Stream<number>): number {\n        return stream.reduce((a, b) => a * b, 0);\n    }\n\n    /**\n     * Compute the minimum of a number stream. Returns `undefined` if the stream is empty.\n     */\n    export function min(stream: Stream<number>): number | undefined {\n        return stream.reduce((a, b) => Math.min(a, b));\n    }\n\n    /**\n     * Compute the maximum of a number stream. Returns `undefined` if the stream is empty.\n     */\n    export function max(stream: Stream<number>): number | undefined {\n        return stream.reduce((a, b) => Math.max(a, b));\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { IToken } from '@chevrotain/types';\nimport type { Range } from 'vscode-languageserver-types';\nimport type { CstNode, CompositeCstNode, LeafCstNode } from '../syntax-tree.js';\nimport type { DocumentSegment } from '../workspace/documents.js';\nimport type { Stream, TreeStream } from './stream.js';\nimport { isCompositeCstNode, isLeafCstNode, isRootCstNode } from '../syntax-tree.js';\nimport { TreeStreamImpl } from './stream.js';\n\n/**\n * Create a stream of all CST nodes that are directly and indirectly contained in the given root node,\n * including the root node itself.\n */\nexport function streamCst(node: CstNode): TreeStream<CstNode> {\n    return new TreeStreamImpl(node, element => {\n        if (isCompositeCstNode(element)) {\n            return element.content;\n        } else {\n            return [];\n        }\n    }, { includeRoot: true });\n}\n\n/**\n * Create a stream of all leaf nodes that are directly and indirectly contained in the given root node.\n */\nexport function flattenCst(node: CstNode): Stream<LeafCstNode> {\n    return streamCst(node).filter(isLeafCstNode);\n}\n\n/**\n * Determines whether the specified cst node is a child of the specified parent node.\n */\nexport function isChildNode(child: CstNode, parent: CstNode): boolean {\n    while (child.container) {\n        child = child.container;\n        if (child === parent) {\n            return true;\n        }\n    }\n    return false;\n}\n\nexport function tokenToRange(token: IToken): Range {\n    // Chevrotain uses 1-based indices everywhere\n    // So we subtract 1 from every value to align with the LSP\n    return {\n        start: {\n            character: token.startColumn! - 1,\n            line: token.startLine! - 1\n        },\n        end: {\n            character: token.endColumn!, // endColumn uses the correct index\n            line: token.endLine! - 1\n        }\n    };\n}\n\nexport function toDocumentSegment(node: CstNode): DocumentSegment;\nexport function toDocumentSegment(node?: CstNode): DocumentSegment | undefined;\nexport function toDocumentSegment(node?: CstNode): DocumentSegment | undefined {\n    if (!node) {\n        return undefined;\n    }\n    const { offset, end, range } = node;\n    return {\n        range,\n        offset,\n        end,\n        length: end - offset\n    };\n}\n\nexport enum RangeComparison {\n    Before = 0,\n    After = 1,\n    OverlapFront = 2,\n    OverlapBack = 3,\n    Inside = 4\n}\n\nexport function compareRange(range: Range, to: Range): RangeComparison {\n    if (range.end.line < to.start.line || (range.end.line === to.start.line && range.end.character < range.start.character)) {\n        return RangeComparison.Before;\n    } else if (range.start.line > to.end.line || (range.start.line === to.end.line && range.start.character > to.end.character)) {\n        return RangeComparison.After;\n    }\n    const startInside = range.start.line > to.start.line || (range.start.line === to.start.line && range.start.character >= to.start.character);\n    const endInside = range.end.line < to.end.line || (range.end.line === to.end.line && range.end.character <= to.end.character);\n    if (startInside && endInside) {\n        return RangeComparison.Inside;\n    } else if (startInside) {\n        return RangeComparison.OverlapBack;\n    } else {\n        return RangeComparison.OverlapFront;\n    }\n}\n\nexport function inRange(range: Range, to: Range): boolean {\n    const comparison = compareRange(range, to);\n    return comparison > RangeComparison.After;\n}\n\n// The \\p{L} regex matches any unicode letter character, i.e. characters from non-english alphabets\n// Together with \\w it matches any kind of character which can commonly appear in IDs\nexport const DefaultNameRegexp = /^[\\w\\p{L}]$/u;\n\n/**\n * Performs `findLeafNodeAtOffset` with a minor difference: When encountering a character that matches the `nameRegexp` argument,\n * it will instead return the leaf node at the `offset - 1` position.\n *\n * For LSP services, users expect that the declaration of an element is available if the cursor is directly after the element.\n */\nexport function findDeclarationNodeAtOffset(cstNode: CstNode | undefined, offset: number, nameRegexp = DefaultNameRegexp): LeafCstNode | undefined {\n    if (cstNode) {\n        if (offset > 0) {\n            const localOffset = offset - cstNode.offset;\n            const textAtOffset = cstNode.text.charAt(localOffset);\n            if (!nameRegexp.test(textAtOffset)) {\n                offset--;\n            }\n        }\n        return findLeafNodeAtOffset(cstNode, offset);\n    }\n    return undefined;\n}\n\nexport function findCommentNode(cstNode: CstNode | undefined, commentNames: string[]): CstNode | undefined {\n    if (cstNode) {\n        const previous = getPreviousNode(cstNode, true);\n        if (previous && isCommentNode(previous, commentNames)) {\n            return previous;\n        }\n        if (isRootCstNode(cstNode)) {\n            // Go from the first non-hidden node through all nodes in reverse order\n            // We do this to find the comment node which directly precedes the root node\n            const endIndex = cstNode.content.findIndex(e => !e.hidden);\n            for (let i = endIndex - 1; i >= 0; i--) {\n                const child = cstNode.content[i];\n                if (isCommentNode(child, commentNames)) {\n                    return child;\n                }\n            }\n        }\n    }\n    return undefined;\n}\n\nexport function isCommentNode(cstNode: CstNode, commentNames: string[]): boolean {\n    return isLeafCstNode(cstNode) && commentNames.includes(cstNode.tokenType.name);\n}\n\n/**\n * Finds the leaf CST node at the specified 0-based string offset.\n * Note that the given offset will be within the range of the returned leaf node.\n *\n * If the offset does not point to a CST node (but just white space), this method will return `undefined`.\n *\n * @param node The CST node to search through.\n * @param offset The specified offset.\n * @returns The CST node at the specified offset.\n */\nexport function findLeafNodeAtOffset(node: CstNode, offset: number): LeafCstNode | undefined {\n    if (isLeafCstNode(node)) {\n        return node;\n    } else if (isCompositeCstNode(node)) {\n        const searchResult = binarySearch(node, offset, false);\n        if (searchResult) {\n            return findLeafNodeAtOffset(searchResult, offset);\n        }\n    }\n    return undefined;\n}\n\n/**\n * Finds the leaf CST node at the specified 0-based string offset.\n * If no CST node exists at the specified position, it will return the leaf node before it.\n *\n * If there is no leaf node before the specified offset, this method will return `undefined`.\n *\n * @param node The CST node to search through.\n * @param offset The specified offset.\n * @returns The CST node closest to the specified offset.\n */\nexport function findLeafNodeBeforeOffset(node: CstNode, offset: number): LeafCstNode | undefined {\n    if (isLeafCstNode(node)) {\n        return node;\n    } else if (isCompositeCstNode(node)) {\n        const searchResult = binarySearch(node, offset, true);\n        if (searchResult) {\n            return findLeafNodeBeforeOffset(searchResult, offset);\n        }\n    }\n    return undefined;\n}\n\nfunction binarySearch(node: CompositeCstNode, offset: number, closest: boolean): CstNode | undefined {\n    let left = 0;\n    let right = node.content.length - 1;\n    let closestNode: CstNode | undefined = undefined;\n\n    while (left <= right) {\n        const middle = Math.floor((left + right) / 2);\n        const middleNode = node.content[middle];\n\n        if (middleNode.offset <= offset && middleNode.end > offset) {\n            // Found an exact match\n            return middleNode;\n        }\n\n        if (middleNode.end <= offset) {\n            // Update the closest node (less than offset) and move to the right half\n            closestNode = closest ? middleNode : undefined;\n            left = middle + 1;\n        } else {\n            // Move to the left half\n            right = middle - 1;\n        }\n    }\n\n    return closestNode;\n}\n\nexport function getPreviousNode(node: CstNode, hidden = true): CstNode | undefined {\n    while (node.container) {\n        const parent = node.container;\n        let index = parent.content.indexOf(node);\n        while (index > 0) {\n            index--;\n            const previous = parent.content[index];\n            if (hidden || !previous.hidden) {\n                return previous;\n            }\n        }\n        node = parent;\n    }\n    return undefined;\n}\n\nexport function getNextNode(node: CstNode, hidden = true): CstNode | undefined {\n    while (node.container) {\n        const parent = node.container;\n        let index = parent.content.indexOf(node);\n        const last = parent.content.length - 1;\n        while (index < last) {\n            index++;\n            const next = parent.content[index];\n            if (hidden || !next.hidden) {\n                return next;\n            }\n        }\n        node = parent;\n    }\n    return undefined;\n}\n\nexport function getStartlineNode(node: CstNode): CstNode {\n    if (node.range.start.character === 0) {\n        return node;\n    }\n    const line = node.range.start.line;\n    let last = node;\n    let index: number | undefined;\n    while (node.container) {\n        const parent = node.container;\n        const selfIndex = index ?? parent.content.indexOf(node);\n        if (selfIndex === 0) {\n            node = parent;\n            index = undefined;\n        } else {\n            index = selfIndex - 1;\n            node = parent.content[index];\n        }\n        if (node.range.start.line !== line) {\n            break;\n        }\n        last = node;\n    }\n    return last;\n}\n\nexport function getInteriorNodes(start: CstNode, end: CstNode): CstNode[] {\n    const commonParent = getCommonParent(start, end);\n    if (!commonParent) {\n        return [];\n    }\n    return commonParent.parent.content.slice(commonParent.a + 1, commonParent.b);\n}\n\nfunction getCommonParent(a: CstNode, b: CstNode): CommonParent | undefined {\n    const aParents = getParentChain(a);\n    const bParents = getParentChain(b);\n    let current: CommonParent | undefined;\n    for (let i = 0; i < aParents.length && i < bParents.length; i++) {\n        const aParent = aParents[i];\n        const bParent = bParents[i];\n        if (aParent.parent === bParent.parent) {\n            current = {\n                parent: aParent.parent,\n                a: aParent.index,\n                b: bParent.index\n            };\n        } else {\n            break;\n        }\n    }\n    return current;\n}\n\ninterface CommonParent {\n    parent: CompositeCstNode\n    a: number\n    b: number\n}\n\nfunction getParentChain(node: CstNode): ParentLink[] {\n    const chain: ParentLink[] = [];\n    while (node.container) {\n        const parent = node.container;\n        const index = parent.content.indexOf(node);\n        chain.push({\n            parent,\n            index\n        });\n        node = parent;\n    }\n    return chain.reverse();\n}\n\ninterface ParentLink {\n    parent: CompositeCstNode\n    index: number\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { CstNode } from '../syntax-tree.js';\n\nexport class ErrorWithLocation extends Error {\n    constructor(node: CstNode | undefined, message: string) {\n        super(node ? `${message} at ${node.range.start.line}:${node.range.start.character}` : message);\n    }\n}\n\nexport function assertUnreachable(_: never): never {\n    throw new Error('Error! The input value was not handled.');\n}\n","/******************************************************************************\n * This file was generated by langium-cli 3.0.0.\n * DO NOT EDIT MANUALLY!\n ******************************************************************************/\n\n/* eslint-disable */\nimport type { AstNode, Reference, ReferenceInfo, TypeMetaData } from '../../syntax-tree.js';\nimport { AbstractAstReflection } from '../../syntax-tree.js';\n\nexport const LangiumGrammarTerminals = {\n    ID: /\\^?[_a-zA-Z][\\w_]*/,\n    STRING: /\"(\\\\.|[^\"\\\\])*\"|'(\\\\.|[^'\\\\])*'/,\n    NUMBER: /NaN|-?((\\d*\\.\\d+|\\d+)([Ee][+-]?\\d+)?|Infinity)/,\n    RegexLiteral: /\\/(?![*+?])(?:[^\\r\\n\\[/\\\\]|\\\\.|\\[(?:[^\\r\\n\\]\\\\]|\\\\.)*\\])+\\/[a-z]*/,\n    WS: /\\s+/,\n    ML_COMMENT: /\\/\\*[\\s\\S]*?\\*\\//,\n    SL_COMMENT: /\\/\\/[^\\n\\r]*/,\n};\n\nexport type AbstractRule = ParserRule | TerminalRule;\n\nexport const AbstractRule = 'AbstractRule';\n\nexport function isAbstractRule(item: unknown): item is AbstractRule {\n    return reflection.isInstance(item, AbstractRule);\n}\n\nexport type AbstractType = InferredType | Interface | ParserRule | Type;\n\nexport const AbstractType = 'AbstractType';\n\nexport function isAbstractType(item: unknown): item is AbstractType {\n    return reflection.isInstance(item, AbstractType);\n}\n\nexport type Condition = BooleanLiteral | Conjunction | Disjunction | Negation | ParameterReference;\n\nexport const Condition = 'Condition';\n\nexport function isCondition(item: unknown): item is Condition {\n    return reflection.isInstance(item, Condition);\n}\n\nexport type FeatureName = 'current' | 'entry' | 'extends' | 'false' | 'fragment' | 'grammar' | 'hidden' | 'import' | 'infer' | 'infers' | 'interface' | 'returns' | 'terminal' | 'true' | 'type' | 'with' | PrimitiveType | string;\n\nexport function isFeatureName(item: unknown): item is FeatureName {\n    return isPrimitiveType(item) || item === 'current' || item === 'entry' || item === 'extends' || item === 'false' || item === 'fragment' || item === 'grammar' || item === 'hidden' || item === 'import' || item === 'interface' || item === 'returns' || item === 'terminal' || item === 'true' || item === 'type' || item === 'infer' || item === 'infers' || item === 'with' || (typeof item === 'string' && (/\\^?[_a-zA-Z][\\w_]*/.test(item)));\n}\n\nexport type PrimitiveType = 'Date' | 'bigint' | 'boolean' | 'number' | 'string';\n\nexport function isPrimitiveType(item: unknown): item is PrimitiveType {\n    return item === 'string' || item === 'number' || item === 'boolean' || item === 'Date' || item === 'bigint';\n}\n\nexport type TypeDefinition = ArrayType | ReferenceType | SimpleType | UnionType;\n\nexport const TypeDefinition = 'TypeDefinition';\n\nexport function isTypeDefinition(item: unknown): item is TypeDefinition {\n    return reflection.isInstance(item, TypeDefinition);\n}\n\nexport type ValueLiteral = ArrayLiteral | BooleanLiteral | NumberLiteral | StringLiteral;\n\nexport const ValueLiteral = 'ValueLiteral';\n\nexport function isValueLiteral(item: unknown): item is ValueLiteral {\n    return reflection.isInstance(item, ValueLiteral);\n}\n\nexport interface AbstractElement extends AstNode {\n    readonly $type: 'AbstractElement' | 'Action' | 'Alternatives' | 'Assignment' | 'CharacterRange' | 'CrossReference' | 'EndOfFile' | 'Group' | 'Keyword' | 'NegatedToken' | 'RegexToken' | 'RuleCall' | 'TerminalAlternatives' | 'TerminalGroup' | 'TerminalRuleCall' | 'UnorderedGroup' | 'UntilToken' | 'Wildcard';\n    cardinality?: '*' | '+' | '?';\n    lookahead?: '?!' | '?<!' | '?<=' | '?=';\n}\n\nexport const AbstractElement = 'AbstractElement';\n\nexport function isAbstractElement(item: unknown): item is AbstractElement {\n    return reflection.isInstance(item, AbstractElement);\n}\n\nexport interface ArrayLiteral extends AstNode {\n    readonly $container: ArrayLiteral | TypeAttribute;\n    readonly $type: 'ArrayLiteral';\n    elements: Array<ValueLiteral>;\n}\n\nexport const ArrayLiteral = 'ArrayLiteral';\n\nexport function isArrayLiteral(item: unknown): item is ArrayLiteral {\n    return reflection.isInstance(item, ArrayLiteral);\n}\n\nexport interface ArrayType extends AstNode {\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\n    readonly $type: 'ArrayType';\n    elementType: TypeDefinition;\n}\n\nexport const ArrayType = 'ArrayType';\n\nexport function isArrayType(item: unknown): item is ArrayType {\n    return reflection.isInstance(item, ArrayType);\n}\n\nexport interface BooleanLiteral extends AstNode {\n    readonly $container: ArrayLiteral | Conjunction | Disjunction | Group | NamedArgument | Negation | TypeAttribute;\n    readonly $type: 'BooleanLiteral';\n    true: boolean;\n}\n\nexport const BooleanLiteral = 'BooleanLiteral';\n\nexport function isBooleanLiteral(item: unknown): item is BooleanLiteral {\n    return reflection.isInstance(item, BooleanLiteral);\n}\n\nexport interface Conjunction extends AstNode {\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\n    readonly $type: 'Conjunction';\n    left: Condition;\n    right: Condition;\n}\n\nexport const Conjunction = 'Conjunction';\n\nexport function isConjunction(item: unknown): item is Conjunction {\n    return reflection.isInstance(item, Conjunction);\n}\n\nexport interface Disjunction extends AstNode {\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\n    readonly $type: 'Disjunction';\n    left: Condition;\n    right: Condition;\n}\n\nexport const Disjunction = 'Disjunction';\n\nexport function isDisjunction(item: unknown): item is Disjunction {\n    return reflection.isInstance(item, Disjunction);\n}\n\nexport interface Grammar extends AstNode {\n    readonly $type: 'Grammar';\n    definesHiddenTokens: boolean;\n    hiddenTokens: Array<Reference<AbstractRule>>;\n    imports: Array<GrammarImport>;\n    interfaces: Array<Interface>;\n    isDeclared: boolean;\n    name?: string;\n    rules: Array<AbstractRule>;\n    types: Array<Type>;\n    usedGrammars: Array<Reference<Grammar>>;\n}\n\nexport const Grammar = 'Grammar';\n\nexport function isGrammar(item: unknown): item is Grammar {\n    return reflection.isInstance(item, Grammar);\n}\n\nexport interface GrammarImport extends AstNode {\n    readonly $container: Grammar;\n    readonly $type: 'GrammarImport';\n    path: string;\n}\n\nexport const GrammarImport = 'GrammarImport';\n\nexport function isGrammarImport(item: unknown): item is GrammarImport {\n    return reflection.isInstance(item, GrammarImport);\n}\n\nexport interface InferredType extends AstNode {\n    readonly $container: Action | ParserRule;\n    readonly $type: 'InferredType';\n    name: string;\n}\n\nexport const InferredType = 'InferredType';\n\nexport function isInferredType(item: unknown): item is InferredType {\n    return reflection.isInstance(item, InferredType);\n}\n\nexport interface Interface extends AstNode {\n    readonly $container: Grammar;\n    readonly $type: 'Interface';\n    attributes: Array<TypeAttribute>;\n    name: string;\n    superTypes: Array<Reference<AbstractType>>;\n}\n\nexport const Interface = 'Interface';\n\nexport function isInterface(item: unknown): item is Interface {\n    return reflection.isInstance(item, Interface);\n}\n\nexport interface NamedArgument extends AstNode {\n    readonly $container: RuleCall;\n    readonly $type: 'NamedArgument';\n    calledByName: boolean;\n    parameter?: Reference<Parameter>;\n    value: Condition;\n}\n\nexport const NamedArgument = 'NamedArgument';\n\nexport function isNamedArgument(item: unknown): item is NamedArgument {\n    return reflection.isInstance(item, NamedArgument);\n}\n\nexport interface Negation extends AstNode {\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\n    readonly $type: 'Negation';\n    value: Condition;\n}\n\nexport const Negation = 'Negation';\n\nexport function isNegation(item: unknown): item is Negation {\n    return reflection.isInstance(item, Negation);\n}\n\nexport interface NumberLiteral extends AstNode {\n    readonly $container: ArrayLiteral | TypeAttribute;\n    readonly $type: 'NumberLiteral';\n    value: number;\n}\n\nexport const NumberLiteral = 'NumberLiteral';\n\nexport function isNumberLiteral(item: unknown): item is NumberLiteral {\n    return reflection.isInstance(item, NumberLiteral);\n}\n\nexport interface Parameter extends AstNode {\n    readonly $container: ParserRule;\n    readonly $type: 'Parameter';\n    name: string;\n}\n\nexport const Parameter = 'Parameter';\n\nexport function isParameter(item: unknown): item is Parameter {\n    return reflection.isInstance(item, Parameter);\n}\n\nexport interface ParameterReference extends AstNode {\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\n    readonly $type: 'ParameterReference';\n    parameter: Reference<Parameter>;\n}\n\nexport const ParameterReference = 'ParameterReference';\n\nexport function isParameterReference(item: unknown): item is ParameterReference {\n    return reflection.isInstance(item, ParameterReference);\n}\n\nexport interface ParserRule extends AstNode {\n    readonly $container: Grammar;\n    readonly $type: 'ParserRule';\n    dataType?: PrimitiveType;\n    definesHiddenTokens: boolean;\n    definition: AbstractElement;\n    entry: boolean;\n    fragment: boolean;\n    hiddenTokens: Array<Reference<AbstractRule>>;\n    inferredType?: InferredType;\n    name: string;\n    parameters: Array<Parameter>;\n    returnType?: Reference<AbstractType>;\n    wildcard: boolean;\n}\n\nexport const ParserRule = 'ParserRule';\n\nexport function isParserRule(item: unknown): item is ParserRule {\n    return reflection.isInstance(item, ParserRule);\n}\n\nexport interface ReferenceType extends AstNode {\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\n    readonly $type: 'ReferenceType';\n    referenceType: TypeDefinition;\n}\n\nexport const ReferenceType = 'ReferenceType';\n\nexport function isReferenceType(item: unknown): item is ReferenceType {\n    return reflection.isInstance(item, ReferenceType);\n}\n\nexport interface ReturnType extends AstNode {\n    readonly $container: TerminalRule;\n    readonly $type: 'ReturnType';\n    name: PrimitiveType | string;\n}\n\nexport const ReturnType = 'ReturnType';\n\nexport function isReturnType(item: unknown): item is ReturnType {\n    return reflection.isInstance(item, ReturnType);\n}\n\nexport interface SimpleType extends AstNode {\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\n    readonly $type: 'SimpleType';\n    primitiveType?: PrimitiveType;\n    stringType?: string;\n    typeRef?: Reference<AbstractType>;\n}\n\nexport const SimpleType = 'SimpleType';\n\nexport function isSimpleType(item: unknown): item is SimpleType {\n    return reflection.isInstance(item, SimpleType);\n}\n\nexport interface StringLiteral extends AstNode {\n    readonly $container: ArrayLiteral | TypeAttribute;\n    readonly $type: 'StringLiteral';\n    value: string;\n}\n\nexport const StringLiteral = 'StringLiteral';\n\nexport function isStringLiteral(item: unknown): item is StringLiteral {\n    return reflection.isInstance(item, StringLiteral);\n}\n\nexport interface TerminalRule extends AstNode {\n    readonly $container: Grammar;\n    readonly $type: 'TerminalRule';\n    definition: AbstractElement;\n    fragment: boolean;\n    hidden: boolean;\n    name: string;\n    type?: ReturnType;\n}\n\nexport const TerminalRule = 'TerminalRule';\n\nexport function isTerminalRule(item: unknown): item is TerminalRule {\n    return reflection.isInstance(item, TerminalRule);\n}\n\nexport interface Type extends AstNode {\n    readonly $container: Grammar;\n    readonly $type: 'Type';\n    name: string;\n    type: TypeDefinition;\n}\n\nexport const Type = 'Type';\n\nexport function isType(item: unknown): item is Type {\n    return reflection.isInstance(item, Type);\n}\n\nexport interface TypeAttribute extends AstNode {\n    readonly $container: Interface;\n    readonly $type: 'TypeAttribute';\n    defaultValue?: ValueLiteral;\n    isOptional: boolean;\n    name: FeatureName;\n    type: TypeDefinition;\n}\n\nexport const TypeAttribute = 'TypeAttribute';\n\nexport function isTypeAttribute(item: unknown): item is TypeAttribute {\n    return reflection.isInstance(item, TypeAttribute);\n}\n\nexport interface UnionType extends AstNode {\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\n    readonly $type: 'UnionType';\n    types: Array<TypeDefinition>;\n}\n\nexport const UnionType = 'UnionType';\n\nexport function isUnionType(item: unknown): item is UnionType {\n    return reflection.isInstance(item, UnionType);\n}\n\nexport interface Action extends AbstractElement {\n    readonly $type: 'Action';\n    feature?: FeatureName;\n    inferredType?: InferredType;\n    operator?: '+=' | '=';\n    type?: Reference<AbstractType>;\n}\n\nexport const Action = 'Action';\n\nexport function isAction(item: unknown): item is Action {\n    return reflection.isInstance(item, Action);\n}\n\nexport interface Alternatives extends AbstractElement {\n    readonly $type: 'Alternatives';\n    elements: Array<AbstractElement>;\n}\n\nexport const Alternatives = 'Alternatives';\n\nexport function isAlternatives(item: unknown): item is Alternatives {\n    return reflection.isInstance(item, Alternatives);\n}\n\nexport interface Assignment extends AbstractElement {\n    readonly $type: 'Assignment';\n    feature: FeatureName;\n    operator: '+=' | '=' | '?=';\n    terminal: AbstractElement;\n}\n\nexport const Assignment = 'Assignment';\n\nexport function isAssignment(item: unknown): item is Assignment {\n    return reflection.isInstance(item, Assignment);\n}\n\nexport interface CharacterRange extends AbstractElement {\n    readonly $type: 'CharacterRange';\n    left: Keyword;\n    right?: Keyword;\n}\n\nexport const CharacterRange = 'CharacterRange';\n\nexport function isCharacterRange(item: unknown): item is CharacterRange {\n    return reflection.isInstance(item, CharacterRange);\n}\n\nexport interface CrossReference extends AbstractElement {\n    readonly $type: 'CrossReference';\n    deprecatedSyntax: boolean;\n    terminal?: AbstractElement;\n    type: Reference<AbstractType>;\n}\n\nexport const CrossReference = 'CrossReference';\n\nexport function isCrossReference(item: unknown): item is CrossReference {\n    return reflection.isInstance(item, CrossReference);\n}\n\nexport interface EndOfFile extends AbstractElement {\n    readonly $type: 'EndOfFile';\n}\n\nexport const EndOfFile = 'EndOfFile';\n\nexport function isEndOfFile(item: unknown): item is EndOfFile {\n    return reflection.isInstance(item, EndOfFile);\n}\n\nexport interface Group extends AbstractElement {\n    readonly $type: 'Group';\n    elements: Array<AbstractElement>;\n    guardCondition?: Condition;\n}\n\nexport const Group = 'Group';\n\nexport function isGroup(item: unknown): item is Group {\n    return reflection.isInstance(item, Group);\n}\n\nexport interface Keyword extends AbstractElement {\n    readonly $container: CharacterRange;\n    readonly $type: 'Keyword';\n    value: string;\n}\n\nexport const Keyword = 'Keyword';\n\nexport function isKeyword(item: unknown): item is Keyword {\n    return reflection.isInstance(item, Keyword);\n}\n\nexport interface NegatedToken extends AbstractElement {\n    readonly $type: 'NegatedToken';\n    terminal: AbstractElement;\n}\n\nexport const NegatedToken = 'NegatedToken';\n\nexport function isNegatedToken(item: unknown): item is NegatedToken {\n    return reflection.isInstance(item, NegatedToken);\n}\n\nexport interface RegexToken extends AbstractElement {\n    readonly $type: 'RegexToken';\n    regex: string;\n}\n\nexport const RegexToken = 'RegexToken';\n\nexport function isRegexToken(item: unknown): item is RegexToken {\n    return reflection.isInstance(item, RegexToken);\n}\n\nexport interface RuleCall extends AbstractElement {\n    readonly $type: 'RuleCall';\n    arguments: Array<NamedArgument>;\n    rule: Reference<AbstractRule>;\n}\n\nexport const RuleCall = 'RuleCall';\n\nexport function isRuleCall(item: unknown): item is RuleCall {\n    return reflection.isInstance(item, RuleCall);\n}\n\nexport interface TerminalAlternatives extends AbstractElement {\n    readonly $type: 'TerminalAlternatives';\n    elements: Array<AbstractElement>;\n}\n\nexport const TerminalAlternatives = 'TerminalAlternatives';\n\nexport function isTerminalAlternatives(item: unknown): item is TerminalAlternatives {\n    return reflection.isInstance(item, TerminalAlternatives);\n}\n\nexport interface TerminalGroup extends AbstractElement {\n    readonly $type: 'TerminalGroup';\n    elements: Array<AbstractElement>;\n}\n\nexport const TerminalGroup = 'TerminalGroup';\n\nexport function isTerminalGroup(item: unknown): item is TerminalGroup {\n    return reflection.isInstance(item, TerminalGroup);\n}\n\nexport interface TerminalRuleCall extends AbstractElement {\n    readonly $type: 'TerminalRuleCall';\n    rule: Reference<TerminalRule>;\n}\n\nexport const TerminalRuleCall = 'TerminalRuleCall';\n\nexport function isTerminalRuleCall(item: unknown): item is TerminalRuleCall {\n    return reflection.isInstance(item, TerminalRuleCall);\n}\n\nexport interface UnorderedGroup extends AbstractElement {\n    readonly $type: 'UnorderedGroup';\n    elements: Array<AbstractElement>;\n}\n\nexport const UnorderedGroup = 'UnorderedGroup';\n\nexport function isUnorderedGroup(item: unknown): item is UnorderedGroup {\n    return reflection.isInstance(item, UnorderedGroup);\n}\n\nexport interface UntilToken extends AbstractElement {\n    readonly $type: 'UntilToken';\n    terminal: AbstractElement;\n}\n\nexport const UntilToken = 'UntilToken';\n\nexport function isUntilToken(item: unknown): item is UntilToken {\n    return reflection.isInstance(item, UntilToken);\n}\n\nexport interface Wildcard extends AbstractElement {\n    readonly $type: 'Wildcard';\n}\n\nexport const Wildcard = 'Wildcard';\n\nexport function isWildcard(item: unknown): item is Wildcard {\n    return reflection.isInstance(item, Wildcard);\n}\n\nexport type LangiumGrammarAstType = {\n    AbstractElement: AbstractElement\n    AbstractRule: AbstractRule\n    AbstractType: AbstractType\n    Action: Action\n    Alternatives: Alternatives\n    ArrayLiteral: ArrayLiteral\n    ArrayType: ArrayType\n    Assignment: Assignment\n    BooleanLiteral: BooleanLiteral\n    CharacterRange: CharacterRange\n    Condition: Condition\n    Conjunction: Conjunction\n    CrossReference: CrossReference\n    Disjunction: Disjunction\n    EndOfFile: EndOfFile\n    Grammar: Grammar\n    GrammarImport: GrammarImport\n    Group: Group\n    InferredType: InferredType\n    Interface: Interface\n    Keyword: Keyword\n    NamedArgument: NamedArgument\n    NegatedToken: NegatedToken\n    Negation: Negation\n    NumberLiteral: NumberLiteral\n    Parameter: Parameter\n    ParameterReference: ParameterReference\n    ParserRule: ParserRule\n    ReferenceType: ReferenceType\n    RegexToken: RegexToken\n    ReturnType: ReturnType\n    RuleCall: RuleCall\n    SimpleType: SimpleType\n    StringLiteral: StringLiteral\n    TerminalAlternatives: TerminalAlternatives\n    TerminalGroup: TerminalGroup\n    TerminalRule: TerminalRule\n    TerminalRuleCall: TerminalRuleCall\n    Type: Type\n    TypeAttribute: TypeAttribute\n    TypeDefinition: TypeDefinition\n    UnionType: UnionType\n    UnorderedGroup: UnorderedGroup\n    UntilToken: UntilToken\n    ValueLiteral: ValueLiteral\n    Wildcard: Wildcard\n}\n\nexport class LangiumGrammarAstReflection extends AbstractAstReflection {\n\n    getAllTypes(): string[] {\n        return ['AbstractElement', 'AbstractRule', 'AbstractType', 'Action', 'Alternatives', 'ArrayLiteral', 'ArrayType', 'Assignment', 'BooleanLiteral', 'CharacterRange', 'Condition', 'Conjunction', 'CrossReference', 'Disjunction', 'EndOfFile', 'Grammar', 'GrammarImport', 'Group', 'InferredType', 'Interface', 'Keyword', 'NamedArgument', 'NegatedToken', 'Negation', 'NumberLiteral', 'Parameter', 'ParameterReference', 'ParserRule', 'ReferenceType', 'RegexToken', 'ReturnType', 'RuleCall', 'SimpleType', 'StringLiteral', 'TerminalAlternatives', 'TerminalGroup', 'TerminalRule', 'TerminalRuleCall', 'Type', 'TypeAttribute', 'TypeDefinition', 'UnionType', 'UnorderedGroup', 'UntilToken', 'ValueLiteral', 'Wildcard'];\n    }\n\n    protected override computeIsSubtype(subtype: string, supertype: string): boolean {\n        switch (subtype) {\n            case Action:\n            case Alternatives:\n            case Assignment:\n            case CharacterRange:\n            case CrossReference:\n            case EndOfFile:\n            case Group:\n            case Keyword:\n            case NegatedToken:\n            case RegexToken:\n            case RuleCall:\n            case TerminalAlternatives:\n            case TerminalGroup:\n            case TerminalRuleCall:\n            case UnorderedGroup:\n            case UntilToken:\n            case Wildcard: {\n                return this.isSubtype(AbstractElement, supertype);\n            }\n            case ArrayLiteral:\n            case NumberLiteral:\n            case StringLiteral: {\n                return this.isSubtype(ValueLiteral, supertype);\n            }\n            case ArrayType:\n            case ReferenceType:\n            case SimpleType:\n            case UnionType: {\n                return this.isSubtype(TypeDefinition, supertype);\n            }\n            case BooleanLiteral: {\n                return this.isSubtype(Condition, supertype) || this.isSubtype(ValueLiteral, supertype);\n            }\n            case Conjunction:\n            case Disjunction:\n            case Negation:\n            case ParameterReference: {\n                return this.isSubtype(Condition, supertype);\n            }\n            case InferredType:\n            case Interface:\n            case Type: {\n                return this.isSubtype(AbstractType, supertype);\n            }\n            case ParserRule: {\n                return this.isSubtype(AbstractRule, supertype) || this.isSubtype(AbstractType, supertype);\n            }\n            case TerminalRule: {\n                return this.isSubtype(AbstractRule, supertype);\n            }\n            default: {\n                return false;\n            }\n        }\n    }\n\n    getReferenceType(refInfo: ReferenceInfo): string {\n        const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\n        switch (referenceId) {\n            case 'Action:type':\n            case 'CrossReference:type':\n            case 'Interface:superTypes':\n            case 'ParserRule:returnType':\n            case 'SimpleType:typeRef': {\n                return AbstractType;\n            }\n            case 'Grammar:hiddenTokens':\n            case 'ParserRule:hiddenTokens':\n            case 'RuleCall:rule': {\n                return AbstractRule;\n            }\n            case 'Grammar:usedGrammars': {\n                return Grammar;\n            }\n            case 'NamedArgument:parameter':\n            case 'ParameterReference:parameter': {\n                return Parameter;\n            }\n            case 'TerminalRuleCall:rule': {\n                return TerminalRule;\n            }\n            default: {\n                throw new Error(`${referenceId} is not a valid reference id.`);\n            }\n        }\n    }\n\n    getTypeMetaData(type: string): TypeMetaData {\n        switch (type) {\n            case 'AbstractElement': {\n                return {\n                    name: 'AbstractElement',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case 'ArrayLiteral': {\n                return {\n                    name: 'ArrayLiteral',\n                    properties: [\n                        { name: 'elements', defaultValue: [] }\n                    ]\n                };\n            }\n            case 'ArrayType': {\n                return {\n                    name: 'ArrayType',\n                    properties: [\n                        { name: 'elementType' }\n                    ]\n                };\n            }\n            case 'BooleanLiteral': {\n                return {\n                    name: 'BooleanLiteral',\n                    properties: [\n                        { name: 'true', defaultValue: false }\n                    ]\n                };\n            }\n            case 'Conjunction': {\n                return {\n                    name: 'Conjunction',\n                    properties: [\n                        { name: 'left' },\n                        { name: 'right' }\n                    ]\n                };\n            }\n            case 'Disjunction': {\n                return {\n                    name: 'Disjunction',\n                    properties: [\n                        { name: 'left' },\n                        { name: 'right' }\n                    ]\n                };\n            }\n            case 'Grammar': {\n                return {\n                    name: 'Grammar',\n                    properties: [\n                        { name: 'definesHiddenTokens', defaultValue: false },\n                        { name: 'hiddenTokens', defaultValue: [] },\n                        { name: 'imports', defaultValue: [] },\n                        { name: 'interfaces', defaultValue: [] },\n                        { name: 'isDeclared', defaultValue: false },\n                        { name: 'name' },\n                        { name: 'rules', defaultValue: [] },\n                        { name: 'types', defaultValue: [] },\n                        { name: 'usedGrammars', defaultValue: [] }\n                    ]\n                };\n            }\n            case 'GrammarImport': {\n                return {\n                    name: 'GrammarImport',\n                    properties: [\n                        { name: 'path' }\n                    ]\n                };\n            }\n            case 'InferredType': {\n                return {\n                    name: 'InferredType',\n                    properties: [\n                        { name: 'name' }\n                    ]\n                };\n            }\n            case 'Interface': {\n                return {\n                    name: 'Interface',\n                    properties: [\n                        { name: 'attributes', defaultValue: [] },\n                        { name: 'name' },\n                        { name: 'superTypes', defaultValue: [] }\n                    ]\n                };\n            }\n            case 'NamedArgument': {\n                return {\n                    name: 'NamedArgument',\n                    properties: [\n                        { name: 'calledByName', defaultValue: false },\n                        { name: 'parameter' },\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case 'Negation': {\n                return {\n                    name: 'Negation',\n                    properties: [\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case 'NumberLiteral': {\n                return {\n                    name: 'NumberLiteral',\n                    properties: [\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case 'Parameter': {\n                return {\n                    name: 'Parameter',\n                    properties: [\n                        { name: 'name' }\n                    ]\n                };\n            }\n            case 'ParameterReference': {\n                return {\n                    name: 'ParameterReference',\n                    properties: [\n                        { name: 'parameter' }\n                    ]\n                };\n            }\n            case 'ParserRule': {\n                return {\n                    name: 'ParserRule',\n                    properties: [\n                        { name: 'dataType' },\n                        { name: 'definesHiddenTokens', defaultValue: false },\n                        { name: 'definition' },\n                        { name: 'entry', defaultValue: false },\n                        { name: 'fragment', defaultValue: false },\n                        { name: 'hiddenTokens', defaultValue: [] },\n                        { name: 'inferredType' },\n                        { name: 'name' },\n                        { name: 'parameters', defaultValue: [] },\n                        { name: 'returnType' },\n                        { name: 'wildcard', defaultValue: false }\n                    ]\n                };\n            }\n            case 'ReferenceType': {\n                return {\n                    name: 'ReferenceType',\n                    properties: [\n                        { name: 'referenceType' }\n                    ]\n                };\n            }\n            case 'ReturnType': {\n                return {\n                    name: 'ReturnType',\n                    properties: [\n                        { name: 'name' }\n                    ]\n                };\n            }\n            case 'SimpleType': {\n                return {\n                    name: 'SimpleType',\n                    properties: [\n                        { name: 'primitiveType' },\n                        { name: 'stringType' },\n                        { name: 'typeRef' }\n                    ]\n                };\n            }\n            case 'StringLiteral': {\n                return {\n                    name: 'StringLiteral',\n                    properties: [\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case 'TerminalRule': {\n                return {\n                    name: 'TerminalRule',\n                    properties: [\n                        { name: 'definition' },\n                        { name: 'fragment', defaultValue: false },\n                        { name: 'hidden', defaultValue: false },\n                        { name: 'name' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case 'Type': {\n                return {\n                    name: 'Type',\n                    properties: [\n                        { name: 'name' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case 'TypeAttribute': {\n                return {\n                    name: 'TypeAttribute',\n                    properties: [\n                        { name: 'defaultValue' },\n                        { name: 'isOptional', defaultValue: false },\n                        { name: 'name' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case 'UnionType': {\n                return {\n                    name: 'UnionType',\n                    properties: [\n                        { name: 'types', defaultValue: [] }\n                    ]\n                };\n            }\n            case 'Action': {\n                return {\n                    name: 'Action',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'feature' },\n                        { name: 'inferredType' },\n                        { name: 'lookahead' },\n                        { name: 'operator' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case 'Alternatives': {\n                return {\n                    name: 'Alternatives',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case 'Assignment': {\n                return {\n                    name: 'Assignment',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'feature' },\n                        { name: 'lookahead' },\n                        { name: 'operator' },\n                        { name: 'terminal' }\n                    ]\n                };\n            }\n            case 'CharacterRange': {\n                return {\n                    name: 'CharacterRange',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'left' },\n                        { name: 'lookahead' },\n                        { name: 'right' }\n                    ]\n                };\n            }\n            case 'CrossReference': {\n                return {\n                    name: 'CrossReference',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'deprecatedSyntax', defaultValue: false },\n                        { name: 'lookahead' },\n                        { name: 'terminal' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case 'EndOfFile': {\n                return {\n                    name: 'EndOfFile',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case 'Group': {\n                return {\n                    name: 'Group',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'guardCondition' },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case 'Keyword': {\n                return {\n                    name: 'Keyword',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case 'NegatedToken': {\n                return {\n                    name: 'NegatedToken',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'terminal' }\n                    ]\n                };\n            }\n            case 'RegexToken': {\n                return {\n                    name: 'RegexToken',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'regex' }\n                    ]\n                };\n            }\n            case 'RuleCall': {\n                return {\n                    name: 'RuleCall',\n                    properties: [\n                        { name: 'arguments', defaultValue: [] },\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'rule' }\n                    ]\n                };\n            }\n            case 'TerminalAlternatives': {\n                return {\n                    name: 'TerminalAlternatives',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case 'TerminalGroup': {\n                return {\n                    name: 'TerminalGroup',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case 'TerminalRuleCall': {\n                return {\n                    name: 'TerminalRuleCall',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'rule' }\n                    ]\n                };\n            }\n            case 'UnorderedGroup': {\n                return {\n                    name: 'UnorderedGroup',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case 'UntilToken': {\n                return {\n                    name: 'UntilToken',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'terminal' }\n                    ]\n                };\n            }\n            case 'Wildcard': {\n                return {\n                    name: 'Wildcard',\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            default: {\n                return {\n                    name: type,\n                    properties: []\n                };\n            }\n        }\n    }\n}\n\nexport const reflection = new LangiumGrammarAstReflection();\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { Range } from 'vscode-languageserver-types';\nimport type { AstNode, AstReflection, CstNode, GenericAstNode, Mutable, PropertyType, Reference, ReferenceInfo } from '../syntax-tree.js';\nimport type { Stream, TreeStream } from './stream.js';\nimport type { LangiumDocument } from '../workspace/documents.js';\nimport { isAstNode, isReference } from '../syntax-tree.js';\nimport { DONE_RESULT, stream, StreamImpl, TreeStreamImpl } from './stream.js';\nimport { inRange } from './cst-utils.js';\n\n/**\n * Link the `$container` and other related properties of every AST node that is directly contained\n * in the given `node`.\n */\nexport function linkContentToContainer(node: AstNode): void {\n    for (const [name, value] of Object.entries(node)) {\n        if (!name.startsWith('$')) {\n            if (Array.isArray(value)) {\n                value.forEach((item, index) => {\n                    if (isAstNode(item)) {\n                        (item as Mutable<AstNode>).$container = node;\n                        (item as Mutable<AstNode>).$containerProperty = name;\n                        (item as Mutable<AstNode>).$containerIndex = index;\n                    }\n                });\n            } else if (isAstNode(value)) {\n                (value as Mutable<AstNode>).$container = node;\n                (value as Mutable<AstNode>).$containerProperty = name;\n            }\n        }\n    }\n}\n\n/**\n * Walk along the hierarchy of containers from the given AST node to the root and return the first\n * node that matches the type predicate. If the start node itself matches, it is returned.\n * If no container matches, `undefined` is returned.\n */\nexport function getContainerOfType<T extends AstNode>(node: AstNode | undefined, typePredicate: (n: AstNode) => n is T): T | undefined {\n    let item = node;\n    while (item) {\n        if (typePredicate(item)) {\n            return item;\n        }\n        item = item.$container;\n    }\n    return undefined;\n}\n\n/**\n * Walk along the hierarchy of containers from the given AST node to the root and check for existence\n * of a container that matches the given predicate. The start node is included in the checks.\n */\nexport function hasContainerOfType(node: AstNode | undefined, predicate: (n: AstNode) => boolean): boolean {\n    let item = node;\n    while (item) {\n        if (predicate(item)) {\n            return true;\n        }\n        item = item.$container;\n    }\n    return false;\n}\n\n/**\n * Retrieve the document in which the given AST node is contained. A reference to the document is\n * usually held by the root node of the AST.\n *\n * @throws an error if the node is not contained in a document.\n */\nexport function getDocument<T extends AstNode = AstNode>(node: AstNode): LangiumDocument<T> {\n    const rootNode = findRootNode(node);\n    const result = rootNode.$document;\n    if (!result) {\n        throw new Error('AST node has no document.');\n    }\n    return result as LangiumDocument<T>;\n}\n\n/**\n * Returns the root node of the given AST node by following the `$container` references.\n */\nexport function findRootNode(node: AstNode): AstNode {\n    while (node.$container) {\n        node = node.$container;\n    }\n    return node;\n}\n\nexport interface AstStreamOptions {\n    /**\n     * Optional target range that the nodes in the stream need to intersect\n     */\n    range?: Range\n}\n\n/**\n * Create a stream of all AST nodes that are directly contained in the given node. This includes\n * single-valued as well as multi-valued (array) properties.\n */\nexport function streamContents(node: AstNode, options?: AstStreamOptions): Stream<AstNode> {\n    if (!node) {\n        throw new Error('Node must be an AstNode.');\n    }\n    const range = options?.range;\n    type State = { keys: string[], keyIndex: number, arrayIndex: number };\n    return new StreamImpl<State, AstNode>(() => ({\n        keys: Object.keys(node),\n        keyIndex: 0,\n        arrayIndex: 0\n    }), state => {\n        while (state.keyIndex < state.keys.length) {\n            const property = state.keys[state.keyIndex];\n            if (!property.startsWith('$')) {\n                const value = (node as GenericAstNode)[property];\n                if (isAstNode(value)) {\n                    state.keyIndex++;\n                    if (isAstNodeInRange(value, range)) {\n                        return { done: false, value };\n                    }\n                } else if (Array.isArray(value)) {\n                    while (state.arrayIndex < value.length) {\n                        const index = state.arrayIndex++;\n                        const element = value[index];\n                        if (isAstNode(element) && isAstNodeInRange(element, range)) {\n                            return { done: false, value: element };\n                        }\n                    }\n                    state.arrayIndex = 0;\n                }\n            }\n            state.keyIndex++;\n        }\n        return DONE_RESULT;\n    });\n}\n\n/**\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node.\n * This does not include the root node itself.\n */\nexport function streamAllContents(root: AstNode, options?: AstStreamOptions): TreeStream<AstNode> {\n    if (!root) {\n        throw new Error('Root node must be an AstNode.');\n    }\n    return new TreeStreamImpl(root, node => streamContents(node, options));\n}\n\n/**\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node,\n * including the root node itself.\n */\nexport function streamAst(root: AstNode, options?: AstStreamOptions): TreeStream<AstNode> {\n    if (!root) {\n        throw new Error('Root node must be an AstNode.');\n    } else if (options?.range && !isAstNodeInRange(root, options.range)) {\n        // Return an empty stream if the root node isn't in range\n        return new TreeStreamImpl(root, () => []);\n    }\n    return new TreeStreamImpl(root, node => streamContents(node, options), { includeRoot: true });\n}\n\nfunction isAstNodeInRange(astNode: AstNode, range?: Range): boolean {\n    if (!range) {\n        return true;\n    }\n    const nodeRange = astNode.$cstNode?.range;\n    if (!nodeRange) {\n        return false;\n    }\n    return inRange(nodeRange, range);\n}\n\n/**\n * Create a stream of all cross-references that are held by the given AST node. This includes\n * single-valued as well as multi-valued (array) properties.\n */\nexport function streamReferences(node: AstNode): Stream<ReferenceInfo> {\n    type State = { keys: string[], keyIndex: number, arrayIndex: number };\n    return new StreamImpl<State, ReferenceInfo>(() => ({\n        keys: Object.keys(node),\n        keyIndex: 0,\n        arrayIndex: 0\n    }), state => {\n        while (state.keyIndex < state.keys.length) {\n            const property = state.keys[state.keyIndex];\n            if (!property.startsWith('$')) {\n                const value = (node as GenericAstNode)[property];\n                if (isReference(value)) {\n                    state.keyIndex++;\n                    return { done: false, value: { reference: value, container: node, property } };\n                } else if (Array.isArray(value)) {\n                    while (state.arrayIndex < value.length) {\n                        const index = state.arrayIndex++;\n                        const element = value[index];\n                        if (isReference(element)) {\n                            return { done: false, value: { reference: element, container: node, property, index } };\n                        }\n                    }\n                    state.arrayIndex = 0;\n                }\n            }\n            state.keyIndex++;\n        }\n        return DONE_RESULT;\n    });\n}\n\n/**\n * Returns a Stream of references to the target node from the AstNode tree\n *\n * @param targetNode AstNode we are looking for\n * @param lookup AstNode where we search for references. If not provided, the root node of the document is used as the default value\n */\nexport function findLocalReferences(targetNode: AstNode, lookup = getDocument(targetNode).parseResult.value): Stream<Reference> {\n    const refs: Reference[] = [];\n    streamAst(lookup).forEach(node => {\n        streamReferences(node).forEach(refInfo => {\n            if (refInfo.reference.ref === targetNode) {\n                refs.push(refInfo.reference);\n            }\n        });\n    });\n    return stream(refs);\n}\n\n/**\n * Assigns all mandatory AST properties to the specified node.\n *\n * @param reflection Reflection object used to gather mandatory properties for the node.\n * @param node Specified node is modified in place and properties are directly assigned.\n */\nexport function assignMandatoryProperties(reflection: AstReflection, node: AstNode): void {\n    const typeMetaData = reflection.getTypeMetaData(node.$type);\n    const genericNode = node as GenericAstNode;\n    for (const property of typeMetaData.properties) {\n        // Only set the value if the property is not already set and if it has a default value\n        if (property.defaultValue !== undefined && genericNode[property.name] === undefined) {\n            genericNode[property.name] = copyDefaultValue(property.defaultValue);\n        }\n    }\n}\n\nfunction copyDefaultValue(propertyType: PropertyType): PropertyType {\n    if (Array.isArray(propertyType)) {\n        return [...propertyType.map(copyDefaultValue)];\n    } else {\n        return propertyType;\n    }\n}\n\n/**\n * Creates a deep copy of the specified AST node.\n * The resulting copy will only contain semantically relevant information, such as the `$type` property and AST properties.\n *\n * References are copied without resolved cross reference. The specified function is used to rebuild them.\n */\nexport function copyAstNode<T extends AstNode = AstNode>(node: T, buildReference: (node: AstNode, property: string, refNode: CstNode | undefined, refText: string) => Reference<AstNode>): T {\n    const copy: GenericAstNode = { $type: node.$type };\n\n    for (const [name, value] of Object.entries(node)) {\n        if (!name.startsWith('$')) {\n            if (isAstNode(value)) {\n                copy[name] = copyAstNode(value, buildReference);\n            } else if (isReference(value)) {\n                copy[name] = buildReference(\n                    copy,\n                    name,\n                    value.$refNode,\n                    value.$refText\n                );\n            } else if (Array.isArray(value)) {\n                const copiedArray: unknown[] = [];\n                for (const element of value) {\n                    if (isAstNode(element)) {\n                        copiedArray.push(copyAstNode(element, buildReference));\n                    } else if (isReference(element)) {\n                        copiedArray.push(\n                            buildReference(\n                                copy,\n                                name,\n                                element.$refNode,\n                                element.$refText\n                            )\n                        );\n                    } else {\n                        copiedArray.push(element);\n                    }\n                }\n                copy[name] = copiedArray;\n            } else {\n                copy[name] = value;\n            }\n        }\n    }\n\n    linkContentToContainer(copy);\n    return copy as unknown as T;\n}\n","import type { Character, IRegExpAST, RegExpFlags } from \"../types\";\n\nexport function cc(char: string): number {\n  return char.charCodeAt(0);\n}\n\nexport function insertToSet<T>(item: T | T[], set: T[]) {\n  if (Array.isArray(item)) {\n    item.forEach(function (subItem) {\n      set.push(subItem);\n    });\n  } else {\n    set.push(item);\n  }\n}\n\nexport function addFlag(\n  flagObj: RegExpFlags,\n  flagKey: keyof Omit<RegExpFlags, keyof IRegExpAST>,\n) {\n  if (flagObj[flagKey] === true) {\n    throw \"duplicate flag \" + flagKey;\n  }\n\n  const x: boolean = flagObj[flagKey];\n  flagObj[flagKey] = true;\n}\n\nexport function ASSERT_EXISTS<T = Object>(obj: any): obj is T {\n  // istanbul ignore next\n  if (obj === undefined) {\n    throw Error(\"Internal Error - Should never get here!\");\n  }\n  return true;\n}\n\n// istanbul ignore next\nexport function ASSERT_NEVER_REACH_HERE(): any {\n  throw Error(\"Internal Error - Should never get here!\");\n}\n\nexport function isCharacter(obj: { type: string }): obj is Character {\n  return obj[\"type\"] === \"Character\";\n}\n","import { cc } from \"./utils.js\";\n\nexport const digitsCharCodes: number[] = [];\nfor (let i = cc(\"0\"); i <= cc(\"9\"); i++) {\n  digitsCharCodes.push(i);\n}\n\nexport const wordCharCodes: number[] = [cc(\"_\")].concat(digitsCharCodes);\nfor (let i = cc(\"a\"); i <= cc(\"z\"); i++) {\n  wordCharCodes.push(i);\n}\n\nfor (let i = cc(\"A\"); i <= cc(\"Z\"); i++) {\n  wordCharCodes.push(i);\n}\n\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp#character-classes\nexport const whitespaceCodes: number[] = [\n  cc(\" \"),\n  cc(\"\\f\"),\n  cc(\"\\n\"),\n  cc(\"\\r\"),\n  cc(\"\\t\"),\n  cc(\"\\v\"),\n  cc(\"\\t\"),\n  cc(\"\\u00a0\"),\n  cc(\"\\u1680\"),\n  cc(\"\\u2000\"),\n  cc(\"\\u2001\"),\n  cc(\"\\u2002\"),\n  cc(\"\\u2003\"),\n  cc(\"\\u2004\"),\n  cc(\"\\u2005\"),\n  cc(\"\\u2006\"),\n  cc(\"\\u2007\"),\n  cc(\"\\u2008\"),\n  cc(\"\\u2009\"),\n  cc(\"\\u200a\"),\n  cc(\"\\u2028\"),\n  cc(\"\\u2029\"),\n  cc(\"\\u202f\"),\n  cc(\"\\u205f\"),\n  cc(\"\\u3000\"),\n  cc(\"\\ufeff\"),\n];\n","import type {\n  Alternative,\n  Assertion,\n  Atom,\n  Character,\n  Disjunction,\n  Group,\n  GroupBackReference,\n  Location,\n  Quantifier,\n  Range,\n  RegExpFlags,\n  RegExpPattern,\n  Set,\n  Term,\n} from \"../types\";\nimport {\n  addFlag,\n  ASSERT_EXISTS,\n  ASSERT_NEVER_REACH_HERE,\n  cc,\n  insertToSet,\n  isCharacter,\n} from \"./utils.js\";\nimport {\n  digitsCharCodes,\n  whitespaceCodes,\n  wordCharCodes,\n} from \"./character-classes.js\";\n\n// consts and utilities\nconst hexDigitPattern = /[0-9a-fA-F]/;\nconst decimalPattern = /[0-9]/;\nconst decimalPatternNoZero = /[1-9]/;\n\n// https://hackernoon.com/the-madness-of-parsing-real-world-javascript-regexps-d9ee336df983\n// https://www.ecma-international.org/ecma-262/8.0/index.html#prod-Pattern\nexport class RegExpParser {\n  protected idx: number = 0;\n  protected input: string = \"\";\n  protected groupIdx: number = 0;\n\n  protected saveState() {\n    return {\n      idx: this.idx,\n      input: this.input,\n      groupIdx: this.groupIdx,\n    };\n  }\n\n  protected restoreState(newState: {\n    idx: number;\n    input: string;\n    groupIdx: number;\n  }) {\n    this.idx = newState.idx;\n    this.input = newState.input;\n    this.groupIdx = newState.groupIdx;\n  }\n\n  public pattern(input: string): RegExpPattern {\n    // parser state\n    this.idx = 0;\n    this.input = input;\n    this.groupIdx = 0;\n\n    this.consumeChar(\"/\");\n    const value = this.disjunction();\n    this.consumeChar(\"/\");\n\n    const flags: RegExpFlags = {\n      type: \"Flags\",\n      loc: { begin: this.idx, end: input.length },\n      global: false,\n      ignoreCase: false,\n      multiLine: false,\n      unicode: false,\n      sticky: false,\n    };\n\n    while (this.isRegExpFlag()) {\n      switch (this.popChar()) {\n        case \"g\":\n          addFlag(flags, \"global\");\n          break;\n        case \"i\":\n          addFlag(flags, \"ignoreCase\");\n          break;\n        case \"m\":\n          addFlag(flags, \"multiLine\");\n          break;\n        case \"u\":\n          addFlag(flags, \"unicode\");\n          break;\n        case \"y\":\n          addFlag(flags, \"sticky\");\n          break;\n      }\n    }\n\n    if (this.idx !== this.input.length) {\n      throw Error(\"Redundant input: \" + this.input.substring(this.idx));\n    }\n    return {\n      type: \"Pattern\",\n      flags: flags,\n      value: value,\n      loc: this.loc(0),\n    };\n  }\n\n  protected disjunction(): Disjunction {\n    const alts = [];\n    const begin = this.idx;\n\n    alts.push(this.alternative());\n\n    while (this.peekChar() === \"|\") {\n      this.consumeChar(\"|\");\n      alts.push(this.alternative());\n    }\n\n    return { type: \"Disjunction\", value: alts, loc: this.loc(begin) };\n  }\n\n  protected alternative(): Alternative {\n    const terms = [];\n    const begin = this.idx;\n\n    while (this.isTerm()) {\n      terms.push(this.term());\n    }\n\n    return { type: \"Alternative\", value: terms, loc: this.loc(begin) };\n  }\n\n  protected term(): Term {\n    if (this.isAssertion()) {\n      return this.assertion();\n    } else {\n      return this.atom();\n    }\n  }\n\n  protected assertion(): Assertion {\n    const begin = this.idx;\n    switch (this.popChar()) {\n      case \"^\":\n        return {\n          type: \"StartAnchor\",\n          loc: this.loc(begin),\n        };\n      case \"$\":\n        return { type: \"EndAnchor\", loc: this.loc(begin) };\n      // '\\b' or '\\B'\n      case \"\\\\\":\n        switch (this.popChar()) {\n          case \"b\":\n            return {\n              type: \"WordBoundary\",\n              loc: this.loc(begin),\n            };\n          case \"B\":\n            return {\n              type: \"NonWordBoundary\",\n              loc: this.loc(begin),\n            };\n        }\n        // istanbul ignore next\n        throw Error(\"Invalid Assertion Escape\");\n      // '(?=' or '(?!'\n      case \"(\":\n        this.consumeChar(\"?\");\n\n        let type: \"Lookahead\" | \"NegativeLookahead\" | undefined;\n        switch (this.popChar()) {\n          case \"=\":\n            type = \"Lookahead\";\n            break;\n          case \"!\":\n            type = \"NegativeLookahead\";\n            break;\n        }\n        ASSERT_EXISTS(type);\n\n        const disjunction = this.disjunction();\n\n        this.consumeChar(\")\");\n\n        return {\n          type: type!,\n          value: disjunction,\n          loc: this.loc(begin),\n        };\n    }\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected quantifier(\n    isBacktracking: boolean = false,\n  ): Quantifier | undefined {\n    let range: Partial<Quantifier> | undefined = undefined;\n    const begin = this.idx;\n    switch (this.popChar()) {\n      case \"*\":\n        range = {\n          atLeast: 0,\n          atMost: Infinity,\n        };\n        break;\n      case \"+\":\n        range = {\n          atLeast: 1,\n          atMost: Infinity,\n        };\n        break;\n      case \"?\":\n        range = {\n          atLeast: 0,\n          atMost: 1,\n        };\n        break;\n      case \"{\":\n        const atLeast = this.integerIncludingZero();\n        switch (this.popChar()) {\n          case \"}\":\n            range = {\n              atLeast: atLeast,\n              atMost: atLeast,\n            };\n            break;\n          case \",\":\n            let atMost;\n            if (this.isDigit()) {\n              atMost = this.integerIncludingZero();\n              range = {\n                atLeast: atLeast,\n                atMost: atMost,\n              };\n            } else {\n              range = {\n                atLeast: atLeast,\n                atMost: Infinity,\n              };\n            }\n            this.consumeChar(\"}\");\n            break;\n        }\n        // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n        // causes severe performance degradations\n        if (isBacktracking === true && range === undefined) {\n          return undefined;\n        }\n        ASSERT_EXISTS(range);\n        break;\n    }\n\n    // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n    // causes severe performance degradations\n    if (isBacktracking === true && range === undefined) {\n      return undefined;\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS(range)) {\n      if (this.peekChar(0) === \"?\") {\n        this.consumeChar(\"?\");\n        range.greedy = false;\n      } else {\n        range.greedy = true;\n      }\n\n      range.type = \"Quantifier\";\n      range.loc = this.loc(begin);\n      return range as Quantifier;\n    }\n  }\n\n  protected atom(): Atom {\n    let atom: Omit<Atom, \"loc\" | \"type\"> | undefined;\n    const begin = this.idx;\n    switch (this.peekChar()) {\n      case \".\":\n        atom = this.dotAll();\n        break;\n      case \"\\\\\":\n        atom = this.atomEscape();\n        break;\n      case \"[\":\n        atom = this.characterClass();\n        break;\n      case \"(\":\n        atom = this.group();\n        break;\n    }\n\n    if (atom === undefined && this.isPatternCharacter()) {\n      atom = this.patternCharacter();\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS<Atom>(atom)) {\n      atom.loc = this.loc(begin);\n\n      if (this.isQuantifier()) {\n        atom.quantifier = this.quantifier();\n      }\n\n      return atom;\n    }\n\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected dotAll(): Omit<Set, \"loc\"> {\n    this.consumeChar(\".\");\n    return {\n      type: \"Set\",\n      complement: true,\n      value: [cc(\"\\n\"), cc(\"\\r\"), cc(\"\\u2028\"), cc(\"\\u2029\")],\n    };\n  }\n\n  protected atomEscape(): Omit<GroupBackReference | Set | Character, \"loc\"> {\n    this.consumeChar(\"\\\\\");\n\n    switch (this.peekChar()) {\n      case \"1\":\n      case \"2\":\n      case \"3\":\n      case \"4\":\n      case \"5\":\n      case \"6\":\n      case \"7\":\n      case \"8\":\n      case \"9\":\n        return this.decimalEscapeAtom();\n      case \"d\":\n      case \"D\":\n      case \"s\":\n      case \"S\":\n      case \"w\":\n      case \"W\":\n        return this.characterClassEscape();\n      case \"f\":\n      case \"n\":\n      case \"r\":\n      case \"t\":\n      case \"v\":\n        return this.controlEscapeAtom();\n      case \"c\":\n        return this.controlLetterEscapeAtom();\n      case \"0\":\n        return this.nulCharacterAtom();\n      case \"x\":\n        return this.hexEscapeSequenceAtom();\n      case \"u\":\n        return this.regExpUnicodeEscapeSequenceAtom();\n      default:\n        return this.identityEscapeAtom();\n    }\n  }\n\n  protected decimalEscapeAtom(): Omit<GroupBackReference, \"loc\"> {\n    const value = this.positiveInteger();\n\n    return { type: \"GroupBackReference\", value: value };\n  }\n\n  protected characterClassEscape(): Omit<Set, \"loc\"> {\n    let set: (number | Range)[] | undefined;\n    let complement = false;\n    switch (this.popChar()) {\n      case \"d\":\n        set = digitsCharCodes;\n        break;\n      case \"D\":\n        set = digitsCharCodes;\n        complement = true;\n        break;\n      case \"s\":\n        set = whitespaceCodes;\n        break;\n      case \"S\":\n        set = whitespaceCodes;\n        complement = true;\n        break;\n      case \"w\":\n        set = wordCharCodes;\n        break;\n      case \"W\":\n        set = wordCharCodes;\n        complement = true;\n        break;\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS(set)) {\n      return { type: \"Set\", value: set, complement: complement };\n    }\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected controlEscapeAtom(): Omit<Character, \"loc\"> {\n    let escapeCode;\n    switch (this.popChar()) {\n      case \"f\":\n        escapeCode = cc(\"\\f\");\n        break;\n      case \"n\":\n        escapeCode = cc(\"\\n\");\n        break;\n      case \"r\":\n        escapeCode = cc(\"\\r\");\n        break;\n      case \"t\":\n        escapeCode = cc(\"\\t\");\n        break;\n      case \"v\":\n        escapeCode = cc(\"\\v\");\n        break;\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS(escapeCode)) {\n      return { type: \"Character\", value: escapeCode };\n    }\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected controlLetterEscapeAtom(): Omit<Character, \"loc\"> {\n    this.consumeChar(\"c\");\n    const letter = this.popChar();\n    if (/[a-zA-Z]/.test(letter) === false) {\n      throw Error(\"Invalid \");\n    }\n\n    const letterCode = letter.toUpperCase().charCodeAt(0) - 64;\n    return { type: \"Character\", value: letterCode };\n  }\n\n  protected nulCharacterAtom(): Omit<Character, \"loc\"> {\n    // TODO implement '[lookahead ∉ DecimalDigit]'\n    // TODO: for the deprecated octal escape sequence\n    this.consumeChar(\"0\");\n    return { type: \"Character\", value: cc(\"\\0\") };\n  }\n\n  protected hexEscapeSequenceAtom(): Omit<Character, \"loc\"> {\n    this.consumeChar(\"x\");\n    return this.parseHexDigits(2);\n  }\n\n  protected regExpUnicodeEscapeSequenceAtom(): Omit<Character, \"loc\"> {\n    this.consumeChar(\"u\");\n    return this.parseHexDigits(4);\n  }\n\n  protected identityEscapeAtom(): Omit<Character, \"loc\"> {\n    // TODO: implement \"SourceCharacter but not UnicodeIDContinue\"\n    // // http://unicode.org/reports/tr31/#Specific_Character_Adjustments\n    const escapedChar = this.popChar();\n    return { type: \"Character\", value: cc(escapedChar) };\n  }\n\n  protected classPatternCharacterAtom(): Omit<Character, \"loc\"> {\n    switch (this.peekChar()) {\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n      // istanbul ignore next\n      case \"\\\\\":\n      // istanbul ignore next\n      case \"]\":\n        throw Error(\"TBD\");\n      default:\n        const nextChar = this.popChar();\n        return { type: \"Character\", value: cc(nextChar) };\n    }\n  }\n\n  protected characterClass(): Omit<Set, \"loc\"> {\n    const set: (number | Range)[] = [];\n    let complement = false;\n    this.consumeChar(\"[\");\n    if (this.peekChar(0) === \"^\") {\n      this.consumeChar(\"^\");\n      complement = true;\n    }\n\n    while (this.isClassAtom()) {\n      const from = this.classAtom();\n      const isFromSingleChar = from.type === \"Character\";\n      if (isCharacter(from) && this.isRangeDash()) {\n        this.consumeChar(\"-\");\n        const to = this.classAtom();\n        const isToSingleChar = to.type === \"Character\";\n\n        // a range can only be used when both sides are single characters\n        if (isCharacter(to)) {\n          if (to.value < from.value) {\n            throw Error(\"Range out of order in character class\");\n          }\n          set.push({ from: from.value, to: to.value });\n        } else {\n          // literal dash\n          insertToSet(from.value, set);\n          set.push(cc(\"-\"));\n          insertToSet(to.value, set);\n        }\n      } else {\n        insertToSet(from.value, set);\n      }\n    }\n\n    this.consumeChar(\"]\");\n\n    return { type: \"Set\", complement: complement, value: set };\n  }\n\n  protected classAtom(): Omit<Character | Set, \"loc\"> {\n    switch (this.peekChar()) {\n      // istanbul ignore next\n      case \"]\":\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n        throw Error(\"TBD\");\n      case \"\\\\\":\n        return this.classEscape();\n      default:\n        return this.classPatternCharacterAtom();\n    }\n  }\n\n  protected classEscape(): Omit<Character | Set, \"loc\"> {\n    this.consumeChar(\"\\\\\");\n    switch (this.peekChar()) {\n      // Matches a backspace.\n      // (Not to be confused with \\b word boundary outside characterClass)\n      case \"b\":\n        this.consumeChar(\"b\");\n        return { type: \"Character\", value: cc(\"\\u0008\") };\n      case \"d\":\n      case \"D\":\n      case \"s\":\n      case \"S\":\n      case \"w\":\n      case \"W\":\n        return this.characterClassEscape();\n      case \"f\":\n      case \"n\":\n      case \"r\":\n      case \"t\":\n      case \"v\":\n        return this.controlEscapeAtom();\n      case \"c\":\n        return this.controlLetterEscapeAtom();\n      case \"0\":\n        return this.nulCharacterAtom();\n      case \"x\":\n        return this.hexEscapeSequenceAtom();\n      case \"u\":\n        return this.regExpUnicodeEscapeSequenceAtom();\n      default:\n        return this.identityEscapeAtom();\n    }\n  }\n\n  protected group(): Omit<Group, \"loc\"> {\n    let capturing = true;\n    this.consumeChar(\"(\");\n    switch (this.peekChar(0)) {\n      case \"?\":\n        this.consumeChar(\"?\");\n        this.consumeChar(\":\");\n        capturing = false;\n        break;\n      default:\n        this.groupIdx++;\n        break;\n    }\n    const value = this.disjunction();\n    this.consumeChar(\")\");\n\n    const groupAst: Omit<Group, \"loc\"> = {\n      type: \"Group\",\n      capturing: capturing,\n      value: value,\n    };\n\n    if (capturing) {\n      groupAst[\"idx\"] = this.groupIdx;\n    }\n\n    return groupAst;\n  }\n\n  protected positiveInteger(): number {\n    let number = this.popChar();\n\n    // istanbul ignore next - can't ever get here due to previous lookahead checks\n    // still implementing this error checking in case this ever changes.\n    if (decimalPatternNoZero.test(number) === false) {\n      throw Error(\"Expecting a positive integer\");\n    }\n\n    while (decimalPattern.test(this.peekChar(0))) {\n      number += this.popChar();\n    }\n\n    return parseInt(number, 10);\n  }\n\n  protected integerIncludingZero(): number {\n    let number = this.popChar();\n    if (decimalPattern.test(number) === false) {\n      throw Error(\"Expecting an integer\");\n    }\n\n    while (decimalPattern.test(this.peekChar(0))) {\n      number += this.popChar();\n    }\n\n    return parseInt(number, 10);\n  }\n\n  protected patternCharacter(): Omit<Character, \"loc\"> {\n    const nextChar = this.popChar();\n    switch (nextChar) {\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n      // istanbul ignore next\n      case \"^\":\n      // istanbul ignore next\n      case \"$\":\n      // istanbul ignore next\n      case \"\\\\\":\n      // istanbul ignore next\n      case \".\":\n      // istanbul ignore next\n      case \"*\":\n      // istanbul ignore next\n      case \"+\":\n      // istanbul ignore next\n      case \"?\":\n      // istanbul ignore next\n      case \"(\":\n      // istanbul ignore next\n      case \")\":\n      // istanbul ignore next\n      case \"[\":\n      // istanbul ignore next\n      case \"|\":\n        // istanbul ignore next\n        throw Error(\"TBD\");\n      default:\n        return { type: \"Character\", value: cc(nextChar) };\n    }\n  }\n  protected isRegExpFlag(): boolean {\n    switch (this.peekChar(0)) {\n      case \"g\":\n      case \"i\":\n      case \"m\":\n      case \"u\":\n      case \"y\":\n        return true;\n      default:\n        return false;\n    }\n  }\n\n  protected isRangeDash(): boolean {\n    return this.peekChar() === \"-\" && this.isClassAtom(1);\n  }\n\n  protected isDigit(): boolean {\n    return decimalPattern.test(this.peekChar(0));\n  }\n\n  protected isClassAtom(howMuch = 0): boolean {\n    switch (this.peekChar(howMuch)) {\n      case \"]\":\n      case \"\\n\":\n      case \"\\r\":\n      case \"\\u2028\":\n      case \"\\u2029\":\n        return false;\n      default:\n        return true;\n    }\n  }\n\n  protected isTerm() {\n    return this.isAtom() || this.isAssertion();\n  }\n\n  protected isAtom(): boolean {\n    if (this.isPatternCharacter()) {\n      return true;\n    }\n\n    switch (this.peekChar(0)) {\n      case \".\":\n      case \"\\\\\": // atomEscape\n      case \"[\": // characterClass\n      // TODO: isAtom must be called before isAssertion - disambiguate\n      case \"(\": // group\n        return true;\n      default:\n        return false;\n    }\n  }\n\n  protected isAssertion(): boolean {\n    switch (this.peekChar(0)) {\n      case \"^\":\n      case \"$\":\n        return true;\n      // '\\b' or '\\B'\n      case \"\\\\\":\n        switch (this.peekChar(1)) {\n          case \"b\":\n          case \"B\":\n            return true;\n          default:\n            return false;\n        }\n      // '(?=' or '(?!'\n      case \"(\":\n        return (\n          this.peekChar(1) === \"?\" &&\n          (this.peekChar(2) === \"=\" || this.peekChar(2) === \"!\")\n        );\n      default:\n        return false;\n    }\n  }\n\n  protected isQuantifier(): boolean {\n    const prevState = this.saveState();\n    try {\n      return this.quantifier(true) !== undefined;\n    } catch (e) {\n      return false;\n    } finally {\n      this.restoreState(prevState);\n    }\n  }\n\n  protected isPatternCharacter(): boolean {\n    switch (this.peekChar()) {\n      case \"^\":\n      case \"$\":\n      case \"\\\\\":\n      case \".\":\n      case \"*\":\n      case \"+\":\n      case \"?\":\n      case \"(\":\n      case \")\":\n      case \"[\":\n      case \"|\":\n      case \"/\":\n      case \"\\n\":\n      case \"\\r\":\n      case \"\\u2028\":\n      case \"\\u2029\":\n        return false;\n      default:\n        return true;\n    }\n  }\n\n  protected parseHexDigits(howMany: number): Omit<Character, \"loc\"> {\n    let hexString = \"\";\n    for (let i = 0; i < howMany; i++) {\n      const hexChar = this.popChar();\n      if (hexDigitPattern.test(hexChar) === false) {\n        throw Error(\"Expecting a HexDecimal digits\");\n      }\n      hexString += hexChar;\n    }\n    const charCode = parseInt(hexString, 16);\n    return { type: \"Character\", value: charCode };\n  }\n\n  protected peekChar(howMuch = 0): string {\n    return this.input[this.idx + howMuch];\n  }\n\n  protected popChar(): string {\n    const nextChar = this.peekChar(0);\n    this.consumeChar(undefined);\n    return nextChar;\n  }\n\n  protected consumeChar(char: string | undefined): void {\n    if (char !== undefined && this.input[this.idx] !== char) {\n      throw Error(\n        \"Expected: '\" +\n          char +\n          \"' but found: '\" +\n          this.input[this.idx] +\n          \"' at offset: \" +\n          this.idx,\n      );\n    }\n\n    if (this.idx >= this.input.length) {\n      throw Error(\"Unexpected end of input\");\n    }\n    this.idx++;\n  }\n\n  protected loc(begin: number): Location {\n    return { begin: begin, end: this.idx };\n  }\n}\n","import type {\n  Alternative,\n  Assertion,\n  Character,\n  Disjunction,\n  Group,\n  GroupBackReference,\n  IRegExpAST,\n  Quantifier,\n  RegExpAstPart,\n  RegExpFlags,\n  RegExpPattern,\n  Set,\n} from \"../types\";\n\nexport class BaseRegExpVisitor {\n  public visitChildren(node: IRegExpAST) {\n    for (const key in node) {\n      const child = (node as any)[key];\n      /* istanbul ignore else */\n      if (node.hasOwnProperty(key)) {\n        if (child.type !== undefined) {\n          this.visit(child);\n        } else if (Array.isArray(child)) {\n          child.forEach((subChild) => {\n            this.visit(subChild);\n          }, this);\n        }\n      }\n    }\n  }\n\n  public visit(node: RegExpAstPart): void {\n    switch (node.type) {\n      case \"Pattern\":\n        this.visitPattern(node);\n        break;\n      case \"Flags\":\n        this.visitFlags(node);\n        break;\n      case \"Disjunction\":\n        this.visitDisjunction(node);\n        break;\n      case \"Alternative\":\n        this.visitAlternative(node);\n        break;\n      case \"StartAnchor\":\n        this.visitStartAnchor(node);\n        break;\n      case \"EndAnchor\":\n        this.visitEndAnchor(node);\n        break;\n      case \"WordBoundary\":\n        this.visitWordBoundary(node);\n        break;\n      case \"NonWordBoundary\":\n        this.visitNonWordBoundary(node);\n        break;\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        break;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        break;\n      case \"Character\":\n        this.visitCharacter(node);\n        break;\n      case \"Set\":\n        this.visitSet(node);\n        break;\n      case \"Group\":\n        this.visitGroup(node);\n        break;\n      case \"GroupBackReference\":\n        this.visitGroupBackReference(node);\n        break;\n      case \"Quantifier\":\n        this.visitQuantifier(node);\n        break;\n    }\n\n    this.visitChildren(node);\n  }\n\n  public visitPattern(node: RegExpPattern): void {}\n\n  public visitFlags(node: RegExpFlags): void {}\n\n  public visitDisjunction(node: Disjunction): void {}\n\n  public visitAlternative(node: Alternative): void {}\n\n  // Assertion\n  public visitStartAnchor(node: Assertion): void {}\n\n  public visitEndAnchor(node: Assertion): void {}\n\n  public visitWordBoundary(node: Assertion): void {}\n\n  public visitNonWordBoundary(node: Assertion): void {}\n\n  public visitLookahead(node: Assertion): void {}\n\n  public visitNegativeLookahead(node: Assertion): void {}\n\n  // atoms\n  public visitCharacter(node: Character): void {}\n\n  public visitSet(node: Set): void {}\n\n  public visitGroup(node: Group): void {}\n\n  public visitGroupBackReference(node: GroupBackReference): void {}\n\n  public visitQuantifier(node: Quantifier): void {}\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { Set, Group, Character, IRegExpAST } from '@chevrotain/regexp-to-ast';\nimport { RegExpParser, BaseRegExpVisitor } from '@chevrotain/regexp-to-ast';\n\nexport const NEWLINE_REGEXP = /\\r?\\n/gm;\n\nconst regexpParser = new RegExpParser();\n\n/**\n * This class is in charge of heuristically identifying start/end tokens of terminals.\n *\n * The way this works is by doing the following:\n * 1. Traverse the regular expression in the \"start state\"\n * 2. Add any encountered sets/single characters to the \"start regexp\"\n * 3. Once we encounter any variable-length content (i.e. with quantifiers such as +/?/*), we enter the \"end state\"\n * 4. In the end state, any sets/single characters are added to an \"end stack\".\n * 5. If we re-encounter any variable-length content we reset the end stack\n * 6. We continue visiting the regex until the end, reseting the end stack and rebuilding it as necessary\n *\n * After traversing a regular expression the `startRegexp/endRegexp` properties allow access to the stored start/end of the terminal\n */\nclass TerminalRegExpVisitor extends BaseRegExpVisitor {\n\n    private isStarting = true;\n    startRegexp: string;\n    private endRegexpStack: string[] = [];\n    multiline = false;\n    regex: string;\n\n    get endRegex(): string {\n        return this.endRegexpStack.join('');\n    }\n\n    reset(regex: string): void {\n        this.multiline = false;\n        this.regex = regex;\n        this.startRegexp = '';\n        this.isStarting = true;\n        this.endRegexpStack = [];\n    }\n\n    override visitGroup(node: Group) {\n        if (node.quantifier) {\n            this.isStarting = false;\n            this.endRegexpStack = [];\n        }\n    }\n\n    override visitCharacter(node: Character): void {\n        const char = String.fromCharCode(node.value);\n        if (!this.multiline && char === '\\n') {\n            this.multiline = true;\n        }\n        if (node.quantifier) {\n            this.isStarting = false;\n            this.endRegexpStack = [];\n        } else {\n            const escapedChar = escapeRegExp(char);\n            this.endRegexpStack.push(escapedChar);\n            if (this.isStarting) {\n                this.startRegexp += escapedChar;\n            }\n        }\n    }\n\n    override visitSet(node: Set): void {\n        if (!this.multiline) {\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\n            const regex = new RegExp(set);\n            this.multiline = Boolean('\\n'.match(regex));\n        }\n        if (node.quantifier) {\n            this.isStarting = false;\n            this.endRegexpStack = [];\n        } else {\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\n            this.endRegexpStack.push(set);\n            if (this.isStarting) {\n                this.startRegexp += set;\n            }\n        }\n    }\n\n    override visitChildren(node: IRegExpAST): void {\n        if (node.type === 'Group') {\n            // Ignore children of groups with quantifier (+/*/?)\n            // These groups are unrelated to start/end tokens of terminals\n            const group = node as Group;\n            if (group.quantifier) {\n                return;\n            }\n        }\n        super.visitChildren(node);\n    }\n}\n\nconst visitor = new TerminalRegExpVisitor();\n\nexport function getTerminalParts(regexp: RegExp | string): Array<{ start: string, end: string }> {\n    try {\n        if (typeof regexp !== 'string') {\n            regexp = regexp.source;\n        }\n        regexp = `/${regexp}/`;\n        const pattern = regexpParser.pattern(regexp);\n        const parts: Array<{ start: string, end: string }> = [];\n        for (const alternative of pattern.value.value) {\n            visitor.reset(regexp);\n            visitor.visit(alternative);\n            parts.push({\n                start: visitor.startRegexp,\n                end: visitor.endRegex\n            });\n        }\n        return parts;\n    } catch {\n        return [];\n    }\n}\n\nexport function isMultilineComment(regexp: RegExp | string): boolean {\n    try {\n        if (typeof regexp === 'string') {\n            regexp = new RegExp(regexp);\n        }\n        regexp = regexp.toString();\n        visitor.reset(regexp);\n        // Parsing the pattern might fail (since it's user code)\n        visitor.visit(regexpParser.pattern(regexp));\n        return visitor.multiline;\n    } catch {\n        return false;\n    }\n}\n\nexport function isWhitespace(value: RegExp | string): boolean {\n    const regexp = typeof value === 'string' ? new RegExp(value) : value;\n    return regexp.test(' ');\n}\n\nexport function escapeRegExp(value: string): string {\n    return value.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n}\n\nexport function getCaseInsensitivePattern(keyword: string): string {\n    return Array.prototype.map.call(keyword, letter =>\n        /\\w/.test(letter) ? `[${letter.toLowerCase()}${letter.toUpperCase()}]` : escapeRegExp(letter)\n    ).join('');\n}\n\n/**\n * Determines whether the given input has a partial match with the specified regex.\n * @param regex The regex to partially match against\n * @param input The input string\n * @returns Whether any match exists.\n */\nexport function partialMatches(regex: RegExp | string, input: string): boolean {\n    const partial = partialRegExp(regex);\n    const match = input.match(partial);\n    return !!match && match[0].length > 0;\n}\n\n/**\n * Builds a partial regex from the input regex. A partial regex is able to match incomplete input strings. E.g.\n * a partial regex constructed from `/ab/` is able to match the string `a` without needing a following `b` character. However it won't match `b` alone.\n * @param regex The input regex to be converted.\n * @returns A partial regex constructed from the input regex.\n */\nexport function partialRegExp(regex: RegExp | string): RegExp {\n    if (typeof regex === 'string') {\n        regex = new RegExp(regex);\n    }\n    const re = regex, source = regex.source;\n    let i = 0;\n\n    function process() {\n        let result = '',\n            tmp;\n\n        function appendRaw(nbChars: number) {\n            result += source.substr(i, nbChars);\n            i += nbChars;\n        }\n\n        function appendOptional(nbChars: number) {\n            result += '(?:' + source.substr(i, nbChars) + '|$)';\n            i += nbChars;\n        }\n\n        while (i < source.length) {\n            switch (source[i]) {\n                case '\\\\':\n                    switch (source[i + 1]) {\n                        case 'c':\n                            appendOptional(3);\n                            break;\n                        case 'x':\n                            appendOptional(4);\n                            break;\n                        case 'u':\n                            if (re.unicode) {\n                                if (source[i + 2] === '{') {\n                                    appendOptional(source.indexOf('}', i) - i + 1);\n                                } else {\n                                    appendOptional(6);\n                                }\n                            } else {\n                                appendOptional(2);\n                            }\n                            break;\n                        case 'p':\n                        case 'P':\n                            if (re.unicode) {\n                                appendOptional(source.indexOf('}', i) - i + 1);\n                            } else {\n                                appendOptional(2);\n                            }\n                            break;\n                        case 'k':\n                            appendOptional(source.indexOf('>', i) - i + 1);\n                            break;\n                        default:\n                            appendOptional(2);\n                            break;\n                    }\n                    break;\n\n                case '[':\n                    tmp = /\\[(?:\\\\.|.)*?\\]/g;\n                    tmp.lastIndex = i;\n                    tmp = tmp.exec(source) || [];\n                    appendOptional(tmp[0].length);\n                    break;\n\n                case '|':\n                case '^':\n                case '$':\n                case '*':\n                case '+':\n                case '?':\n                    appendRaw(1);\n                    break;\n                case '{':\n                    tmp = /\\{\\d+,?\\d*\\}/g;\n                    tmp.lastIndex = i;\n                    tmp = tmp.exec(source);\n                    if (tmp) {\n                        appendRaw(tmp[0].length);\n                    } else {\n                        appendOptional(1);\n                    }\n                    break;\n                case '(':\n                    if (source[i + 1] === '?') {\n                        switch (source[i + 2]) {\n                            case ':':\n                                result += '(?:';\n                                i += 3;\n                                result += process() + '|$)';\n                                break;\n                            case '=':\n                                result += '(?=';\n                                i += 3;\n                                result += process() + ')';\n                                break;\n                            case '!':\n                                tmp = i;\n                                i += 3;\n                                process();\n                                result += source.substr(tmp, i - tmp);\n                                break;\n                            case '<':\n                                switch (source[i + 3]) {\n                                    case '=':\n                                    case '!':\n                                        tmp = i;\n                                        i += 4;\n                                        process();\n                                        result += source.substr(tmp, i - tmp);\n                                        break;\n                                    default:\n                                        appendRaw(source.indexOf('>', i) - i + 1);\n                                        result += process() + '|$)';\n                                        break;\n                                }\n                                break;\n                        }\n                    } else {\n                        appendRaw(1);\n                        result += process() + '|$)';\n                    }\n                    break;\n                case ')':\n                    ++i;\n                    return result;\n                default:\n                    appendOptional(1);\n                    break;\n            }\n        }\n\n        return result;\n    }\n\n    return new RegExp(process(), regex.flags);\n}\n","/******************************************************************************\n * Copyright 2021-2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport { assertUnreachable } from '../utils/errors.js';\nimport * as ast from '../languages/generated/ast.js';\nimport type { AstNode, CstNode } from '../syntax-tree.js';\nimport { isCompositeCstNode } from '../syntax-tree.js';\nimport { getContainerOfType, streamAllContents } from './ast-utils.js';\nimport { streamCst } from './cst-utils.js';\nimport { escapeRegExp } from './regexp-utils.js';\n\n/**\n * Returns the entry rule of the given grammar, if any. If the grammar file does not contain an entry rule,\n * the result is `undefined`.\n */\nexport function getEntryRule(grammar: ast.Grammar): ast.ParserRule | undefined {\n    return grammar.rules.find(e => ast.isParserRule(e) && e.entry) as ast.ParserRule;\n}\n\n/**\n * Returns all hidden terminal rules of the given grammar, if any.\n */\nexport function getHiddenRules(grammar: ast.Grammar) {\n    return grammar.rules.filter((e): e is ast.TerminalRule => ast.isTerminalRule(e) && e.hidden);\n}\n\n/**\n * Returns all rules that can be reached from the topmost rules of the specified grammar (entry and hidden terminal rules).\n *\n * @param grammar The grammar that contains all rules\n * @param allTerminals Whether or not to include terminals that are referenced only by other terminals\n * @returns A list of referenced parser and terminal rules. If the grammar contains no entry rule,\n *      this function returns all rules of the specified grammar.\n */\nexport function getAllReachableRules(grammar: ast.Grammar, allTerminals: boolean): Set<ast.AbstractRule> {\n    const ruleNames = new Set<string>();\n    const entryRule = getEntryRule(grammar);\n    if (!entryRule) {\n        return new Set(grammar.rules);\n    }\n\n    const topMostRules = [entryRule as ast.AbstractRule].concat(getHiddenRules(grammar));\n    for (const rule of topMostRules) {\n        ruleDfs(rule, ruleNames, allTerminals);\n    }\n\n    const rules = new Set<ast.AbstractRule>();\n    for (const rule of grammar.rules) {\n        if (ruleNames.has(rule.name) || (ast.isTerminalRule(rule) && rule.hidden)) {\n            rules.add(rule);\n        }\n    }\n    return rules;\n}\n\nfunction ruleDfs(rule: ast.AbstractRule, visitedSet: Set<string>, allTerminals: boolean): void {\n    visitedSet.add(rule.name);\n    streamAllContents(rule).forEach(node => {\n        if (ast.isRuleCall(node) || (allTerminals && ast.isTerminalRuleCall(node))) {\n            const refRule = node.rule.ref;\n            if (refRule && !visitedSet.has(refRule.name)) {\n                ruleDfs(refRule, visitedSet, allTerminals);\n            }\n        }\n    });\n}\n\n/**\n * Determines the grammar expression used to parse a cross-reference (usually a reference to a terminal rule).\n * A cross-reference can declare this expression explicitly in the form `[Type : Terminal]`, but if `Terminal`\n * is omitted, this function attempts to infer it from the name of the referenced `Type` (using `findNameAssignment`).\n *\n * Returns the grammar expression used to parse the given cross-reference, or `undefined` if it is not declared\n * and cannot be inferred.\n */\nexport function getCrossReferenceTerminal(crossRef: ast.CrossReference): ast.AbstractElement | undefined {\n    if (crossRef.terminal) {\n        return crossRef.terminal;\n    } else if (crossRef.type.ref) {\n        const nameAssigment = findNameAssignment(crossRef.type.ref);\n        return nameAssigment?.terminal;\n    }\n    return undefined;\n}\n\n/**\n * Determines whether the given terminal rule represents a comment. This is true if the rule is marked\n * as `hidden` and it does not match white space. This means every hidden token (i.e. excluded from the AST)\n * that contains visible characters is considered a comment.\n */\nexport function isCommentTerminal(terminalRule: ast.TerminalRule): boolean {\n    return terminalRule.hidden && !terminalRegex(terminalRule).test(' ');\n}\n\n/**\n * Find all CST nodes within the given node that contribute to the specified property.\n *\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is an empty array.\n * @param property A property name of the constructed AST node. If this is undefined, the result is an empty array.\n */\nexport function findNodesForProperty(node: CstNode | undefined, property: string | undefined): CstNode[] {\n    if (!node || !property) {\n        return [];\n    }\n    return findNodesForPropertyInternal(node, property, node.astNode, true);\n}\n\n/**\n * Find a single CST node within the given node that contributes to the specified property.\n *\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is `undefined`.\n * @param property A property name of the constructed AST node. If this is undefined, the result is `undefined`.\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\n *        specified index exceeds the number of assignments to the property, the last found node is returned. Otherwise,\n *        the node with the specified index is returned.\n */\nexport function findNodeForProperty(node: CstNode | undefined, property: string | undefined, index?: number): CstNode | undefined {\n    if (!node || !property) {\n        return undefined;\n    }\n    const nodes = findNodesForPropertyInternal(node, property, node.astNode, true);\n    if (nodes.length === 0) {\n        return undefined;\n    }\n    if (index !== undefined) {\n        index = Math.max(0, Math.min(index, nodes.length - 1));\n    } else {\n        index = 0;\n    }\n    return nodes[index];\n}\n\nfunction findNodesForPropertyInternal(node: CstNode, property: string, element: AstNode | undefined, first: boolean): CstNode[] {\n    if (!first) {\n        const nodeFeature = getContainerOfType(node.grammarSource, ast.isAssignment);\n        if (nodeFeature && nodeFeature.feature === property) {\n            return [node];\n        }\n    }\n    if (isCompositeCstNode(node) && node.astNode === element) {\n        return node.content.flatMap(e => findNodesForPropertyInternal(e, property, element, false));\n    }\n    return [];\n}\n\n/**\n * Find all CST nodes within the given node that correspond to the specified keyword.\n *\n * @param node A CST node in which to look for keywords. If this is undefined, the result is an empty array.\n * @param keyword A keyword as specified in the grammar.\n */\nexport function findNodesForKeyword(node: CstNode | undefined, keyword: string): CstNode[] {\n    if (!node) {\n        return [];\n    }\n    return findNodesForKeywordInternal(node, keyword, node?.astNode);\n}\n\n/**\n * Find a single CST node within the given node that corresponds to the specified keyword.\n *\n * @param node A CST node in which to look for keywords. If this is undefined, the result is `undefined`.\n * @param keyword A keyword as specified in the grammar.\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\n *        specified index exceeds the number of keyword occurrences, the last found node is returned. Otherwise,\n *        the node with the specified index is returned.\n */\nexport function findNodeForKeyword(node: CstNode | undefined, keyword: string, index?: number): CstNode | undefined {\n    if (!node) {\n        return undefined;\n    }\n    const nodes = findNodesForKeywordInternal(node, keyword, node?.astNode);\n    if (nodes.length === 0) {\n        return undefined;\n    }\n    if (index !== undefined) {\n        index = Math.max(0, Math.min(index, nodes.length - 1));\n    } else {\n        index = 0;\n    }\n    return nodes[index];\n}\n\nexport function findNodesForKeywordInternal(node: CstNode, keyword: string, element: AstNode | undefined): CstNode[] {\n    if (node.astNode !== element) {\n        return [];\n    }\n    if (ast.isKeyword(node.grammarSource) && node.grammarSource.value === keyword) {\n        return [node];\n    }\n    const treeIterator = streamCst(node).iterator();\n    let result: IteratorResult<CstNode>;\n    const keywordNodes: CstNode[] = [];\n    do {\n        result = treeIterator.next();\n        if (!result.done) {\n            const childNode = result.value;\n            if (childNode.astNode === element) {\n                if (ast.isKeyword(childNode.grammarSource) && childNode.grammarSource.value === keyword) {\n                    keywordNodes.push(childNode);\n                }\n            } else {\n                treeIterator.prune();\n            }\n        }\n    } while (!result.done);\n    return keywordNodes;\n}\n\n/**\n * If the given CST node was parsed in the context of a property assignment, the respective `Assignment` grammar\n * node is returned. If no assignment is found, the result is `undefined`.\n *\n * @param cstNode A CST node for which to find a property assignment.\n */\nexport function findAssignment(cstNode: CstNode): ast.Assignment | undefined {\n    const astNode = cstNode.astNode;\n    // Only search until the ast node of the parent cst node is no longer the original ast node\n    // This would make us jump to a preceding rule call, which contains only unrelated assignments\n    while (astNode === cstNode.container?.astNode) {\n        const assignment = getContainerOfType(cstNode.grammarSource, ast.isAssignment);\n        if (assignment) {\n            return assignment;\n        }\n        cstNode = cstNode.container;\n    }\n    return undefined;\n}\n\n/**\n * Find an assignment to the `name` property for the given grammar type. This requires the `type` to be inferred\n * from a parser rule, and that rule must contain an assignment to the `name` property. In all other cases,\n * this function returns `undefined`.\n */\nexport function findNameAssignment(type: ast.AbstractType): ast.Assignment | undefined {\n    let startNode: AstNode = type;\n    if (ast.isInferredType(startNode)) {\n        // for inferred types, the location to start searching for the name-assignment is different\n        if (ast.isAction(startNode.$container)) {\n            // a type which is explicitly inferred by an action: investigate the sibbling of the Action node, i.e. start searching at the Action's parent\n            startNode = startNode.$container.$container!;\n        } else if (ast.isParserRule(startNode.$container)) {\n            // investigate the parser rule with the explicitly inferred type\n            startNode = startNode.$container;\n        } else {\n            assertUnreachable(startNode.$container);\n        }\n    }\n    return findNameAssignmentInternal(type, startNode, new Map());\n}\n\nfunction findNameAssignmentInternal(type: ast.AbstractType, startNode: AstNode, cache: Map<ast.AbstractType, ast.Assignment | undefined>): ast.Assignment | undefined {\n    // the cache is only required to prevent infinite loops\n    function go(node: AstNode, refType: ast.AbstractType): ast.Assignment | undefined {\n        let childAssignment: ast.Assignment | undefined = undefined;\n        const parentAssignment = getContainerOfType(node, ast.isAssignment);\n        // No parent assignment implies unassigned rule call\n        if (!parentAssignment) {\n            childAssignment = findNameAssignmentInternal(refType, refType, cache);\n        }\n        cache.set(type, childAssignment);\n        return childAssignment;\n    }\n\n    if (cache.has(type)) {\n        return cache.get(type);\n    }\n    cache.set(type, undefined);\n    for (const node of streamAllContents(startNode)) {\n        if (ast.isAssignment(node) && node.feature.toLowerCase() === 'name') {\n            cache.set(type, node);\n            return node;\n        } else if (ast.isRuleCall(node) && ast.isParserRule(node.rule.ref)) {\n            return go(node, node.rule.ref);\n        } else if (ast.isSimpleType(node) && node.typeRef?.ref) {\n            return go(node, node.typeRef.ref);\n        }\n    }\n    return undefined;\n}\n\nexport function getActionAtElement(element: ast.AbstractElement): ast.Action | undefined {\n    const parent = element.$container;\n    if (ast.isGroup(parent)) {\n        const elements = parent.elements;\n        const index = elements.indexOf(element);\n        for (let i = index - 1; i >= 0; i--) {\n            const item = elements[i];\n            if (ast.isAction(item)) {\n                return item;\n            } else {\n                const action = streamAllContents(elements[i]).find(ast.isAction);\n                if (action) {\n                    return action;\n                }\n            }\n        }\n    }\n    if (ast.isAbstractElement(parent)) {\n        return getActionAtElement(parent);\n    } else {\n        return undefined;\n    }\n}\n\nexport type Cardinality = '?' | '*' | '+' | undefined;\nexport type Operator = '=' | '+=' | '?=' | undefined;\n\nexport function isOptionalCardinality(cardinality?: Cardinality, element?: ast.AbstractElement): boolean {\n    return cardinality === '?' || cardinality === '*' || (ast.isGroup(element) && Boolean(element.guardCondition));\n}\n\nexport function isArrayCardinality(cardinality?: Cardinality): boolean {\n    return cardinality === '*' || cardinality === '+';\n}\n\nexport function isArrayOperator(operator?: Operator): boolean {\n    return operator === '+=';\n}\n\n/**\n * Determines whether the given parser rule is a _data type rule_, meaning that it has a\n * primitive return type like `number`, `boolean`, etc.\n */\nexport function isDataTypeRule(rule: ast.ParserRule): boolean {\n    return isDataTypeRuleInternal(rule, new Set());\n}\n\nfunction isDataTypeRuleInternal(rule: ast.ParserRule, visited: Set<ast.ParserRule>): boolean {\n    if (visited.has(rule)) {\n        return true;\n    } else {\n        visited.add(rule);\n    }\n    for (const node of streamAllContents(rule)) {\n        if (ast.isRuleCall(node)) {\n            if (!node.rule.ref) {\n                // RuleCall to unresolved rule. Don't assume `rule` is a DataType rule.\n                return false;\n            }\n            if (ast.isParserRule(node.rule.ref) && !isDataTypeRuleInternal(node.rule.ref, visited)) {\n                return false;\n            }\n        } else if (ast.isAssignment(node)) {\n            return false;\n        } else if (ast.isAction(node)) {\n            return false;\n        }\n    }\n    return Boolean(rule.definition);\n}\n\nexport function isDataType(type: ast.Type): boolean {\n    return isDataTypeInternal(type.type, new Set());\n}\n\nfunction isDataTypeInternal(type: ast.TypeDefinition, visited: Set<ast.TypeDefinition>): boolean {\n    if (visited.has(type)) {\n        return true;\n    } else {\n        visited.add(type);\n    }\n    if (ast.isArrayType(type)) {\n        return false;\n    } else if (ast.isReferenceType(type)) {\n        return false;\n    } else if (ast.isUnionType(type)) {\n        return type.types.every(e => isDataTypeInternal(e, visited));\n    } else if (ast.isSimpleType(type)) {\n        if (type.primitiveType !== undefined) {\n            return true;\n        } else if (type.stringType !== undefined) {\n            return true;\n        } else if (type.typeRef !== undefined) {\n            const ref = type.typeRef.ref;\n            if (ast.isType(ref)) {\n                return isDataTypeInternal(ref.type, visited);\n            } else {\n                return false;\n            }\n        } else {\n            return false;\n        }\n    } else {\n        return false;\n    }\n}\n\nexport function getExplicitRuleType(rule: ast.ParserRule): string | undefined {\n    if (rule.inferredType) {\n        return rule.inferredType.name;\n    } else if (rule.dataType) {\n        return rule.dataType;\n    } else if (rule.returnType) {\n        const refType = rule.returnType.ref;\n        if(refType) {\n            // check if we need to check Action as return type\n            if (ast.isParserRule(refType)) {\n                return refType.name;\n            }  else if(ast.isInterface(refType) || ast.isType(refType)) {\n                return refType.name;\n            }\n        }\n    }\n    return undefined;\n}\n\nexport function getTypeName(type: ast.AbstractType | ast.Action): string {\n    if (ast.isParserRule(type)) {\n        return isDataTypeRule(type) ? type.name : getExplicitRuleType(type) ?? type.name;\n    } else if (ast.isInterface(type) || ast.isType(type) || ast.isReturnType(type)) {\n        return type.name;\n    } else if (ast.isAction(type)) {\n        const actionType = getActionType(type);\n        if (actionType) {\n            return actionType;\n        }\n    } else if (ast.isInferredType(type)) {\n        return type.name;\n    }\n    throw new Error('Cannot get name of Unknown Type');\n}\n\nexport function getActionType(action: ast.Action): string | undefined {\n    if (action.inferredType) {\n        return action.inferredType.name;\n    } else if (action.type?.ref) {\n        return getTypeName(action.type.ref);\n    }\n    return undefined; // not inferring and not referencing a valid type\n}\n\nexport function getRuleType(rule: ast.AbstractRule): string {\n    if (ast.isTerminalRule(rule)) {\n        return rule.type?.name ?? 'string';\n    } else {\n        return isDataTypeRule(rule) ? rule.name : getExplicitRuleType(rule) ?? rule.name;\n    }\n}\n\nexport function terminalRegex(terminalRule: ast.TerminalRule): RegExp {\n    const flags: Flags = {\n        s: false,\n        i: false,\n        u: false\n    };\n    const source = abstractElementToRegex(terminalRule.definition, flags);\n    const flagText = Object.entries(flags).filter(([, value]) => value).map(([name]) => name).join('');\n    return new RegExp(source, flagText);\n}\n\n// Using [\\s\\S]* allows to match everything, compared to . which doesn't match line terminators\nconst WILDCARD = /[\\s\\S]/.source;\n\ntype Flags = {\n    s: boolean;\n    i: boolean;\n    u: boolean;\n}\n\nfunction abstractElementToRegex(element: ast.AbstractElement, flags?: Flags): string {\n    if (ast.isTerminalAlternatives(element)) {\n        return terminalAlternativesToRegex(element);\n    } else if (ast.isTerminalGroup(element)) {\n        return terminalGroupToRegex(element);\n    } else if (ast.isCharacterRange(element)) {\n        return characterRangeToRegex(element);\n    } else if (ast.isTerminalRuleCall(element)) {\n        const rule = element.rule.ref;\n        if (!rule) {\n            throw new Error('Missing rule reference.');\n        }\n        return withCardinality(abstractElementToRegex(rule.definition), {\n            cardinality: element.cardinality,\n            lookahead: element.lookahead\n        });\n    } else if (ast.isNegatedToken(element)) {\n        return negateTokenToRegex(element);\n    } else if (ast.isUntilToken(element)) {\n        return untilTokenToRegex(element);\n    } else if (ast.isRegexToken(element)) {\n        const lastSlash = element.regex.lastIndexOf('/');\n        const source = element.regex.substring(1, lastSlash);\n        const regexFlags = element.regex.substring(lastSlash + 1);\n        if (flags) {\n            flags.i = regexFlags.includes('i');\n            flags.s = regexFlags.includes('s');\n            flags.u = regexFlags.includes('u');\n        }\n        return withCardinality(source, {\n            cardinality: element.cardinality,\n            lookahead: element.lookahead,\n            wrap: false\n        });\n    } else if (ast.isWildcard(element)) {\n        return withCardinality(WILDCARD, {\n            cardinality: element.cardinality,\n            lookahead: element.lookahead\n        });\n    } else {\n        throw new Error(`Invalid terminal element: ${element?.$type}`);\n    }\n}\n\nfunction terminalAlternativesToRegex(alternatives: ast.TerminalAlternatives): string {\n    return withCardinality(alternatives.elements.map(e => abstractElementToRegex(e)).join('|'), {\n        cardinality: alternatives.cardinality,\n        lookahead: alternatives.lookahead\n    });\n}\n\nfunction terminalGroupToRegex(group: ast.TerminalGroup): string {\n    return withCardinality(group.elements.map(e => abstractElementToRegex(e)).join(''), {\n        cardinality: group.cardinality,\n        lookahead: group.lookahead\n    });\n}\n\nfunction untilTokenToRegex(until: ast.UntilToken): string {\n    return withCardinality(`${WILDCARD}*?${abstractElementToRegex(until.terminal)}`, {\n        cardinality: until.cardinality,\n        lookahead: until.lookahead\n    });\n}\n\nfunction negateTokenToRegex(negate: ast.NegatedToken): string {\n    return withCardinality(`(?!${abstractElementToRegex(negate.terminal)})${WILDCARD}*?`, {\n        cardinality: negate.cardinality,\n        lookahead: negate.lookahead\n    });\n}\n\nfunction characterRangeToRegex(range: ast.CharacterRange): string {\n    if (range.right) {\n        return withCardinality(`[${keywordToRegex(range.left)}-${keywordToRegex(range.right)}]`, {\n            cardinality: range.cardinality,\n            lookahead: range.lookahead,\n            wrap: false\n        });\n    }\n    return withCardinality(keywordToRegex(range.left), {\n        cardinality: range.cardinality,\n        lookahead: range.lookahead,\n        wrap: false\n    });\n}\n\nfunction keywordToRegex(keyword: ast.Keyword): string {\n    return escapeRegExp(keyword.value);\n}\n\nfunction withCardinality(regex: string, options: {\n    cardinality?: string\n    wrap?: boolean\n    lookahead?: string\n}): string {\n    if (options.wrap !== false || options.lookahead) {\n        regex = `(${options.lookahead ?? ''}${regex})`;\n    }\n    if (options.cardinality) {\n        return `${regex}${options.cardinality}`;\n    }\n    return regex;\n}\n","// based on: https://github.com/petkaantonov/bluebird/blob/b97c0d2d487e8c5076e8bd897e0dcd4622d31846/src/util.js#L201-L216\nexport function toFastProperties(toBecomeFast: any) {\n  function FakeConstructor() {}\n\n  // If our object is used as a constructor, it would receive\n  FakeConstructor.prototype = toBecomeFast;\n  const fakeInstance = new (FakeConstructor as any)();\n\n  function fakeAccess() {\n    return typeof fakeInstance.bar;\n  }\n\n  // help V8 understand this is a \"real\" prototype by actually using\n  // the fake instance.\n  fakeAccess();\n  fakeAccess();\n\n  // Always true condition to suppress the Firefox warning of unreachable\n  // code after a return statement.\n  if (1) return toBecomeFast;\n\n  // Eval prevents optimization of this method (even though this is dead code)\n  // - https://esbuild.github.io/content-types/#direct-eval\n  /* istanbul ignore next */\n  // tslint:disable-next-line\n  (0, eval)(toBecomeFast);\n}\n","/**\n * The base implementation of `_.slice` without an iteratee call guard.\n *\n * @private\n * @param {Array} array The array to slice.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the slice of `array`.\n */\nfunction baseSlice(array, start, end) {\n  var index = -1,\n      length = array.length;\n\n  if (start < 0) {\n    start = -start > length ? 0 : (length + start);\n  }\n  end = end > length ? length : end;\n  if (end < 0) {\n    end += length;\n  }\n  length = start > end ? 0 : ((end - start) >>> 0);\n  start >>>= 0;\n\n  var result = Array(length);\n  while (++index < length) {\n    result[index] = array[index + start];\n  }\n  return result;\n}\n\nexport default baseSlice;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the beginning.\n *\n * @static\n * @memberOf _\n * @since 0.5.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.drop([1, 2, 3]);\n * // => [2, 3]\n *\n * _.drop([1, 2, 3], 2);\n * // => [3]\n *\n * _.drop([1, 2, 3], 5);\n * // => []\n *\n * _.drop([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction drop(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  return baseSlice(array, n < 0 ? 0 : n, length);\n}\n\nexport default drop;\n","import assignValue from './_assignValue.js';\nimport copyObject from './_copyObject.js';\nimport createAssigner from './_createAssigner.js';\nimport isArrayLike from './isArrayLike.js';\nimport isPrototype from './_isPrototype.js';\nimport keys from './keys.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own enumerable string keyed properties of source objects to the\n * destination object. Source objects are applied from left to right.\n * Subsequent sources overwrite property assignments of previous sources.\n *\n * **Note:** This method mutates `object` and is loosely based on\n * [`Object.assign`](https://mdn.io/Object/assign).\n *\n * @static\n * @memberOf _\n * @since 0.10.0\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.assignIn\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * function Bar() {\n *   this.c = 3;\n * }\n *\n * Foo.prototype.b = 2;\n * Bar.prototype.d = 4;\n *\n * _.assign({ 'a': 0 }, new Foo, new Bar);\n * // => { 'a': 1, 'c': 3 }\n */\nvar assign = createAssigner(function(object, source) {\n  if (isPrototype(source) || isArrayLike(source)) {\n    copyObject(source, keys(source), object);\n    return;\n  }\n  for (var key in source) {\n    if (hasOwnProperty.call(source, key)) {\n      assignValue(object, key, source[key]);\n    }\n  }\n});\n\nexport default assign;\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport basePickBy from './_basePickBy.js';\nimport getAllKeysIn from './_getAllKeysIn.js';\n\n/**\n * Creates an object composed of the `object` properties `predicate` returns\n * truthy for. The predicate is invoked with two arguments: (value, key).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Object\n * @param {Object} object The source object.\n * @param {Function} [predicate=_.identity] The function invoked per property.\n * @returns {Object} Returns the new object.\n * @example\n *\n * var object = { 'a': 1, 'b': '2', 'c': 3 };\n *\n * _.pickBy(object, _.isNumber);\n * // => { 'a': 1, 'c': 3 }\n */\nfunction pickBy(object, predicate) {\n  if (object == null) {\n    return {};\n  }\n  var props = arrayMap(getAllKeysIn(object), function(prop) {\n    return [prop];\n  });\n  predicate = baseIteratee(predicate);\n  return basePickBy(object, props, function(value, path) {\n    return predicate(value, path[0]);\n  });\n}\n\nexport default pickBy;\n","import baseGetTag from './_baseGetTag.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar regexpTag = '[object RegExp]';\n\n/**\n * The base implementation of `_.isRegExp` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n */\nfunction baseIsRegExp(value) {\n  return isObjectLike(value) && baseGetTag(value) == regexpTag;\n}\n\nexport default baseIsRegExp;\n","import baseIsRegExp from './_baseIsRegExp.js';\nimport baseUnary from './_baseUnary.js';\nimport nodeUtil from './_nodeUtil.js';\n\n/* Node.js helper references. */\nvar nodeIsRegExp = nodeUtil && nodeUtil.isRegExp;\n\n/**\n * Checks if `value` is classified as a `RegExp` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n * @example\n *\n * _.isRegExp(/abc/);\n * // => true\n *\n * _.isRegExp('/abc/');\n * // => false\n */\nvar isRegExp = nodeIsRegExp ? baseUnary(nodeIsRegExp) : baseIsRegExp;\n\nexport default isRegExp;\n","import { assign, forEach, isRegExp, isString, map, pickBy } from \"lodash-es\";\nimport type {\n  IGASTVisitor,\n  IProduction,\n  IProductionWithOccurrence,\n  ISerializedGast,\n  TokenType,\n} from \"@chevrotain/types\";\n\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction tokenLabel(tokType: TokenType): string {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\n\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction hasTokenLabel(\n  obj: TokenType,\n): obj is TokenType & Pick<Required<TokenType>, \"LABEL\"> {\n  return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\n\nexport abstract class AbstractProduction<T extends IProduction = IProduction>\n  implements IProduction\n{\n  public get definition(): T[] {\n    return this._definition;\n  }\n  public set definition(value: T[]) {\n    this._definition = value;\n  }\n\n  constructor(protected _definition: T[]) {}\n\n  accept(visitor: IGASTVisitor): void {\n    visitor.visit(this);\n    forEach(this.definition, (prod) => {\n      prod.accept(visitor);\n    });\n  }\n}\n\nexport class NonTerminal\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public nonTerminalName!: string;\n  public label?: string;\n  public referencedRule!: Rule;\n  public idx: number = 1;\n\n  constructor(options: {\n    nonTerminalName: string;\n    label?: string;\n    referencedRule?: Rule;\n    idx?: number;\n  }) {\n    super([]);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n\n  set definition(definition: IProduction[]) {\n    // immutable\n  }\n\n  get definition(): IProduction[] {\n    if (this.referencedRule !== undefined) {\n      return this.referencedRule.definition;\n    }\n    return [];\n  }\n\n  accept(visitor: IGASTVisitor): void {\n    visitor.visit(this);\n    // don't visit children of a reference, we will get cyclic infinite loops if we do so\n  }\n}\n\nexport class Rule extends AbstractProduction {\n  public name!: string;\n  public orgText: string = \"\";\n\n  constructor(options: {\n    name: string;\n    definition: IProduction[];\n    orgText?: string;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Alternative extends AbstractProduction {\n  public ignoreAmbiguities: boolean = false;\n\n  constructor(options: {\n    definition: IProduction[];\n    ignoreAmbiguities?: boolean;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Option\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    idx?: number;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class RepetitionMandatory\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    idx?: number;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class RepetitionMandatoryWithSeparator\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public separator!: TokenType;\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    separator: TokenType;\n    idx?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Repetition\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public separator!: TokenType;\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    idx?: number;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class RepetitionWithSeparator\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public separator!: TokenType;\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    separator: TokenType;\n    idx?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Alternation\n  extends AbstractProduction<Alternative>\n  implements IProductionWithOccurrence\n{\n  public idx: number = 1;\n  public ignoreAmbiguities: boolean = false;\n  public hasPredicates: boolean = false;\n  public maxLookahead?: number;\n\n  public get definition(): Alternative[] {\n    return this._definition;\n  }\n  public set definition(value: Alternative[]) {\n    this._definition = value;\n  }\n\n  constructor(options: {\n    definition: Alternative[];\n    idx?: number;\n    ignoreAmbiguities?: boolean;\n    hasPredicates?: boolean;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Terminal implements IProductionWithOccurrence {\n  public terminalType!: TokenType;\n  public label?: string;\n  public idx: number = 1;\n\n  constructor(options: {\n    terminalType: TokenType;\n    label?: string;\n    idx?: number;\n  }) {\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n\n  accept(visitor: IGASTVisitor): void {\n    visitor.visit(this);\n  }\n}\n\nexport interface ISerializedBasic extends ISerializedGast {\n  type:\n    | \"Alternative\"\n    | \"Option\"\n    | \"RepetitionMandatory\"\n    | \"Repetition\"\n    | \"Alternation\";\n  idx?: number;\n}\n\nexport interface ISerializedGastRule extends ISerializedGast {\n  type: \"Rule\";\n  name: string;\n  orgText: string;\n}\n\nexport interface ISerializedNonTerminal extends ISerializedGast {\n  type: \"NonTerminal\";\n  name: string;\n  label?: string;\n  idx: number;\n}\n\nexport interface ISerializedTerminal extends ISerializedGast {\n  type: \"Terminal\";\n  name: string;\n  terminalLabel?: string;\n  label?: string;\n  pattern?: string;\n  idx: number;\n}\n\nexport interface ISerializedTerminalWithSeparator extends ISerializedGast {\n  type: \"RepetitionMandatoryWithSeparator\" | \"RepetitionWithSeparator\";\n  idx: number;\n  separator: ISerializedTerminal;\n}\n\nexport type ISerializedGastAny =\n  | ISerializedBasic\n  | ISerializedGastRule\n  | ISerializedNonTerminal\n  | ISerializedTerminal\n  | ISerializedTerminalWithSeparator;\n\nexport function serializeGrammar(topRules: Rule[]): ISerializedGast[] {\n  return map(topRules, serializeProduction);\n}\n\nexport function serializeProduction(node: IProduction): ISerializedGast {\n  function convertDefinition(definition: IProduction[]): ISerializedGast[] {\n    return map(definition, serializeProduction);\n  }\n  /* istanbul ignore else */\n  if (node instanceof NonTerminal) {\n    const serializedNonTerminal: ISerializedNonTerminal = {\n      type: \"NonTerminal\",\n      name: node.nonTerminalName,\n      idx: node.idx,\n    };\n\n    if (isString(node.label)) {\n      serializedNonTerminal.label = node.label;\n    }\n\n    return serializedNonTerminal;\n  } else if (node instanceof Alternative) {\n    return <ISerializedBasic>{\n      type: \"Alternative\",\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Option) {\n    return <ISerializedBasic>{\n      type: \"Option\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof RepetitionMandatory) {\n    return <ISerializedBasic>{\n      type: \"RepetitionMandatory\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof RepetitionMandatoryWithSeparator) {\n    return <ISerializedTerminalWithSeparator>{\n      type: \"RepetitionMandatoryWithSeparator\",\n      idx: node.idx,\n      separator: <ISerializedTerminal>(\n        serializeProduction(new Terminal({ terminalType: node.separator }))\n      ),\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof RepetitionWithSeparator) {\n    return <ISerializedTerminalWithSeparator>{\n      type: \"RepetitionWithSeparator\",\n      idx: node.idx,\n      separator: <ISerializedTerminal>(\n        serializeProduction(new Terminal({ terminalType: node.separator }))\n      ),\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Repetition) {\n    return <ISerializedBasic>{\n      type: \"Repetition\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Alternation) {\n    return <ISerializedBasic>{\n      type: \"Alternation\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Terminal) {\n    const serializedTerminal = <ISerializedTerminal>{\n      type: \"Terminal\",\n      name: node.terminalType.name,\n      label: tokenLabel(node.terminalType),\n      idx: node.idx,\n    };\n\n    if (isString(node.label)) {\n      serializedTerminal.terminalLabel = node.label;\n    }\n\n    const pattern = node.terminalType.PATTERN;\n    if (node.terminalType.PATTERN) {\n      serializedTerminal.pattern = isRegExp(pattern)\n        ? (<any>pattern).source\n        : pattern;\n    }\n\n    return serializedTerminal;\n  } else if (node instanceof Rule) {\n    return <ISerializedGastRule>{\n      type: \"Rule\",\n      name: node.name,\n      orgText: node.orgText,\n      definition: convertDefinition(node.definition),\n    };\n    /* c8 ignore next 3 */\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n","import {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"./model.js\";\nimport type { IProduction } from \"@chevrotain/types\";\n\nexport abstract class GAstVisitor {\n  public visit(node: IProduction): any {\n    const nodeAny: any = node;\n    switch (nodeAny.constructor) {\n      case NonTerminal:\n        return this.visitNonTerminal(nodeAny);\n      case Alternative:\n        return this.visitAlternative(nodeAny);\n      case Option:\n        return this.visitOption(nodeAny);\n      case RepetitionMandatory:\n        return this.visitRepetitionMandatory(nodeAny);\n      case RepetitionMandatoryWithSeparator:\n        return this.visitRepetitionMandatoryWithSeparator(nodeAny);\n      case RepetitionWithSeparator:\n        return this.visitRepetitionWithSeparator(nodeAny);\n      case Repetition:\n        return this.visitRepetition(nodeAny);\n      case Alternation:\n        return this.visitAlternation(nodeAny);\n      case Terminal:\n        return this.visitTerminal(nodeAny);\n      case Rule:\n        return this.visitRule(nodeAny);\n      /* c8 ignore next 2 */\n      default:\n        throw Error(\"non exhaustive match\");\n    }\n  }\n\n  /* c8 ignore next */\n  public visitNonTerminal(node: NonTerminal): any {}\n\n  /* c8 ignore next */\n  public visitAlternative(node: Alternative): any {}\n\n  /* c8 ignore next */\n  public visitOption(node: Option): any {}\n\n  /* c8 ignore next */\n  public visitRepetition(node: Repetition): any {}\n\n  /* c8 ignore next */\n  public visitRepetitionMandatory(node: RepetitionMandatory): any {}\n\n  /* c8 ignore next 3 */\n  public visitRepetitionMandatoryWithSeparator(\n    node: RepetitionMandatoryWithSeparator,\n  ): any {}\n\n  /* c8 ignore next */\n  public visitRepetitionWithSeparator(node: RepetitionWithSeparator): any {}\n\n  /* c8 ignore next */\n  public visitAlternation(node: Alternation): any {}\n\n  /* c8 ignore next */\n  public visitTerminal(node: Terminal): any {}\n\n  /* c8 ignore next */\n  public visitRule(node: Rule): any {}\n}\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.some` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n */\nfunction baseSome(collection, predicate) {\n  var result;\n\n  baseEach(collection, function(value, index, collection) {\n    result = predicate(value, index, collection);\n    return !result;\n  });\n  return !!result;\n}\n\nexport default baseSome;\n","import arraySome from './_arraySome.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseSome from './_baseSome.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **any** element of `collection`.\n * Iteration is stopped once `predicate` returns truthy. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n * @example\n *\n * _.some([null, 0, 'yes', false], Boolean);\n * // => true\n *\n * var users = [\n *   { 'user': 'barney', 'active': true },\n *   { 'user': 'fred',   'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.some(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.some(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.some(users, 'active');\n * // => true\n */\nfunction some(collection, predicate, guard) {\n  var func = isArray(collection) ? arraySome : baseSome;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default some;\n","import baseIndexOf from './_baseIndexOf.js';\nimport isArrayLike from './isArrayLike.js';\nimport isString from './isString.js';\nimport toInteger from './toInteger.js';\nimport values from './values.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Checks if `value` is in `collection`. If `collection` is a string, it's\n * checked for a substring of `value`, otherwise\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * is used for equality comparisons. If `fromIndex` is negative, it's used as\n * the offset from the end of `collection`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object|string} collection The collection to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.reduce`.\n * @returns {boolean} Returns `true` if `value` is found, else `false`.\n * @example\n *\n * _.includes([1, 2, 3], 1);\n * // => true\n *\n * _.includes([1, 2, 3], 1, 2);\n * // => false\n *\n * _.includes({ 'a': 1, 'b': 2 }, 1);\n * // => true\n *\n * _.includes('abcd', 'bc');\n * // => true\n */\nfunction includes(collection, value, fromIndex, guard) {\n  collection = isArrayLike(collection) ? collection : values(collection);\n  fromIndex = (fromIndex && !guard) ? toInteger(fromIndex) : 0;\n\n  var length = collection.length;\n  if (fromIndex < 0) {\n    fromIndex = nativeMax(length + fromIndex, 0);\n  }\n  return isString(collection)\n    ? (fromIndex <= length && collection.indexOf(value, fromIndex) > -1)\n    : (!!length && baseIndexOf(collection, value, fromIndex) > -1);\n}\n\nexport default includes;\n","/**\n * A specialized version of `_.every` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n */\nfunction arrayEvery(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (!predicate(array[index], index, array)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport default arrayEvery;\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.every` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`\n */\nfunction baseEvery(collection, predicate) {\n  var result = true;\n  baseEach(collection, function(value, index, collection) {\n    result = !!predicate(value, index, collection);\n    return result;\n  });\n  return result;\n}\n\nexport default baseEvery;\n","import arrayEvery from './_arrayEvery.js';\nimport baseEvery from './_baseEvery.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **all** elements of `collection`.\n * Iteration is stopped once `predicate` returns falsey. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * **Note:** This method returns `true` for\n * [empty collections](https://en.wikipedia.org/wiki/Empty_set) because\n * [everything is true](https://en.wikipedia.org/wiki/Vacuous_truth) of\n * elements of empty collections.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n * @example\n *\n * _.every([true, 1, null, 'yes'], Boolean);\n * // => false\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.every(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.every(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.every(users, 'active');\n * // => false\n */\nfunction every(collection, predicate, guard) {\n  var func = isArray(collection) ? arrayEvery : baseEvery;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default every;\n","import { every, includes, some } from \"lodash-es\";\nimport {\n  AbstractProduction,\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"./model.js\";\nimport type { IProduction, IProductionWithOccurrence } from \"@chevrotain/types\";\n\nexport function isSequenceProd(\n  prod: IProduction,\n): prod is { definition: IProduction[] } & IProduction {\n  return (\n    prod instanceof Alternative ||\n    prod instanceof Option ||\n    prod instanceof Repetition ||\n    prod instanceof RepetitionMandatory ||\n    prod instanceof RepetitionMandatoryWithSeparator ||\n    prod instanceof RepetitionWithSeparator ||\n    prod instanceof Terminal ||\n    prod instanceof Rule\n  );\n}\n\nexport function isOptionalProd(\n  prod: IProduction,\n  alreadyVisited: NonTerminal[] = [],\n): boolean {\n  const isDirectlyOptional =\n    prod instanceof Option ||\n    prod instanceof Repetition ||\n    prod instanceof RepetitionWithSeparator;\n  if (isDirectlyOptional) {\n    return true;\n  }\n\n  // note that this can cause infinite loop if one optional empty TOP production has a cyclic dependency with another\n  // empty optional top rule\n  // may be indirectly optional ((A?B?C?) | (D?E?F?))\n  if (prod instanceof Alternation) {\n    // for OR its enough for just one of the alternatives to be optional\n    return some((<Alternation>prod).definition, (subProd: IProduction) => {\n      return isOptionalProd(subProd, alreadyVisited);\n    });\n  } else if (prod instanceof NonTerminal && includes(alreadyVisited, prod)) {\n    // avoiding stack overflow due to infinite recursion\n    return false;\n  } else if (prod instanceof AbstractProduction) {\n    if (prod instanceof NonTerminal) {\n      alreadyVisited.push(prod);\n    }\n    return every(\n      (<AbstractProduction>prod).definition,\n      (subProd: IProduction) => {\n        return isOptionalProd(subProd, alreadyVisited);\n      },\n    );\n  } else {\n    return false;\n  }\n}\n\nexport function isBranchingProd(\n  prod: IProduction,\n): prod is { definition: IProduction[] } & IProduction {\n  return prod instanceof Alternation;\n}\n\nexport function getProductionDslName(prod: IProductionWithOccurrence): string {\n  /* istanbul ignore else */\n  if (prod instanceof NonTerminal) {\n    return \"SUBRULE\";\n  } else if (prod instanceof Option) {\n    return \"OPTION\";\n  } else if (prod instanceof Alternation) {\n    return \"OR\";\n  } else if (prod instanceof RepetitionMandatory) {\n    return \"AT_LEAST_ONE\";\n  } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n    return \"AT_LEAST_ONE_SEP\";\n  } else if (prod instanceof RepetitionWithSeparator) {\n    return \"MANY_SEP\";\n  } else if (prod instanceof Repetition) {\n    return \"MANY\";\n  } else if (prod instanceof Terminal) {\n    return \"CONSUME\";\n    /* c8 ignore next 3 */\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n","import { drop, forEach } from \"lodash-es\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { IProduction } from \"@chevrotain/types\";\n\n/**\n *  A Grammar Walker that computes the \"remaining\" grammar \"after\" a productions in the grammar.\n */\nexport abstract class RestWalker {\n  walk(prod: { definition: IProduction[] }, prevRest: any[] = []): void {\n    forEach(prod.definition, (subProd: IProduction, index) => {\n      const currRest = drop(prod.definition, index + 1);\n      /* istanbul ignore else */\n      if (subProd instanceof NonTerminal) {\n        this.walkProdRef(subProd, currRest, prevRest);\n      } else if (subProd instanceof Terminal) {\n        this.walkTerminal(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternative) {\n        this.walkFlat(subProd, currRest, prevRest);\n      } else if (subProd instanceof Option) {\n        this.walkOption(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatory) {\n        this.walkAtLeastOne(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatoryWithSeparator) {\n        this.walkAtLeastOneSep(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionWithSeparator) {\n        this.walkManySep(subProd, currRest, prevRest);\n      } else if (subProd instanceof Repetition) {\n        this.walkMany(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternation) {\n        this.walkOr(subProd, currRest, prevRest);\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {}\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {}\n\n  walkFlat(\n    flatProd: Alternative,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABCDEF => after the D the rest is EF\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(flatProd, <any>fullOrRest);\n  }\n\n  walkOption(\n    optionProd: Option,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)?F => after the (DE)? the rest is F\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(optionProd, <any>fullOrRest);\n  }\n\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)+F => after the (DE)+ the rest is (DE)?F\n    const fullAtLeastOneRest: IProduction[] = [\n      new Option({ definition: atLeastOneProd.definition }),\n    ].concat(<any>currRest, <any>prevRest);\n    this.walk(atLeastOneProd, fullAtLeastOneRest);\n  }\n\n  walkAtLeastOneSep(\n    atLeastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC DE(,DE)* F => after the (,DE)+ the rest is (,DE)?F\n    const fullAtLeastOneSepRest = restForRepetitionWithSeparator(\n      atLeastOneSepProd,\n      currRest,\n      prevRest,\n    );\n    this.walk(atLeastOneSepProd, fullAtLeastOneSepRest);\n  }\n\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)*F => after the (DE)* the rest is (DE)?F\n    const fullManyRest: IProduction[] = [\n      new Option({ definition: manyProd.definition }),\n    ].concat(<any>currRest, <any>prevRest);\n    this.walk(manyProd, fullManyRest);\n  }\n\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC (DE(,DE)*)? F => after the (,DE)* the rest is (,DE)?F\n    const fullManySepRest = restForRepetitionWithSeparator(\n      manySepProd,\n      currRest,\n      prevRest,\n    );\n    this.walk(manySepProd, fullManySepRest);\n  }\n\n  walkOr(\n    orProd: Alternation,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(D|E|F)G => when finding the (D|E|F) the rest is G\n    const fullOrRest = currRest.concat(prevRest);\n    // walk all different alternatives\n    forEach(orProd.definition, (alt) => {\n      // wrapping each alternative in a single definition wrapper\n      // to avoid errors in computing the rest of that alternative in the invocation to computeInProdFollows\n      // (otherwise for OR([alt1,alt2]) alt2 will be considered in 'rest' of alt1\n      const prodWrapper = new Alternative({ definition: [alt] });\n      this.walk(prodWrapper, <any>fullOrRest);\n    });\n  }\n}\n\nfunction restForRepetitionWithSeparator(\n  repSepProd: RepetitionWithSeparator,\n  currRest: IProduction[],\n  prevRest: IProduction[],\n) {\n  const repSepRest = [\n    new Option({\n      definition: [\n        new Terminal({ terminalType: repSepProd.separator }) as IProduction,\n      ].concat(repSepProd.definition),\n    }) as IProduction,\n  ];\n  const fullRepSepRest: IProduction[] = repSepRest.concat(currRest, prevRest);\n  return fullRepSepRest;\n}\n","import baseUniq from './_baseUniq.js';\n\n/**\n * Creates a duplicate-free version of an array, using\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons, in which only the first occurrence of each element\n * is kept. The order of result values is determined by the order they occur\n * in the array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniq([2, 1, 2]);\n * // => [2, 1]\n */\nfunction uniq(array) {\n  return (array && array.length) ? baseUniq(array) : [];\n}\n\nexport default uniq;\n","import { flatten, map, uniq } from \"lodash-es\";\nimport {\n  isBranchingProd,\n  isOptionalProd,\n  isSequenceProd,\n  NonTerminal,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { IProduction, TokenType } from \"@chevrotain/types\";\n\nexport function first(prod: IProduction): TokenType[] {\n  /* istanbul ignore else */\n  if (prod instanceof NonTerminal) {\n    // this could in theory cause infinite loops if\n    // (1) prod A refs prod B.\n    // (2) prod B refs prod A\n    // (3) AB can match the empty set\n    // in other words a cycle where everything is optional so the first will keep\n    // looking ahead for the next optional part and will never exit\n    // currently there is no safeguard for this unique edge case because\n    // (1) not sure a grammar in which this can happen is useful for anything (productive)\n    return first((<NonTerminal>prod).referencedRule);\n  } else if (prod instanceof Terminal) {\n    return firstForTerminal(<Terminal>prod);\n  } else if (isSequenceProd(prod)) {\n    return firstForSequence(prod);\n  } else if (isBranchingProd(prod)) {\n    return firstForBranching(prod);\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function firstForSequence(prod: {\n  definition: IProduction[];\n}): TokenType[] {\n  let firstSet: TokenType[] = [];\n  const seq = prod.definition;\n  let nextSubProdIdx = 0;\n  let hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  let currSubProd;\n  // so we enter the loop at least once (if the definition is not empty\n  let isLastInnerProdOptional = true;\n  // scan a sequence until it's end or until we have found a NONE optional production in it\n  while (hasInnerProdsRemaining && isLastInnerProdOptional) {\n    currSubProd = seq[nextSubProdIdx];\n    isLastInnerProdOptional = isOptionalProd(currSubProd);\n    firstSet = firstSet.concat(first(currSubProd));\n    nextSubProdIdx = nextSubProdIdx + 1;\n    hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  }\n\n  return uniq(firstSet);\n}\n\nexport function firstForBranching(prod: {\n  definition: IProduction[];\n}): TokenType[] {\n  const allAlternativesFirsts: TokenType[][] = map(\n    prod.definition,\n    (innerProd) => {\n      return first(innerProd);\n    },\n  );\n  return uniq(flatten<TokenType>(allAlternativesFirsts));\n}\n\nexport function firstForTerminal(terminal: Terminal): TokenType[] {\n  return [terminal.terminalType];\n}\n","// TODO: can this be removed? where is it used?\nexport const IN = \"_~IN~_\";\n","import { RestWalker } from \"./rest.js\";\nimport { first } from \"./first.js\";\nimport { assign, forEach } from \"lodash-es\";\nimport { IN } from \"../constants.js\";\nimport { Alternative, NonTerminal, Rule, Terminal } from \"@chevrotain/gast\";\nimport { IProduction, TokenType } from \"@chevrotain/types\";\n\n// This ResyncFollowsWalker computes all of the follows required for RESYNC\n// (skipping reference production).\nexport class ResyncFollowsWalker extends RestWalker {\n  public follows: Record<string, TokenType[]> = {};\n\n  constructor(private topProd: Rule) {\n    super();\n  }\n\n  startWalking(): Record<string, TokenType[]> {\n    this.walk(this.topProd);\n    return this.follows;\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // do nothing! just like in the public sector after 13:00\n  }\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    const followName =\n      buildBetweenProdsFollowPrefix(refProd.referencedRule, refProd.idx) +\n      this.topProd.name;\n    const fullRest: IProduction[] = currRest.concat(prevRest);\n    const restProd = new Alternative({ definition: fullRest });\n    const t_in_topProd_follows = first(restProd);\n    this.follows[followName] = t_in_topProd_follows;\n  }\n}\n\nexport function computeAllProdsFollows(\n  topProductions: Rule[],\n): Record<string, TokenType[]> {\n  const reSyncFollows = {};\n\n  forEach(topProductions, (topProd) => {\n    const currRefsFollow = new ResyncFollowsWalker(topProd).startWalking();\n    assign(reSyncFollows, currRefsFollow);\n  });\n  return reSyncFollows;\n}\n\nexport function buildBetweenProdsFollowPrefix(\n  inner: Rule,\n  occurenceInParent: number,\n): string {\n  return inner.name + occurenceInParent + IN;\n}\n\nexport function buildInProdFollowPrefix(terminal: Terminal): string {\n  const terminalName = terminal.terminalType.name;\n  return terminalName + terminal.idx + IN;\n}\n","/** Error message constants. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/**\n * Creates a function that negates the result of the predicate `func`. The\n * `func` predicate is invoked with the `this` binding and arguments of the\n * created function.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Function\n * @param {Function} predicate The predicate to negate.\n * @returns {Function} Returns the new negated function.\n * @example\n *\n * function isEven(n) {\n *   return n % 2 == 0;\n * }\n *\n * _.filter([1, 2, 3, 4, 5, 6], _.negate(isEven));\n * // => [1, 3, 5]\n */\nfunction negate(predicate) {\n  if (typeof predicate != 'function') {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  return function() {\n    var args = arguments;\n    switch (args.length) {\n      case 0: return !predicate.call(this);\n      case 1: return !predicate.call(this, args[0]);\n      case 2: return !predicate.call(this, args[0], args[1]);\n      case 3: return !predicate.call(this, args[0], args[1], args[2]);\n    }\n    return !predicate.apply(this, args);\n  };\n}\n\nexport default negate;\n","import arrayFilter from './_arrayFilter.js';\nimport baseFilter from './_baseFilter.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport negate from './negate.js';\n\n/**\n * The opposite of `_.filter`; this method returns the elements of `collection`\n * that `predicate` does **not** return truthy for.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n * @see _.filter\n * @example\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': true }\n * ];\n *\n * _.reject(users, function(o) { return !o.active; });\n * // => objects for ['fred']\n *\n * // The `_.matches` iteratee shorthand.\n * _.reject(users, { 'age': 40, 'active': true });\n * // => objects for ['barney']\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.reject(users, ['active', false]);\n * // => objects for ['fred']\n *\n * // The `_.property` iteratee shorthand.\n * _.reject(users, 'active');\n * // => objects for ['barney']\n */\nfunction reject(collection, predicate) {\n  var func = isArray(collection) ? arrayFilter : baseFilter;\n  return func(collection, negate(baseIteratee(predicate, 3)));\n}\n\nexport default reject;\n","import baseIndexOf from './_baseIndexOf.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Gets the index at which the first occurrence of `value` is found in `array`\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. If `fromIndex` is negative, it's used as the\n * offset from the end of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n * @example\n *\n * _.indexOf([1, 2, 1, 2], 2);\n * // => 1\n *\n * // Search from the `fromIndex`.\n * _.indexOf([1, 2, 1, 2], 2, 2);\n * // => 3\n */\nfunction indexOf(array, value, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseIndexOf(array, value, index);\n}\n\nexport default indexOf;\n","import SetCache from './_SetCache.js';\nimport arrayIncludes from './_arrayIncludes.js';\nimport arrayIncludesWith from './_arrayIncludesWith.js';\nimport arrayMap from './_arrayMap.js';\nimport baseUnary from './_baseUnary.js';\nimport cacheHas from './_cacheHas.js';\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * The base implementation of methods like `_.difference` without support\n * for excluding multiple arrays or iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Array} values The values to exclude.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new array of filtered values.\n */\nfunction baseDifference(array, values, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      isCommon = true,\n      length = array.length,\n      result = [],\n      valuesLength = values.length;\n\n  if (!length) {\n    return result;\n  }\n  if (iteratee) {\n    values = arrayMap(values, baseUnary(iteratee));\n  }\n  if (comparator) {\n    includes = arrayIncludesWith;\n    isCommon = false;\n  }\n  else if (values.length >= LARGE_ARRAY_SIZE) {\n    includes = cacheHas;\n    isCommon = false;\n    values = new SetCache(values);\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee == null ? value : iteratee(value);\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var valuesIndex = valuesLength;\n      while (valuesIndex--) {\n        if (values[valuesIndex] === computed) {\n          continue outer;\n        }\n      }\n      result.push(value);\n    }\n    else if (!includes(values, computed, comparator)) {\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nexport default baseDifference;\n","import baseDifference from './_baseDifference.js';\nimport baseFlatten from './_baseFlatten.js';\nimport baseRest from './_baseRest.js';\nimport isArrayLikeObject from './isArrayLikeObject.js';\n\n/**\n * Creates an array of `array` values not included in the other given arrays\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. The order and references of result values are\n * determined by the first array.\n *\n * **Note:** Unlike `_.pullAll`, this method returns a new array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {...Array} [values] The values to exclude.\n * @returns {Array} Returns the new array of filtered values.\n * @see _.without, _.xor\n * @example\n *\n * _.difference([2, 1], [2, 3]);\n * // => [1]\n */\nvar difference = baseRest(function(array, values) {\n  return isArrayLikeObject(array)\n    ? baseDifference(array, baseFlatten(values, 1, isArrayLikeObject, true))\n    : [];\n});\n\nexport default difference;\n","/**\n * Creates an array with all falsey values removed. The values `false`, `null`,\n * `0`, `\"\"`, `undefined`, and `NaN` are falsey.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to compact.\n * @returns {Array} Returns the new array of filtered values.\n * @example\n *\n * _.compact([0, 1, false, 2, '', 3]);\n * // => [1, 2, 3]\n */\nfunction compact(array) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n\n  while (++index < length) {\n    var value = array[index];\n    if (value) {\n      result[resIndex++] = value;\n    }\n  }\n  return result;\n}\n\nexport default compact;\n","/**\n * Gets the first element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @alias first\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the first element of `array`.\n * @example\n *\n * _.head([1, 2, 3]);\n * // => 1\n *\n * _.head([]);\n * // => undefined\n */\nfunction head(array) {\n  return (array && array.length) ? array[0] : undefined;\n}\n\nexport default head;\n","export function PRINT_ERROR(msg: string) {\n  /* istanbul ignore else - can't override global.console in node.js */\n  if (console && console.error) {\n    console.error(`Error: ${msg}`);\n  }\n}\n\nexport function PRINT_WARNING(msg: string) {\n  /* istanbul ignore else - can't override global.console in node.js*/\n  if (console && console.warn) {\n    // TODO: modify docs accordingly\n    console.warn(`Warning: ${msg}`);\n  }\n}\n","import {\n  Alternative,\n  Assertion,\n  Atom,\n  Disjunction,\n  RegExpParser,\n  RegExpPattern,\n} from \"@chevrotain/regexp-to-ast\";\n\nlet regExpAstCache: { [regex: string]: RegExpPattern } = {};\nconst regExpParser = new RegExpParser();\n\n// this should be moved to regexp-to-ast\nexport type ASTNode =\n  | RegExpPattern\n  | Disjunction\n  | Alternative\n  | Assertion\n  | Atom;\n\nexport function getRegExpAst(regExp: RegExp): RegExpPattern {\n  const regExpStr = regExp.toString();\n  if (regExpAstCache.hasOwnProperty(regExpStr)) {\n    return regExpAstCache[regExpStr];\n  } else {\n    const regExpAst = regExpParser.pattern(regExpStr);\n    regExpAstCache[regExpStr] = regExpAst;\n    return regExpAst;\n  }\n}\n\nexport function clearRegExpParserCache() {\n  regExpAstCache = {};\n}\n","import {\n  Alternative,\n  Atom,\n  BaseRegExpVisitor,\n  Character,\n  Disjunction,\n  Group,\n  Set,\n} from \"@chevrotain/regexp-to-ast\";\nimport { every, find, forEach, includes, isArray, values } from \"lodash-es\";\nimport { PRINT_ERROR, PRINT_WARNING } from \"@chevrotain/utils\";\nimport { ASTNode, getRegExpAst } from \"./reg_exp_parser.js\";\nimport { charCodeToOptimizedIndex, minOptimizationVal } from \"./lexer.js\";\n\nconst complementErrorMessage =\n  \"Complement Sets are not supported for first char optimization\";\nexport const failedOptimizationPrefixMsg =\n  'Unable to use \"first char\" lexer optimizations:\\n';\n\nexport function getOptimizedStartCodesIndices(\n  regExp: RegExp,\n  ensureOptimizations = false,\n): number[] {\n  try {\n    const ast = getRegExpAst(regExp);\n    const firstChars = firstCharOptimizedIndices(\n      ast.value,\n      {},\n      ast.flags.ignoreCase,\n    );\n    return firstChars;\n  } catch (e) {\n    /* istanbul ignore next */\n    // Testing this relies on the regexp-to-ast library having a bug... */\n    // TODO: only the else branch needs to be ignored, try to fix with newer prettier / tsc\n    if (e.message === complementErrorMessage) {\n      if (ensureOptimizations) {\n        PRINT_WARNING(\n          `${failedOptimizationPrefixMsg}` +\n            `\\tUnable to optimize: < ${regExp.toString()} >\\n` +\n            \"\\tComplement Sets cannot be automatically optimized.\\n\" +\n            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n            \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#COMPLEMENT for details.\",\n        );\n      }\n    } else {\n      let msgSuffix = \"\";\n      if (ensureOptimizations) {\n        msgSuffix =\n          \"\\n\\tThis will disable the lexer's first char optimizations.\\n\" +\n          \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#REGEXP_PARSING for details.\";\n      }\n      PRINT_ERROR(\n        `${failedOptimizationPrefixMsg}\\n` +\n          `\\tFailed parsing: < ${regExp.toString()} >\\n` +\n          `\\tUsing the @chevrotain/regexp-to-ast library\\n` +\n          \"\\tPlease open an issue at: https://github.com/chevrotain/chevrotain/issues\" +\n          msgSuffix,\n      );\n    }\n  }\n\n  return [];\n}\n\nexport function firstCharOptimizedIndices(\n  ast: ASTNode,\n  result: { [charCode: number]: number },\n  ignoreCase: boolean,\n): number[] {\n  switch (ast.type) {\n    case \"Disjunction\":\n      for (let i = 0; i < ast.value.length; i++) {\n        firstCharOptimizedIndices(ast.value[i], result, ignoreCase);\n      }\n      break;\n    case \"Alternative\":\n      const terms = ast.value;\n      for (let i = 0; i < terms.length; i++) {\n        const term = terms[i];\n\n        // skip terms that cannot effect the first char results\n        switch (term.type) {\n          case \"EndAnchor\":\n          // A group back reference cannot affect potential starting char.\n          // because if a back reference is the first production than automatically\n          // the group being referenced has had to come BEFORE so its codes have already been added\n          case \"GroupBackReference\":\n          // assertions do not affect potential starting codes\n          case \"Lookahead\":\n          case \"NegativeLookahead\":\n          case \"StartAnchor\":\n          case \"WordBoundary\":\n          case \"NonWordBoundary\":\n            continue;\n        }\n\n        const atom = term;\n        switch (atom.type) {\n          case \"Character\":\n            addOptimizedIdxToResult(atom.value, result, ignoreCase);\n            break;\n          case \"Set\":\n            if (atom.complement === true) {\n              throw Error(complementErrorMessage);\n            }\n            forEach(atom.value, (code) => {\n              if (typeof code === \"number\") {\n                addOptimizedIdxToResult(code, result, ignoreCase);\n              } else {\n                // range\n                const range = code as any;\n                // cannot optimize when ignoreCase is\n                if (ignoreCase === true) {\n                  for (\n                    let rangeCode = range.from;\n                    rangeCode <= range.to;\n                    rangeCode++\n                  ) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n                }\n                // Optimization (2 orders of magnitude less work for very large ranges)\n                else {\n                  // handle unoptimized values\n                  for (\n                    let rangeCode = range.from;\n                    rangeCode <= range.to && rangeCode < minOptimizationVal;\n                    rangeCode++\n                  ) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n\n                  // Less common charCode where we optimize for faster init time, by using larger \"buckets\"\n                  if (range.to >= minOptimizationVal) {\n                    const minUnOptVal =\n                      range.from >= minOptimizationVal\n                        ? range.from\n                        : minOptimizationVal;\n                    const maxUnOptVal = range.to;\n                    const minOptIdx = charCodeToOptimizedIndex(minUnOptVal);\n                    const maxOptIdx = charCodeToOptimizedIndex(maxUnOptVal);\n\n                    for (\n                      let currOptIdx = minOptIdx;\n                      currOptIdx <= maxOptIdx;\n                      currOptIdx++\n                    ) {\n                      result[currOptIdx] = currOptIdx;\n                    }\n                  }\n                }\n              }\n            });\n            break;\n          case \"Group\":\n            firstCharOptimizedIndices(atom.value, result, ignoreCase);\n            break;\n          /* istanbul ignore next */\n          default:\n            throw Error(\"Non Exhaustive Match\");\n        }\n\n        // reached a mandatory production, no more **start** codes can be found on this alternative\n        const isOptionalQuantifier =\n          atom.quantifier !== undefined && atom.quantifier.atLeast === 0;\n        if (\n          // A group may be optional due to empty contents /(?:)/\n          // or if everything inside it is optional /((a)?)/\n          (atom.type === \"Group\" && isWholeOptional(atom) === false) ||\n          // If this term is not a group it may only be optional if it has an optional quantifier\n          (atom.type !== \"Group\" && isOptionalQuantifier === false)\n        ) {\n          break;\n        }\n      }\n      break;\n    /* istanbul ignore next */\n    default:\n      throw Error(\"non exhaustive match!\");\n  }\n\n  // console.log(Object.keys(result).length)\n  return values(result);\n}\n\nfunction addOptimizedIdxToResult(\n  code: number,\n  result: { [charCode: number]: number },\n  ignoreCase: boolean,\n) {\n  const optimizedCharIdx = charCodeToOptimizedIndex(code);\n  result[optimizedCharIdx] = optimizedCharIdx;\n\n  if (ignoreCase === true) {\n    handleIgnoreCase(code, result);\n  }\n}\n\nfunction handleIgnoreCase(\n  code: number,\n  result: { [charCode: number]: number },\n) {\n  const char = String.fromCharCode(code);\n  const upperChar = char.toUpperCase();\n  /* istanbul ignore else */\n  if (upperChar !== char) {\n    const optimizedCharIdx = charCodeToOptimizedIndex(upperChar.charCodeAt(0));\n    result[optimizedCharIdx] = optimizedCharIdx;\n  } else {\n    const lowerChar = char.toLowerCase();\n    if (lowerChar !== char) {\n      const optimizedCharIdx = charCodeToOptimizedIndex(\n        lowerChar.charCodeAt(0),\n      );\n      result[optimizedCharIdx] = optimizedCharIdx;\n    }\n  }\n}\n\nfunction findCode(setNode: Set, targetCharCodes: number[]) {\n  return find(setNode.value, (codeOrRange) => {\n    if (typeof codeOrRange === \"number\") {\n      return includes(targetCharCodes, codeOrRange);\n    } else {\n      // range\n      const range = <any>codeOrRange;\n      return (\n        find(\n          targetCharCodes,\n          (targetCode) => range.from <= targetCode && targetCode <= range.to,\n        ) !== undefined\n      );\n    }\n  });\n}\n\nfunction isWholeOptional(ast: any): boolean {\n  const quantifier = (ast as Atom).quantifier;\n  if (quantifier && quantifier.atLeast === 0) {\n    return true;\n  }\n\n  if (!ast.value) {\n    return false;\n  }\n\n  return isArray(ast.value)\n    ? every(ast.value, isWholeOptional)\n    : isWholeOptional(ast.value);\n}\n\nclass CharCodeFinder extends BaseRegExpVisitor {\n  found: boolean = false;\n\n  constructor(private targetCharCodes: number[]) {\n    super();\n  }\n\n  visitChildren(node: ASTNode) {\n    // No need to keep looking...\n    if (this.found === true) {\n      return;\n    }\n\n    // switch lookaheads as they do not actually consume any characters thus\n    // finding a charCode at lookahead context does not mean that regexp can actually contain it in a match.\n    switch (node.type) {\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        return;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        return;\n    }\n\n    super.visitChildren(node);\n  }\n\n  visitCharacter(node: Character) {\n    if (includes(this.targetCharCodes, node.value)) {\n      this.found = true;\n    }\n  }\n\n  visitSet(node: Set) {\n    if (node.complement) {\n      if (findCode(node, this.targetCharCodes) === undefined) {\n        this.found = true;\n      }\n    } else {\n      if (findCode(node, this.targetCharCodes) !== undefined) {\n        this.found = true;\n      }\n    }\n  }\n}\n\nexport function canMatchCharCode(\n  charCodes: number[],\n  pattern: RegExp | string,\n) {\n  if (pattern instanceof RegExp) {\n    const ast = getRegExpAst(pattern);\n    const charCodeFinder = new CharCodeFinder(charCodes);\n    charCodeFinder.visit(ast);\n    return charCodeFinder.found;\n  } else {\n    return (\n      find(<any>pattern, (char) => {\n        return includes(charCodes, (<string>char).charCodeAt(0));\n      }) !== undefined\n    );\n  }\n}\n","import { BaseRegExpVisitor } from \"@chevrotain/regexp-to-ast\";\nimport {\n  IRegExpExec,\n  Lexer,\n  LexerDefinitionErrorType,\n} from \"./lexer_public.js\";\nimport {\n  compact,\n  defaults,\n  difference,\n  filter,\n  find,\n  first,\n  flatten,\n  forEach,\n  has,\n  includes,\n  indexOf,\n  isArray,\n  isEmpty,\n  isFunction,\n  isRegExp,\n  isString,\n  isUndefined,\n  keys,\n  map,\n  reduce,\n  reject,\n  values,\n} from \"lodash-es\";\nimport { PRINT_ERROR } from \"@chevrotain/utils\";\nimport {\n  canMatchCharCode,\n  failedOptimizationPrefixMsg,\n  getOptimizedStartCodesIndices,\n} from \"./reg_exp.js\";\nimport {\n  ILexerDefinitionError,\n  ILineTerminatorsTester,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { getRegExpAst } from \"./reg_exp_parser.js\";\n\nconst PATTERN = \"PATTERN\";\nexport const DEFAULT_MODE = \"defaultMode\";\nexport const MODES = \"modes\";\n\nexport interface IPatternConfig {\n  pattern: IRegExpExec | string;\n  longerAlt: number[] | undefined;\n  canLineTerminator: boolean;\n  isCustom: boolean;\n  short: number | false;\n  group: string | undefined | false;\n  push: string | undefined;\n  pop: boolean;\n  tokenType: TokenType;\n  tokenTypeIdx: number;\n}\n\nexport interface IAnalyzeResult {\n  patternIdxToConfig: IPatternConfig[];\n  charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] };\n  emptyGroups: { [groupName: string]: IToken[] };\n  hasCustom: boolean;\n  canBeOptimized: boolean;\n}\n\nexport let SUPPORT_STICKY =\n  typeof (<any>new RegExp(\"(?:)\")).sticky === \"boolean\";\n\nexport function disableSticky() {\n  SUPPORT_STICKY = false;\n}\n\nexport function enableSticky() {\n  SUPPORT_STICKY = true;\n}\n\nexport function analyzeTokenTypes(\n  tokenTypes: TokenType[],\n  options: {\n    positionTracking?: \"full\" | \"onlyStart\" | \"onlyOffset\";\n    ensureOptimizations?: boolean;\n    lineTerminatorCharacters?: (number | string)[];\n    // TODO: should `useSticky` be an argument here?\n    useSticky?: boolean;\n    safeMode?: boolean;\n    tracer?: (msg: string, action: () => void) => void;\n  },\n): IAnalyzeResult {\n  options = defaults(options, {\n    useSticky: SUPPORT_STICKY,\n    debug: false as boolean,\n    safeMode: false as boolean,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: (msg: string, action: Function) => action(),\n  });\n\n  const tracer = options.tracer!;\n\n  tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n    initCharCodeToOptimizedIndexMap();\n  });\n\n  let onlyRelevantTypes: TokenType[];\n  tracer(\"Reject Lexer.NA\", () => {\n    onlyRelevantTypes = reject(tokenTypes, (currType) => {\n      return currType[PATTERN] === Lexer.NA;\n    });\n  });\n\n  let hasCustom = false;\n  let allTransformedPatterns: (IRegExpExec | string)[];\n  tracer(\"Transform Patterns\", () => {\n    hasCustom = false;\n    allTransformedPatterns = map(\n      onlyRelevantTypes,\n      (currType): IRegExpExec | string => {\n        const currPattern = currType[PATTERN];\n\n        /* istanbul ignore else */\n        if (isRegExp(currPattern)) {\n          const regExpSource = currPattern.source;\n          if (\n            regExpSource.length === 1 &&\n            // only these regExp meta characters which can appear in a length one regExp\n            regExpSource !== \"^\" &&\n            regExpSource !== \"$\" &&\n            regExpSource !== \".\" &&\n            !currPattern.ignoreCase\n          ) {\n            return regExpSource;\n          } else if (\n            regExpSource.length === 2 &&\n            regExpSource[0] === \"\\\\\" &&\n            // not a meta character\n            !includes(\n              [\n                \"d\",\n                \"D\",\n                \"s\",\n                \"S\",\n                \"t\",\n                \"r\",\n                \"n\",\n                \"t\",\n                \"0\",\n                \"c\",\n                \"b\",\n                \"B\",\n                \"f\",\n                \"v\",\n                \"w\",\n                \"W\",\n              ],\n              regExpSource[1],\n            )\n          ) {\n            // escaped meta Characters: /\\+/ /\\[/\n            // or redundant escaping: /\\a/\n            // without the escaping \"\\\"\n            return regExpSource[1];\n          } else {\n            return options.useSticky\n              ? addStickyFlag(currPattern)\n              : addStartOfInput(currPattern);\n          }\n        } else if (isFunction(currPattern)) {\n          hasCustom = true;\n          // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n          return { exec: currPattern };\n        } else if (typeof currPattern === \"object\") {\n          hasCustom = true;\n          // ICustomPattern\n          return currPattern;\n        } else if (typeof currPattern === \"string\") {\n          if (currPattern.length === 1) {\n            return currPattern;\n          } else {\n            const escapedRegExpString = currPattern.replace(\n              /[\\\\^$.*+?()[\\]{}|]/g,\n              \"\\\\$&\",\n            );\n            const wrappedRegExp = new RegExp(escapedRegExpString);\n            return options.useSticky\n              ? addStickyFlag(wrappedRegExp)\n              : addStartOfInput(wrappedRegExp);\n          }\n        } else {\n          throw Error(\"non exhaustive match\");\n        }\n      },\n    );\n  });\n\n  let patternIdxToType: number[];\n  let patternIdxToGroup: (string | undefined | false)[];\n  let patternIdxToLongerAltIdxArr: (number[] | undefined)[];\n  let patternIdxToPushMode: (string | undefined)[];\n  let patternIdxToPopMode: boolean[];\n  tracer(\"misc mapping\", () => {\n    patternIdxToType = map(\n      onlyRelevantTypes,\n      (currType) => currType.tokenTypeIdx!,\n    );\n\n    patternIdxToGroup = map(onlyRelevantTypes, (clazz: any) => {\n      const groupName = clazz.GROUP;\n      /* istanbul ignore next */\n      if (groupName === Lexer.SKIPPED) {\n        return undefined;\n      } else if (isString(groupName)) {\n        return groupName;\n      } else if (isUndefined(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n\n    patternIdxToLongerAltIdxArr = map(onlyRelevantTypes, (clazz: any) => {\n      const longerAltType = clazz.LONGER_ALT;\n\n      if (longerAltType) {\n        const longerAltIdxArr = isArray(longerAltType)\n          ? map(longerAltType, (type: any) => indexOf(onlyRelevantTypes, type))\n          : [indexOf(onlyRelevantTypes, longerAltType)];\n        return longerAltIdxArr;\n      }\n    });\n\n    patternIdxToPushMode = map(\n      onlyRelevantTypes,\n      (clazz: any) => clazz.PUSH_MODE,\n    );\n\n    patternIdxToPopMode = map(onlyRelevantTypes, (clazz: any) =>\n      has(clazz, \"POP_MODE\"),\n    );\n  });\n\n  let patternIdxToCanLineTerminator: boolean[];\n  tracer(\"Line Terminator Handling\", () => {\n    const lineTerminatorCharCodes = getCharCodes(\n      options.lineTerminatorCharacters!,\n    );\n    patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => false);\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => {\n        if (has(tokType, \"LINE_BREAKS\")) {\n          return !!tokType.LINE_BREAKS;\n        } else {\n          return (\n            checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false &&\n            canMatchCharCode(\n              lineTerminatorCharCodes,\n              tokType.PATTERN as RegExp | string,\n            )\n          );\n        }\n      });\n    }\n  });\n\n  let patternIdxToIsCustom: boolean[];\n  let patternIdxToShort: (number | false)[];\n  let emptyGroups!: { [groupName: string]: IToken[] };\n  let patternIdxToConfig!: IPatternConfig[];\n  tracer(\"Misc Mapping #2\", () => {\n    patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n\n    emptyGroups = reduce(\n      onlyRelevantTypes,\n      (acc, clazz: any) => {\n        const groupName = clazz.GROUP;\n        if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n          acc[groupName] = [];\n        }\n        return acc;\n      },\n      {} as { [groupName: string]: IToken[] },\n    );\n\n    patternIdxToConfig = map(\n      allTransformedPatterns,\n      (x, idx): IPatternConfig => {\n        return {\n          pattern: allTransformedPatterns[idx],\n          longerAlt: patternIdxToLongerAltIdxArr[idx],\n          canLineTerminator: patternIdxToCanLineTerminator[idx],\n          isCustom: patternIdxToIsCustom[idx],\n          short: patternIdxToShort[idx],\n          group: patternIdxToGroup[idx],\n          push: patternIdxToPushMode[idx],\n          pop: patternIdxToPopMode[idx],\n          tokenTypeIdx: patternIdxToType[idx],\n          tokenType: onlyRelevantTypes[idx],\n        };\n      },\n    );\n  });\n\n  let canBeOptimized = true;\n  let charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] } =\n    [];\n\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", () => {\n      charCodeToPatternIdxToConfig = reduce(\n        onlyRelevantTypes,\n        (result, currTokType, idx) => {\n          if (typeof currTokType.PATTERN === \"string\") {\n            const charCode = currTokType.PATTERN.charCodeAt(0);\n            const optimizedIdx = charCodeToOptimizedIndex(charCode);\n            addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n          } else if (isArray(currTokType.START_CHARS_HINT)) {\n            let lastOptimizedIdx: number;\n            forEach(currTokType.START_CHARS_HINT, (charOrInt) => {\n              const charCode =\n                typeof charOrInt === \"string\"\n                  ? charOrInt.charCodeAt(0)\n                  : charOrInt;\n              const currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n              // Avoid adding the config multiple times\n              /* istanbul ignore else */\n              // - Difficult to check this scenario effects as it is only a performance\n              //   optimization that does not change correctness\n              if (lastOptimizedIdx !== currOptimizedIdx) {\n                lastOptimizedIdx = currOptimizedIdx;\n                addToMapOfArrays(\n                  result,\n                  currOptimizedIdx,\n                  patternIdxToConfig[idx],\n                );\n              }\n            });\n          } else if (isRegExp(currTokType.PATTERN)) {\n            if (currTokType.PATTERN.unicode) {\n              canBeOptimized = false;\n              if (options.ensureOptimizations) {\n                PRINT_ERROR(\n                  `${failedOptimizationPrefixMsg}` +\n                    `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` +\n                    \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                    \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                    \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\",\n                );\n              }\n            } else {\n              const optimizedCodes = getOptimizedStartCodesIndices(\n                currTokType.PATTERN,\n                options.ensureOptimizations,\n              );\n              /* istanbul ignore if */\n              // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n              // the first should be a different validation and the second cannot be tested.\n              if (isEmpty(optimizedCodes)) {\n                // we cannot understand what codes may start possible matches\n                // The optimization correctness requires knowing start codes for ALL patterns.\n                // Not actually sure this is an error, no debug message\n                canBeOptimized = false;\n              }\n              forEach(optimizedCodes, (code) => {\n                addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n              });\n            }\n          } else {\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(\n                `${failedOptimizationPrefixMsg}` +\n                  `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` +\n                  \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                  \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\",\n              );\n            }\n            canBeOptimized = false;\n          }\n\n          return result;\n        },\n        [] as { [charCode: number]: IPatternConfig[] },\n      );\n    });\n  }\n\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized,\n  };\n}\n\nexport function validatePatterns(\n  tokenTypes: TokenType[],\n  validModesNames: string[],\n): ILexerDefinitionError[] {\n  let errors: ILexerDefinitionError[] = [];\n\n  const missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n\n  const invalidResult = findInvalidPatterns(missingResult.valid);\n  const validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n\n  errors = errors.concat(\n    findModesThatDoNotExist(validTokenTypes, validModesNames),\n  );\n\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n\n  return errors;\n}\n\nfunction validateRegExpPattern(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  let errors: ILexerDefinitionError[] = [];\n  const withRegExpPatterns = filter(tokenTypes, (currTokType) =>\n    isRegExp(currTokType[PATTERN]),\n  );\n\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n\n  return errors;\n}\n\nexport interface ILexerFilterResult {\n  errors: ILexerDefinitionError[];\n  valid: TokenType[];\n}\n\nexport function findMissingPatterns(\n  tokenTypes: TokenType[],\n): ILexerFilterResult {\n  const tokenTypesWithMissingPattern = filter(tokenTypes, (currType) => {\n    return !has(currType, PATTERN);\n  });\n\n  const errors = map(tokenTypesWithMissingPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- missing static 'PATTERN' property\",\n      type: LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  const valid = difference(tokenTypes, tokenTypesWithMissingPattern);\n  return { errors, valid };\n}\n\nexport function findInvalidPatterns(\n  tokenTypes: TokenType[],\n): ILexerFilterResult {\n  const tokenTypesWithInvalidPattern = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return (\n      !isRegExp(pattern) &&\n      !isFunction(pattern) &&\n      !has(pattern, \"exec\") &&\n      !isString(pattern)\n    );\n  });\n\n  const errors = map(tokenTypesWithInvalidPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' can only be a RegExp, a\" +\n        \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  const valid = difference(tokenTypes, tokenTypesWithInvalidPattern);\n  return { errors, valid };\n}\n\nconst end_of_input = /[^\\\\][$]/;\n\nexport function findEndOfInputAnchor(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  class EndAnchorFinder extends BaseRegExpVisitor {\n    found = false;\n\n    visitEndAnchor(node: unknown) {\n      this.found = true;\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN;\n\n    try {\n      const regexpAst = getRegExpAst(pattern as RegExp);\n      const endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test((pattern as RegExp).source);\n    }\n  });\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n        \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findEmptyMatchRegExps(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const matchesEmptyString = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN as RegExp;\n    return pattern.test(\"\");\n  });\n\n  const errors = map(matchesEmptyString, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' must not match an empty string\",\n      type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nconst start_of_input = /[^\\\\[][\\^]|^\\^/;\n\nexport function findStartOfInputAnchor(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  class StartAnchorFinder extends BaseRegExpVisitor {\n    found = false;\n\n    visitStartAnchor(node: unknown) {\n      this.found = true;\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN as RegExp;\n    try {\n      const regexpAst = getRegExpAst(pattern);\n      const startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findUnsupportedFlags(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const invalidFlags = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n\n  const errors = map(invalidFlags, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const found: TokenType[] = [];\n  let identicalPatterns = map(tokenTypes, (outerType: any) => {\n    return reduce(\n      tokenTypes,\n      (result, innerType) => {\n        if (\n          outerType.PATTERN.source === (innerType.PATTERN as RegExp).source &&\n          !includes(found, innerType) &&\n          innerType.PATTERN !== Lexer.NA\n        ) {\n          // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n          // in essence we are creating Equivalence classes on equality relation.\n          found.push(innerType);\n          result.push(innerType);\n          return result;\n        }\n        return result;\n      },\n      [] as TokenType[],\n    );\n  });\n\n  identicalPatterns = compact(identicalPatterns);\n\n  const duplicatePatterns = filter(identicalPatterns, (currIdenticalSet) => {\n    return currIdenticalSet.length > 1;\n  });\n\n  const errors = map(duplicatePatterns, (setOfIdentical: any) => {\n    const tokenTypeNames = map(setOfIdentical, (currType: any) => {\n      return currType.name;\n    });\n\n    const dupPatternSrc = (<any>first(setOfIdentical)).PATTERN;\n    return {\n      message:\n        `The same RegExp pattern ->${dupPatternSrc}<-` +\n        `has been used in all of the following Token Types: ${tokenTypeNames.join(\n          \", \",\n        )} <-`,\n      type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical,\n    };\n  });\n\n  return errors;\n}\n\nexport function findInvalidGroupType(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const invalidTypes = filter(tokenTypes, (clazz: any) => {\n    if (!has(clazz, \"GROUP\")) {\n      return false;\n    }\n    const group = clazz.GROUP;\n\n    return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group);\n  });\n\n  const errors = map(invalidTypes, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findModesThatDoNotExist(\n  tokenTypes: TokenType[],\n  validModes: string[],\n): ILexerDefinitionError[] {\n  const invalidModes = filter(tokenTypes, (clazz: any) => {\n    return (\n      clazz.PUSH_MODE !== undefined && !includes(validModes, clazz.PUSH_MODE)\n    );\n  });\n\n  const errors = map(invalidModes, (tokType) => {\n    const msg =\n      `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` +\n      `which does not exist`;\n    return {\n      message: msg,\n      type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findUnreachablePatterns(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const errors: ILexerDefinitionError[] = [];\n\n  const canBeTested = reduce(\n    tokenTypes,\n    (result, tokType, idx) => {\n      const pattern = tokType.PATTERN;\n\n      if (pattern === Lexer.NA) {\n        return result;\n      }\n\n      // a more comprehensive validation for all forms of regExps would require\n      // deeper regExp analysis capabilities\n      if (isString(pattern)) {\n        result.push({ str: pattern, idx, tokenType: tokType });\n      } else if (isRegExp(pattern) && noMetaChar(pattern)) {\n        result.push({ str: pattern.source, idx, tokenType: tokType });\n      }\n      return result;\n    },\n    [] as { str: string; idx: number; tokenType: TokenType }[],\n  );\n\n  forEach(tokenTypes, (tokType, testIdx) => {\n    forEach(canBeTested, ({ str, idx, tokenType }) => {\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        const msg =\n          `Token: ->${tokenType.name}<- can never be matched.\\n` +\n          `Because it appears AFTER the Token Type ->${tokType.name}<-` +\n          `in the lexer's definition.\\n` +\n          `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n        errors.push({\n          message: msg,\n          type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType],\n        });\n      }\n    });\n  });\n\n  return errors;\n}\n\nfunction testTokenType(str: string, pattern: any): boolean {\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    const regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if (isFunction(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if (has(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction noMetaChar(regExp: RegExp): boolean {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  const metaChars = [\n    \".\",\n    \"\\\\\",\n    \"[\",\n    \"]\",\n    \"|\",\n    \"^\",\n    \"$\",\n    \"(\",\n    \")\",\n    \"?\",\n    \"*\",\n    \"+\",\n    \"{\",\n  ];\n  return (\n    find(metaChars, (char) => regExp.source.indexOf(char) !== -1) === undefined\n  );\n}\n\nexport function addStartOfInput(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"i\" : \"\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`^(?:${pattern.source})`, flags);\n}\n\nexport function addStickyFlag(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"iy\" : \"y\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`${pattern.source}`, flags);\n}\n\nexport function performRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[],\n): ILexerDefinitionError[] {\n  const errors: ILexerDefinitionError[] = [];\n\n  // some run time checks to help the end users.\n  if (!has(lexerDefinition, DEFAULT_MODE)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        DEFAULT_MODE +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n    });\n  }\n  if (!has(lexerDefinition, MODES)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        MODES +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n    });\n  }\n\n  if (\n    has(lexerDefinition, MODES) &&\n    has(lexerDefinition, DEFAULT_MODE) &&\n    !has(lexerDefinition.modes, lexerDefinition.defaultMode)\n  ) {\n    errors.push({\n      message:\n        `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` +\n        `which does not exist\\n`,\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n    });\n  }\n\n  if (has(lexerDefinition, MODES)) {\n    forEach(lexerDefinition.modes, (currModeValue, currModeName) => {\n      forEach(currModeValue, (currTokType, currIdx) => {\n        if (isUndefined(currTokType)) {\n          errors.push({\n            message:\n              `A Lexer cannot be initialized using an undefined Token Type. Mode:` +\n              `<${currModeName}> at index: <${currIdx}>\\n`,\n            type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n          });\n        } else if (has(currTokType, \"LONGER_ALT\")) {\n          const longerAlt = isArray(currTokType.LONGER_ALT)\n            ? currTokType.LONGER_ALT\n            : [currTokType.LONGER_ALT];\n          forEach(longerAlt, (currLongerAlt) => {\n            if (\n              !isUndefined(currLongerAlt) &&\n              !includes(currModeValue, currLongerAlt)\n            ) {\n              errors.push({\n                message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\\n`,\n                type: LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n              });\n            }\n          });\n        }\n      });\n    });\n  }\n\n  return errors;\n}\n\nexport function performWarningRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[],\n): ILexerDefinitionError[] {\n  const warnings = [];\n  let hasAnyLineBreak = false;\n  const allTokenTypes = compact(flatten(values(lexerDefinition.modes)));\n\n  const concreteTokenTypes = reject(\n    allTokenTypes,\n    (currType) => currType[PATTERN] === Lexer.NA,\n  );\n  const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n  if (trackLines) {\n    forEach(concreteTokenTypes, (tokType) => {\n      const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n      if (currIssue !== false) {\n        const message = buildLineBreakIssueMessage(tokType, currIssue);\n        const warningDescriptor = {\n          message,\n          type: currIssue.issue,\n          tokenType: tokType,\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if (has(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if (\n            canMatchCharCode(terminatorCharCodes, tokType.PATTERN as RegExp)\n          ) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message:\n        \"Warning: No LINE_BREAKS Found.\\n\" +\n        \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n        \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS,\n    });\n  }\n  return warnings;\n}\n\nexport function cloneEmptyGroups(emptyGroups: {\n  [groupName: string]: IToken;\n}): { [groupName: string]: IToken } {\n  const clonedResult: any = {};\n  const groupKeys = keys(emptyGroups);\n\n  forEach(groupKeys, (currKey) => {\n    const currGroupValue = emptyGroups[currKey];\n\n    /* istanbul ignore else */\n    if (isArray(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n\n  return clonedResult;\n}\n\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType: TokenType): boolean {\n  const pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    return false;\n  } else if (isFunction(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if (has(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if (isString(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function isShortPattern(pattern: any): number | false {\n  if (isString(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\n\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport const LineTerminatorOptimizedTester: ILineTerminatorsTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    const len = text.length;\n    for (let i = this.lastIndex; i < len; i++) {\n      const c = text.charCodeAt(i);\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n        return true;\n      }\n    }\n    return false;\n  },\n\n  lastIndex: 0,\n};\n\nfunction checkLineBreaksIssues(\n  tokType: TokenType,\n  lineTerminatorCharCodes: number[],\n):\n  | {\n      issue:\n        | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n        | LexerDefinitionErrorType.CUSTOM_LINE_BREAK;\n      errMsg?: string;\n    }\n  | false {\n  if (has(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if (isRegExp(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN as RegExp);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: (e as Error).message,\n        };\n      }\n      return false;\n    } else if (isString(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\n\nexport function buildLineBreakIssueMessage(\n  tokType: TokenType,\n  details: {\n    issue:\n      | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n      | LexerDefinitionErrorType.CUSTOM_LINE_BREAK;\n    errMsg?: string;\n  },\n): string {\n  /* istanbul ignore else */\n  if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return (\n      \"Warning: unable to identify line terminator usage in pattern.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      `\\t Root cause: ${details.errMsg}.\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\"\n    );\n  } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return (\n      \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\"\n    );\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction getCharCodes(charsOrCodes: (number | string)[]): number[] {\n  const charCodes = map(charsOrCodes, (numOrString) => {\n    if (isString(numOrString)) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n\n  return charCodes;\n}\n\nfunction addToMapOfArrays<T>(\n  map: Record<number, T[]>,\n  key: number,\n  value: T,\n): void {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\n\nexport const minOptimizationVal = 256;\n\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nlet charCodeToOptimizedIdxMap: number[] = [];\nexport function charCodeToOptimizedIndex(charCode: number): number {\n  return charCode < minOptimizationVal\n    ? charCode\n    : charCodeToOptimizedIdxMap[charCode];\n}\n\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n  if (isEmpty(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n    for (let i = 0; i < 65536; i++) {\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n    }\n  }\n}\n","export function timer<T>(func: () => T): { time: number; value: T } {\n  const start = new Date().getTime();\n  const val = func();\n  const end = new Date().getTime();\n  const total = end - start;\n  return { time: total, value: val };\n}\n","import {\n  clone,\n  compact,\n  difference,\n  flatten,\n  forEach,\n  has,\n  includes,\n  isArray,\n  isEmpty,\n  map,\n} from \"lodash-es\";\nimport { IToken, TokenType } from \"@chevrotain/types\";\n\nexport function tokenStructuredMatcher(\n  tokInstance: IToken,\n  tokConstructor: TokenType,\n) {\n  const instanceType = tokInstance.tokenTypeIdx;\n  if (instanceType === tokConstructor.tokenTypeIdx) {\n    return true;\n  } else {\n    return (\n      tokConstructor.isParent === true &&\n      tokConstructor.categoryMatchesMap![instanceType] === true\n    );\n  }\n}\n\n// Optimized tokenMatcher in case our grammar does not use token categories\n// Being so tiny it is much more likely to be in-lined and this avoid the function call overhead\nexport function tokenStructuredMatcherNoCategories(\n  token: IToken,\n  tokType: TokenType,\n) {\n  return token.tokenTypeIdx === tokType.tokenTypeIdx;\n}\n\nexport let tokenShortNameIdx = 1;\nexport const tokenIdxToClass: { [tokenIdx: number]: TokenType } = {};\n\nexport function augmentTokenTypes(tokenTypes: TokenType[]): void {\n  // collect the parent Token Types as well.\n  const tokenTypesAndParents = expandCategories(tokenTypes);\n\n  // add required tokenType and categoryMatches properties\n  assignTokenDefaultProps(tokenTypesAndParents);\n\n  // fill up the categoryMatches\n  assignCategoriesMapProp(tokenTypesAndParents);\n  assignCategoriesTokensProp(tokenTypesAndParents);\n\n  forEach(tokenTypesAndParents, (tokType) => {\n    tokType.isParent = tokType.categoryMatches!.length > 0;\n  });\n}\n\nexport function expandCategories(tokenTypes: TokenType[]): TokenType[] {\n  let result = clone(tokenTypes);\n\n  let categories = tokenTypes;\n  let searching = true;\n  while (searching) {\n    categories = compact(\n      flatten(map(categories, (currTokType) => currTokType.CATEGORIES)),\n    );\n\n    const newCategories = difference(categories, result);\n\n    result = result.concat(newCategories);\n\n    if (isEmpty(newCategories)) {\n      searching = false;\n    } else {\n      categories = newCategories;\n    }\n  }\n  return result;\n}\n\nexport function assignTokenDefaultProps(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    if (!hasShortKeyProperty(currTokType)) {\n      tokenIdxToClass[tokenShortNameIdx] = currTokType;\n      (<any>currTokType).tokenTypeIdx = tokenShortNameIdx++;\n    }\n\n    // CATEGORIES? : TokenType | TokenType[]\n    if (\n      hasCategoriesProperty(currTokType) &&\n      !isArray(currTokType.CATEGORIES)\n      // &&\n      // !isUndefined(currTokType.CATEGORIES.PATTERN)\n    ) {\n      currTokType.CATEGORIES = [currTokType.CATEGORIES as unknown as TokenType];\n    }\n\n    if (!hasCategoriesProperty(currTokType)) {\n      currTokType.CATEGORIES = [];\n    }\n\n    if (!hasExtendingTokensTypesProperty(currTokType)) {\n      currTokType.categoryMatches = [];\n    }\n\n    if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n      currTokType.categoryMatchesMap = {};\n    }\n  });\n}\n\nexport function assignCategoriesTokensProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    // avoid duplications\n    currTokType.categoryMatches = [];\n    forEach(currTokType.categoryMatchesMap!, (val, key) => {\n      currTokType.categoryMatches!.push(\n        tokenIdxToClass[key as unknown as number].tokenTypeIdx!,\n      );\n    });\n  });\n}\n\nexport function assignCategoriesMapProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    singleAssignCategoriesToksMap([], currTokType);\n  });\n}\n\nexport function singleAssignCategoriesToksMap(\n  path: TokenType[],\n  nextNode: TokenType,\n): void {\n  forEach(path, (pathNode) => {\n    nextNode.categoryMatchesMap![pathNode.tokenTypeIdx!] = true;\n  });\n\n  forEach(nextNode.CATEGORIES, (nextCategory) => {\n    const newPath = path.concat(nextNode);\n    // avoids infinite loops due to cyclic categories.\n    if (!includes(newPath, nextCategory)) {\n      singleAssignCategoriesToksMap(newPath, nextCategory);\n    }\n  });\n}\n\nexport function hasShortKeyProperty(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\");\n}\n\nexport function hasCategoriesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"CATEGORIES\");\n}\n\nexport function hasExtendingTokensTypesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"categoryMatches\");\n}\n\nexport function hasExtendingTokensTypesMapProperty(\n  tokType: TokenType,\n): boolean {\n  return has(tokType, \"categoryMatchesMap\");\n}\n\nexport function isTokenType(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\");\n}\n","import { ILexerErrorMessageProvider, IToken } from \"@chevrotain/types\";\n\nexport const defaultLexerErrorProvider: ILexerErrorMessageProvider = {\n  buildUnableToPopLexerModeMessage(token: IToken): string {\n    return `Unable to pop Lexer Mode after encountering Token ->${token.image}<- The Mode Stack is empty`;\n  },\n\n  buildUnexpectedCharactersMessage(\n    fullText: string,\n    startOffset: number,\n    length: number,\n    line?: number,\n    column?: number,\n  ): string {\n    return (\n      `unexpected character: ->${fullText.charAt(\n        startOffset,\n      )}<- at offset: ${startOffset},` + ` skipped ${length} characters.`\n    );\n  },\n};\n","import {\n  analyzeTokenTypes,\n  charCodeToOptimizedIndex,\n  cloneEmptyGroups,\n  DEFAULT_MODE,\n  IAnalyzeResult,\n  IPatternConfig,\n  LineTerminatorOptimizedTester,\n  performRuntimeChecks,\n  performWarningRuntimeChecks,\n  SUPPORT_STICKY,\n  validatePatterns,\n} from \"./lexer.js\";\nimport {\n  assign,\n  clone,\n  forEach,\n  identity,\n  isArray,\n  isEmpty,\n  isUndefined,\n  keys,\n  last,\n  map,\n  noop,\n  reduce,\n  reject,\n} from \"lodash-es\";\nimport { PRINT_WARNING, timer, toFastProperties } from \"@chevrotain/utils\";\nimport { augmentTokenTypes } from \"./tokens.js\";\nimport {\n  CustomPatternMatcherFunc,\n  CustomPatternMatcherReturn,\n  ILexerConfig,\n  ILexerDefinitionError,\n  ILexingError,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { defaultLexerErrorProvider } from \"./lexer_errors_public.js\";\nimport { clearRegExpParserCache } from \"./reg_exp_parser.js\";\n\nexport interface ILexingResult {\n  tokens: IToken[];\n  groups: { [groupName: string]: IToken[] };\n  errors: ILexingError[];\n}\n\nexport enum LexerDefinitionErrorType {\n  MISSING_PATTERN,\n  INVALID_PATTERN,\n  EOI_ANCHOR_FOUND,\n  UNSUPPORTED_FLAGS_FOUND,\n  DUPLICATE_PATTERNS_FOUND,\n  INVALID_GROUP_TYPE_FOUND,\n  PUSH_MODE_DOES_NOT_EXIST,\n  MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n  MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n  MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n  LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n  SOI_ANCHOR_FOUND,\n  EMPTY_MATCH_PATTERN,\n  NO_LINE_BREAKS_FLAGS,\n  UNREACHABLE_PATTERN,\n  IDENTIFY_TERMINATOR,\n  CUSTOM_LINE_BREAK,\n  MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n}\n\nexport interface IRegExpExec {\n  exec: CustomPatternMatcherFunc;\n}\n\nconst DEFAULT_LEXER_CONFIG: Required<ILexerConfig> = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false,\n  recoveryEnabled: true,\n};\n\nObject.freeze(DEFAULT_LEXER_CONFIG);\n\nexport class Lexer {\n  public static SKIPPED =\n    \"This marks a skipped Token pattern, this means each token identified by it will\" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\n\n  public static NA = /NOT_APPLICABLE/;\n  public lexerDefinitionErrors: ILexerDefinitionError[] = [];\n  public lexerDefinitionWarning: ILexerDefinitionError[] = [];\n\n  protected patternIdxToConfig: Record<string, IPatternConfig[]> = {};\n  protected charCodeToPatternIdxToConfig: {\n    [modeName: string]: { [charCode: number]: IPatternConfig[] };\n  } = {};\n\n  protected modes: string[] = [];\n  protected defaultMode!: string;\n  protected emptyGroups: { [groupName: string]: IToken } = {};\n\n  private config: Required<ILexerConfig>;\n  private trackStartLines: boolean = true;\n  private trackEndLines: boolean = true;\n  private hasCustom: boolean = false;\n  private canModeBeOptimized: Record<string, boolean> = {};\n\n  private traceInitPerf!: boolean | number;\n  private traceInitMaxIdent!: number;\n  private traceInitIndent: number;\n\n  constructor(\n    protected lexerDefinition: TokenType[] | IMultiModeLexerDefinition,\n    config: ILexerConfig = DEFAULT_LEXER_CONFIG,\n  ) {\n    if (typeof config === \"boolean\") {\n      throw Error(\n        \"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n          \"a boolean 2nd argument is no longer supported\",\n      );\n    }\n\n    // todo: defaults func?\n    this.config = assign({}, DEFAULT_LEXER_CONFIG, config) as any;\n\n    const traceInitVal = this.config.traceInitPerf;\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity;\n      this.traceInitPerf = true;\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal;\n      this.traceInitPerf = true;\n    }\n    this.traceInitIndent = -1;\n\n    this.TRACE_INIT(\"Lexer Constructor\", () => {\n      let actualDefinition!: IMultiModeLexerDefinition;\n      let hasOnlySingleMode = true;\n      this.TRACE_INIT(\"Lexer Config handling\", () => {\n        if (\n          this.config.lineTerminatorsPattern ===\n          DEFAULT_LEXER_CONFIG.lineTerminatorsPattern\n        ) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester;\n        } else {\n          if (\n            this.config.lineTerminatorCharacters ===\n            DEFAULT_LEXER_CONFIG.lineTerminatorCharacters\n          ) {\n            throw Error(\n              \"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\",\n            );\n          }\n        }\n\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error(\n            '\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.',\n          );\n        }\n\n        this.trackStartLines = /full|onlyStart/i.test(\n          this.config.positionTracking,\n        );\n        this.trackEndLines = /full/i.test(this.config.positionTracking);\n\n        // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n        if (isArray(lexerDefinition)) {\n          actualDefinition = {\n            modes: { defaultMode: clone(lexerDefinition) },\n            defaultMode: DEFAULT_MODE,\n          };\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false;\n          actualDefinition = clone(<IMultiModeLexerDefinition>lexerDefinition);\n        }\n      });\n\n      if (this.config.skipValidations === false) {\n        this.TRACE_INIT(\"performRuntimeChecks\", () => {\n          this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n            performRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters,\n            ),\n          );\n        });\n\n        this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n          this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(\n            performWarningRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters,\n            ),\n          );\n        });\n      }\n\n      // for extra robustness to avoid throwing an none informative error message\n      actualDefinition.modes = actualDefinition.modes\n        ? actualDefinition.modes\n        : {};\n\n      // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n      forEach(actualDefinition.modes, (currModeValue, currModeName) => {\n        actualDefinition.modes[currModeName] = reject<TokenType>(\n          currModeValue,\n          (currTokType) => isUndefined(currTokType),\n        );\n      });\n\n      const allModeNames = keys(actualDefinition.modes);\n\n      forEach(\n        actualDefinition.modes,\n        (currModDef: TokenType[], currModName) => {\n          this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n            this.modes.push(currModName);\n\n            if (this.config.skipValidations === false) {\n              this.TRACE_INIT(`validatePatterns`, () => {\n                this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n                  validatePatterns(currModDef, allModeNames),\n                );\n              });\n            }\n\n            // If definition errors were encountered, the analysis phase may fail unexpectedly/\n            // Considering a lexer with definition errors may never be used, there is no point\n            // to performing the analysis anyhow...\n            if (isEmpty(this.lexerDefinitionErrors)) {\n              augmentTokenTypes(currModDef);\n\n              let currAnalyzeResult!: IAnalyzeResult;\n              this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                  lineTerminatorCharacters:\n                    this.config.lineTerminatorCharacters,\n                  positionTracking: config.positionTracking,\n                  ensureOptimizations: config.ensureOptimizations,\n                  safeMode: config.safeMode,\n                  tracer: this.TRACE_INIT,\n                });\n              });\n\n              this.patternIdxToConfig[currModName] =\n                currAnalyzeResult.patternIdxToConfig;\n\n              this.charCodeToPatternIdxToConfig[currModName] =\n                currAnalyzeResult.charCodeToPatternIdxToConfig;\n\n              this.emptyGroups = assign(\n                {},\n                this.emptyGroups,\n                currAnalyzeResult.emptyGroups,\n              ) as any;\n\n              this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n\n              this.canModeBeOptimized[currModName] =\n                currAnalyzeResult.canBeOptimized;\n            }\n          });\n        },\n      );\n\n      this.defaultMode = actualDefinition.defaultMode;\n\n      if (\n        !isEmpty(this.lexerDefinitionErrors) &&\n        !this.config.deferDefinitionErrorsHandling\n      ) {\n        const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n          return error.message;\n        });\n        const allErrMessagesString = allErrMessages.join(\n          \"-----------------------\\n\",\n        );\n        throw new Error(\n          \"Errors detected in definition of Lexer:\\n\" + allErrMessagesString,\n        );\n      }\n\n      // Only print warning if there are no errors, This will avoid pl\n      forEach(this.lexerDefinitionWarning, (warningDescriptor) => {\n        PRINT_WARNING(warningDescriptor.message);\n      });\n\n      this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (SUPPORT_STICKY) {\n          this.chopInput = <any>identity;\n          this.match = this.matchWithTest;\n        } else {\n          this.updateLastIndex = noop;\n          this.match = this.matchWithExec;\n        }\n\n        if (hasOnlySingleMode) {\n          this.handleModes = noop;\n        }\n\n        if (this.trackStartLines === false) {\n          this.computeNewColumn = identity;\n        }\n\n        if (this.trackEndLines === false) {\n          this.updateTokenEndLineColumnLocation = noop;\n        }\n\n        if (/full/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createFullToken;\n        } else if (/onlyStart/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createStartOnlyToken;\n        } else if (/onlyOffset/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createOffsetOnlyToken;\n        } else {\n          throw Error(\n            `Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`,\n          );\n        }\n\n        if (this.hasCustom) {\n          this.addToken = this.addTokenUsingPush;\n          this.handlePayload = this.handlePayloadWithCustom;\n        } else {\n          this.addToken = this.addTokenUsingMemberAccess;\n          this.handlePayload = this.handlePayloadNoCustom;\n        }\n      });\n\n      this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n        const unOptimizedModes = reduce(\n          this.canModeBeOptimized,\n          (cannotBeOptimized, canBeOptimized, modeName) => {\n            if (canBeOptimized === false) {\n              cannotBeOptimized.push(modeName);\n            }\n            return cannotBeOptimized;\n          },\n          [] as string[],\n        );\n\n        if (config.ensureOptimizations && !isEmpty(unOptimizedModes)) {\n          throw Error(\n            `Lexer Modes: < ${unOptimizedModes.join(\n              \", \",\n            )} > cannot be optimized.\\n` +\n              '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n              \"\\t Or inspect the console log for details on how to resolve these issues.\",\n          );\n        }\n      });\n\n      this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n        clearRegExpParserCache();\n      });\n\n      this.TRACE_INIT(\"toFastProperties\", () => {\n        toFastProperties(this);\n      });\n    });\n  }\n\n  public tokenize(\n    text: string,\n    initialMode: string = this.defaultMode,\n  ): ILexingResult {\n    if (!isEmpty(this.lexerDefinitionErrors)) {\n      const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n        return error.message;\n      });\n      const allErrMessagesString = allErrMessages.join(\n        \"-----------------------\\n\",\n      );\n      throw new Error(\n        \"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n          allErrMessagesString,\n      );\n    }\n\n    return this.tokenizeInternal(text, initialMode);\n  }\n\n  // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n  private tokenizeInternal(text: string, initialMode: string): ILexingResult {\n    let i,\n      j,\n      k,\n      matchAltImage,\n      longerAlt,\n      matchedImage: string | null,\n      payload,\n      altPayload,\n      imageLength,\n      group,\n      tokType,\n      newToken: IToken,\n      errLength,\n      droppedChar,\n      msg,\n      match;\n    const orgText = text;\n    const orgLength = orgText.length;\n    let offset = 0;\n    let matchedTokensIndex = 0;\n    // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n    const guessedNumberOfTokens = this.hasCustom\n      ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n      : Math.floor(text.length / 10);\n    const matchedTokens = new Array(guessedNumberOfTokens);\n    const errors: ILexingError[] = [];\n    let line = this.trackStartLines ? 1 : undefined;\n    let column = this.trackStartLines ? 1 : undefined;\n    const groups: any = cloneEmptyGroups(this.emptyGroups);\n    const trackLines = this.trackStartLines;\n    const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n\n    let currModePatternsLength = 0;\n    let patternIdxToConfig: IPatternConfig[] = [];\n    let currCharCodeToPatternIdxToConfig: {\n      [charCode: number]: IPatternConfig[];\n    } = [];\n\n    const modeStack: string[] = [];\n\n    const emptyArray: IPatternConfig[] = [];\n    Object.freeze(emptyArray);\n    let getPossiblePatterns!: (charCode: number) => IPatternConfig[];\n\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig;\n    }\n\n    function getPossiblePatternsOptimized(charCode: number): IPatternConfig[] {\n      const optimizedCharIdx = charCodeToOptimizedIndex(charCode);\n      const possiblePatterns =\n        currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n      if (possiblePatterns === undefined) {\n        return emptyArray;\n      } else {\n        return possiblePatterns;\n      }\n    }\n\n    const pop_mode = (popToken: IToken) => {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (\n        modeStack.length === 1 &&\n        // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n        // So no error should occur.\n        popToken.tokenType.PUSH_MODE === undefined\n      ) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        const msg =\n          this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(\n            popToken,\n          );\n\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg,\n        });\n      } else {\n        modeStack.pop();\n        const newMode = last(modeStack)!;\n        patternIdxToConfig = this.patternIdxToConfig[newMode];\n        currCharCodeToPatternIdxToConfig =\n          this.charCodeToPatternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        const modeCanBeOptimized =\n          this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n    };\n\n    function push_mode(this: Lexer, newMode: string) {\n      modeStack.push(newMode);\n      currCharCodeToPatternIdxToConfig =\n        this.charCodeToPatternIdxToConfig[newMode];\n\n      patternIdxToConfig = this.patternIdxToConfig[newMode];\n      currModePatternsLength = patternIdxToConfig.length;\n\n      currModePatternsLength = patternIdxToConfig.length;\n      const modeCanBeOptimized =\n        this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized;\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow;\n      }\n    }\n\n    // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n    push_mode.call(this, initialMode);\n\n    let currConfig!: IPatternConfig;\n\n    const recoveryEnabled = this.config.recoveryEnabled;\n\n    while (offset < orgLength) {\n      matchedImage = null;\n\n      const nextCharCode = orgText.charCodeAt(offset);\n      const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n      const chosenPatternsLength = chosenPatternIdxToConfig.length;\n\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i];\n        const currPattern = currConfig.pattern;\n        payload = null;\n\n        // manually in-lined because > 600 chars won't be in-lined in V8\n        const singleCharCode = currConfig.short;\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern as string;\n          }\n        } else if (currConfig.isCustom === true) {\n          match = (currPattern as IRegExpExec).exec(\n            orgText,\n            offset,\n            matchedTokens,\n            groups,\n          );\n          if (match !== null) {\n            matchedImage = match[0];\n            if ((match as CustomPatternMatcherReturn).payload !== undefined) {\n              payload = (match as CustomPatternMatcherReturn).payload;\n            }\n          } else {\n            matchedImage = null;\n          }\n        } else {\n          this.updateLastIndex(currPattern as RegExp, offset);\n          matchedImage = this.match(currPattern as RegExp, text, offset);\n        }\n\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt;\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            const longerAltLength = longerAlt.length;\n            for (k = 0; k < longerAltLength; k++) {\n              const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n              const longerAltPattern = longerAltConfig.pattern;\n              altPayload = null;\n\n              // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n              if (longerAltConfig.isCustom === true) {\n                match = (longerAltPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups,\n                );\n                if (match !== null) {\n                  matchAltImage = match[0];\n                  if (\n                    (match as CustomPatternMatcherReturn).payload !== undefined\n                  ) {\n                    altPayload = (match as CustomPatternMatcherReturn).payload;\n                  }\n                } else {\n                  matchAltImage = null;\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern as RegExp, offset);\n                matchAltImage = this.match(\n                  longerAltPattern as RegExp,\n                  text,\n                  offset,\n                );\n              }\n\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage;\n                payload = altPayload;\n                currConfig = longerAltConfig;\n                // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n                break;\n              }\n            }\n          }\n          break;\n        }\n      }\n\n      // successful match\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length;\n        group = currConfig.group;\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx;\n          // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n          newToken = this.createTokenInstance(\n            matchedImage,\n            offset,\n            tokType,\n            currConfig.tokenType,\n            line,\n            column,\n            imageLength,\n          );\n\n          this.handlePayload(newToken, payload);\n\n          // TODO: optimize NOOP in case there are no special groups?\n          if (group === false) {\n            matchedTokensIndex = this.addToken(\n              matchedTokens,\n              matchedTokensIndex,\n              newToken,\n            );\n          } else {\n            groups[group].push(newToken);\n          }\n        }\n        text = this.chopInput(text, imageLength);\n        offset = offset + imageLength;\n\n        // TODO: with newlines the column may be assigned twice\n        column = this.computeNewColumn(column!, imageLength);\n\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          let numOfLTsInMatch = 0;\n          let foundTerminator;\n          let lastLTEndOffset: number;\n          lineTerminatorPattern.lastIndex = 0;\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage);\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n              numOfLTsInMatch++;\n            }\n          } while (foundTerminator === true);\n\n          if (numOfLTsInMatch !== 0) {\n            line = line! + numOfLTsInMatch;\n            column = imageLength - lastLTEndOffset!;\n            this.updateTokenEndLineColumnLocation(\n              newToken!,\n              group!,\n              lastLTEndOffset!,\n              numOfLTsInMatch,\n              line,\n              column,\n              imageLength,\n            );\n          }\n        }\n        // will be NOOP if no modes present\n        this.handleModes(currConfig, pop_mode, push_mode, newToken!);\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        const errorStartOffset = offset;\n        const errorLine = line;\n        const errorColumn = column;\n        let foundResyncPoint = recoveryEnabled === false;\n\n        while (foundResyncPoint === false && offset < orgLength) {\n          // Identity Func (when sticky flag is enabled)\n          text = this.chopInput(text, 1);\n          offset++;\n          for (j = 0; j < currModePatternsLength; j++) {\n            const currConfig = patternIdxToConfig[j];\n            const currPattern = currConfig.pattern;\n\n            // manually in-lined because > 600 chars won't be in-lined in V8\n            const singleCharCode = currConfig.short;\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true;\n              }\n            } else if (currConfig.isCustom === true) {\n              foundResyncPoint =\n                (currPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups,\n                ) !== null;\n            } else {\n              this.updateLastIndex(currPattern as RegExp, offset);\n              foundResyncPoint = (currPattern as RegExp).exec(text) !== null;\n            }\n\n            if (foundResyncPoint === true) {\n              break;\n            }\n          }\n        }\n\n        errLength = offset - errorStartOffset;\n        column = this.computeNewColumn(column!, errLength);\n        // at this point we either re-synced or reached the end of the input text\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(\n          orgText,\n          errorStartOffset,\n          errLength,\n          errorLine,\n          errorColumn,\n        );\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg,\n        });\n\n        if (recoveryEnabled === false) {\n          break;\n        }\n      }\n    }\n\n    // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex;\n    }\n\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors,\n    };\n  }\n\n  private handleModes(\n    config: IPatternConfig,\n    pop_mode: (tok: IToken) => void,\n    push_mode: (this: Lexer, pushMode: string) => void,\n    newToken: IToken,\n  ) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      const pushMode = config.push;\n      pop_mode(newToken);\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode);\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push);\n    }\n  }\n\n  private chopInput(text: string, length: number): string {\n    return text.substring(length);\n  }\n\n  private updateLastIndex(regExp: RegExp, newLastIndex: number): void {\n    regExp.lastIndex = newLastIndex;\n  }\n\n  // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n  private updateTokenEndLineColumnLocation(\n    newToken: IToken,\n    group: string | false,\n    lastLTIdx: number,\n    numOfLTsInMatch: number,\n    line: number,\n    column: number,\n    imageLength: number,\n  ): void {\n    let lastCharIsLT, fixForEndingInLT;\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1;\n      fixForEndingInLT = lastCharIsLT ? -1 : 0;\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT;\n        // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n        newToken.endColumn = column - 1 + -fixForEndingInLT;\n      }\n      // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n    }\n  }\n\n  private computeNewColumn(oldColumn: number, imageLength: number) {\n    return oldColumn + imageLength;\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private createTokenInstance!: (...args: any[]) => IToken;\n\n  private createOffsetOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n  ) {\n    return {\n      image,\n      startOffset,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  private createStartOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n  ) {\n    return {\n      image,\n      startOffset,\n      startLine,\n      startColumn,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  private createFullToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n    imageLength: number,\n  ): IToken {\n    return {\n      image,\n      startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine,\n      endLine: startLine,\n      startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private addToken!: (\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ) => number;\n\n  private addTokenUsingPush(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ): number {\n    tokenVector.push(tokenToAdd);\n    return index;\n  }\n\n  private addTokenUsingMemberAccess(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ): number {\n    tokenVector[index] = tokenToAdd;\n    index++;\n    return index;\n  }\n\n  // Place holder, will be replaced by the correct variant according to the hasCustom flag option at runtime.\n  private handlePayload: (token: IToken, payload: any) => void;\n\n  private handlePayloadNoCustom(token: IToken, payload: any): void {}\n\n  private handlePayloadWithCustom(token: IToken, payload: any): void {\n    if (payload !== null) {\n      token.payload = payload;\n    }\n  }\n\n  // place holder to be replaced with chosen alternative at runtime\n  private match!: (\n    pattern: RegExp,\n    text: string,\n    offset: number,\n  ) => string | null;\n\n  private matchWithTest(\n    pattern: RegExp,\n    text: string,\n    offset: number,\n  ): string | null {\n    const found = pattern.test(text);\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex);\n    }\n    return null;\n  }\n\n  private matchWithExec(pattern: RegExp, text: string): string | null {\n    const regExpArray = pattern.exec(text);\n    return regExpArray !== null ? regExpArray[0] : null;\n  }\n\n  // Duplicated from the parser's perf trace trait to allow future extraction\n  // of the lexer to a separate package.\n  TRACE_INIT = <T>(phaseDesc: string, phaseImpl: () => T): T => {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++;\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`);\n      }\n      const { time, value } = timer(phaseImpl);\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log;\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n      }\n      this.traceInitIndent--;\n      return value;\n    } else {\n      return phaseImpl();\n    }\n  };\n}\n","import { has, isString, isUndefined } from \"lodash-es\";\nimport { Lexer } from \"./lexer_public.js\";\nimport { augmentTokenTypes, tokenStructuredMatcher } from \"./tokens.js\";\nimport { IToken, ITokenConfig, TokenType } from \"@chevrotain/types\";\n\nexport function tokenLabel(tokType: TokenType): string {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\n\nexport function tokenName(tokType: TokenType): string {\n  return tokType.name;\n}\n\nexport function hasTokenLabel(\n  obj: TokenType,\n): obj is TokenType & Pick<Required<TokenType>, \"LABEL\"> {\n  return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\n\nconst PARENT = \"parent\";\nconst CATEGORIES = \"categories\";\nconst LABEL = \"label\";\nconst GROUP = \"group\";\nconst PUSH_MODE = \"push_mode\";\nconst POP_MODE = \"pop_mode\";\nconst LONGER_ALT = \"longer_alt\";\nconst LINE_BREAKS = \"line_breaks\";\nconst START_CHARS_HINT = \"start_chars_hint\";\n\nexport function createToken(config: ITokenConfig): TokenType {\n  return createTokenInternal(config);\n}\n\nfunction createTokenInternal(config: ITokenConfig): TokenType {\n  const pattern = config.pattern;\n\n  const tokenType: TokenType = <any>{};\n  tokenType.name = config.name;\n\n  if (!isUndefined(pattern)) {\n    tokenType.PATTERN = pattern;\n  }\n\n  if (has(config, PARENT)) {\n    throw (\n      \"The parent property is no longer supported.\\n\" +\n      \"See: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\"\n    );\n  }\n\n  if (has(config, CATEGORIES)) {\n    // casting to ANY as this will be fixed inside `augmentTokenTypes``\n    tokenType.CATEGORIES = <any>config[CATEGORIES];\n  }\n\n  augmentTokenTypes([tokenType]);\n\n  if (has(config, LABEL)) {\n    tokenType.LABEL = config[LABEL];\n  }\n\n  if (has(config, GROUP)) {\n    tokenType.GROUP = config[GROUP];\n  }\n\n  if (has(config, POP_MODE)) {\n    tokenType.POP_MODE = config[POP_MODE];\n  }\n\n  if (has(config, PUSH_MODE)) {\n    tokenType.PUSH_MODE = config[PUSH_MODE];\n  }\n\n  if (has(config, LONGER_ALT)) {\n    tokenType.LONGER_ALT = config[LONGER_ALT];\n  }\n\n  if (has(config, LINE_BREAKS)) {\n    tokenType.LINE_BREAKS = config[LINE_BREAKS];\n  }\n\n  if (has(config, START_CHARS_HINT)) {\n    tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n  }\n\n  return tokenType;\n}\n\nexport const EOF = createToken({ name: \"EOF\", pattern: Lexer.NA });\naugmentTokenTypes([EOF]);\n\nexport function createTokenInstance(\n  tokType: TokenType,\n  image: string,\n  startOffset: number,\n  endOffset: number,\n  startLine: number,\n  endLine: number,\n  startColumn: number,\n  endColumn: number,\n): IToken {\n  return {\n    image,\n    startOffset,\n    endOffset,\n    startLine,\n    endLine,\n    startColumn,\n    endColumn,\n    tokenTypeIdx: (<any>tokType).tokenTypeIdx,\n    tokenType: tokType,\n  };\n}\n\nexport function tokenMatcher(token: IToken, tokType: TokenType): boolean {\n  return tokenStructuredMatcher(token, tokType);\n}\n","import { hasTokenLabel, tokenLabel } from \"../scan/tokens_public.js\";\nimport { first, map, reduce } from \"lodash-es\";\nimport {\n  Alternation,\n  getProductionDslName,\n  NonTerminal,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  IParserErrorMessageProvider,\n  IProductionWithOccurrence,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IGrammarValidatorErrorMessageProvider,\n} from \"./grammar/types.js\";\n\nexport const defaultParserErrorProvider: IParserErrorMessageProvider = {\n  buildMismatchTokenMessage({ expected, actual, previous, ruleName }): string {\n    const hasLabel = hasTokenLabel(expected);\n    const expectedMsg = hasLabel\n      ? `--> ${tokenLabel(expected)} <--`\n      : `token of type --> ${expected.name} <--`;\n\n    const msg = `Expecting ${expectedMsg} but found --> '${actual.image}' <--`;\n\n    return msg;\n  },\n\n  buildNotAllInputParsedMessage({ firstRedundant, ruleName }): string {\n    return \"Redundant input, expecting EOF but found: \" + firstRedundant.image;\n  },\n\n  buildNoViableAltMessage({\n    expectedPathsPerAlt,\n    actual,\n    previous,\n    customUserDescription,\n    ruleName,\n  }): string {\n    const errPrefix = \"Expecting: \";\n    // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n    const actualText = first(actual)!.image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const allLookAheadPaths = reduce(\n        expectedPathsPerAlt,\n        (result, currAltPaths) => result.concat(currAltPaths),\n        [] as TokenType[][],\n      );\n      const nextValidTokenSequences = map(\n        allLookAheadPaths,\n        (currPath) =>\n          `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\n            \", \",\n          )}]`,\n      );\n      const nextValidSequenceItems = map(\n        nextValidTokenSequences,\n        (itemMsg, idx) => `  ${idx + 1}. ${itemMsg}`,\n      );\n      const calculatedDescription = `one of these possible Token sequences:\\n${nextValidSequenceItems.join(\n        \"\\n\",\n      )}`;\n\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  },\n\n  buildEarlyExitMessage({\n    expectedIterationPaths,\n    actual,\n    customUserDescription,\n    ruleName,\n  }): string {\n    const errPrefix = \"Expecting: \";\n    // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n    const actualText = first(actual)!.image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const nextValidTokenSequences = map(\n        expectedIterationPaths,\n        (currPath) =>\n          `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\n            \",\",\n          )}]`,\n      );\n      const calculatedDescription =\n        `expecting at least one iteration which starts with one of these possible Token sequences::\\n  ` +\n        `<${nextValidTokenSequences.join(\" ,\")}>`;\n\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  },\n};\n\nObject.freeze(defaultParserErrorProvider);\n\nexport const defaultGrammarResolverErrorProvider: IGrammarResolverErrorMessageProvider =\n  {\n    buildRuleNotFoundError(\n      topLevelRule: Rule,\n      undefinedRule: NonTerminal,\n    ): string {\n      const msg =\n        \"Invalid grammar, reference to a rule which is not defined: ->\" +\n        undefinedRule.nonTerminalName +\n        \"<-\\n\" +\n        \"inside top level rule: ->\" +\n        topLevelRule.name +\n        \"<-\";\n      return msg;\n    },\n  };\n\nexport const defaultGrammarValidatorErrorProvider: IGrammarValidatorErrorMessageProvider =\n  {\n    buildDuplicateFoundError(\n      topLevelRule: Rule,\n      duplicateProds: IProductionWithOccurrence[],\n    ): string {\n      function getExtraProductionArgument(\n        prod: IProductionWithOccurrence,\n      ): string {\n        if (prod instanceof Terminal) {\n          return prod.terminalType.name;\n        } else if (prod instanceof NonTerminal) {\n          return prod.nonTerminalName;\n        } else {\n          return \"\";\n        }\n      }\n\n      const topLevelName = topLevelRule.name;\n      const duplicateProd = first(duplicateProds)!;\n      const index = duplicateProd.idx;\n      const dslName = getProductionDslName(duplicateProd);\n      const extraArgument = getExtraProductionArgument(duplicateProd);\n\n      const hasExplicitIndex = index > 0;\n      let msg = `->${dslName}${hasExplicitIndex ? index : \"\"}<- ${\n        extraArgument ? `with argument: ->${extraArgument}<-` : \"\"\n      }\n                  appears more than once (${\n                    duplicateProds.length\n                  } times) in the top level rule: ->${topLevelName}<-.                  \n                  For further details see: https://chevrotain.io/docs/FAQ.html#NUMERICAL_SUFFIXES \n                  `;\n\n      // white space trimming time! better to trim afterwards as it allows to use WELL formatted multi line template strings...\n      msg = msg.replace(/[ \\t]+/g, \" \");\n      msg = msg.replace(/\\s\\s+/g, \"\\n\");\n\n      return msg;\n    },\n\n    buildNamespaceConflictError(rule: Rule): string {\n      const errMsg =\n        `Namespace conflict found in grammar.\\n` +\n        `The grammar has both a Terminal(Token) and a Non-Terminal(Rule) named: <${rule.name}>.\\n` +\n        `To resolve this make sure each Terminal and Non-Terminal names are unique\\n` +\n        `This is easy to accomplish by using the convention that Terminal names start with an uppercase letter\\n` +\n        `and Non-Terminal names start with a lower case letter.`;\n\n      return errMsg;\n    },\n\n    buildAlternationPrefixAmbiguityError(options: {\n      topLevelRule: Rule;\n      prefixPath: TokenType[];\n      ambiguityIndices: number[];\n      alternation: Alternation;\n    }): string {\n      const pathMsg = map(options.prefixPath, (currTok) =>\n        tokenLabel(currTok),\n      ).join(\", \");\n      const occurrence =\n        options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      const errMsg =\n        `Ambiguous alternatives: <${options.ambiguityIndices.join(\n          \" ,\",\n        )}> due to common lookahead prefix\\n` +\n        `in <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n` +\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#COMMON_PREFIX\\n` +\n        `For Further details.`;\n\n      return errMsg;\n    },\n\n    buildAlternationAmbiguityError(options: {\n      topLevelRule: Rule;\n      prefixPath: TokenType[];\n      ambiguityIndices: number[];\n      alternation: Alternation;\n    }): string {\n      const pathMsg = map(options.prefixPath, (currtok) =>\n        tokenLabel(currtok),\n      ).join(\", \");\n      const occurrence =\n        options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      let currMessage =\n        `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\n          \" ,\",\n        )}> in <OR${occurrence}>` +\n        ` inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`;\n\n      currMessage =\n        currMessage +\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\n        `For Further details.`;\n      return currMessage;\n    },\n\n    buildEmptyRepetitionError(options: {\n      topLevelRule: Rule;\n      repetition: IProductionWithOccurrence;\n    }): string {\n      let dslName = getProductionDslName(options.repetition);\n      if (options.repetition.idx !== 0) {\n        dslName += options.repetition.idx;\n      }\n\n      const errMsg =\n        `The repetition <${dslName}> within Rule <${options.topLevelRule.name}> can never consume any tokens.\\n` +\n        `This could lead to an infinite loop.`;\n\n      return errMsg;\n    },\n\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildTokenNameError(options: {\n      tokenType: TokenType;\n      expectedPattern: RegExp;\n    }): string {\n      /* istanbul ignore next */\n      return \"deprecated\";\n    },\n\n    buildEmptyAlternationError(options: {\n      topLevelRule: Rule;\n      alternation: Alternation;\n      emptyChoiceIdx: number;\n    }): string {\n      const errMsg =\n        `Ambiguous empty alternative: <${options.emptyChoiceIdx + 1}>` +\n        ` in <OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\\n` +\n        `Only the last alternative may be an empty alternative.`;\n\n      return errMsg;\n    },\n\n    buildTooManyAlternativesError(options: {\n      topLevelRule: Rule;\n      alternation: Alternation;\n    }): string {\n      const errMsg =\n        `An Alternation cannot have more than 256 alternatives:\\n` +\n        `<OR${options.alternation.idx}> inside <${\n          options.topLevelRule.name\n        }> Rule.\\n has ${\n          options.alternation.definition.length + 1\n        } alternatives.`;\n\n      return errMsg;\n    },\n\n    buildLeftRecursionError(options: {\n      topLevelRule: Rule;\n      leftRecursionPath: Rule[];\n    }): string {\n      const ruleName = options.topLevelRule.name;\n      const pathNames = map(\n        options.leftRecursionPath,\n        (currRule) => currRule.name,\n      );\n      const leftRecursivePath = `${ruleName} --> ${pathNames\n        .concat([ruleName])\n        .join(\" --> \")}`;\n      const errMsg =\n        `Left Recursion found in grammar.\\n` +\n        `rule: <${ruleName}> can be invoked from itself (directly or indirectly)\\n` +\n        `without consuming any Tokens. The grammar path that causes this is: \\n ${leftRecursivePath}\\n` +\n        ` To fix this refactor your grammar to remove the left recursion.\\n` +\n        `see: https://en.wikipedia.org/wiki/LL_parser#Left_factoring.`;\n\n      return errMsg;\n    },\n\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildInvalidRuleNameError(options: {\n      topLevelRule: Rule;\n      expectedPattern: RegExp;\n    }): string {\n      /* istanbul ignore next */\n      return \"deprecated\";\n    },\n\n    buildDuplicateRuleNameError(options: {\n      topLevelRule: Rule | string;\n      grammarName: string;\n    }): string {\n      let ruleName;\n      if (options.topLevelRule instanceof Rule) {\n        ruleName = options.topLevelRule.name;\n      } else {\n        ruleName = options.topLevelRule;\n      }\n\n      const errMsg = `Duplicate definition, rule: ->${ruleName}<- is already defined in the grammar: ->${options.grammarName}<-`;\n\n      return errMsg;\n    },\n  };\n","import {\n  IParserUnresolvedRefDefinitionError,\n  ParserDefinitionErrorType,\n} from \"../parser/parser.js\";\nimport { forEach, values } from \"lodash-es\";\nimport { GAstVisitor, NonTerminal, Rule } from \"@chevrotain/gast\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IParserDefinitionError,\n} from \"./types.js\";\n\nexport function resolveGrammar(\n  topLevels: Record<string, Rule>,\n  errMsgProvider: IGrammarResolverErrorMessageProvider,\n): IParserDefinitionError[] {\n  const refResolver = new GastRefResolverVisitor(topLevels, errMsgProvider);\n  refResolver.resolveRefs();\n  return refResolver.errors;\n}\n\nexport class GastRefResolverVisitor extends GAstVisitor {\n  public errors: IParserUnresolvedRefDefinitionError[] = [];\n  private currTopLevel: Rule;\n\n  constructor(\n    private nameToTopRule: Record<string, Rule>,\n    private errMsgProvider: IGrammarResolverErrorMessageProvider,\n  ) {\n    super();\n  }\n\n  public resolveRefs(): void {\n    forEach(values(this.nameToTopRule), (prod) => {\n      this.currTopLevel = prod;\n      prod.accept(this);\n    });\n  }\n\n  public visitNonTerminal(node: NonTerminal): void {\n    const ref = this.nameToTopRule[node.nonTerminalName];\n\n    if (!ref) {\n      const msg = this.errMsgProvider.buildRuleNotFoundError(\n        this.currTopLevel,\n        node,\n      );\n      this.errors.push({\n        message: msg,\n        type: ParserDefinitionErrorType.UNRESOLVED_SUBRULE_REF,\n        ruleName: this.currTopLevel.name,\n        unresolvedRefName: node.nonTerminalName,\n      });\n    } else {\n      node.referencedRule = ref;\n    }\n  }\n}\n","import baseFlatten from './_baseFlatten.js';\nimport map from './map.js';\n\n/**\n * Creates a flattened array of values by running each element in `collection`\n * thru `iteratee` and flattening the mapped results. The iteratee is invoked\n * with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * function duplicate(n) {\n *   return [n, n];\n * }\n *\n * _.flatMap([1, 2], duplicate);\n * // => [1, 1, 2, 2]\n */\nfunction flatMap(collection, iteratee) {\n  return baseFlatten(map(collection, iteratee), 1);\n}\n\nexport default flatMap;\n","/**\n * A specialized version of `baseAggregator` for arrays.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction arrayAggregator(array, setter, iteratee, accumulator) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    var value = array[index];\n    setter(accumulator, value, iteratee(value), array);\n  }\n  return accumulator;\n}\n\nexport default arrayAggregator;\n","import baseEach from './_baseEach.js';\n\n/**\n * Aggregates elements of `collection` on `accumulator` with keys transformed\n * by `iteratee` and values set by `setter`.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction baseAggregator(collection, setter, iteratee, accumulator) {\n  baseEach(collection, function(value, key, collection) {\n    setter(accumulator, value, iteratee(value), collection);\n  });\n  return accumulator;\n}\n\nexport default baseAggregator;\n","import arrayAggregator from './_arrayAggregator.js';\nimport baseAggregator from './_baseAggregator.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates a function like `_.groupBy`.\n *\n * @private\n * @param {Function} setter The function to set accumulator values.\n * @param {Function} [initializer] The accumulator object initializer.\n * @returns {Function} Returns the new aggregator function.\n */\nfunction createAggregator(setter, initializer) {\n  return function(collection, iteratee) {\n    var func = isArray(collection) ? arrayAggregator : baseAggregator,\n        accumulator = initializer ? initializer() : {};\n\n    return func(collection, setter, baseIteratee(iteratee, 2), accumulator);\n  };\n}\n\nexport default createAggregator;\n","import baseAssignValue from './_baseAssignValue.js';\nimport createAggregator from './_createAggregator.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates an object composed of keys generated from the results of running\n * each element of `collection` thru `iteratee`. The order of grouped values\n * is determined by the order they occur in `collection`. The corresponding\n * value of each key is an array of elements responsible for generating the\n * key. The iteratee is invoked with one argument: (value).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The iteratee to transform keys.\n * @returns {Object} Returns the composed aggregate object.\n * @example\n *\n * _.groupBy([6.1, 4.2, 6.3], Math.floor);\n * // => { '4': [4.2], '6': [6.1, 6.3] }\n *\n * // The `_.property` iteratee shorthand.\n * _.groupBy(['one', 'two', 'three'], 'length');\n * // => { '3': ['one', 'two'], '5': ['three'] }\n */\nvar groupBy = createAggregator(function(result, value, key) {\n  if (hasOwnProperty.call(result, key)) {\n    result[key].push(value);\n  } else {\n    baseAssignValue(result, key, [value]);\n  }\n});\n\nexport default groupBy;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the end.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.dropRight([1, 2, 3]);\n * // => [1, 2]\n *\n * _.dropRight([1, 2, 3], 2);\n * // => [1]\n *\n * _.dropRight([1, 2, 3], 5);\n * // => []\n *\n * _.dropRight([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction dropRight(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  n = length - n;\n  return baseSlice(array, 0, n < 0 ? 0 : n);\n}\n\nexport default dropRight;\n","import {\n  clone,\n  drop,\n  dropRight,\n  first as _first,\n  forEach,\n  isEmpty,\n  last,\n} from \"lodash-es\";\nimport { first } from \"./first.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { TokenMatcher } from \"../parser/parser.js\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  IGrammarPath,\n  IProduction,\n  ISyntacticContentAssistPath,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\n\nexport abstract class AbstractNextPossibleTokensWalker extends RestWalker {\n  protected possibleTokTypes: TokenType[] = [];\n  protected ruleStack: string[];\n  protected occurrenceStack: number[];\n\n  protected nextProductionName = \"\";\n  protected nextProductionOccurrence = 0;\n  protected found = false;\n  protected isAtEndOfPath = false;\n\n  constructor(\n    protected topProd: Rule,\n    protected path: IGrammarPath,\n  ) {\n    super();\n  }\n\n  startWalking(): TokenType[] {\n    this.found = false;\n\n    if (this.path.ruleStack[0] !== this.topProd.name) {\n      throw Error(\"The path does not start with the walker's top Rule!\");\n    }\n\n    // immutable for the win\n    this.ruleStack = clone(this.path.ruleStack).reverse(); // intelij bug requires assertion\n    this.occurrenceStack = clone(this.path.occurrenceStack).reverse(); // intelij bug requires assertion\n\n    // already verified that the first production is valid, we now seek the 2nd production\n    this.ruleStack.pop();\n    this.occurrenceStack.pop();\n\n    this.updateExpectedNext();\n    this.walk(this.topProd);\n\n    return this.possibleTokTypes;\n  }\n\n  walk(\n    prod: { definition: IProduction[] },\n    prevRest: IProduction[] = [],\n  ): void {\n    // stop scanning once we found the path\n    if (!this.found) {\n      super.walk(prod, prevRest);\n    }\n  }\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // found the next production, need to keep walking in it\n    if (\n      refProd.referencedRule.name === this.nextProductionName &&\n      refProd.idx === this.nextProductionOccurrence\n    ) {\n      const fullRest = currRest.concat(prevRest);\n      this.updateExpectedNext();\n      this.walk(refProd.referencedRule, <any>fullRest);\n    }\n  }\n\n  updateExpectedNext(): void {\n    // need to consume the Terminal\n    if (isEmpty(this.ruleStack)) {\n      // must reset nextProductionXXX to avoid walking down another Top Level production while what we are\n      // really seeking is the last Terminal...\n      this.nextProductionName = \"\";\n      this.nextProductionOccurrence = 0;\n      this.isAtEndOfPath = true;\n    } else {\n      this.nextProductionName = this.ruleStack.pop()!;\n      this.nextProductionOccurrence = this.occurrenceStack.pop()!;\n    }\n  }\n}\n\nexport class NextAfterTokenWalker extends AbstractNextPossibleTokensWalker {\n  private nextTerminalName = \"\";\n  private nextTerminalOccurrence = 0;\n\n  constructor(\n    topProd: Rule,\n    protected path: ITokenGrammarPath,\n  ) {\n    super(topProd, path);\n    this.nextTerminalName = this.path.lastTok.name;\n    this.nextTerminalOccurrence = this.path.lastTokOccurrence;\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      this.isAtEndOfPath &&\n      terminal.terminalType.name === this.nextTerminalName &&\n      terminal.idx === this.nextTerminalOccurrence &&\n      !this.found\n    ) {\n      const fullRest = currRest.concat(prevRest);\n      const restProd = new Alternative({ definition: fullRest });\n      this.possibleTokTypes = first(restProd);\n      this.found = true;\n    }\n  }\n}\n\nexport type AlternativesFirstTokens = TokenType[][];\n\nexport interface IFirstAfterRepetition {\n  token: TokenType | undefined;\n  occurrence: number | undefined;\n  isEndOfRule: boolean | undefined;\n}\n\n/**\n * This walker only \"walks\" a single \"TOP\" level in the Grammar Ast, this means\n * it never \"follows\" production refs\n */\nexport class AbstractNextTerminalAfterProductionWalker extends RestWalker {\n  protected result: IFirstAfterRepetition = {\n    token: undefined,\n    occurrence: undefined,\n    isEndOfRule: undefined,\n  };\n\n  constructor(\n    protected topRule: Rule,\n    protected occurrence: number,\n  ) {\n    super();\n  }\n\n  startWalking(): IFirstAfterRepetition {\n    this.walk(this.topRule);\n    return this.result;\n  }\n}\n\nexport class NextTerminalAfterManyWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (manyProd.idx === this.occurrence) {\n      const firstAfterMany = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterMany === undefined;\n      if (firstAfterMany instanceof Terminal) {\n        this.result.token = firstAfterMany.terminalType;\n        this.result.occurrence = firstAfterMany.idx;\n      }\n    } else {\n      super.walkMany(manyProd, currRest, prevRest);\n    }\n  }\n}\n\nexport class NextTerminalAfterManySepWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (manySepProd.idx === this.occurrence) {\n      const firstAfterManySep = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterManySep === undefined;\n      if (firstAfterManySep instanceof Terminal) {\n        this.result.token = firstAfterManySep.terminalType;\n        this.result.occurrence = firstAfterManySep.idx;\n      }\n    } else {\n      super.walkManySep(manySepProd, currRest, prevRest);\n    }\n  }\n}\n\nexport class NextTerminalAfterAtLeastOneWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (atLeastOneProd.idx === this.occurrence) {\n      const firstAfterAtLeastOne = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterAtLeastOne === undefined;\n      if (firstAfterAtLeastOne instanceof Terminal) {\n        this.result.token = firstAfterAtLeastOne.terminalType;\n        this.result.occurrence = firstAfterAtLeastOne.idx;\n      }\n    } else {\n      super.walkAtLeastOne(atLeastOneProd, currRest, prevRest);\n    }\n  }\n}\n\n// TODO: reduce code duplication in the AfterWalkers\nexport class NextTerminalAfterAtLeastOneSepWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkAtLeastOneSep(\n    atleastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (atleastOneSepProd.idx === this.occurrence) {\n      const firstAfterfirstAfterAtLeastOneSep = _first(\n        currRest.concat(prevRest),\n      );\n      this.result.isEndOfRule = firstAfterfirstAfterAtLeastOneSep === undefined;\n      if (firstAfterfirstAfterAtLeastOneSep instanceof Terminal) {\n        this.result.token = firstAfterfirstAfterAtLeastOneSep.terminalType;\n        this.result.occurrence = firstAfterfirstAfterAtLeastOneSep.idx;\n      }\n    } else {\n      super.walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest);\n    }\n  }\n}\n\nexport interface PartialPathAndSuffixes {\n  partialPath: TokenType[];\n  suffixDef: IProduction[];\n}\n\nexport function possiblePathsFrom(\n  targetDef: IProduction[],\n  maxLength: number,\n  currPath: TokenType[] = [],\n): PartialPathAndSuffixes[] {\n  // avoid side effects\n  currPath = clone(currPath);\n  let result: PartialPathAndSuffixes[] = [];\n  let i = 0;\n\n  // TODO: avoid inner funcs\n  function remainingPathWith(nextDef: IProduction[]) {\n    return nextDef.concat(drop(targetDef, i + 1));\n  }\n\n  // TODO: avoid inner funcs\n  function getAlternativesForProd(definition: IProduction[]) {\n    const alternatives = possiblePathsFrom(\n      remainingPathWith(definition),\n      maxLength,\n      currPath,\n    );\n    return result.concat(alternatives);\n  }\n\n  /**\n   * Mandatory productions will halt the loop as the paths computed from their recursive calls will already contain the\n   * following (rest) of the targetDef.\n   *\n   * For optional productions (Option/Repetition/...) the loop will continue to represent the paths that do not include the\n   * the optional production.\n   */\n  while (currPath.length < maxLength && i < targetDef.length) {\n    const prod = targetDef[i];\n\n    /* istanbul ignore else */\n    if (prod instanceof Alternative) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof NonTerminal) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof Option) {\n      result = getAlternativesForProd(prod.definition);\n    } else if (prod instanceof RepetitionMandatory) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition,\n        }),\n      ]);\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      const newDef = [\n        new Alternative({ definition: prod.definition }),\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(\n            <any>prod.definition,\n          ),\n        }),\n      ];\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(\n            <any>prod.definition,\n          ),\n        }),\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Repetition) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition,\n        }),\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Alternation) {\n      forEach(prod.definition, (currAlt) => {\n        // TODO: this is a limited check for empty alternatives\n        //   It would prevent a common case of infinite loops during parser initialization.\n        //   However **in-directly** empty alternatives may still cause issues.\n        if (isEmpty(currAlt.definition) === false) {\n          result = getAlternativesForProd(currAlt.definition);\n        }\n      });\n      return result;\n    } else if (prod instanceof Terminal) {\n      currPath.push(prod.terminalType);\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n\n    i++;\n  }\n  result.push({\n    partialPath: currPath,\n    suffixDef: drop(targetDef, i),\n  });\n\n  return result;\n}\n\ninterface IPathToExamine {\n  idx: number;\n  def: IProduction[];\n  ruleStack: string[];\n  occurrenceStack: number[];\n}\n\nexport function nextPossibleTokensAfter(\n  initialDef: IProduction[],\n  tokenVector: IToken[],\n  tokMatcher: TokenMatcher,\n  maxLookAhead: number,\n): ISyntacticContentAssistPath[] {\n  const EXIT_NON_TERMINAL: any = \"EXIT_NONE_TERMINAL\";\n  // to avoid creating a new Array each time.\n  const EXIT_NON_TERMINAL_ARR = [EXIT_NON_TERMINAL];\n  const EXIT_ALTERNATIVE: any = \"EXIT_ALTERNATIVE\";\n  let foundCompletePath = false;\n\n  const tokenVectorLength = tokenVector.length;\n  const minimalAlternativesIndex = tokenVectorLength - maxLookAhead - 1;\n\n  const result: ISyntacticContentAssistPath[] = [];\n\n  const possiblePaths: IPathToExamine[] = [];\n  possiblePaths.push({\n    idx: -1,\n    def: initialDef,\n    ruleStack: [],\n    occurrenceStack: [],\n  });\n\n  while (!isEmpty(possiblePaths)) {\n    const currPath = possiblePaths.pop()!;\n\n    // skip alternatives if no more results can be found (assuming deterministic grammar with fixed lookahead)\n    if (currPath === EXIT_ALTERNATIVE) {\n      if (\n        foundCompletePath &&\n        last(possiblePaths)!.idx <= minimalAlternativesIndex\n      ) {\n        // remove irrelevant alternative\n        possiblePaths.pop();\n      }\n      continue;\n    }\n\n    const currDef = currPath.def;\n    const currIdx = currPath.idx;\n    const currRuleStack = currPath.ruleStack;\n    const currOccurrenceStack = currPath.occurrenceStack;\n\n    // For Example: an empty path could exist in a valid grammar in the case of an EMPTY_ALT\n    if (isEmpty(currDef)) {\n      continue;\n    }\n\n    const prod = currDef[0];\n    /* istanbul ignore else */\n    if (prod === EXIT_NON_TERMINAL) {\n      const nextPath = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: dropRight(currRuleStack),\n        occurrenceStack: dropRight(currOccurrenceStack),\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Terminal) {\n      /* istanbul ignore else */\n      if (currIdx < tokenVectorLength - 1) {\n        const nextIdx = currIdx + 1;\n        const actualToken = tokenVector[nextIdx];\n        if (tokMatcher!(actualToken, prod.terminalType)) {\n          const nextPath = {\n            idx: nextIdx,\n            def: drop(currDef),\n            ruleStack: currRuleStack,\n            occurrenceStack: currOccurrenceStack,\n          };\n          possiblePaths.push(nextPath);\n        }\n        // end of the line\n      } else if (currIdx === tokenVectorLength - 1) {\n        // IGNORE ABOVE ELSE\n        result.push({\n          nextTokenType: prod.terminalType,\n          nextTokenOccurrence: prod.idx,\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack,\n        });\n        foundCompletePath = true;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    } else if (prod instanceof NonTerminal) {\n      const newRuleStack = clone(currRuleStack);\n      newRuleStack.push(prod.nonTerminalName);\n\n      const newOccurrenceStack = clone(currOccurrenceStack);\n      newOccurrenceStack.push(prod.idx);\n\n      const nextPath = {\n        idx: currIdx,\n        def: prod.definition.concat(EXIT_NON_TERMINAL_ARR, drop(currDef)),\n        ruleStack: newRuleStack,\n        occurrenceStack: newOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Option) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      const nextPathWith = {\n        idx: currIdx,\n        def: prod.definition.concat(drop(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof RepetitionMandatory) {\n      // TODO:(THE NEW operators here take a while...) (convert once?)\n      const secondIteration = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      // TODO:(THE NEW operators here take a while...) (convert once?)\n      const separatorGast = new Terminal({\n        terminalType: prod.separator,\n      });\n      const secondIteration = new Repetition({\n        definition: [<any>separatorGast].concat(prod.definition),\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      const separatorGast = new Terminal({\n        terminalType: prod.separator,\n      });\n      const nthRepetition = new Repetition({\n        definition: [<any>separatorGast].concat(prod.definition),\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Repetition) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      // TODO: an empty repetition will cause infinite loops here, will the parser detect this in selfAnalysis?\n      const nthRepetition = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Alternation) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      for (let i = prod.definition.length - 1; i >= 0; i--) {\n        const currAlt: any = prod.definition[i];\n        const currAltPath = {\n          idx: currIdx,\n          def: currAlt.definition.concat(drop(currDef)),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack,\n        };\n        possiblePaths.push(currAltPath);\n        possiblePaths.push(EXIT_ALTERNATIVE);\n      }\n    } else if (prod instanceof Alternative) {\n      possiblePaths.push({\n        idx: currIdx,\n        def: prod.definition.concat(drop(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      });\n    } else if (prod instanceof Rule) {\n      // last because we should only encounter at most a single one of these per invocation.\n      possiblePaths.push(\n        expandTopLevelRule(prod, currIdx, currRuleStack, currOccurrenceStack),\n      );\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  return result;\n}\n\nfunction expandTopLevelRule(\n  topRule: Rule,\n  currIdx: number,\n  currRuleStack: string[],\n  currOccurrenceStack: number[],\n): IPathToExamine {\n  const newRuleStack = clone(currRuleStack);\n  newRuleStack.push(topRule.name);\n\n  const newCurrOccurrenceStack = clone(currOccurrenceStack);\n  // top rule is always assumed to have been called with occurrence index 1\n  newCurrOccurrenceStack.push(1);\n\n  return {\n    idx: currIdx,\n    def: topRule.definition,\n    ruleStack: newRuleStack,\n    occurrenceStack: newCurrOccurrenceStack,\n  };\n}\n","import { every, flatten, forEach, has, isEmpty, map, reduce } from \"lodash-es\";\nimport { possiblePathsFrom } from \"./interpreter.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { Predicate, TokenMatcher } from \"../parser/parser.js\";\nimport {\n  tokenStructuredMatcher,\n  tokenStructuredMatcherNoCategories,\n} from \"../../scan/tokens.js\";\nimport {\n  Alternation,\n  Alternative as AlternativeGAST,\n  GAstVisitor,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n} from \"@chevrotain/gast\";\nimport {\n  BaseParser,\n  IOrAlt,\n  IProduction,\n  IProductionWithOccurrence,\n  LookaheadProductionType,\n  LookaheadSequence,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\n\nexport enum PROD_TYPE {\n  OPTION,\n  REPETITION,\n  REPETITION_MANDATORY,\n  REPETITION_MANDATORY_WITH_SEPARATOR,\n  REPETITION_WITH_SEPARATOR,\n  ALTERNATION,\n}\n\nexport function getProdType(\n  prod: IProduction | LookaheadProductionType,\n): PROD_TYPE {\n  /* istanbul ignore else */\n  if (prod instanceof Option || prod === \"Option\") {\n    return PROD_TYPE.OPTION;\n  } else if (prod instanceof Repetition || prod === \"Repetition\") {\n    return PROD_TYPE.REPETITION;\n  } else if (\n    prod instanceof RepetitionMandatory ||\n    prod === \"RepetitionMandatory\"\n  ) {\n    return PROD_TYPE.REPETITION_MANDATORY;\n  } else if (\n    prod instanceof RepetitionMandatoryWithSeparator ||\n    prod === \"RepetitionMandatoryWithSeparator\"\n  ) {\n    return PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR;\n  } else if (\n    prod instanceof RepetitionWithSeparator ||\n    prod === \"RepetitionWithSeparator\"\n  ) {\n    return PROD_TYPE.REPETITION_WITH_SEPARATOR;\n  } else if (prod instanceof Alternation || prod === \"Alternation\") {\n    return PROD_TYPE.ALTERNATION;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function getLookaheadPaths(options: {\n  occurrence: number;\n  rule: Rule;\n  prodType: LookaheadProductionType;\n  maxLookahead: number;\n}): LookaheadSequence[] {\n  const { occurrence, rule, prodType, maxLookahead } = options;\n  const type = getProdType(prodType);\n  if (type === PROD_TYPE.ALTERNATION) {\n    return getLookaheadPathsForOr(occurrence, rule, maxLookahead);\n  } else {\n    return getLookaheadPathsForOptionalProd(\n      occurrence,\n      rule,\n      type,\n      maxLookahead,\n    );\n  }\n}\n\nexport function buildLookaheadFuncForOr(\n  occurrence: number,\n  ruleGrammar: Rule,\n  maxLookahead: number,\n  hasPredicates: boolean,\n  dynamicTokensEnabled: boolean,\n  laFuncBuilder: Function,\n): (orAlts?: IOrAlt<any>[]) => number | undefined {\n  const lookAheadPaths = getLookaheadPathsForOr(\n    occurrence,\n    ruleGrammar,\n    maxLookahead,\n  );\n\n  const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n    ? tokenStructuredMatcherNoCategories\n    : tokenStructuredMatcher;\n\n  return laFuncBuilder(\n    lookAheadPaths,\n    hasPredicates,\n    tokenMatcher,\n    dynamicTokensEnabled,\n  );\n}\n\n/**\n *  When dealing with an Optional production (OPTION/MANY/2nd iteration of AT_LEAST_ONE/...) we need to compare\n *  the lookahead \"inside\" the production and the lookahead immediately \"after\" it in the same top level rule (context free).\n *\n *  Example: given a production:\n *  ABC(DE)?DF\n *\n *  The optional '(DE)?' should only be entered if we see 'DE'. a single Token 'D' is not sufficient to distinguish between the two\n *  alternatives.\n *\n *  @returns A Lookahead function which will return true IFF the parser should parse the Optional production.\n */\nexport function buildLookaheadFuncForOptionalProd(\n  occurrence: number,\n  ruleGrammar: Rule,\n  k: number,\n  dynamicTokensEnabled: boolean,\n  prodType: PROD_TYPE,\n  lookaheadBuilder: (\n    lookAheadSequence: LookaheadSequence,\n    tokenMatcher: TokenMatcher,\n    dynamicTokensEnabled: boolean,\n  ) => () => boolean,\n): () => boolean {\n  const lookAheadPaths = getLookaheadPathsForOptionalProd(\n    occurrence,\n    ruleGrammar,\n    prodType,\n    k,\n  );\n\n  const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n    ? tokenStructuredMatcherNoCategories\n    : tokenStructuredMatcher;\n\n  return lookaheadBuilder(\n    lookAheadPaths[0],\n    tokenMatcher,\n    dynamicTokensEnabled,\n  );\n}\n\nexport type Alternative = TokenType[][];\n\nexport function buildAlternativesLookAheadFunc(\n  alts: LookaheadSequence[],\n  hasPredicates: boolean,\n  tokenMatcher: TokenMatcher,\n  dynamicTokensEnabled: boolean,\n): (orAlts: IOrAlt<any>[]) => number | undefined {\n  const numOfAlts = alts.length;\n  const areAllOneTokenLookahead = every(alts, (currAlt) => {\n    return every(currAlt, (currPath) => {\n      return currPath.length === 1;\n    });\n  });\n\n  // This version takes into account the predicates as well.\n  if (hasPredicates) {\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (\n      this: BaseParser,\n      orAlts: IOrAlt<any>[],\n    ): number | undefined {\n      // unfortunately the predicates must be extracted every single time\n      // as they cannot be cached due to references to parameters(vars) which are no longer valid.\n      // note that in the common case of no predicates, no cpu time will be wasted on this (see else block)\n      const predicates: (Predicate | undefined)[] = map(\n        orAlts,\n        (currAlt) => currAlt.GATE,\n      );\n\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n\n        const currPredicate = predicates[t];\n        if (currPredicate !== undefined && currPredicate.call(this) === false) {\n          // if the predicate does not match there is no point in checking the paths\n          continue;\n        }\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher(nextToken, currPath[i]) === false) {\n              // mismatch in current path\n              // try the next pth\n              continue nextPath;\n            }\n          }\n          // found a full path that matches.\n          // this will also work for an empty ALT as the loop will be skipped\n          return t;\n        }\n        // none of the paths for the current alternative matched\n        // try the next alternative\n      }\n      // none of the alternatives could be matched\n      return undefined;\n    };\n  } else if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    // optimized (common) case of all the lookaheads paths requiring only\n    // a single token lookahead. These Optimizations cannot work if dynamically defined Tokens are used.\n    const singleTokenAlts = map(alts, (currAlt) => {\n      return flatten(currAlt);\n    });\n\n    const choiceToAlt = reduce(\n      singleTokenAlts,\n      (result, currAlt, idx) => {\n        forEach(currAlt, (currTokType) => {\n          if (!has(result, currTokType.tokenTypeIdx!)) {\n            result[currTokType.tokenTypeIdx!] = idx;\n          }\n          forEach(currTokType.categoryMatches!, (currExtendingType) => {\n            if (!has(result, currExtendingType)) {\n              result[currExtendingType] = idx;\n            }\n          });\n        });\n        return result;\n      },\n      {} as Record<number, number>,\n    );\n\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (this: BaseParser): number {\n      const nextToken = this.LA(1);\n      return choiceToAlt[nextToken.tokenTypeIdx];\n    };\n  } else {\n    // optimized lookahead without needing to check the predicates at all.\n    // this causes code duplication which is intentional to improve performance.\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (this: BaseParser): number | undefined {\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher(nextToken, currPath[i]) === false) {\n              // mismatch in current path\n              // try the next pth\n              continue nextPath;\n            }\n          }\n          // found a full path that matches.\n          // this will also work for an empty ALT as the loop will be skipped\n          return t;\n        }\n        // none of the paths for the current alternative matched\n        // try the next alternative\n      }\n      // none of the alternatives could be matched\n      return undefined;\n    };\n  }\n}\n\nexport function buildSingleAlternativeLookaheadFunction(\n  alt: LookaheadSequence,\n  tokenMatcher: TokenMatcher,\n  dynamicTokensEnabled: boolean,\n): () => boolean {\n  const areAllOneTokenLookahead = every(alt, (currPath) => {\n    return currPath.length === 1;\n  });\n\n  const numOfPaths = alt.length;\n\n  // optimized (common) case of all the lookaheads paths requiring only\n  // a single token lookahead.\n  if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    const singleTokensTypes = flatten(alt);\n\n    if (\n      singleTokensTypes.length === 1 &&\n      isEmpty((<any>singleTokensTypes[0]).categoryMatches)\n    ) {\n      const expectedTokenType = singleTokensTypes[0];\n      const expectedTokenUniqueKey = (<any>expectedTokenType).tokenTypeIdx;\n\n      return function (this: BaseParser): boolean {\n        return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n      };\n    } else {\n      const choiceToAlt = reduce(\n        singleTokensTypes,\n        (result, currTokType, idx) => {\n          result[currTokType.tokenTypeIdx!] = true;\n          forEach(currTokType.categoryMatches!, (currExtendingType) => {\n            result[currExtendingType] = true;\n          });\n          return result;\n        },\n        [] as boolean[],\n      );\n\n      return function (this: BaseParser): boolean {\n        const nextToken = this.LA(1);\n        return choiceToAlt[nextToken.tokenTypeIdx] === true;\n      };\n    }\n  } else {\n    return function (this: BaseParser): boolean {\n      nextPath: for (let j = 0; j < numOfPaths; j++) {\n        const currPath = alt[j];\n        const currPathLength = currPath.length;\n        for (let i = 0; i < currPathLength; i++) {\n          const nextToken = this.LA(i + 1);\n          if (tokenMatcher(nextToken, currPath[i]) === false) {\n            // mismatch in current path\n            // try the next pth\n            continue nextPath;\n          }\n        }\n        // found a full path that matches.\n        return true;\n      }\n\n      // none of the paths matched\n      return false;\n    };\n  }\n}\n\nclass RestDefinitionFinderWalker extends RestWalker {\n  private restDef: IProduction[];\n\n  constructor(\n    private topProd: Rule,\n    private targetOccurrence: number,\n    private targetProdType: PROD_TYPE,\n  ) {\n    super();\n  }\n\n  startWalking(): IProduction[] {\n    this.walk(this.topProd);\n    return this.restDef;\n  }\n\n  private checkIsTarget(\n    node: IProductionWithOccurrence,\n    expectedProdType: PROD_TYPE,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): boolean {\n    if (\n      node.idx === this.targetOccurrence &&\n      this.targetProdType === expectedProdType\n    ) {\n      this.restDef = currRest.concat(prevRest);\n      return true;\n    }\n    // performance optimization, do not iterate over the entire Grammar ast after we have found the target\n    return false;\n  }\n\n  walkOption(\n    optionProd: Option,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (!this.checkIsTarget(optionProd, PROD_TYPE.OPTION, currRest, prevRest)) {\n      super.walkOption(optionProd, currRest, prevRest);\n    }\n  }\n\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        atLeastOneProd,\n        PROD_TYPE.REPETITION_MANDATORY,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(atLeastOneProd, currRest, prevRest);\n    }\n  }\n\n  walkAtLeastOneSep(\n    atLeastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        atLeastOneSepProd,\n        PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(atLeastOneSepProd, currRest, prevRest);\n    }\n  }\n\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(manyProd, PROD_TYPE.REPETITION, currRest, prevRest)\n    ) {\n      super.walkOption(manyProd, currRest, prevRest);\n    }\n  }\n\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        manySepProd,\n        PROD_TYPE.REPETITION_WITH_SEPARATOR,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(manySepProd, currRest, prevRest);\n    }\n  }\n}\n\n/**\n * Returns the definition of a target production in a top level level rule.\n */\nclass InsideDefinitionFinderVisitor extends GAstVisitor {\n  public result: IProduction[] = [];\n\n  constructor(\n    private targetOccurrence: number,\n    private targetProdType: PROD_TYPE,\n    private targetRef?: any,\n  ) {\n    super();\n  }\n\n  private checkIsTarget(\n    node: { definition: IProduction[] } & IProductionWithOccurrence,\n    expectedProdName: PROD_TYPE,\n  ): void {\n    if (\n      node.idx === this.targetOccurrence &&\n      this.targetProdType === expectedProdName &&\n      (this.targetRef === undefined || node === this.targetRef)\n    ) {\n      this.result = node.definition;\n    }\n  }\n\n  public visitOption(node: Option): void {\n    this.checkIsTarget(node, PROD_TYPE.OPTION);\n  }\n\n  public visitRepetition(node: Repetition): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION);\n  }\n\n  public visitRepetitionMandatory(node: RepetitionMandatory): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    node: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR);\n  }\n\n  public visitRepetitionWithSeparator(node: RepetitionWithSeparator): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_WITH_SEPARATOR);\n  }\n\n  public visitAlternation(node: Alternation): void {\n    this.checkIsTarget(node, PROD_TYPE.ALTERNATION);\n  }\n}\n\nfunction initializeArrayOfArrays(size: number): any[][] {\n  const result = new Array(size);\n  for (let i = 0; i < size; i++) {\n    result[i] = [];\n  }\n  return result;\n}\n\n/**\n * A sort of hash function between a Path in the grammar and a string.\n * Note that this returns multiple \"hashes\" to support the scenario of token categories.\n * -  A single path with categories may match multiple **actual** paths.\n */\nfunction pathToHashKeys(path: TokenType[]): string[] {\n  let keys = [\"\"];\n  for (let i = 0; i < path.length; i++) {\n    const tokType = path[i];\n    const longerKeys = [];\n    for (let j = 0; j < keys.length; j++) {\n      const currShorterKey = keys[j];\n      longerKeys.push(currShorterKey + \"_\" + tokType.tokenTypeIdx);\n      for (let t = 0; t < tokType.categoryMatches!.length; t++) {\n        const categoriesKeySuffix = \"_\" + tokType.categoryMatches![t];\n        longerKeys.push(currShorterKey + categoriesKeySuffix);\n      }\n    }\n    keys = longerKeys;\n  }\n  return keys;\n}\n\n/**\n * Imperative style due to being called from a hot spot\n */\nfunction isUniquePrefixHash(\n  altKnownPathsKeys: Record<string, boolean>[],\n  searchPathKeys: string[],\n  idx: number,\n): boolean {\n  for (\n    let currAltIdx = 0;\n    currAltIdx < altKnownPathsKeys.length;\n    currAltIdx++\n  ) {\n    // We only want to test vs the other alternatives\n    if (currAltIdx === idx) {\n      continue;\n    }\n    const otherAltKnownPathsKeys = altKnownPathsKeys[currAltIdx];\n    for (let searchIdx = 0; searchIdx < searchPathKeys.length; searchIdx++) {\n      const searchKey = searchPathKeys[searchIdx];\n      if (otherAltKnownPathsKeys[searchKey] === true) {\n        return false;\n      }\n    }\n  }\n  // None of the SearchPathKeys were found in any of the other alternatives\n  return true;\n}\n\nexport function lookAheadSequenceFromAlternatives(\n  altsDefs: IProduction[],\n  k: number,\n): LookaheadSequence[] {\n  const partialAlts = map(altsDefs, (currAlt) =>\n    possiblePathsFrom([currAlt], 1),\n  );\n  const finalResult = initializeArrayOfArrays(partialAlts.length);\n  const altsHashes = map(partialAlts, (currAltPaths) => {\n    const dict: { [key: string]: boolean } = {};\n    forEach(currAltPaths, (item) => {\n      const keys = pathToHashKeys(item.partialPath);\n      forEach(keys, (currKey) => {\n        dict[currKey] = true;\n      });\n    });\n    return dict;\n  });\n  let newData = partialAlts;\n\n  // maxLookahead loop\n  for (let pathLength = 1; pathLength <= k; pathLength++) {\n    const currDataset = newData;\n    newData = initializeArrayOfArrays(currDataset.length);\n\n    // alternatives loop\n    for (let altIdx = 0; altIdx < currDataset.length; altIdx++) {\n      const currAltPathsAndSuffixes = currDataset[altIdx];\n      // paths in current alternative loop\n      for (\n        let currPathIdx = 0;\n        currPathIdx < currAltPathsAndSuffixes.length;\n        currPathIdx++\n      ) {\n        const currPathPrefix = currAltPathsAndSuffixes[currPathIdx].partialPath;\n        const suffixDef = currAltPathsAndSuffixes[currPathIdx].suffixDef;\n        const prefixKeys = pathToHashKeys(currPathPrefix);\n        const isUnique = isUniquePrefixHash(altsHashes, prefixKeys, altIdx);\n        // End of the line for this path.\n        if (isUnique || isEmpty(suffixDef) || currPathPrefix.length === k) {\n          const currAltResult = finalResult[altIdx];\n          // TODO: Can we implement a containsPath using Maps/Dictionaries?\n          if (containsPath(currAltResult, currPathPrefix) === false) {\n            currAltResult.push(currPathPrefix);\n            // Update all new  keys for the current path.\n            for (let j = 0; j < prefixKeys.length; j++) {\n              const currKey = prefixKeys[j];\n              altsHashes[altIdx][currKey] = true;\n            }\n          }\n        }\n        // Expand longer paths\n        else {\n          const newPartialPathsAndSuffixes = possiblePathsFrom(\n            suffixDef,\n            pathLength + 1,\n            currPathPrefix,\n          );\n          newData[altIdx] = newData[altIdx].concat(newPartialPathsAndSuffixes);\n\n          // Update keys for new known paths\n          forEach(newPartialPathsAndSuffixes, (item) => {\n            const prefixKeys = pathToHashKeys(item.partialPath);\n            forEach(prefixKeys, (key) => {\n              altsHashes[altIdx][key] = true;\n            });\n          });\n        }\n      }\n    }\n  }\n\n  return finalResult;\n}\n\nexport function getLookaheadPathsForOr(\n  occurrence: number,\n  ruleGrammar: Rule,\n  k: number,\n  orProd?: Alternation,\n): LookaheadSequence[] {\n  const visitor = new InsideDefinitionFinderVisitor(\n    occurrence,\n    PROD_TYPE.ALTERNATION,\n    orProd,\n  );\n  ruleGrammar.accept(visitor);\n  return lookAheadSequenceFromAlternatives(visitor.result, k);\n}\n\nexport function getLookaheadPathsForOptionalProd(\n  occurrence: number,\n  ruleGrammar: Rule,\n  prodType: PROD_TYPE,\n  k: number,\n): LookaheadSequence[] {\n  const insideDefVisitor = new InsideDefinitionFinderVisitor(\n    occurrence,\n    prodType,\n  );\n  ruleGrammar.accept(insideDefVisitor);\n  const insideDef = insideDefVisitor.result;\n\n  const afterDefWalker = new RestDefinitionFinderWalker(\n    ruleGrammar,\n    occurrence,\n    prodType,\n  );\n  const afterDef = afterDefWalker.startWalking();\n\n  const insideFlat = new AlternativeGAST({ definition: insideDef });\n  const afterFlat = new AlternativeGAST({ definition: afterDef });\n\n  return lookAheadSequenceFromAlternatives([insideFlat, afterFlat], k);\n}\n\nexport function containsPath(\n  alternative: Alternative,\n  searchPath: TokenType[],\n): boolean {\n  compareOtherPath: for (let i = 0; i < alternative.length; i++) {\n    const otherPath = alternative[i];\n    if (otherPath.length !== searchPath.length) {\n      continue;\n    }\n    for (let j = 0; j < otherPath.length; j++) {\n      const searchTok = searchPath[j];\n      const otherTok = otherPath[j];\n\n      const matchingTokens =\n        searchTok === otherTok ||\n        otherTok.categoryMatchesMap![searchTok.tokenTypeIdx!] !== undefined;\n      if (matchingTokens === false) {\n        continue compareOtherPath;\n      }\n    }\n    return true;\n  }\n\n  return false;\n}\n\nexport function isStrictPrefixOfPath(\n  prefix: TokenType[],\n  other: TokenType[],\n): boolean {\n  return (\n    prefix.length < other.length &&\n    every(prefix, (tokType, idx) => {\n      const otherTokType = other[idx];\n      return (\n        tokType === otherTokType ||\n        otherTokType.categoryMatchesMap![tokType.tokenTypeIdx!]\n      );\n    })\n  );\n}\n\nexport function areTokenCategoriesNotUsed(\n  lookAheadPaths: LookaheadSequence[],\n): boolean {\n  return every(lookAheadPaths, (singleAltPaths) =>\n    every(singleAltPaths, (singlePath) =>\n      every(singlePath, (token) => isEmpty(token.categoryMatches!)),\n    ),\n  );\n}\n","import {\n  clone,\n  compact,\n  difference,\n  drop,\n  dropRight,\n  filter,\n  first,\n  flatMap,\n  flatten,\n  forEach,\n  groupBy,\n  includes,\n  isEmpty,\n  map,\n  pickBy,\n  reduce,\n  reject,\n  values,\n} from \"lodash-es\";\nimport {\n  IParserAmbiguousAlternativesDefinitionError,\n  IParserDuplicatesDefinitionError,\n  IParserEmptyAlternativeDefinitionError,\n  ParserDefinitionErrorType,\n} from \"../parser/parser.js\";\nimport {\n  Alternation,\n  Alternative as AlternativeGAST,\n  GAstVisitor,\n  getProductionDslName,\n  isOptionalProd,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  Alternative,\n  containsPath,\n  getLookaheadPathsForOptionalProd,\n  getLookaheadPathsForOr,\n  getProdType,\n  isStrictPrefixOfPath,\n} from \"./lookahead.js\";\nimport { nextPossibleTokensAfter } from \"./interpreter.js\";\nimport {\n  ILookaheadStrategy,\n  IProduction,\n  IProductionWithOccurrence,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  IGrammarValidatorErrorMessageProvider,\n  IParserDefinitionError,\n} from \"./types.js\";\nimport { tokenStructuredMatcher } from \"../../scan/tokens.js\";\n\nexport function validateLookahead(options: {\n  lookaheadStrategy: ILookaheadStrategy;\n  rules: Rule[];\n  tokenTypes: TokenType[];\n  grammarName: string;\n}): IParserDefinitionError[] {\n  const lookaheadValidationErrorMessages = options.lookaheadStrategy.validate({\n    rules: options.rules,\n    tokenTypes: options.tokenTypes,\n    grammarName: options.grammarName,\n  });\n  return map(lookaheadValidationErrorMessages, (errorMessage) => ({\n    type: ParserDefinitionErrorType.CUSTOM_LOOKAHEAD_VALIDATION,\n    ...errorMessage,\n  }));\n}\n\nexport function validateGrammar(\n  topLevels: Rule[],\n  tokenTypes: TokenType[],\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n  grammarName: string,\n): IParserDefinitionError[] {\n  const duplicateErrors: IParserDefinitionError[] = flatMap(\n    topLevels,\n    (currTopLevel) =>\n      validateDuplicateProductions(currTopLevel, errMsgProvider),\n  );\n\n  const termsNamespaceConflictErrors = checkTerminalAndNoneTerminalsNameSpace(\n    topLevels,\n    tokenTypes,\n    errMsgProvider,\n  );\n\n  const tooManyAltsErrors = flatMap(topLevels, (curRule) =>\n    validateTooManyAlts(curRule, errMsgProvider),\n  );\n\n  const duplicateRulesError = flatMap(topLevels, (curRule) =>\n    validateRuleDoesNotAlreadyExist(\n      curRule,\n      topLevels,\n      grammarName,\n      errMsgProvider,\n    ),\n  );\n\n  return duplicateErrors.concat(\n    termsNamespaceConflictErrors,\n    tooManyAltsErrors,\n    duplicateRulesError,\n  );\n}\n\nfunction validateDuplicateProductions(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDuplicatesDefinitionError[] {\n  const collectorVisitor = new OccurrenceValidationCollector();\n  topLevelRule.accept(collectorVisitor);\n  const allRuleProductions = collectorVisitor.allProductions;\n\n  const productionGroups = groupBy(\n    allRuleProductions,\n    identifyProductionForDuplicates,\n  );\n\n  const duplicates: any = pickBy(productionGroups, (currGroup) => {\n    return currGroup.length > 1;\n  });\n\n  const errors = map(values(duplicates), (currDuplicates: any) => {\n    const firstProd: any = first(currDuplicates);\n    const msg = errMsgProvider.buildDuplicateFoundError(\n      topLevelRule,\n      currDuplicates,\n    );\n    const dslName = getProductionDslName(firstProd);\n    const defError: IParserDuplicatesDefinitionError = {\n      message: msg,\n      type: ParserDefinitionErrorType.DUPLICATE_PRODUCTIONS,\n      ruleName: topLevelRule.name,\n      dslName: dslName,\n      occurrence: firstProd.idx,\n    };\n\n    const param = getExtraProductionArgument(firstProd);\n    if (param) {\n      defError.parameter = param;\n    }\n\n    return defError;\n  });\n  return errors;\n}\n\nexport function identifyProductionForDuplicates(\n  prod: IProductionWithOccurrence,\n): string {\n  return `${getProductionDslName(prod)}_#_${\n    prod.idx\n  }_#_${getExtraProductionArgument(prod)}`;\n}\n\nfunction getExtraProductionArgument(prod: IProductionWithOccurrence): string {\n  if (prod instanceof Terminal) {\n    return prod.terminalType.name;\n  } else if (prod instanceof NonTerminal) {\n    return prod.nonTerminalName;\n  } else {\n    return \"\";\n  }\n}\n\nexport class OccurrenceValidationCollector extends GAstVisitor {\n  public allProductions: IProductionWithOccurrence[] = [];\n\n  public visitNonTerminal(subrule: NonTerminal): void {\n    this.allProductions.push(subrule);\n  }\n\n  public visitOption(option: Option): void {\n    this.allProductions.push(option);\n  }\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.allProductions.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.allProductions.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.allProductions.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.allProductions.push(many);\n  }\n\n  public visitAlternation(or: Alternation): void {\n    this.allProductions.push(or);\n  }\n\n  public visitTerminal(terminal: Terminal): void {\n    this.allProductions.push(terminal);\n  }\n}\n\nexport function validateRuleDoesNotAlreadyExist(\n  rule: Rule,\n  allRules: Rule[],\n  className: string,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors = [];\n  const occurrences = reduce(\n    allRules,\n    (result, curRule) => {\n      if (curRule.name === rule.name) {\n        return result + 1;\n      }\n      return result;\n    },\n    0,\n  );\n  if (occurrences > 1) {\n    const errMsg = errMsgProvider.buildDuplicateRuleNameError({\n      topLevelRule: rule,\n      grammarName: className,\n    });\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n      ruleName: rule.name,\n    });\n  }\n\n  return errors;\n}\n\n// TODO: is there anyway to get only the rule names of rules inherited from the super grammars?\n// This is not part of the IGrammarErrorProvider because the validation cannot be performed on\n// The grammar structure, only at runtime.\nexport function validateRuleIsOverridden(\n  ruleName: string,\n  definedRulesNames: string[],\n  className: string,\n): IParserDefinitionError[] {\n  const errors = [];\n  let errMsg;\n\n  if (!includes(definedRulesNames, ruleName)) {\n    errMsg =\n      `Invalid rule override, rule: ->${ruleName}<- cannot be overridden in the grammar: ->${className}<-` +\n      `as it is not defined in any of the super grammars `;\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.INVALID_RULE_OVERRIDE,\n      ruleName: ruleName,\n    });\n  }\n\n  return errors;\n}\n\nexport function validateNoLeftRecursion(\n  topRule: Rule,\n  currRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n  path: Rule[] = [],\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n  const nextNonTerminals = getFirstNoneTerminal(currRule.definition);\n  if (isEmpty(nextNonTerminals)) {\n    return [];\n  } else {\n    const ruleName = topRule.name;\n    const foundLeftRecursion = includes(nextNonTerminals, topRule);\n    if (foundLeftRecursion) {\n      errors.push({\n        message: errMsgProvider.buildLeftRecursionError({\n          topLevelRule: topRule,\n          leftRecursionPath: path,\n        }),\n        type: ParserDefinitionErrorType.LEFT_RECURSION,\n        ruleName: ruleName,\n      });\n    }\n\n    // we are only looking for cyclic paths leading back to the specific topRule\n    // other cyclic paths are ignored, we still need this difference to avoid infinite loops...\n    const validNextSteps = difference(nextNonTerminals, path.concat([topRule]));\n    const errorsFromNextSteps = flatMap(validNextSteps, (currRefRule) => {\n      const newPath = clone(path);\n      newPath.push(currRefRule);\n      return validateNoLeftRecursion(\n        topRule,\n        currRefRule,\n        errMsgProvider,\n        newPath,\n      );\n    });\n\n    return errors.concat(errorsFromNextSteps);\n  }\n}\n\nexport function getFirstNoneTerminal(definition: IProduction[]): Rule[] {\n  let result: Rule[] = [];\n  if (isEmpty(definition)) {\n    return result;\n  }\n  const firstProd = first(definition);\n\n  /* istanbul ignore else */\n  if (firstProd instanceof NonTerminal) {\n    result.push(firstProd.referencedRule);\n  } else if (\n    firstProd instanceof AlternativeGAST ||\n    firstProd instanceof Option ||\n    firstProd instanceof RepetitionMandatory ||\n    firstProd instanceof RepetitionMandatoryWithSeparator ||\n    firstProd instanceof RepetitionWithSeparator ||\n    firstProd instanceof Repetition\n  ) {\n    result = result.concat(\n      getFirstNoneTerminal(<IProduction[]>firstProd.definition),\n    );\n  } else if (firstProd instanceof Alternation) {\n    // each sub definition in alternation is a FLAT\n    result = flatten(\n      map(firstProd.definition, (currSubDef) =>\n        getFirstNoneTerminal((<AlternativeGAST>currSubDef).definition),\n      ),\n    );\n  } else if (firstProd instanceof Terminal) {\n    // nothing to see, move along\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n\n  const isFirstOptional = isOptionalProd(firstProd);\n  const hasMore = definition.length > 1;\n  if (isFirstOptional && hasMore) {\n    const rest = drop(definition);\n    return result.concat(getFirstNoneTerminal(rest));\n  } else {\n    return result;\n  }\n}\n\nclass OrCollector extends GAstVisitor {\n  public alternations: Alternation[] = [];\n\n  public visitAlternation(node: Alternation): void {\n    this.alternations.push(node);\n  }\n}\n\nexport function validateEmptyOrAlternative(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserEmptyAlternativeDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n\n  const errors = flatMap<Alternation, IParserEmptyAlternativeDefinitionError>(\n    ors,\n    (currOr) => {\n      const exceptLast = dropRight(currOr.definition);\n      return flatMap(exceptLast, (currAlternative, currAltIdx) => {\n        const possibleFirstInAlt = nextPossibleTokensAfter(\n          [currAlternative],\n          [],\n          tokenStructuredMatcher,\n          1,\n        );\n        if (isEmpty(possibleFirstInAlt)) {\n          return [\n            {\n              message: errMsgProvider.buildEmptyAlternationError({\n                topLevelRule: topLevelRule,\n                alternation: currOr,\n                emptyChoiceIdx: currAltIdx,\n              }),\n              type: ParserDefinitionErrorType.NONE_LAST_EMPTY_ALT,\n              ruleName: topLevelRule.name,\n              occurrence: currOr.idx,\n              alternative: currAltIdx + 1,\n            },\n          ];\n        } else {\n          return [];\n        }\n      });\n    },\n  );\n\n  return errors;\n}\n\nexport function validateAmbiguousAlternationAlternatives(\n  topLevelRule: Rule,\n  globalMaxLookahead: number,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  let ors = orCollector.alternations;\n\n  // New Handling of ignoring ambiguities\n  // - https://github.com/chevrotain/chevrotain/issues/869\n  ors = reject(ors, (currOr) => currOr.ignoreAmbiguities === true);\n\n  const errors = flatMap(ors, (currOr: Alternation) => {\n    const currOccurrence = currOr.idx;\n    const actualMaxLookahead = currOr.maxLookahead || globalMaxLookahead;\n    const alternatives = getLookaheadPathsForOr(\n      currOccurrence,\n      topLevelRule,\n      actualMaxLookahead,\n      currOr,\n    );\n    const altsAmbiguityErrors = checkAlternativesAmbiguities(\n      alternatives,\n      currOr,\n      topLevelRule,\n      errMsgProvider,\n    );\n    const altsPrefixAmbiguityErrors = checkPrefixAlternativesAmbiguities(\n      alternatives,\n      currOr,\n      topLevelRule,\n      errMsgProvider,\n    );\n\n    return altsAmbiguityErrors.concat(altsPrefixAmbiguityErrors);\n  });\n\n  return errors;\n}\n\nexport class RepetitionCollector extends GAstVisitor {\n  public allProductions: (IProductionWithOccurrence & {\n    maxLookahead?: number;\n  })[] = [];\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.allProductions.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.allProductions.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.allProductions.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.allProductions.push(many);\n  }\n}\n\nexport function validateTooManyAlts(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n\n  const errors = flatMap(ors, (currOr) => {\n    if (currOr.definition.length > 255) {\n      return [\n        {\n          message: errMsgProvider.buildTooManyAlternativesError({\n            topLevelRule: topLevelRule,\n            alternation: currOr,\n          }),\n          type: ParserDefinitionErrorType.TOO_MANY_ALTS,\n          ruleName: topLevelRule.name,\n          occurrence: currOr.idx,\n        },\n      ];\n    } else {\n      return [];\n    }\n  });\n\n  return errors;\n}\n\nexport function validateSomeNonEmptyLookaheadPath(\n  topLevelRules: Rule[],\n  maxLookahead: number,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n  forEach(topLevelRules, (currTopRule) => {\n    const collectorVisitor = new RepetitionCollector();\n    currTopRule.accept(collectorVisitor);\n    const allRuleProductions = collectorVisitor.allProductions;\n    forEach(allRuleProductions, (currProd) => {\n      const prodType = getProdType(currProd);\n      const actualMaxLookahead = currProd.maxLookahead || maxLookahead;\n      const currOccurrence = currProd.idx;\n      const paths = getLookaheadPathsForOptionalProd(\n        currOccurrence,\n        currTopRule,\n        prodType,\n        actualMaxLookahead,\n      );\n      const pathsInsideProduction = paths[0];\n      if (isEmpty(flatten(pathsInsideProduction))) {\n        const errMsg = errMsgProvider.buildEmptyRepetitionError({\n          topLevelRule: currTopRule,\n          repetition: currProd,\n        });\n        errors.push({\n          message: errMsg,\n          type: ParserDefinitionErrorType.NO_NON_EMPTY_LOOKAHEAD,\n          ruleName: currTopRule.name,\n        });\n      }\n    });\n  });\n\n  return errors;\n}\n\nexport interface IAmbiguityDescriptor {\n  alts: number[];\n  path: TokenType[];\n}\n\nfunction checkAlternativesAmbiguities(\n  alternatives: Alternative[],\n  alternation: Alternation,\n  rule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  const foundAmbiguousPaths: Alternative = [];\n  const identicalAmbiguities = reduce(\n    alternatives,\n    (result, currAlt, currAltIdx) => {\n      // ignore (skip) ambiguities with this alternative\n      if (alternation.definition[currAltIdx].ignoreAmbiguities === true) {\n        return result;\n      }\n\n      forEach(currAlt, (currPath) => {\n        const altsCurrPathAppearsIn = [currAltIdx];\n        forEach(alternatives, (currOtherAlt, currOtherAltIdx) => {\n          if (\n            currAltIdx !== currOtherAltIdx &&\n            containsPath(currOtherAlt, currPath) &&\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[currOtherAltIdx].ignoreAmbiguities !== true\n          ) {\n            altsCurrPathAppearsIn.push(currOtherAltIdx);\n          }\n        });\n\n        if (\n          altsCurrPathAppearsIn.length > 1 &&\n          !containsPath(foundAmbiguousPaths, currPath)\n        ) {\n          foundAmbiguousPaths.push(currPath);\n          result.push({\n            alts: altsCurrPathAppearsIn,\n            path: currPath,\n          });\n        }\n      });\n      return result;\n    },\n    [] as { alts: number[]; path: TokenType[] }[],\n  );\n\n  const currErrors = map(identicalAmbiguities, (currAmbDescriptor) => {\n    const ambgIndices = map(\n      currAmbDescriptor.alts,\n      (currAltIdx) => currAltIdx + 1,\n    );\n\n    const currMessage = errMsgProvider.buildAlternationAmbiguityError({\n      topLevelRule: rule,\n      alternation: alternation,\n      ambiguityIndices: ambgIndices,\n      prefixPath: currAmbDescriptor.path,\n    });\n\n    return {\n      message: currMessage,\n      type: ParserDefinitionErrorType.AMBIGUOUS_ALTS,\n      ruleName: rule.name,\n      occurrence: alternation.idx,\n      alternatives: currAmbDescriptor.alts,\n    };\n  });\n\n  return currErrors;\n}\n\nexport function checkPrefixAlternativesAmbiguities(\n  alternatives: Alternative[],\n  alternation: Alternation,\n  rule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  // flatten\n  const pathsAndIndices = reduce(\n    alternatives,\n    (result, currAlt, idx) => {\n      const currPathsAndIdx = map(currAlt, (currPath) => {\n        return { idx: idx, path: currPath };\n      });\n      return result.concat(currPathsAndIdx);\n    },\n    [] as { idx: number; path: TokenType[] }[],\n  );\n\n  const errors = compact(\n    flatMap(pathsAndIndices, (currPathAndIdx) => {\n      const alternativeGast = alternation.definition[currPathAndIdx.idx];\n      // ignore (skip) ambiguities with this alternative\n      if (alternativeGast.ignoreAmbiguities === true) {\n        return [];\n      }\n      const targetIdx = currPathAndIdx.idx;\n      const targetPath = currPathAndIdx.path;\n\n      const prefixAmbiguitiesPathsAndIndices = filter(\n        pathsAndIndices,\n        (searchPathAndIdx) => {\n          // prefix ambiguity can only be created from lower idx (higher priority) path\n          return (\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[searchPathAndIdx.idx].ignoreAmbiguities !==\n              true &&\n            searchPathAndIdx.idx < targetIdx &&\n            // checking for strict prefix because identical lookaheads\n            // will be be detected using a different validation.\n            isStrictPrefixOfPath(searchPathAndIdx.path, targetPath)\n          );\n        },\n      );\n\n      const currPathPrefixErrors = map(\n        prefixAmbiguitiesPathsAndIndices,\n        (currAmbPathAndIdx): IParserAmbiguousAlternativesDefinitionError => {\n          const ambgIndices = [currAmbPathAndIdx.idx + 1, targetIdx + 1];\n          const occurrence = alternation.idx === 0 ? \"\" : alternation.idx;\n\n          const message = errMsgProvider.buildAlternationPrefixAmbiguityError({\n            topLevelRule: rule,\n            alternation: alternation,\n            ambiguityIndices: ambgIndices,\n            prefixPath: currAmbPathAndIdx.path,\n          });\n          return {\n            message: message,\n            type: ParserDefinitionErrorType.AMBIGUOUS_PREFIX_ALTS,\n            ruleName: rule.name,\n            occurrence: occurrence,\n            alternatives: ambgIndices,\n          };\n        },\n      );\n\n      return currPathPrefixErrors;\n    }),\n  );\n\n  return errors;\n}\n\nfunction checkTerminalAndNoneTerminalsNameSpace(\n  topLevels: Rule[],\n  tokenTypes: TokenType[],\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n\n  const tokenNames = map(tokenTypes, (currToken) => currToken.name);\n\n  forEach(topLevels, (currRule) => {\n    const currRuleName = currRule.name;\n    if (includes(tokenNames, currRuleName)) {\n      const errMsg = errMsgProvider.buildNamespaceConflictError(currRule);\n\n      errors.push({\n        message: errMsg,\n        type: ParserDefinitionErrorType.CONFLICT_TOKENS_RULES_NAMESPACE,\n        ruleName: currRuleName,\n      });\n    }\n  });\n\n  return errors;\n}\n","import { Rule } from \"@chevrotain/gast\";\nimport { defaults, forEach } from \"lodash-es\";\nimport { resolveGrammar as orgResolveGrammar } from \"../resolver.js\";\nimport { validateGrammar as orgValidateGrammar } from \"../checks.js\";\nimport {\n  defaultGrammarResolverErrorProvider,\n  defaultGrammarValidatorErrorProvider,\n} from \"../../errors_public.js\";\nimport { TokenType } from \"@chevrotain/types\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IGrammarValidatorErrorMessageProvider,\n  IParserDefinitionError,\n} from \"../types.js\";\n\ntype ResolveGrammarOpts = {\n  rules: Rule[];\n  errMsgProvider?: IGrammarResolverErrorMessageProvider;\n};\nexport function resolveGrammar(\n  options: ResolveGrammarOpts,\n): IParserDefinitionError[] {\n  const actualOptions: Required<ResolveGrammarOpts> = defaults(options, {\n    errMsgProvider: defaultGrammarResolverErrorProvider,\n  });\n\n  const topRulesTable: { [ruleName: string]: Rule } = {};\n  forEach(options.rules, (rule) => {\n    topRulesTable[rule.name] = rule;\n  });\n  return orgResolveGrammar(topRulesTable, actualOptions.errMsgProvider);\n}\n\nexport function validateGrammar(options: {\n  rules: Rule[];\n  tokenTypes: TokenType[];\n  grammarName: string;\n  errMsgProvider: IGrammarValidatorErrorMessageProvider;\n}): IParserDefinitionError[] {\n  options = defaults(options, {\n    errMsgProvider: defaultGrammarValidatorErrorProvider,\n  });\n\n  return orgValidateGrammar(\n    options.rules,\n    options.tokenTypes,\n    options.errMsgProvider,\n    options.grammarName,\n  );\n}\n","import { includes } from \"lodash-es\";\nimport {\n  IRecognitionException,\n  IRecognizerContext,\n  IToken,\n} from \"@chevrotain/types\";\n\nconst MISMATCHED_TOKEN_EXCEPTION = \"MismatchedTokenException\";\nconst NO_VIABLE_ALT_EXCEPTION = \"NoViableAltException\";\nconst EARLY_EXIT_EXCEPTION = \"EarlyExitException\";\nconst NOT_ALL_INPUT_PARSED_EXCEPTION = \"NotAllInputParsedException\";\n\nconst RECOGNITION_EXCEPTION_NAMES = [\n  MISMATCHED_TOKEN_EXCEPTION,\n  NO_VIABLE_ALT_EXCEPTION,\n  EARLY_EXIT_EXCEPTION,\n  NOT_ALL_INPUT_PARSED_EXCEPTION,\n];\n\nObject.freeze(RECOGNITION_EXCEPTION_NAMES);\n\n// hacks to bypass no support for custom Errors in javascript/typescript\nexport function isRecognitionException(error: Error) {\n  // can't do instanceof on hacked custom js exceptions\n  return includes(RECOGNITION_EXCEPTION_NAMES, error.name);\n}\n\nabstract class RecognitionException\n  extends Error\n  implements IRecognitionException\n{\n  context: IRecognizerContext;\n  resyncedTokens: IToken[] = [];\n\n  protected constructor(\n    message: string,\n    public token: IToken,\n  ) {\n    super(message);\n\n    // fix prototype chain when typescript target is ES5\n    Object.setPrototypeOf(this, new.target.prototype);\n\n    /* istanbul ignore next - V8 workaround to remove constructor from stacktrace when typescript target is ES5 */\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n}\n\nexport class MismatchedTokenException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = MISMATCHED_TOKEN_EXCEPTION;\n  }\n}\n\nexport class NoViableAltException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = NO_VIABLE_ALT_EXCEPTION;\n  }\n}\n\nexport class NotAllInputParsedException extends RecognitionException {\n  constructor(message: string, token: IToken) {\n    super(message, token);\n    this.name = NOT_ALL_INPUT_PARSED_EXCEPTION;\n  }\n}\n\nexport class EarlyExitException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = EARLY_EXIT_EXCEPTION;\n  }\n}\n","import {\n  createTokenInstance,\n  EOF,\n  tokenMatcher,\n} from \"../../../scan/tokens_public.js\";\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  IFirstAfterRepetition,\n} from \"../../grammar/interpreter.js\";\nimport {\n  clone,\n  dropRight,\n  find,\n  flatten,\n  has,\n  includes,\n  isEmpty,\n  map,\n} from \"lodash-es\";\nimport {\n  IParserConfig,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { MismatchedTokenException } from \"../../exceptions_public.js\";\nimport { IN } from \"../../constants.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\nexport const EOF_FOLLOW_KEY: any = {};\n\nexport interface IFollowKey {\n  ruleName: string;\n  idxInCallingRule: number;\n  inRule: string;\n}\n\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\n\nexport class InRuleRecoveryException extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = IN_RULE_RECOVERY_EXCEPTION;\n  }\n}\n\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n  recoveryEnabled: boolean;\n  firstAfterRepMap: Record<string, IFirstAfterRepetition>;\n  resyncFollows: Record<string, TokenType[]>;\n\n  initRecoverable(config: IParserConfig) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n\n    this.recoveryEnabled = has(config, \"recoveryEnabled\")\n      ? (config.recoveryEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.recoveryEnabled;\n\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  }\n\n  public getTokenToInsert(tokType: TokenType): IToken {\n    const tokToInsert = createTokenInstance(\n      tokType,\n      \"\",\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n    );\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  }\n\n  public canTokenTypeBeInsertedInRecovery(tokType: TokenType): boolean {\n    return true;\n  }\n\n  public canTokenTypeBeDeletedInRecovery(tokType: TokenType): boolean {\n    return true;\n  }\n\n  tryInRepetitionRecovery(\n    this: MixedInParser,\n    grammarRule: Function,\n    grammarRuleArgs: any[],\n    lookAheadFunc: () => boolean,\n    expectedTokType: TokenType,\n  ): void {\n    // TODO: can the resyncTokenType be cached?\n    const reSyncTokType = this.findReSyncTokenType();\n    const savedLexerState = this.exportLexerState();\n    const resyncedTokens: IToken[] = [];\n    let passedResyncPoint = false;\n\n    const nextTokenWithoutResync = this.LA(1);\n    let currToken = this.LA(1);\n\n    const generateErrorMessage = () => {\n      const previousToken = this.LA(0);\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName(),\n      });\n      const error = new MismatchedTokenException(\n        msg,\n        nextTokenWithoutResync,\n        this.LA(0),\n      );\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = dropRight(resyncedTokens);\n      this.SAVE_ERROR(error);\n    };\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return; // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage();\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs);\n        return; // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    }\n\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState);\n  }\n\n  shouldInRepetitionRecoveryBeTried(\n    this: MixedInParser,\n    expectTokAfterLastMatch: TokenType,\n    nextTokIdx: number,\n    notStuck: boolean | undefined,\n  ): boolean {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false;\n    }\n\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    }\n\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false;\n    }\n\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (\n      this.canPerformInRuleRecovery(\n        expectTokAfterLastMatch,\n        this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx),\n      )\n    ) {\n      return false;\n    }\n\n    return true;\n  }\n\n  // Error Recovery functionality\n  getFollowsForInRuleRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number,\n  ): TokenType[] {\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    const follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  }\n\n  tryInRuleRecovery(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[],\n  ): IToken {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      const tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      const nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  }\n\n  canPerformInRuleRecovery(\n    this: MixedInParser,\n    expectedToken: TokenType,\n    follows: TokenType[],\n  ): boolean {\n    return (\n      this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n      this.canRecoverWithSingleTokenDeletion(expectedToken)\n    );\n  }\n\n  canRecoverWithSingleTokenInsertion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[],\n  ): boolean {\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    }\n\n    // must know the possible following tokens to perform single token insertion\n    if (isEmpty(follows)) {\n      return false;\n    }\n\n    const mismatchedTok = this.LA(1);\n    const isMisMatchedTokInFollows =\n      find(follows, (possibleFollowsTokType: TokenType) => {\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n      }) !== undefined;\n\n    return isMisMatchedTokInFollows;\n  }\n\n  canRecoverWithSingleTokenDeletion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n  ): boolean {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false;\n    }\n\n    const isNextTokenWhatIsExpected = this.tokenMatcher(\n      this.LA(2),\n      expectedTokType,\n    );\n    return isNextTokenWhatIsExpected;\n  }\n\n  isInCurrentRuleReSyncSet(\n    this: MixedInParser,\n    tokenTypeIdx: TokenType,\n  ): boolean {\n    const followKey = this.getCurrFollowKey();\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return includes(currentRuleReSyncSet, tokenTypeIdx);\n  }\n\n  findReSyncTokenType(this: MixedInParser): TokenType {\n    const allPossibleReSyncTokTypes = this.flattenFollowSet();\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    let nextToken = this.LA(1);\n    let k = 2;\n    while (true) {\n      const foundMatch = find(allPossibleReSyncTokTypes, (resyncTokType) => {\n        const canMatch = tokenMatcher(nextToken, resyncTokType);\n        return canMatch;\n      });\n      if (foundMatch !== undefined) {\n        return foundMatch;\n      }\n      nextToken = this.LA(k);\n      k++;\n    }\n  }\n\n  getCurrFollowKey(this: MixedInParser): IFollowKey {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return EOF_FOLLOW_KEY;\n    }\n    const currRuleShortName = this.getLastExplicitRuleShortName();\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName();\n\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName),\n    };\n  }\n\n  buildFullFollowKeyStack(this: MixedInParser): IFollowKey[] {\n    const explicitRuleStack = this.RULE_STACK;\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n\n    return map(explicitRuleStack, (ruleName, idx) => {\n      if (idx === 0) {\n        return EOF_FOLLOW_KEY;\n      }\n      return {\n        ruleName: this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1]),\n      };\n    });\n  }\n\n  flattenFollowSet(this: MixedInParser): TokenType[] {\n    const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n      return this.getFollowSetFromFollowKey(currKey);\n    });\n    return <any>flatten(followStack);\n  }\n\n  getFollowSetFromFollowKey(\n    this: MixedInParser,\n    followKey: IFollowKey,\n  ): TokenType[] {\n    if (followKey === EOF_FOLLOW_KEY) {\n      return [EOF];\n    }\n\n    const followName =\n      followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule;\n\n    return this.resyncFollows[followName];\n  }\n\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  addToResyncTokens(\n    this: MixedInParser,\n    token: IToken,\n    resyncTokens: IToken[],\n  ): IToken[] {\n    if (!this.tokenMatcher(token, EOF)) {\n      resyncTokens.push(token);\n    }\n    return resyncTokens;\n  }\n\n  reSyncTo(this: MixedInParser, tokType: TokenType): IToken[] {\n    const resyncedTokens: IToken[] = [];\n    let nextTok = this.LA(1);\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    }\n    // the last token is not part of the error.\n    return dropRight(resyncedTokens);\n  }\n\n  attemptInRepetitionRecovery(\n    this: MixedInParser,\n    prodFunc: Function,\n    args: any[],\n    lookaheadFunc: () => boolean,\n    dslMethodIdx: number,\n    prodOccurrence: number,\n    nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n    notStuck?: boolean,\n  ): void {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  }\n\n  getCurrentGrammarPath(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number,\n  ): ITokenGrammarPath {\n    const pathRuleStack: string[] = this.getHumanReadableRuleStack();\n    const pathOccurrenceStack: number[] = clone(this.RULE_OCCURRENCE_STACK);\n    const grammarPath: any = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule,\n    };\n\n    return grammarPath;\n  }\n  getHumanReadableRuleStack(this: MixedInParser): string[] {\n    return map(this.RULE_STACK, (currShortName) =>\n      this.shortRuleNameToFullName(currShortName),\n    );\n  }\n}\n\nexport function attemptInRepetitionRecovery(\n  this: MixedInParser,\n  prodFunc: Function,\n  args: any[],\n  lookaheadFunc: () => boolean,\n  dslMethodIdx: number,\n  prodOccurrence: number,\n  nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  notStuck?: boolean,\n): void {\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  let firstAfterRepInfo = this.firstAfterRepMap[key];\n  if (firstAfterRepInfo === undefined) {\n    const currRuleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[currRuleName];\n    const walker: AbstractNextTerminalAfterProductionWalker =\n      new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n\n  let expectTokAfterLastMatch = firstAfterRepInfo.token;\n  let nextTokIdx = firstAfterRepInfo.occurrence;\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule;\n\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (\n    this.RULE_STACK.length === 1 &&\n    isEndOfRule &&\n    expectTokAfterLastMatch === undefined\n  ) {\n    expectTokAfterLastMatch = EOF;\n    nextTokIdx = 1;\n  }\n\n  // We don't have anything to re-sync to...\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n    return;\n  }\n\n  if (\n    this.shouldInRepetitionRecoveryBeTried(\n      expectTokAfterLastMatch,\n      nextTokIdx,\n      notStuck,\n    )\n  ) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(\n      prodFunc,\n      args,\n      lookaheadFunc,\n      expectTokAfterLastMatch,\n    );\n  }\n}\n","// Lookahead keys are 32Bit integers in the form\n// TTTTTTTT-ZZZZZZZZZZZZ-YYYY-XXXXXXXX\n// XXXX -> Occurrence Index bitmap.\n// YYYY -> DSL Method Type bitmap.\n// ZZZZZZZZZZZZZZZ -> Rule short Index bitmap.\n// TTTTTTTTT -> alternation alternative index bitmap\n\nexport const BITS_FOR_METHOD_TYPE = 4;\nexport const BITS_FOR_OCCURRENCE_IDX = 8;\nexport const BITS_FOR_RULE_IDX = 12;\n// TODO: validation, this means that there may at most 2^8 --> 256 alternatives for an alternation.\nexport const BITS_FOR_ALT_IDX = 8;\n\n// short string used as part of mapping keys.\n// being short improves the performance when composing KEYS for maps out of these\n// The 5 - 8 bits (16 possible values, are reserved for the DSL method indices)\nexport const OR_IDX = 1 << BITS_FOR_OCCURRENCE_IDX;\nexport const OPTION_IDX = 2 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_IDX = 3 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_IDX = 4 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_SEP_IDX = 5 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_SEP_IDX = 6 << BITS_FOR_OCCURRENCE_IDX;\n\n// this actually returns a number, but it is always used as a string (object prop key)\nexport function getKeyForAutomaticLookahead(\n  ruleIdx: number,\n  dslMethodIdx: number,\n  occurrence: number,\n): number {\n  return occurrence | dslMethodIdx | ruleIdx;\n}\n\nconst BITS_START_FOR_ALT_IDX = 32 - BITS_FOR_ALT_IDX;\n","import {\n  ILookaheadStrategy,\n  ILookaheadValidationError,\n  IOrAlt,\n  OptionalProductionType,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { flatMap, isEmpty } from \"lodash-es\";\nimport { defaultGrammarValidatorErrorProvider } from \"../errors_public.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser/parser.js\";\nimport {\n  validateAmbiguousAlternationAlternatives,\n  validateEmptyOrAlternative,\n  validateNoLeftRecursion,\n  validateSomeNonEmptyLookaheadPath,\n} from \"./checks.js\";\nimport {\n  buildAlternativesLookAheadFunc,\n  buildLookaheadFuncForOptionalProd,\n  buildLookaheadFuncForOr,\n  buildSingleAlternativeLookaheadFunction,\n  getProdType,\n} from \"./lookahead.js\";\nimport { IParserDefinitionError } from \"./types.js\";\n\nexport class LLkLookaheadStrategy implements ILookaheadStrategy {\n  readonly maxLookahead: number;\n\n  constructor(options?: { maxLookahead?: number }) {\n    this.maxLookahead =\n      options?.maxLookahead ?? DEFAULT_PARSER_CONFIG.maxLookahead;\n  }\n\n  validate(options: {\n    rules: Rule[];\n    tokenTypes: TokenType[];\n    grammarName: string;\n  }): ILookaheadValidationError[] {\n    const leftRecursionErrors = this.validateNoLeftRecursion(options.rules);\n\n    if (isEmpty(leftRecursionErrors)) {\n      const emptyAltErrors = this.validateEmptyOrAlternatives(options.rules);\n      const ambiguousAltsErrors = this.validateAmbiguousAlternationAlternatives(\n        options.rules,\n        this.maxLookahead,\n      );\n      const emptyRepetitionErrors = this.validateSomeNonEmptyLookaheadPath(\n        options.rules,\n        this.maxLookahead,\n      );\n      const allErrors = [\n        ...leftRecursionErrors,\n        ...emptyAltErrors,\n        ...ambiguousAltsErrors,\n        ...emptyRepetitionErrors,\n      ];\n      return allErrors;\n    }\n    return leftRecursionErrors;\n  }\n\n  validateNoLeftRecursion(rules: Rule[]): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateNoLeftRecursion(\n        currTopRule,\n        currTopRule,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateEmptyOrAlternatives(rules: Rule[]): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateEmptyOrAlternative(\n        currTopRule,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateAmbiguousAlternationAlternatives(\n    rules: Rule[],\n    maxLookahead: number,\n  ): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateAmbiguousAlternationAlternatives(\n        currTopRule,\n        maxLookahead,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateSomeNonEmptyLookaheadPath(\n    rules: Rule[],\n    maxLookahead: number,\n  ): IParserDefinitionError[] {\n    return validateSomeNonEmptyLookaheadPath(\n      rules,\n      maxLookahead,\n      defaultGrammarValidatorErrorProvider,\n    );\n  }\n\n  buildLookaheadForAlternation(options: {\n    prodOccurrence: number;\n    rule: Rule;\n    maxLookahead: number;\n    hasPredicates: boolean;\n    dynamicTokensEnabled: boolean;\n  }): (orAlts?: IOrAlt<any>[] | undefined) => number | undefined {\n    return buildLookaheadFuncForOr(\n      options.prodOccurrence,\n      options.rule,\n      options.maxLookahead,\n      options.hasPredicates,\n      options.dynamicTokensEnabled,\n      buildAlternativesLookAheadFunc,\n    );\n  }\n\n  buildLookaheadForOptional(options: {\n    prodOccurrence: number;\n    prodType: OptionalProductionType;\n    rule: Rule;\n    maxLookahead: number;\n    dynamicTokensEnabled: boolean;\n  }): () => boolean {\n    return buildLookaheadFuncForOptionalProd(\n      options.prodOccurrence,\n      options.rule,\n      options.maxLookahead,\n      options.dynamicTokensEnabled,\n      getProdType(options.prodType),\n      buildSingleAlternativeLookaheadFunction,\n    );\n  }\n}\n","import { forEach, has } from \"lodash-es\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\nimport {\n  ILookaheadStrategy,\n  IParserConfig,\n  OptionalProductionType,\n} from \"@chevrotain/types\";\nimport {\n  AT_LEAST_ONE_IDX,\n  AT_LEAST_ONE_SEP_IDX,\n  getKeyForAutomaticLookahead,\n  MANY_IDX,\n  MANY_SEP_IDX,\n  OPTION_IDX,\n  OR_IDX,\n} from \"../../grammar/keys.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  Alternation,\n  GAstVisitor,\n  getProductionDslName,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n} from \"@chevrotain/gast\";\nimport { LLkLookaheadStrategy } from \"../../grammar/llk_lookahead.js\";\n\n/**\n * Trait responsible for the lookahead related utilities and optimizations.\n */\nexport class LooksAhead {\n  maxLookahead: number;\n  lookAheadFuncsCache: any;\n  dynamicTokensEnabled: boolean;\n  lookaheadStrategy: ILookaheadStrategy;\n\n  initLooksAhead(config: IParserConfig) {\n    this.dynamicTokensEnabled = has(config, \"dynamicTokensEnabled\")\n      ? (config.dynamicTokensEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.dynamicTokensEnabled;\n\n    this.maxLookahead = has(config, \"maxLookahead\")\n      ? (config.maxLookahead as number) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.maxLookahead;\n\n    this.lookaheadStrategy = has(config, \"lookaheadStrategy\")\n      ? (config.lookaheadStrategy as ILookaheadStrategy) // assumes end user provides the correct config value/type\n      : new LLkLookaheadStrategy({ maxLookahead: this.maxLookahead });\n\n    this.lookAheadFuncsCache = new Map();\n  }\n\n  preComputeLookaheadFunctions(this: MixedInParser, rules: Rule[]): void {\n    forEach(rules, (currRule) => {\n      this.TRACE_INIT(`${currRule.name} Rule Lookahead`, () => {\n        const {\n          alternation,\n          repetition,\n          option,\n          repetitionMandatory,\n          repetitionMandatoryWithSeparator,\n          repetitionWithSeparator,\n        } = collectMethods(currRule);\n\n        forEach(alternation, (currProd) => {\n          const prodIdx = currProd.idx === 0 ? \"\" : currProd.idx;\n          this.TRACE_INIT(`${getProductionDslName(currProd)}${prodIdx}`, () => {\n            const laFunc = this.lookaheadStrategy.buildLookaheadForAlternation({\n              prodOccurrence: currProd.idx,\n              rule: currRule,\n              maxLookahead: currProd.maxLookahead || this.maxLookahead,\n              hasPredicates: currProd.hasPredicates,\n              dynamicTokensEnabled: this.dynamicTokensEnabled,\n            });\n\n            const key = getKeyForAutomaticLookahead(\n              this.fullRuleNameToShort[currRule.name],\n              OR_IDX,\n              currProd.idx,\n            );\n            this.setLaFuncCache(key, laFunc);\n          });\n        });\n\n        forEach(repetition, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            MANY_IDX,\n            \"Repetition\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(option, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            OPTION_IDX,\n            \"Option\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionMandatory, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            AT_LEAST_ONE_IDX,\n            \"RepetitionMandatory\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionMandatoryWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            AT_LEAST_ONE_SEP_IDX,\n            \"RepetitionMandatoryWithSeparator\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            MANY_SEP_IDX,\n            \"RepetitionWithSeparator\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n      });\n    });\n  }\n\n  computeLookaheadFunc(\n    this: MixedInParser,\n    rule: Rule,\n    prodOccurrence: number,\n    prodKey: number,\n    prodType: OptionalProductionType,\n    prodMaxLookahead: number | undefined,\n    dslMethodName: string,\n  ): void {\n    this.TRACE_INIT(\n      `${dslMethodName}${prodOccurrence === 0 ? \"\" : prodOccurrence}`,\n      () => {\n        const laFunc = this.lookaheadStrategy.buildLookaheadForOptional({\n          prodOccurrence,\n          rule,\n          maxLookahead: prodMaxLookahead || this.maxLookahead,\n          dynamicTokensEnabled: this.dynamicTokensEnabled,\n          prodType,\n        });\n        const key = getKeyForAutomaticLookahead(\n          this.fullRuleNameToShort[rule.name],\n          prodKey,\n          prodOccurrence,\n        );\n        this.setLaFuncCache(key, laFunc);\n      },\n    );\n  }\n\n  // this actually returns a number, but it is always used as a string (object prop key)\n  getKeyForAutomaticLookahead(\n    this: MixedInParser,\n    dslMethodIdx: number,\n    occurrence: number,\n  ): number {\n    const currRuleShortName: any = this.getLastExplicitRuleShortName();\n    return getKeyForAutomaticLookahead(\n      currRuleShortName,\n      dslMethodIdx,\n      occurrence,\n    );\n  }\n\n  getLaFuncFromCache(this: MixedInParser, key: number): Function {\n    return this.lookAheadFuncsCache.get(key);\n  }\n\n  /* istanbul ignore next */\n  setLaFuncCache(this: MixedInParser, key: number, value: Function): void {\n    this.lookAheadFuncsCache.set(key, value);\n  }\n}\n\nclass DslMethodsCollectorVisitor extends GAstVisitor {\n  public dslMethods: {\n    option: Option[];\n    alternation: Alternation[];\n    repetition: Repetition[];\n    repetitionWithSeparator: RepetitionWithSeparator[];\n    repetitionMandatory: RepetitionMandatory[];\n    repetitionMandatoryWithSeparator: RepetitionMandatoryWithSeparator[];\n  } = {\n    option: [],\n    alternation: [],\n    repetition: [],\n    repetitionWithSeparator: [],\n    repetitionMandatory: [],\n    repetitionMandatoryWithSeparator: [],\n  };\n\n  reset() {\n    this.dslMethods = {\n      option: [],\n      alternation: [],\n      repetition: [],\n      repetitionWithSeparator: [],\n      repetitionMandatory: [],\n      repetitionMandatoryWithSeparator: [],\n    };\n  }\n\n  public visitOption(option: Option): void {\n    this.dslMethods.option.push(option);\n  }\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.dslMethods.repetitionWithSeparator.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.dslMethods.repetitionMandatory.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.dslMethods.repetitionMandatoryWithSeparator.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.dslMethods.repetition.push(many);\n  }\n\n  public visitAlternation(or: Alternation): void {\n    this.dslMethods.alternation.push(or);\n  }\n}\n\nconst collectorVisitor = new DslMethodsCollectorVisitor();\nexport function collectMethods(rule: Rule): {\n  option: Option[];\n  alternation: Alternation[];\n  repetition: Repetition[];\n  repetitionWithSeparator: RepetitionWithSeparator[];\n  repetitionMandatory: RepetitionMandatory[];\n  repetitionMandatoryWithSeparator: RepetitionMandatoryWithSeparator[];\n} {\n  collectorVisitor.reset();\n  rule.accept(collectorVisitor);\n  const dslMethods = collectorVisitor.dslMethods;\n  // avoid uncleaned references\n  collectorVisitor.reset();\n  return <any>dslMethods;\n}\n","import { CstNode, CstNodeLocation, IToken } from \"@chevrotain/types\";\n\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationOnlyOffset(\n  currNodeLocation: CstNodeLocation,\n  newLocationInfo: Required<Pick<IToken, \"startOffset\" | \"endOffset\">>,\n): void {\n  // First (valid) update for this cst node\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    // assumption1: Token location information is either NaN or a valid number\n    // assumption2: Token location information is fully valid if it exist\n    // (both start/end offsets exist and are numbers).\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  }\n  // Once the startOffset has been updated with a valid number it should never receive\n  // any farther updates as the Token vector is sorted.\n  // We still have to check this this condition for every new possible location info\n  // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n  else if (currNodeLocation.endOffset! < newLocationInfo.endOffset === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  }\n}\n\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationFull(\n  currNodeLocation: CstNodeLocation,\n  newLocationInfo: CstNodeLocation,\n): void {\n  // First (valid) update for this cst node\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    // assumption1: Token location information is either NaN or a valid number\n    // assumption2: Token location information is fully valid if it exist\n    // (all start/end props exist and are numbers).\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.startColumn = newLocationInfo.startColumn;\n    currNodeLocation.startLine = newLocationInfo.startLine;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  }\n  // Once the start props has been updated with a valid number it should never receive\n  // any farther updates as the Token vector is sorted.\n  // We still have to check this this condition for every new possible location info\n  // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n  else if (currNodeLocation.endOffset! < newLocationInfo.endOffset! === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  }\n}\n\nexport function addTerminalToCst(\n  node: CstNode,\n  token: IToken,\n  tokenTypeName: string,\n): void {\n  if (node.children[tokenTypeName] === undefined) {\n    node.children[tokenTypeName] = [token];\n  } else {\n    node.children[tokenTypeName].push(token);\n  }\n}\n\nexport function addNoneTerminalToCst(\n  node: CstNode,\n  ruleName: string,\n  ruleResult: any,\n): void {\n  if (node.children[ruleName] === undefined) {\n    node.children[ruleName] = [ruleResult];\n  } else {\n    node.children[ruleName].push(ruleResult);\n  }\n}\n","const NAME = \"name\";\n\nexport function defineNameProp(obj: {}, nameValue: string): void {\n  Object.defineProperty(obj, NAME, {\n    enumerable: false,\n    configurable: true,\n    writable: false,\n    value: nameValue,\n  });\n}\n","import {\n  compact,\n  filter,\n  forEach,\n  isArray,\n  isEmpty,\n  isFunction,\n  isUndefined,\n  keys,\n  map,\n} from \"lodash-es\";\nimport { defineNameProp } from \"../../lang/lang_extensions.js\";\nimport { CstNode, ICstVisitor } from \"@chevrotain/types\";\n\nexport function defaultVisit<IN>(ctx: any, param: IN): void {\n  const childrenNames = keys(ctx);\n  const childrenNamesLength = childrenNames.length;\n  for (let i = 0; i < childrenNamesLength; i++) {\n    const currChildName = childrenNames[i];\n    const currChildArray = ctx[currChildName];\n    const currChildArrayLength = currChildArray.length;\n    for (let j = 0; j < currChildArrayLength; j++) {\n      const currChild: any = currChildArray[j];\n      // distinction between Tokens Children and CstNode children\n      if (currChild.tokenTypeIdx === undefined) {\n        this[currChild.name](currChild.children, param);\n      }\n    }\n  }\n  // defaultVisit does not support generic out param\n}\n\nexport function createBaseSemanticVisitorConstructor(\n  grammarName: string,\n  ruleNames: string[],\n): {\n  new (...args: any[]): ICstVisitor<any, any>;\n} {\n  const derivedConstructor: any = function () {};\n\n  // can be overwritten according to:\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n  // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemantics\");\n\n  const semanticProto = {\n    visit: function (cstNode: CstNode | CstNode[], param: any) {\n      // enables writing more concise visitor methods when CstNode has only a single child\n      if (isArray(cstNode)) {\n        // A CST Node's children dictionary can never have empty arrays as values\n        // If a key is defined there will be at least one element in the corresponding value array.\n        cstNode = cstNode[0];\n      }\n\n      // enables passing optional CstNodes concisely.\n      if (isUndefined(cstNode)) {\n        return undefined;\n      }\n\n      return this[cstNode.name](cstNode.children, param);\n    },\n\n    validateVisitor: function () {\n      const semanticDefinitionErrors = validateVisitor(this, ruleNames);\n      if (!isEmpty(semanticDefinitionErrors)) {\n        const errorMessages = map(\n          semanticDefinitionErrors,\n          (currDefError) => currDefError.msg,\n        );\n        throw Error(\n          `Errors Detected in CST Visitor <${this.constructor.name}>:\\n\\t` +\n            `${errorMessages.join(\"\\n\\n\").replace(/\\n/g, \"\\n\\t\")}`,\n        );\n      }\n    },\n  };\n\n  derivedConstructor.prototype = semanticProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n\n  derivedConstructor._RULE_NAMES = ruleNames;\n\n  return derivedConstructor;\n}\n\nexport function createBaseVisitorConstructorWithDefaults(\n  grammarName: string,\n  ruleNames: string[],\n  baseConstructor: Function,\n): {\n  new (...args: any[]): ICstVisitor<any, any>;\n} {\n  const derivedConstructor: any = function () {};\n\n  // can be overwritten according to:\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n  // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemanticsWithDefaults\");\n\n  const withDefaultsProto = Object.create(baseConstructor.prototype);\n  forEach(ruleNames, (ruleName) => {\n    withDefaultsProto[ruleName] = defaultVisit;\n  });\n\n  derivedConstructor.prototype = withDefaultsProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n\n  return derivedConstructor;\n}\n\nexport enum CstVisitorDefinitionError {\n  REDUNDANT_METHOD,\n  MISSING_METHOD,\n}\n\nexport interface IVisitorDefinitionError {\n  msg: string;\n  type: CstVisitorDefinitionError;\n  methodName: string;\n}\n\nexport function validateVisitor(\n  visitorInstance: ICstVisitor<unknown, unknown>,\n  ruleNames: string[],\n): IVisitorDefinitionError[] {\n  const missingErrors = validateMissingCstMethods(visitorInstance, ruleNames);\n\n  return missingErrors;\n}\n\nexport function validateMissingCstMethods(\n  visitorInstance: ICstVisitor<unknown, unknown>,\n  ruleNames: string[],\n): IVisitorDefinitionError[] {\n  const missingRuleNames = filter(ruleNames, (currRuleName) => {\n    return isFunction((visitorInstance as any)[currRuleName]) === false;\n  });\n\n  const errors: IVisitorDefinitionError[] = map(\n    missingRuleNames,\n    (currRuleName) => {\n      return {\n        msg: `Missing visitor method: <${currRuleName}> on ${<any>(\n          visitorInstance.constructor.name\n        )} CST Visitor.`,\n        type: CstVisitorDefinitionError.MISSING_METHOD,\n        methodName: currRuleName,\n      };\n    },\n  );\n\n  return compact<IVisitorDefinitionError>(errors);\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  CstNode,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IParserConfig,\n  IProduction,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  SubruleMethodOpts,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  forEach,\n  has,\n  isArray,\n  isFunction,\n  last as peek,\n  some,\n} from \"lodash-es\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { Lexer } from \"../../../scan/lexer_public.js\";\nimport {\n  augmentTokenTypes,\n  hasShortKeyProperty,\n} from \"../../../scan/tokens.js\";\nimport {\n  createToken,\n  createTokenInstance,\n} from \"../../../scan/tokens_public.js\";\nimport { END_OF_FILE } from \"../parser.js\";\nimport { BITS_FOR_OCCURRENCE_IDX } from \"../../grammar/keys.js\";\nimport { ParserMethodInternal } from \"../types.js\";\n\ntype ProdWithDef = IProduction & { definition?: IProduction[] };\nconst RECORDING_NULL_OBJECT = {\n  description: \"This Object indicates the Parser is during Recording Phase\",\n};\nObject.freeze(RECORDING_NULL_OBJECT);\n\nconst HANDLE_SEPARATOR = true;\nconst MAX_METHOD_IDX = Math.pow(2, BITS_FOR_OCCURRENCE_IDX) - 1;\n\nconst RFT = createToken({ name: \"RECORDING_PHASE_TOKEN\", pattern: Lexer.NA });\naugmentTokenTypes([RFT]);\nconst RECORDING_PHASE_TOKEN = createTokenInstance(\n  RFT,\n  \"This IToken indicates the Parser is in Recording Phase\\n\\t\" +\n    \"\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  // Using \"-1\" instead of NaN (as in EOF) because an actual number is less likely to\n  // cause errors if the output of LA or CONSUME would be (incorrectly) used during the recording phase.\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n);\nObject.freeze(RECORDING_PHASE_TOKEN);\n\nconst RECORDING_PHASE_CSTNODE: CstNode = {\n  name:\n    \"This CSTNode indicates the Parser is in Recording Phase\\n\\t\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  children: {},\n};\n\n/**\n * This trait handles the creation of the GAST structure for Chevrotain Grammars\n */\nexport class GastRecorder {\n  recordingProdStack: ProdWithDef[];\n  RECORDING_PHASE: boolean;\n\n  initGastRecorder(this: MixedInParser, config: IParserConfig): void {\n    this.recordingProdStack = [];\n    this.RECORDING_PHASE = false;\n  }\n\n  enableRecording(this: MixedInParser): void {\n    this.RECORDING_PHASE = true;\n\n    this.TRACE_INIT(\"Enable Recording\", () => {\n      /**\n       * Warning Dark Voodoo Magic upcoming!\n       * We are \"replacing\" the public parsing DSL methods API\n       * With **new** alternative implementations on the Parser **instance**\n       *\n       * So far this is the only way I've found to avoid performance regressions during parsing time.\n       * - Approx 30% performance regression was measured on Chrome 75 Canary when attempting to replace the \"internal\"\n       *   implementations directly instead.\n       */\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        this[`CONSUME${idx}` as \"CONSUME\"] = function (arg1, arg2) {\n          return this.consumeInternalRecord(arg1, i, arg2);\n        };\n        this[`SUBRULE${idx}` as \"SUBRULE\"] = function (arg1, arg2) {\n          return this.subruleInternalRecord(arg1, i, arg2) as any;\n        };\n        this[`OPTION${idx}` as \"OPTION\"] = function (arg1) {\n          return this.optionInternalRecord(arg1, i);\n        };\n        this[`OR${idx}` as \"OR\"] = function (arg1) {\n          return this.orInternalRecord(arg1, i);\n        };\n        this[`MANY${idx}` as \"MANY\"] = function (arg1) {\n          this.manyInternalRecord(i, arg1);\n        };\n        this[`MANY_SEP${idx}` as \"MANY_SEP\"] = function (arg1) {\n          this.manySepFirstInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE${idx}` as \"AT_LEAST_ONE\"] = function (arg1) {\n          this.atLeastOneInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE_SEP${idx}` as \"AT_LEAST_ONE_SEP\"] = function (arg1) {\n          this.atLeastOneSepFirstInternalRecord(i, arg1);\n        };\n      }\n\n      // DSL methods with the idx(suffix) as an argument\n      this[`consume`] = function (idx, arg1, arg2) {\n        return this.consumeInternalRecord(arg1, idx, arg2);\n      };\n      this[`subrule`] = function (idx, arg1, arg2) {\n        return this.subruleInternalRecord(arg1, idx, arg2) as any;\n      };\n      this[`option`] = function (idx, arg1) {\n        return this.optionInternalRecord(arg1, idx);\n      };\n      this[`or`] = function (idx, arg1) {\n        return this.orInternalRecord(arg1, idx);\n      };\n      this[`many`] = function (idx, arg1) {\n        this.manyInternalRecord(idx, arg1);\n      };\n      this[`atLeastOne`] = function (idx, arg1) {\n        this.atLeastOneInternalRecord(idx, arg1);\n      };\n\n      this.ACTION = this.ACTION_RECORD;\n      this.BACKTRACK = this.BACKTRACK_RECORD;\n      this.LA = this.LA_RECORD;\n    });\n  }\n\n  disableRecording(this: MixedInParser) {\n    this.RECORDING_PHASE = false;\n    // By deleting these **instance** properties, any future invocation\n    // will be deferred to the original methods on the **prototype** object\n    // This seems to get rid of any incorrect optimizations that V8 may\n    // do during the recording phase.\n    this.TRACE_INIT(\"Deleting Recording methods\", () => {\n      const that: any = this;\n\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        delete that[`CONSUME${idx}`];\n        delete that[`SUBRULE${idx}`];\n        delete that[`OPTION${idx}`];\n        delete that[`OR${idx}`];\n        delete that[`MANY${idx}`];\n        delete that[`MANY_SEP${idx}`];\n        delete that[`AT_LEAST_ONE${idx}`];\n        delete that[`AT_LEAST_ONE_SEP${idx}`];\n      }\n\n      delete that[`consume`];\n      delete that[`subrule`];\n      delete that[`option`];\n      delete that[`or`];\n      delete that[`many`];\n      delete that[`atLeastOne`];\n\n      delete that.ACTION;\n      delete that.BACKTRACK;\n      delete that.LA;\n    });\n  }\n\n  //   Parser methods are called inside an ACTION?\n  //   Maybe try/catch/finally on ACTIONS while disabling the recorders state changes?\n  // @ts-expect-error -- noop place holder\n  ACTION_RECORD<T>(this: MixedInParser, impl: () => T): T {\n    // NO-OP during recording\n  }\n\n  // Executing backtracking logic will break our recording logic assumptions\n  BACKTRACK_RECORD<T>(\n    grammarRule: (...args: any[]) => T,\n    args?: any[],\n  ): () => boolean {\n    return () => true;\n  }\n\n  // LA is part of the official API and may be used for custom lookahead logic\n  // by end users who may forget to wrap it in ACTION or inside a GATE\n  LA_RECORD(howMuch: number): IToken {\n    // We cannot use the RECORD_PHASE_TOKEN here because someone may depend\n    // On LA return EOF at the end of the input so an infinite loop may occur.\n    return END_OF_FILE;\n  }\n\n  topLevelRuleRecord(name: string, def: Function): Rule {\n    try {\n      const newTopLevelRule = new Rule({ definition: [], name: name });\n      newTopLevelRule.name = name;\n      this.recordingProdStack.push(newTopLevelRule);\n      def.call(this);\n      this.recordingProdStack.pop();\n      return newTopLevelRule;\n    } catch (originalError) {\n      if (originalError.KNOWN_RECORDER_ERROR !== true) {\n        try {\n          originalError.message =\n            originalError.message +\n            '\\n\\t This error was thrown during the \"grammar recording phase\" For more info see:\\n\\t' +\n            \"https://chevrotain.io/docs/guide/internals.html#grammar-recording\";\n        } catch (mutabilityError) {\n          // We may not be able to modify the original error object\n          throw originalError;\n        }\n      }\n      throw originalError;\n    }\n  }\n\n  // Implementation of parsing DSL\n  optionInternalRecord<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n  ): OUT {\n    return recordProd.call(this, Option, actionORMethodDef, occurrence);\n  }\n\n  atLeastOneInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    recordProd.call(this, RepetitionMandatory, actionORMethodDef, occurrence);\n  }\n\n  atLeastOneSepFirstInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    recordProd.call(\n      this,\n      RepetitionMandatoryWithSeparator,\n      options,\n      occurrence,\n      HANDLE_SEPARATOR,\n    );\n  }\n\n  manyInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    recordProd.call(this, Repetition, actionORMethodDef, occurrence);\n  }\n\n  manySepFirstInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    options: ManySepMethodOpts<OUT>,\n  ): void {\n    recordProd.call(\n      this,\n      RepetitionWithSeparator,\n      options,\n      occurrence,\n      HANDLE_SEPARATOR,\n    );\n  }\n\n  orInternalRecord<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n    occurrence: number,\n  ): T {\n    return recordOrProd.call(this, altsOrOpts, occurrence);\n  }\n\n  subruleInternalRecord<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    occurrence: number,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R | CstNode {\n    assertMethodIdxIsValid(occurrence);\n    if (!ruleToCall || has(ruleToCall, \"ruleName\") === false) {\n      const error: any = new Error(\n        `<SUBRULE${getIdxSuffix(occurrence)}> argument is invalid` +\n          ` expecting a Parser method reference but got: <${JSON.stringify(\n            ruleToCall,\n          )}>` +\n          `\\n inside top level rule: <${\n            (<Rule>this.recordingProdStack[0]).name\n          }>`,\n      );\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n\n    const prevProd: any = peek(this.recordingProdStack);\n    const ruleName = ruleToCall.ruleName;\n    const newNoneTerminal = new NonTerminal({\n      idx: occurrence,\n      nonTerminalName: ruleName,\n      label: options?.LABEL,\n      // The resolving of the `referencedRule` property will be done once all the Rule's GASTs have been created\n      referencedRule: undefined,\n    });\n    prevProd.definition.push(newNoneTerminal);\n\n    return this.outputCst\n      ? RECORDING_PHASE_CSTNODE\n      : <any>RECORDING_NULL_OBJECT;\n  }\n\n  consumeInternalRecord(\n    this: MixedInParser,\n    tokType: TokenType,\n    occurrence: number,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    assertMethodIdxIsValid(occurrence);\n    if (!hasShortKeyProperty(tokType)) {\n      const error: any = new Error(\n        `<CONSUME${getIdxSuffix(occurrence)}> argument is invalid` +\n          ` expecting a TokenType reference but got: <${JSON.stringify(\n            tokType,\n          )}>` +\n          `\\n inside top level rule: <${\n            (<Rule>this.recordingProdStack[0]).name\n          }>`,\n      );\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n    const prevProd: any = peek(this.recordingProdStack);\n    const newNoneTerminal = new Terminal({\n      idx: occurrence,\n      terminalType: tokType,\n      label: options?.LABEL,\n    });\n    prevProd.definition.push(newNoneTerminal);\n\n    return RECORDING_PHASE_TOKEN;\n  }\n}\n\nfunction recordProd(\n  prodConstructor: any,\n  mainProdArg: any,\n  occurrence: number,\n  handleSep: boolean = false,\n): any {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd: any = peek(this.recordingProdStack);\n  const grammarAction = isFunction(mainProdArg) ? mainProdArg : mainProdArg.DEF;\n\n  const newProd = new prodConstructor({ definition: [], idx: occurrence });\n  if (handleSep) {\n    newProd.separator = mainProdArg.SEP;\n  }\n  if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n\n  this.recordingProdStack.push(newProd);\n  grammarAction.call(this);\n  prevProd.definition.push(newProd);\n  this.recordingProdStack.pop();\n\n  return RECORDING_NULL_OBJECT;\n}\n\nfunction recordOrProd(mainProdArg: any, occurrence: number): any {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd: any = peek(this.recordingProdStack);\n  // Only an array of alternatives\n  const hasOptions = isArray(mainProdArg) === false;\n  const alts: IOrAlt<unknown>[] =\n    hasOptions === false ? mainProdArg : mainProdArg.DEF;\n\n  const newOrProd = new Alternation({\n    definition: [],\n    idx: occurrence,\n    ignoreAmbiguities: hasOptions && mainProdArg.IGNORE_AMBIGUITIES === true,\n  });\n  if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newOrProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n\n  const hasPredicates = some(alts, (currAlt: any) => isFunction(currAlt.GATE));\n  newOrProd.hasPredicates = hasPredicates;\n\n  prevProd.definition.push(newOrProd);\n\n  forEach(alts, (currAlt) => {\n    const currAltFlat = new Alternative({ definition: [] });\n    newOrProd.definition.push(currAltFlat);\n    if (has(currAlt, \"IGNORE_AMBIGUITIES\")) {\n      currAltFlat.ignoreAmbiguities = currAlt.IGNORE_AMBIGUITIES as boolean; // assumes end user provides the correct config value/type\n    }\n    // **implicit** ignoreAmbiguities due to usage of gate\n    else if (has(currAlt, \"GATE\")) {\n      currAltFlat.ignoreAmbiguities = true;\n    }\n    this.recordingProdStack.push(currAltFlat);\n    currAlt.ALT.call(this);\n    this.recordingProdStack.pop();\n  });\n  return RECORDING_NULL_OBJECT;\n}\n\nfunction getIdxSuffix(idx: number): string {\n  return idx === 0 ? \"\" : `${idx}`;\n}\n\nfunction assertMethodIdxIsValid(idx: number): void {\n  if (idx < 0 || idx > MAX_METHOD_IDX) {\n    const error: any = new Error(\n      // The stack trace will contain all the needed details\n      `Invalid DSL Method idx value: <${idx}>\\n\\t` +\n        `Idx value must be a none negative value smaller than ${\n          MAX_METHOD_IDX + 1\n        }`,\n    );\n    error.KNOWN_RECORDER_ERROR = true;\n    throw error;\n  }\n}\n","import { clone, forEach, has, isEmpty, map, values } from \"lodash-es\";\nimport { toFastProperties } from \"@chevrotain/utils\";\nimport { computeAllProdsFollows } from \"../grammar/follow.js\";\nimport { createTokenInstance, EOF } from \"../../scan/tokens_public.js\";\nimport {\n  defaultGrammarValidatorErrorProvider,\n  defaultParserErrorProvider,\n} from \"../errors_public.js\";\nimport {\n  resolveGrammar,\n  validateGrammar,\n} from \"../grammar/gast/gast_resolver_public.js\";\nimport {\n  CstNode,\n  IParserConfig,\n  IRecognitionException,\n  IRuleConfig,\n  IToken,\n  TokenType,\n  TokenVocabulary,\n} from \"@chevrotain/types\";\nimport { Recoverable } from \"./traits/recoverable.js\";\nimport { LooksAhead } from \"./traits/looksahead.js\";\nimport { TreeBuilder } from \"./traits/tree_builder.js\";\nimport { LexerAdapter } from \"./traits/lexer_adapter.js\";\nimport { RecognizerApi } from \"./traits/recognizer_api.js\";\nimport { RecognizerEngine } from \"./traits/recognizer_engine.js\";\n\nimport { ErrorHandler } from \"./traits/error_handler.js\";\nimport { MixedInParser } from \"./traits/parser_traits.js\";\nimport { ContentAssist } from \"./traits/context_assist.js\";\nimport { GastRecorder } from \"./traits/gast_recorder.js\";\nimport { PerformanceTracer } from \"./traits/perf_tracer.js\";\nimport { applyMixins } from \"./utils/apply_mixins.js\";\nimport { IParserDefinitionError } from \"../grammar/types.js\";\nimport { Rule } from \"@chevrotain/gast\";\nimport { IParserConfigInternal, ParserMethodInternal } from \"./types.js\";\nimport { validateLookahead } from \"../grammar/checks.js\";\n\nexport const END_OF_FILE = createTokenInstance(\n  EOF,\n  \"\",\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n);\nObject.freeze(END_OF_FILE);\n\nexport type TokenMatcher = (token: IToken, tokType: TokenType) => boolean;\n\nexport const DEFAULT_PARSER_CONFIG: Required<\n  Omit<IParserConfigInternal, \"lookaheadStrategy\">\n> = Object.freeze({\n  recoveryEnabled: false,\n  maxLookahead: 3,\n  dynamicTokensEnabled: false,\n  outputCst: true,\n  errorMessageProvider: defaultParserErrorProvider,\n  nodeLocationTracking: \"none\",\n  traceInitPerf: false,\n  skipValidations: false,\n});\n\nexport const DEFAULT_RULE_CONFIG: Required<IRuleConfig<any>> = Object.freeze({\n  recoveryValueFunc: () => undefined,\n  resyncEnabled: true,\n});\n\nexport enum ParserDefinitionErrorType {\n  INVALID_RULE_NAME = 0,\n  DUPLICATE_RULE_NAME = 1,\n  INVALID_RULE_OVERRIDE = 2,\n  DUPLICATE_PRODUCTIONS = 3,\n  UNRESOLVED_SUBRULE_REF = 4,\n  LEFT_RECURSION = 5,\n  NONE_LAST_EMPTY_ALT = 6,\n  AMBIGUOUS_ALTS = 7,\n  CONFLICT_TOKENS_RULES_NAMESPACE = 8,\n  INVALID_TOKEN_NAME = 9,\n  NO_NON_EMPTY_LOOKAHEAD = 10,\n  AMBIGUOUS_PREFIX_ALTS = 11,\n  TOO_MANY_ALTS = 12,\n  CUSTOM_LOOKAHEAD_VALIDATION = 13,\n}\n\nexport interface IParserDuplicatesDefinitionError\n  extends IParserDefinitionError {\n  dslName: string;\n  occurrence: number;\n  parameter?: string;\n}\n\nexport interface IParserEmptyAlternativeDefinitionError\n  extends IParserDefinitionError {\n  occurrence: number;\n  alternative: number;\n}\n\nexport interface IParserAmbiguousAlternativesDefinitionError\n  extends IParserDefinitionError {\n  occurrence: number | string;\n  alternatives: number[];\n}\n\nexport interface IParserUnresolvedRefDefinitionError\n  extends IParserDefinitionError {\n  unresolvedRefName: string;\n}\n\nexport interface IParserState {\n  errors: IRecognitionException[];\n  lexerState: any;\n  RULE_STACK: number[];\n  CST_STACK: CstNode[];\n}\n\nexport type Predicate = () => boolean;\n\nexport function EMPTY_ALT(): () => undefined;\nexport function EMPTY_ALT<T>(value: T): () => T;\nexport function EMPTY_ALT(value: any = undefined) {\n  return function () {\n    return value;\n  };\n}\n\nexport class Parser {\n  // Set this flag to true if you don't want the Parser to throw error when problems in it's definition are detected.\n  // (normally during the parser's constructor).\n  // This is a design time flag, it will not affect the runtime error handling of the parser, just design time errors,\n  // for example: duplicate rule names, referencing an unresolved subrule, ect...\n  // This flag should not be enabled during normal usage, it is used in special situations, for example when\n  // needing to display the parser definition errors in some GUI(online playground).\n  static DEFER_DEFINITION_ERRORS_HANDLING: boolean = false;\n\n  /**\n   *  @deprecated use the **instance** method with the same name instead\n   */\n  static performSelfAnalysis(parserInstance: Parser): void {\n    throw Error(\n      \"The **static** `performSelfAnalysis` method has been deprecated.\" +\n        \"\\t\\nUse the **instance** method with the same name instead.\",\n    );\n  }\n\n  public performSelfAnalysis(this: MixedInParser): void {\n    this.TRACE_INIT(\"performSelfAnalysis\", () => {\n      let defErrorsMsgs;\n\n      this.selfAnalysisDone = true;\n      const className = this.className;\n\n      this.TRACE_INIT(\"toFastProps\", () => {\n        // Without this voodoo magic the parser would be x3-x4 slower\n        // It seems it is better to invoke `toFastProperties` **before**\n        // Any manipulations of the `this` object done during the recording phase.\n        toFastProperties(this);\n      });\n\n      this.TRACE_INIT(\"Grammar Recording\", () => {\n        try {\n          this.enableRecording();\n          // Building the GAST\n          forEach(this.definedRulesNames, (currRuleName) => {\n            const wrappedRule = (this as any)[\n              currRuleName\n            ] as ParserMethodInternal<unknown[], unknown>;\n            const originalGrammarAction = wrappedRule[\"originalGrammarAction\"];\n            let recordedRuleGast!: Rule;\n            this.TRACE_INIT(`${currRuleName} Rule`, () => {\n              recordedRuleGast = this.topLevelRuleRecord(\n                currRuleName,\n                originalGrammarAction,\n              );\n            });\n            this.gastProductionsCache[currRuleName] = recordedRuleGast;\n          });\n        } finally {\n          this.disableRecording();\n        }\n      });\n\n      let resolverErrors: IParserDefinitionError[] = [];\n      this.TRACE_INIT(\"Grammar Resolving\", () => {\n        resolverErrors = resolveGrammar({\n          rules: values(this.gastProductionsCache),\n        });\n        this.definitionErrors = this.definitionErrors.concat(resolverErrors);\n      });\n\n      this.TRACE_INIT(\"Grammar Validations\", () => {\n        // only perform additional grammar validations IFF no resolving errors have occurred.\n        // as unresolved grammar may lead to unhandled runtime exceptions in the follow up validations.\n        if (isEmpty(resolverErrors) && this.skipValidations === false) {\n          const validationErrors = validateGrammar({\n            rules: values(this.gastProductionsCache),\n            tokenTypes: values(this.tokensMap),\n            errMsgProvider: defaultGrammarValidatorErrorProvider,\n            grammarName: className,\n          });\n          const lookaheadValidationErrors = validateLookahead({\n            lookaheadStrategy: this.lookaheadStrategy,\n            rules: values(this.gastProductionsCache),\n            tokenTypes: values(this.tokensMap),\n            grammarName: className,\n          });\n          this.definitionErrors = this.definitionErrors.concat(\n            validationErrors,\n            lookaheadValidationErrors,\n          );\n        }\n      });\n\n      // this analysis may fail if the grammar is not perfectly valid\n      if (isEmpty(this.definitionErrors)) {\n        // The results of these computations are not needed unless error recovery is enabled.\n        if (this.recoveryEnabled) {\n          this.TRACE_INIT(\"computeAllProdsFollows\", () => {\n            const allFollows = computeAllProdsFollows(\n              values(this.gastProductionsCache),\n            );\n            this.resyncFollows = allFollows;\n          });\n        }\n\n        this.TRACE_INIT(\"ComputeLookaheadFunctions\", () => {\n          this.lookaheadStrategy.initialize?.({\n            rules: values(this.gastProductionsCache),\n          });\n          this.preComputeLookaheadFunctions(values(this.gastProductionsCache));\n        });\n      }\n\n      if (\n        !Parser.DEFER_DEFINITION_ERRORS_HANDLING &&\n        !isEmpty(this.definitionErrors)\n      ) {\n        defErrorsMsgs = map(\n          this.definitionErrors,\n          (defError) => defError.message,\n        );\n        throw new Error(\n          `Parser Definition Errors detected:\\n ${defErrorsMsgs.join(\n            \"\\n-------------------------------\\n\",\n          )}`,\n        );\n      }\n    });\n  }\n\n  definitionErrors: IParserDefinitionError[] = [];\n  selfAnalysisDone = false;\n  protected skipValidations: boolean;\n\n  constructor(tokenVocabulary: TokenVocabulary, config: IParserConfig) {\n    const that: MixedInParser = this as any;\n    that.initErrorHandler(config);\n    that.initLexerAdapter();\n    that.initLooksAhead(config);\n    that.initRecognizerEngine(tokenVocabulary, config);\n    that.initRecoverable(config);\n    that.initTreeBuilder(config);\n    that.initContentAssist();\n    that.initGastRecorder(config);\n    that.initPerformanceTracer(config);\n\n    if (has(config, \"ignoredIssues\")) {\n      throw new Error(\n        \"The <ignoredIssues> IParserConfig property has been deprecated.\\n\\t\" +\n          \"Please use the <IGNORE_AMBIGUITIES> flag on the relevant DSL method instead.\\n\\t\" +\n          \"See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#IGNORING_AMBIGUITIES\\n\\t\" +\n          \"For further details.\",\n      );\n    }\n\n    this.skipValidations = has(config, \"skipValidations\")\n      ? (config.skipValidations as boolean) // casting assumes the end user passing the correct type\n      : DEFAULT_PARSER_CONFIG.skipValidations;\n  }\n}\n\napplyMixins(Parser, [\n  Recoverable,\n  LooksAhead,\n  TreeBuilder,\n  LexerAdapter,\n  RecognizerEngine,\n  RecognizerApi,\n  ErrorHandler,\n  ContentAssist,\n  GastRecorder,\n  PerformanceTracer,\n]);\n\nexport class CstParser extends Parser {\n  constructor(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfigInternal = DEFAULT_PARSER_CONFIG,\n  ) {\n    const configClone = clone(config);\n    configClone.outputCst = true;\n    super(tokenVocabulary, configClone);\n  }\n}\n\nexport class EmbeddedActionsParser extends Parser {\n  constructor(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfigInternal = DEFAULT_PARSER_CONFIG,\n  ) {\n    const configClone = clone(config);\n    configClone.outputCst = false;\n    super(tokenVocabulary, configClone);\n  }\n}\n","export function applyMixins(derivedCtor: any, baseCtors: any[]) {\n  baseCtors.forEach((baseCtor) => {\n    const baseProto = baseCtor.prototype;\n    Object.getOwnPropertyNames(baseProto).forEach((propName) => {\n      if (propName === \"constructor\") {\n        return;\n      }\n\n      const basePropDescriptor = Object.getOwnPropertyDescriptor(\n        baseProto,\n        propName,\n      );\n      // Handle Accessors\n      if (\n        basePropDescriptor &&\n        (basePropDescriptor.get || basePropDescriptor.set)\n      ) {\n        Object.defineProperty(\n          derivedCtor.prototype,\n          propName,\n          basePropDescriptor,\n        );\n      } else {\n        derivedCtor.prototype[propName] = baseCtor.prototype[propName];\n      }\n    });\n  });\n}\n","import {\n  addNoneTerminalToCst,\n  addTerminalToCst,\n  setNodeLocationFull,\n  setNodeLocationOnlyOffset,\n} from \"../../cst/cst.js\";\nimport { has, isUndefined, keys, noop } from \"lodash-es\";\nimport {\n  createBaseSemanticVisitorConstructor,\n  createBaseVisitorConstructorWithDefaults,\n} from \"../../cst/cst_visitor.js\";\nimport {\n  CstNode,\n  CstNodeLocation,\n  ICstVisitor,\n  IParserConfig,\n  IToken,\n  nodeLocationTrackingOptions,\n} from \"@chevrotain/types\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * This trait is responsible for the CST building logic.\n */\nexport class TreeBuilder {\n  outputCst: boolean;\n  CST_STACK: CstNode[];\n  baseCstVisitorConstructor: Function;\n  baseCstVisitorWithDefaultsConstructor: Function;\n\n  // dynamically assigned Methods\n  setNodeLocationFromNode: (\n    nodeLocation: CstNodeLocation,\n    locationInformation: CstNodeLocation,\n  ) => void;\n  setNodeLocationFromToken: (\n    nodeLocation: CstNodeLocation,\n    locationInformation: CstNodeLocation,\n  ) => void;\n  cstPostRule: (this: MixedInParser, ruleCstNode: CstNode) => void;\n\n  setInitialNodeLocation: (cstNode: CstNode) => void;\n  nodeLocationTracking: nodeLocationTrackingOptions;\n\n  initTreeBuilder(this: MixedInParser, config: IParserConfig) {\n    this.CST_STACK = [];\n\n    // outputCst is no longer exposed/defined in the pubic API\n    this.outputCst = (config as any).outputCst;\n\n    this.nodeLocationTracking = has(config, \"nodeLocationTracking\")\n      ? (config.nodeLocationTracking as nodeLocationTrackingOptions) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.nodeLocationTracking;\n\n    if (!this.outputCst) {\n      this.cstInvocationStateUpdate = noop;\n      this.cstFinallyStateUpdate = noop;\n      this.cstPostTerminal = noop;\n      this.cstPostNonTerminal = noop;\n      this.cstPostRule = noop;\n    } else {\n      if (/full/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = setNodeLocationFull;\n          this.setNodeLocationFromNode = setNodeLocationFull;\n          this.cstPostRule = noop;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop;\n          this.setNodeLocationFromNode = noop;\n          this.cstPostRule = this.cstPostRuleFull;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRegular;\n        }\n      } else if (/onlyOffset/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = <any>setNodeLocationOnlyOffset;\n          this.setNodeLocationFromNode = <any>setNodeLocationOnlyOffset;\n          this.cstPostRule = noop;\n          this.setInitialNodeLocation =\n            this.setInitialNodeLocationOnlyOffsetRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop;\n          this.setNodeLocationFromNode = noop;\n          this.cstPostRule = this.cstPostRuleOnlyOffset;\n          this.setInitialNodeLocation =\n            this.setInitialNodeLocationOnlyOffsetRegular;\n        }\n      } else if (/none/i.test(this.nodeLocationTracking)) {\n        this.setNodeLocationFromToken = noop;\n        this.setNodeLocationFromNode = noop;\n        this.cstPostRule = noop;\n        this.setInitialNodeLocation = noop;\n      } else {\n        throw Error(\n          `Invalid <nodeLocationTracking> config option: \"${config.nodeLocationTracking}\"`,\n        );\n      }\n    }\n  }\n\n  setInitialNodeLocationOnlyOffsetRecovery(\n    this: MixedInParser,\n    cstNode: any,\n  ): void {\n    cstNode.location = {\n      startOffset: NaN,\n      endOffset: NaN,\n    };\n  }\n\n  setInitialNodeLocationOnlyOffsetRegular(\n    this: MixedInParser,\n    cstNode: any,\n  ): void {\n    cstNode.location = {\n      // without error recovery the starting Location of a new CstNode is guaranteed\n      // To be the next Token's startOffset (for valid inputs).\n      // For invalid inputs there won't be any CSTOutput so this potential\n      // inaccuracy does not matter\n      startOffset: this.LA(1).startOffset,\n      endOffset: NaN,\n    };\n  }\n\n  setInitialNodeLocationFullRecovery(this: MixedInParser, cstNode: any): void {\n    cstNode.location = {\n      startOffset: NaN,\n      startLine: NaN,\n      startColumn: NaN,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN,\n    };\n  }\n\n  /**\n     *  @see setInitialNodeLocationOnlyOffsetRegular for explanation why this work\n\n     * @param cstNode\n     */\n  setInitialNodeLocationFullRegular(this: MixedInParser, cstNode: any): void {\n    const nextToken = this.LA(1);\n    cstNode.location = {\n      startOffset: nextToken.startOffset,\n      startLine: nextToken.startLine,\n      startColumn: nextToken.startColumn,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN,\n    };\n  }\n\n  cstInvocationStateUpdate(this: MixedInParser, fullRuleName: string): void {\n    const cstNode: CstNode = {\n      name: fullRuleName,\n      children: Object.create(null),\n    };\n\n    this.setInitialNodeLocation(cstNode);\n    this.CST_STACK.push(cstNode);\n  }\n\n  cstFinallyStateUpdate(this: MixedInParser): void {\n    this.CST_STACK.pop();\n  }\n\n  cstPostRuleFull(this: MixedInParser, ruleCstNode: CstNode): void {\n    // casts to `required<CstNodeLocation>` are safe because `cstPostRuleFull` should only be invoked when full location is enabled\n    const prevToken = this.LA(0) as Required<CstNodeLocation>;\n    const loc = ruleCstNode.location as Required<CstNodeLocation>;\n\n    // If this condition is true it means we consumed at least one Token\n    // In this CstNode.\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n      loc.endLine = prevToken.endLine;\n      loc.endColumn = prevToken.endColumn;\n    }\n    // \"empty\" CstNode edge case\n    else {\n      loc.startOffset = NaN;\n      loc.startLine = NaN;\n      loc.startColumn = NaN;\n    }\n  }\n\n  cstPostRuleOnlyOffset(this: MixedInParser, ruleCstNode: CstNode): void {\n    const prevToken = this.LA(0);\n    // `location' is not null because `cstPostRuleOnlyOffset` will only be invoked when location tracking is enabled.\n    const loc = ruleCstNode.location!;\n\n    // If this condition is true it means we consumed at least one Token\n    // In this CstNode.\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n    }\n    // \"empty\" CstNode edge case\n    else {\n      loc.startOffset = NaN;\n    }\n  }\n\n  cstPostTerminal(\n    this: MixedInParser,\n    key: string,\n    consumedToken: IToken,\n  ): void {\n    const rootCst = this.CST_STACK[this.CST_STACK.length - 1];\n    addTerminalToCst(rootCst, consumedToken, key);\n    // This is only used when **both** error recovery and CST Output are enabled.\n    this.setNodeLocationFromToken(rootCst.location!, <any>consumedToken);\n  }\n\n  cstPostNonTerminal(\n    this: MixedInParser,\n    ruleCstResult: CstNode,\n    ruleName: string,\n  ): void {\n    const preCstNode = this.CST_STACK[this.CST_STACK.length - 1];\n    addNoneTerminalToCst(preCstNode, ruleName, ruleCstResult);\n    // This is only used when **both** error recovery and CST Output are enabled.\n    this.setNodeLocationFromNode(preCstNode.location!, ruleCstResult.location!);\n  }\n\n  getBaseCstVisitorConstructor<IN = any, OUT = any>(\n    this: MixedInParser,\n  ): {\n    new (...args: any[]): ICstVisitor<IN, OUT>;\n  } {\n    if (isUndefined(this.baseCstVisitorConstructor)) {\n      const newBaseCstVisitorConstructor = createBaseSemanticVisitorConstructor(\n        this.className,\n        keys(this.gastProductionsCache),\n      );\n      this.baseCstVisitorConstructor = newBaseCstVisitorConstructor;\n      return newBaseCstVisitorConstructor;\n    }\n\n    return <any>this.baseCstVisitorConstructor;\n  }\n\n  getBaseCstVisitorConstructorWithDefaults<IN = any, OUT = any>(\n    this: MixedInParser,\n  ): {\n    new (...args: any[]): ICstVisitor<IN, OUT>;\n  } {\n    if (isUndefined(this.baseCstVisitorWithDefaultsConstructor)) {\n      const newConstructor = createBaseVisitorConstructorWithDefaults(\n        this.className,\n        keys(this.gastProductionsCache),\n        this.getBaseCstVisitorConstructor(),\n      );\n      this.baseCstVisitorWithDefaultsConstructor = newConstructor;\n      return newConstructor;\n    }\n\n    return <any>this.baseCstVisitorWithDefaultsConstructor;\n  }\n\n  getLastExplicitRuleShortName(this: MixedInParser): number {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 1];\n  }\n\n  getPreviousExplicitRuleShortName(this: MixedInParser): number {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 2];\n  }\n\n  getLastExplicitRuleOccurrenceIndex(this: MixedInParser): number {\n    const occurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return occurrenceStack[occurrenceStack.length - 1];\n  }\n}\n","import { END_OF_FILE } from \"../parser.js\";\nimport { IToken } from \"@chevrotain/types\";\nimport { MixedInParser } from \"./parser_traits.js\";\n\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nexport class LexerAdapter {\n  tokVector: IToken[];\n  tokVectorLength: number;\n  currIdx: number;\n\n  initLexerAdapter() {\n    this.tokVector = [];\n    this.tokVectorLength = 0;\n    this.currIdx = -1;\n  }\n\n  set input(newInput: IToken[]) {\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    if (this.selfAnalysisDone !== true) {\n      throw Error(\n        `Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`,\n      );\n    }\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    this.reset();\n    this.tokVector = newInput;\n    this.tokVectorLength = newInput.length;\n  }\n\n  get input(): IToken[] {\n    return this.tokVector;\n  }\n\n  // skips a token and returns the next token\n  SKIP_TOKEN(this: MixedInParser): IToken {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken();\n      return this.LA(1);\n    } else {\n      return END_OF_FILE;\n    }\n  }\n\n  // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n  LA(this: MixedInParser, howMuch: number): IToken {\n    const soughtIdx = this.currIdx + howMuch;\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return END_OF_FILE;\n    } else {\n      return this.tokVector[soughtIdx];\n    }\n  }\n\n  consumeToken(this: MixedInParser) {\n    this.currIdx++;\n  }\n\n  exportLexerState(this: MixedInParser): number {\n    return this.currIdx;\n  }\n\n  importLexerState(this: MixedInParser, newState: number) {\n    this.currIdx = newState;\n  }\n\n  resetLexerState(this: MixedInParser): void {\n    this.currIdx = -1;\n  }\n\n  moveToTerminatedState(this: MixedInParser): void {\n    this.currIdx = this.tokVector.length - 1;\n  }\n\n  getLexerPosition(this: MixedInParser): number {\n    return this.exportLexerState();\n  }\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IParserConfig,\n  IRuleConfig,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  ParserMethod,\n  SubruleMethodOpts,\n  TokenType,\n  TokenTypeDictionary,\n  TokenVocabulary,\n} from \"@chevrotain/types\";\nimport {\n  clone,\n  every,\n  flatten,\n  has,\n  isArray,\n  isEmpty,\n  isObject,\n  reduce,\n  uniq,\n  values,\n} from \"lodash-es\";\nimport {\n  AT_LEAST_ONE_IDX,\n  AT_LEAST_ONE_SEP_IDX,\n  BITS_FOR_METHOD_TYPE,\n  BITS_FOR_OCCURRENCE_IDX,\n  MANY_IDX,\n  MANY_SEP_IDX,\n  OPTION_IDX,\n  OR_IDX,\n} from \"../../grammar/keys.js\";\nimport {\n  isRecognitionException,\n  MismatchedTokenException,\n  NotAllInputParsedException,\n} from \"../../exceptions_public.js\";\nimport { PROD_TYPE } from \"../../grammar/lookahead.js\";\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  NextTerminalAfterAtLeastOneSepWalker,\n  NextTerminalAfterAtLeastOneWalker,\n  NextTerminalAfterManySepWalker,\n  NextTerminalAfterManyWalker,\n} from \"../../grammar/interpreter.js\";\nimport { DEFAULT_RULE_CONFIG, IParserState, TokenMatcher } from \"../parser.js\";\nimport { IN_RULE_RECOVERY_EXCEPTION } from \"./recoverable.js\";\nimport { EOF } from \"../../../scan/tokens_public.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  augmentTokenTypes,\n  isTokenType,\n  tokenStructuredMatcher,\n  tokenStructuredMatcherNoCategories,\n} from \"../../../scan/tokens.js\";\nimport { Rule } from \"@chevrotain/gast\";\nimport { ParserMethodInternal } from \"../types.js\";\n\n/**\n * This trait is responsible for the runtime parsing engine\n * Used by the official API (recognizer_api.ts)\n */\nexport class RecognizerEngine {\n  isBackTrackingStack: boolean[];\n  className: string;\n  RULE_STACK: number[];\n  RULE_OCCURRENCE_STACK: number[];\n  definedRulesNames: string[];\n  tokensMap: { [fqn: string]: TokenType };\n  gastProductionsCache: Record<string, Rule>;\n  shortRuleNameToFull: Record<string, string>;\n  fullRuleNameToShort: Record<string, number>;\n  // The shortName Index must be coded \"after\" the first 8bits to enable building unique lookahead keys\n  ruleShortNameIdx: number;\n  tokenMatcher: TokenMatcher;\n  subruleIdx: number;\n\n  initRecognizerEngine(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfig,\n  ) {\n    this.className = this.constructor.name;\n    // TODO: would using an ES6 Map or plain object be faster (CST building scenario)\n    this.shortRuleNameToFull = {};\n    this.fullRuleNameToShort = {};\n    this.ruleShortNameIdx = 256;\n    this.tokenMatcher = tokenStructuredMatcherNoCategories;\n    this.subruleIdx = 0;\n\n    this.definedRulesNames = [];\n    this.tokensMap = {};\n    this.isBackTrackingStack = [];\n    this.RULE_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n    this.gastProductionsCache = {};\n\n    if (has(config, \"serializedGrammar\")) {\n      throw Error(\n        \"The Parser's configuration can no longer contain a <serializedGrammar> property.\\n\" +\n          \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_6-0-0\\n\" +\n          \"\\tFor Further details.\",\n      );\n    }\n\n    if (isArray(tokenVocabulary)) {\n      // This only checks for Token vocabularies provided as arrays.\n      // That is good enough because the main objective is to detect users of pre-V4.0 APIs\n      // rather than all edge cases of empty Token vocabularies.\n      if (isEmpty(tokenVocabulary as any[])) {\n        throw Error(\n          \"A Token Vocabulary cannot be empty.\\n\" +\n            \"\\tNote that the first argument for the parser constructor\\n\" +\n            \"\\tis no longer a Token vector (since v4.0).\",\n        );\n      }\n\n      if (typeof (tokenVocabulary as any[])[0].startOffset === \"number\") {\n        throw Error(\n          \"The Parser constructor no longer accepts a token vector as the first argument.\\n\" +\n            \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_4-0-0\\n\" +\n            \"\\tFor Further details.\",\n        );\n      }\n    }\n\n    if (isArray(tokenVocabulary)) {\n      this.tokensMap = reduce(\n        tokenVocabulary,\n        (acc, tokType: TokenType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        },\n        {} as { [tokenName: string]: TokenType },\n      );\n    } else if (\n      has(tokenVocabulary, \"modes\") &&\n      every(flatten(values((<any>tokenVocabulary).modes)), isTokenType)\n    ) {\n      const allTokenTypes = flatten(values((<any>tokenVocabulary).modes));\n      const uniqueTokens = uniq(allTokenTypes);\n      this.tokensMap = <any>reduce(\n        uniqueTokens,\n        (acc, tokType: TokenType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        },\n        {} as { [tokenName: string]: TokenType },\n      );\n    } else if (isObject(tokenVocabulary)) {\n      this.tokensMap = clone(tokenVocabulary as TokenTypeDictionary);\n    } else {\n      throw new Error(\n        \"<tokensDictionary> argument must be An Array of Token constructors,\" +\n          \" A dictionary of Token constructors or an IMultiModeLexerDefinition\",\n      );\n    }\n\n    // always add EOF to the tokenNames -> constructors map. it is useful to assure all the input has been\n    // parsed with a clear error message (\"expecting EOF but found ...\")\n    this.tokensMap[\"EOF\"] = EOF;\n\n    const allTokenTypes = has(tokenVocabulary, \"modes\")\n      ? flatten(values((<any>tokenVocabulary).modes))\n      : values(tokenVocabulary);\n    const noTokenCategoriesUsed = every(allTokenTypes, (tokenConstructor) =>\n      isEmpty(tokenConstructor.categoryMatches),\n    );\n\n    this.tokenMatcher = noTokenCategoriesUsed\n      ? tokenStructuredMatcherNoCategories\n      : tokenStructuredMatcher;\n\n    // Because ES2015+ syntax should be supported for creating Token classes\n    // We cannot assume that the Token classes were created using the \"extendToken\" utilities\n    // Therefore we must augment the Token classes both on Lexer initialization and on Parser initialization\n    augmentTokenTypes(values(this.tokensMap));\n  }\n\n  defineRule<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleName: string,\n    impl: (...args: ARGS) => R,\n    config: IRuleConfig<R>,\n  ): ParserMethodInternal<ARGS, R> {\n    if (this.selfAnalysisDone) {\n      throw Error(\n        `Grammar rule <${ruleName}> may not be defined after the 'performSelfAnalysis' method has been called'\\n` +\n          `Make sure that all grammar rule definitions are done before 'performSelfAnalysis' is called.`,\n      );\n    }\n    const resyncEnabled: boolean = has(config, \"resyncEnabled\")\n      ? (config.resyncEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_RULE_CONFIG.resyncEnabled;\n    const recoveryValueFunc = has(config, \"recoveryValueFunc\")\n      ? (config.recoveryValueFunc as () => R) // assumes end user provides the correct config value/type\n      : DEFAULT_RULE_CONFIG.recoveryValueFunc;\n\n    // performance optimization: Use small integers as keys for the longer human readable \"full\" rule names.\n    // this greatly improves Map access time (as much as 8% for some performance benchmarks).\n    const shortName =\n      this.ruleShortNameIdx << (BITS_FOR_METHOD_TYPE + BITS_FOR_OCCURRENCE_IDX);\n\n    this.ruleShortNameIdx++;\n    this.shortRuleNameToFull[shortName] = ruleName;\n    this.fullRuleNameToShort[ruleName] = shortName;\n\n    let invokeRuleWithTry: ParserMethod<ARGS, R>;\n\n    // Micro optimization, only check the condition **once** on rule definition\n    // instead of **every single** rule invocation.\n    if (this.outputCst === true) {\n      invokeRuleWithTry = function invokeRuleWithTry(\n        this: MixedInParser,\n        ...args: ARGS\n      ): R {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          impl.apply(this, args);\n          const cst = this.CST_STACK[this.CST_STACK.length - 1];\n          this.cstPostRule(cst);\n          return cst as unknown as R;\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc) as R;\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      };\n    } else {\n      invokeRuleWithTry = function invokeRuleWithTryCst(\n        this: MixedInParser,\n        ...args: ARGS\n      ): R {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          return impl.apply(this, args);\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc) as R;\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      };\n    }\n\n    const wrappedGrammarRule: ParserMethodInternal<ARGS, R> = Object.assign(\n      invokeRuleWithTry as any,\n      { ruleName, originalGrammarAction: impl },\n    );\n\n    return wrappedGrammarRule;\n  }\n\n  invokeRuleCatch(\n    this: MixedInParser,\n    e: Error,\n    resyncEnabledConfig: boolean,\n    recoveryValueFunc: Function,\n  ): unknown {\n    const isFirstInvokedRule = this.RULE_STACK.length === 1;\n    // note the reSync is always enabled for the first rule invocation, because we must always be able to\n    // reSync with EOF and just output some INVALID ParseTree\n    // during backtracking reSync recovery is disabled, otherwise we can't be certain the backtracking\n    // path is really the most valid one\n    const reSyncEnabled =\n      resyncEnabledConfig && !this.isBackTracking() && this.recoveryEnabled;\n\n    if (isRecognitionException(e)) {\n      const recogError: any = e;\n      if (reSyncEnabled) {\n        const reSyncTokType = this.findReSyncTokenType();\n        if (this.isInCurrentRuleReSyncSet(reSyncTokType)) {\n          recogError.resyncedTokens = this.reSyncTo(reSyncTokType);\n          if (this.outputCst) {\n            const partialCstResult: any =\n              this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            return partialCstResult;\n          } else {\n            return recoveryValueFunc(e);\n          }\n        } else {\n          if (this.outputCst) {\n            const partialCstResult: any =\n              this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            recogError.partialCstResult = partialCstResult;\n          }\n          // to be handled Further up the call stack\n          throw recogError;\n        }\n      } else if (isFirstInvokedRule) {\n        // otherwise a Redundant input error will be created as well and we cannot guarantee that this is indeed the case\n        this.moveToTerminatedState();\n        // the parser should never throw one of its own errors outside its flow.\n        // even if error recovery is disabled\n        return recoveryValueFunc(e);\n      } else {\n        // to be recovered Further up the call stack\n        throw recogError;\n      }\n    } else {\n      // some other Error type which we don't know how to handle (for example a built in JavaScript Error)\n      throw e;\n    }\n  }\n\n  // Implementation of parsing DSL\n  optionInternal<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n  ): OUT | undefined {\n    const key = this.getKeyForAutomaticLookahead(OPTION_IDX, occurrence);\n    return this.optionInternalLogic(actionORMethodDef, occurrence, key);\n  }\n\n  optionInternalLogic<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n    key: number,\n  ): OUT | undefined {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action: GrammarAction<OUT>;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    if (lookAheadFunc.call(this) === true) {\n      return action.call(this);\n    }\n    return undefined;\n  }\n\n  atLeastOneInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      AT_LEAST_ONE_IDX,\n      prodOccurrence,\n    );\n    return this.atLeastOneInternalLogic(\n      prodOccurrence,\n      actionORMethodDef,\n      laKey,\n    );\n  }\n\n  atLeastOneInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n    key: number,\n  ): void {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    if ((<Function>lookAheadFunc).call(this) === true) {\n      let notStuck = this.doSingleRepetition(action);\n      while (\n        (<Function>lookAheadFunc).call(this) === true &&\n        notStuck === true\n      ) {\n        notStuck = this.doSingleRepetition(action);\n      }\n    } else {\n      throw this.raiseEarlyExitException(\n        prodOccurrence,\n        PROD_TYPE.REPETITION_MANDATORY,\n        (<DSLMethodOptsWithErr<OUT>>actionORMethodDef).ERR_MSG,\n      );\n    }\n\n    // note that while it may seem that this can cause an error because by using a recursive call to\n    // AT_LEAST_ONE we change the grammar to AT_LEAST_TWO, AT_LEAST_THREE ... , the possible recursive call\n    // from the tryInRepetitionRecovery(...) will only happen IFF there really are TWO/THREE/.... items.\n\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    this.attemptInRepetitionRecovery(\n      this.atLeastOneInternal,\n      [prodOccurrence, actionORMethodDef],\n      <any>lookAheadFunc,\n      AT_LEAST_ONE_IDX,\n      prodOccurrence,\n      NextTerminalAfterAtLeastOneWalker,\n    );\n  }\n\n  atLeastOneSepFirstInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      AT_LEAST_ONE_SEP_IDX,\n      prodOccurrence,\n    );\n    this.atLeastOneSepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n\n  atLeastOneSepFirstInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n    key: number,\n  ): void {\n    const action = options.DEF;\n    const separator = options.SEP;\n\n    const firstIterationLookaheadFunc = this.getLaFuncFromCache(key);\n\n    // 1st iteration\n    if (firstIterationLookaheadFunc.call(this) === true) {\n      (<GrammarAction<OUT>>action).call(this);\n\n      //  TODO: Optimization can move this function construction into \"attemptInRepetitionRecovery\"\n      //  because it is only needed in error recovery scenarios.\n      const separatorLookAheadFunc = () => {\n        return this.tokenMatcher(this.LA(1), separator);\n      };\n\n      // 2nd..nth iterations\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        // note that this CONSUME will never enter recovery because\n        // the separatorLookAheadFunc checks that the separator really does exist.\n        this.CONSUME(separator);\n        // No need for checking infinite loop here due to consuming the separator.\n        (<GrammarAction<OUT>>action).call(this);\n      }\n\n      // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n      this.attemptInRepetitionRecovery(\n        this.repetitionSepSecondInternal,\n        [\n          prodOccurrence,\n          separator,\n          separatorLookAheadFunc,\n          action,\n          NextTerminalAfterAtLeastOneSepWalker,\n        ],\n        separatorLookAheadFunc,\n        AT_LEAST_ONE_SEP_IDX,\n        prodOccurrence,\n        NextTerminalAfterAtLeastOneSepWalker,\n      );\n    } else {\n      throw this.raiseEarlyExitException(\n        prodOccurrence,\n        PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR,\n        options.ERR_MSG,\n      );\n    }\n  }\n\n  manyInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(MANY_IDX, prodOccurrence);\n    return this.manyInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n  }\n\n  manyInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    key: number,\n  ) {\n    let lookaheadFunction = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookaheadFunction;\n        lookaheadFunction = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    let notStuck = true;\n    while (lookaheadFunction.call(this) === true && notStuck === true) {\n      notStuck = this.doSingleRepetition(action);\n    }\n\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    this.attemptInRepetitionRecovery(\n      this.manyInternal,\n      [prodOccurrence, actionORMethodDef],\n      <any>lookaheadFunction,\n      MANY_IDX,\n      prodOccurrence,\n      NextTerminalAfterManyWalker,\n      // The notStuck parameter is only relevant when \"attemptInRepetitionRecovery\"\n      // is invoked from manyInternal, in the MANY_SEP case and AT_LEAST_ONE[_SEP]\n      // An infinite loop cannot occur as:\n      // - Either the lookahead is guaranteed to consume something (Single Token Separator)\n      // - AT_LEAST_ONE by definition is guaranteed to consume something (or error out).\n      notStuck,\n    );\n  }\n\n  manySepFirstInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: ManySepMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      MANY_SEP_IDX,\n      prodOccurrence,\n    );\n    this.manySepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n\n  manySepFirstInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: ManySepMethodOpts<OUT>,\n    key: number,\n  ): void {\n    const action = options.DEF;\n    const separator = options.SEP;\n    const firstIterationLaFunc = this.getLaFuncFromCache(key);\n\n    // 1st iteration\n    if (firstIterationLaFunc.call(this) === true) {\n      action.call(this);\n\n      const separatorLookAheadFunc = () => {\n        return this.tokenMatcher(this.LA(1), separator);\n      };\n      // 2nd..nth iterations\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        // note that this CONSUME will never enter recovery because\n        // the separatorLookAheadFunc checks that the separator really does exist.\n        this.CONSUME(separator);\n        // No need for checking infinite loop here due to consuming the separator.\n        action.call(this);\n      }\n\n      // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n      this.attemptInRepetitionRecovery(\n        this.repetitionSepSecondInternal,\n        [\n          prodOccurrence,\n          separator,\n          separatorLookAheadFunc,\n          action,\n          NextTerminalAfterManySepWalker,\n        ],\n        separatorLookAheadFunc,\n        MANY_SEP_IDX,\n        prodOccurrence,\n        NextTerminalAfterManySepWalker,\n      );\n    }\n  }\n\n  repetitionSepSecondInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    separator: TokenType,\n    separatorLookAheadFunc: () => boolean,\n    action: GrammarAction<OUT>,\n    nextTerminalAfterWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  ): void {\n    while (separatorLookAheadFunc()) {\n      // note that this CONSUME will never enter recovery because\n      // the separatorLookAheadFunc checks that the separator really does exist.\n      this.CONSUME(separator);\n      action.call(this);\n    }\n\n    // we can only arrive to this function after an error\n    // has occurred (hence the name 'second') so the following\n    // IF will always be entered, its possible to remove it...\n    // however it is kept to avoid confusion and be consistent.\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    /* istanbul ignore else */\n    this.attemptInRepetitionRecovery(\n      this.repetitionSepSecondInternal,\n      [\n        prodOccurrence,\n        separator,\n        separatorLookAheadFunc,\n        action,\n        nextTerminalAfterWalker,\n      ],\n      separatorLookAheadFunc,\n      AT_LEAST_ONE_SEP_IDX,\n      prodOccurrence,\n      nextTerminalAfterWalker,\n    );\n  }\n\n  doSingleRepetition(this: MixedInParser, action: Function): any {\n    const beforeIteration = this.getLexerPosition();\n    action.call(this);\n    const afterIteration = this.getLexerPosition();\n\n    // This boolean will indicate if this repetition progressed\n    // or if we are \"stuck\" (potential infinite loop in the repetition).\n    return afterIteration > beforeIteration;\n  }\n\n  orInternal<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n    occurrence: number,\n  ): T {\n    const laKey = this.getKeyForAutomaticLookahead(OR_IDX, occurrence);\n    const alts = isArray(altsOrOpts) ? altsOrOpts : altsOrOpts.DEF;\n\n    const laFunc = this.getLaFuncFromCache(laKey);\n    const altIdxToTake = laFunc.call(this, alts);\n    if (altIdxToTake !== undefined) {\n      const chosenAlternative: any = alts[altIdxToTake];\n      return chosenAlternative.ALT.call(this);\n    }\n    this.raiseNoAltException(\n      occurrence,\n      (altsOrOpts as OrMethodOpts<unknown>).ERR_MSG,\n    );\n  }\n\n  ruleFinallyStateUpdate(this: MixedInParser): void {\n    this.RULE_STACK.pop();\n    this.RULE_OCCURRENCE_STACK.pop();\n\n    // NOOP when cst is disabled\n    this.cstFinallyStateUpdate();\n\n    if (this.RULE_STACK.length === 0 && this.isAtEndOfInput() === false) {\n      const firstRedundantTok = this.LA(1);\n      const errMsg = this.errorMessageProvider.buildNotAllInputParsedMessage({\n        firstRedundant: firstRedundantTok,\n        ruleName: this.getCurrRuleFullName(),\n      });\n      this.SAVE_ERROR(\n        new NotAllInputParsedException(errMsg, firstRedundantTok),\n      );\n    }\n  }\n\n  subruleInternal<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    idx: number,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    let ruleResult;\n    try {\n      const args = options !== undefined ? options.ARGS : undefined;\n      this.subruleIdx = idx;\n      ruleResult = ruleToCall.apply(this, args);\n      this.cstPostNonTerminal(\n        ruleResult,\n        options !== undefined && options.LABEL !== undefined\n          ? options.LABEL\n          : ruleToCall.ruleName,\n      );\n      return ruleResult;\n    } catch (e) {\n      throw this.subruleInternalError(e, options, ruleToCall.ruleName);\n    }\n  }\n\n  subruleInternalError(\n    this: MixedInParser,\n    e: any,\n    options: SubruleMethodOpts<unknown[]> | undefined,\n    ruleName: string,\n  ): void {\n    if (isRecognitionException(e) && e.partialCstResult !== undefined) {\n      this.cstPostNonTerminal(\n        e.partialCstResult,\n        options !== undefined && options.LABEL !== undefined\n          ? options.LABEL\n          : ruleName,\n      );\n\n      delete e.partialCstResult;\n    }\n    throw e;\n  }\n\n  consumeInternal(\n    this: MixedInParser,\n    tokType: TokenType,\n    idx: number,\n    options: ConsumeMethodOpts | undefined,\n  ): IToken {\n    let consumedToken!: IToken;\n    try {\n      const nextToken = this.LA(1);\n      if (this.tokenMatcher(nextToken, tokType) === true) {\n        this.consumeToken();\n        consumedToken = nextToken;\n      } else {\n        this.consumeInternalError(tokType, nextToken, options);\n      }\n    } catch (eFromConsumption) {\n      consumedToken = this.consumeInternalRecovery(\n        tokType,\n        idx,\n        eFromConsumption,\n      );\n    }\n\n    this.cstPostTerminal(\n      options !== undefined && options.LABEL !== undefined\n        ? options.LABEL\n        : tokType.name,\n      consumedToken,\n    );\n    return consumedToken;\n  }\n\n  consumeInternalError(\n    this: MixedInParser,\n    tokType: TokenType,\n    nextToken: IToken,\n    options: ConsumeMethodOpts | undefined,\n  ): void {\n    let msg;\n    const previousToken = this.LA(0);\n    if (options !== undefined && options.ERR_MSG) {\n      msg = options.ERR_MSG;\n    } else {\n      msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: tokType,\n        actual: nextToken,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName(),\n      });\n    }\n    throw this.SAVE_ERROR(\n      new MismatchedTokenException(msg, nextToken, previousToken),\n    );\n  }\n\n  consumeInternalRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    idx: number,\n    eFromConsumption: Error,\n  ): IToken {\n    // no recovery allowed during backtracking, otherwise backtracking may recover invalid syntax and accept it\n    // but the original syntax could have been parsed successfully without any backtracking + recovery\n    if (\n      this.recoveryEnabled &&\n      // TODO: more robust checking of the exception type. Perhaps Typescript extending expressions?\n      eFromConsumption.name === \"MismatchedTokenException\" &&\n      !this.isBackTracking()\n    ) {\n      const follows = this.getFollowsForInRuleRecovery(<any>tokType, idx);\n      try {\n        return this.tryInRuleRecovery(<any>tokType, follows);\n      } catch (eFromInRuleRecovery) {\n        if (eFromInRuleRecovery.name === IN_RULE_RECOVERY_EXCEPTION) {\n          // failed in RuleRecovery.\n          // throw the original error in order to trigger reSync error recovery\n          throw eFromConsumption;\n        } else {\n          throw eFromInRuleRecovery;\n        }\n      }\n    } else {\n      throw eFromConsumption;\n    }\n  }\n\n  saveRecogState(this: MixedInParser): IParserState {\n    // errors is a getter which will clone the errors array\n    const savedErrors = this.errors;\n    const savedRuleStack = clone(this.RULE_STACK);\n    return {\n      errors: savedErrors,\n      lexerState: this.exportLexerState(),\n      RULE_STACK: savedRuleStack,\n      CST_STACK: this.CST_STACK,\n    };\n  }\n\n  reloadRecogState(this: MixedInParser, newState: IParserState) {\n    this.errors = newState.errors;\n    this.importLexerState(newState.lexerState);\n    this.RULE_STACK = newState.RULE_STACK;\n  }\n\n  ruleInvocationStateUpdate(\n    this: MixedInParser,\n    shortName: number,\n    fullName: string,\n    idxInCallingRule: number,\n  ): void {\n    this.RULE_OCCURRENCE_STACK.push(idxInCallingRule);\n    this.RULE_STACK.push(shortName);\n    // NOOP when cst is disabled\n    this.cstInvocationStateUpdate(fullName);\n  }\n\n  isBackTracking(this: MixedInParser): boolean {\n    return this.isBackTrackingStack.length !== 0;\n  }\n\n  getCurrRuleFullName(this: MixedInParser): string {\n    const shortName = this.getLastExplicitRuleShortName();\n    return this.shortRuleNameToFull[shortName];\n  }\n\n  shortRuleNameToFullName(this: MixedInParser, shortName: number) {\n    return this.shortRuleNameToFull[shortName];\n  }\n\n  public isAtEndOfInput(this: MixedInParser): boolean {\n    return this.tokenMatcher(this.LA(1), EOF);\n  }\n\n  public reset(this: MixedInParser): void {\n    this.resetLexerState();\n    this.subruleIdx = 0;\n    this.isBackTrackingStack = [];\n    this.errors = [];\n    this.RULE_STACK = [];\n    // TODO: extract a specific reset for TreeBuilder trait\n    this.CST_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n  }\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IRuleConfig,\n  ISerializedGast,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  SubruleMethodOpts,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { includes, values } from \"lodash-es\";\nimport { isRecognitionException } from \"../../exceptions_public.js\";\nimport { DEFAULT_RULE_CONFIG, ParserDefinitionErrorType } from \"../parser.js\";\nimport { defaultGrammarValidatorErrorProvider } from \"../../errors_public.js\";\nimport { validateRuleIsOverridden } from \"../../grammar/checks.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { Rule, serializeGrammar } from \"@chevrotain/gast\";\nimport { IParserDefinitionError } from \"../../grammar/types.js\";\nimport { ParserMethodInternal } from \"../types.js\";\n\n/**\n * This trait is responsible for implementing the public API\n * for defining Chevrotain parsers, i.e:\n * - CONSUME\n * - RULE\n * - OPTION\n * - ...\n */\nexport class RecognizerApi {\n  ACTION<T>(this: MixedInParser, impl: () => T): T {\n    return impl.call(this);\n  }\n\n  consume(\n    this: MixedInParser,\n    idx: number,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, idx, options);\n  }\n\n  subrule<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    idx: number,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, idx, options);\n  }\n\n  option<OUT>(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, idx);\n  }\n\n  or(\n    this: MixedInParser,\n    idx: number,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<any>,\n  ): any {\n    return this.orInternal(altsOrOpts, idx);\n  }\n\n  many(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<any> | DSLMethodOpts<any>,\n  ): void {\n    return this.manyInternal(idx, actionORMethodDef);\n  }\n\n  atLeastOne(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<any> | DSLMethodOptsWithErr<any>,\n  ): void {\n    return this.atLeastOneInternal(idx, actionORMethodDef);\n  }\n\n  CONSUME(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 0, options);\n  }\n\n  CONSUME1(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 1, options);\n  }\n\n  CONSUME2(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 2, options);\n  }\n\n  CONSUME3(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 3, options);\n  }\n\n  CONSUME4(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 4, options);\n  }\n\n  CONSUME5(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 5, options);\n  }\n\n  CONSUME6(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 6, options);\n  }\n\n  CONSUME7(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 7, options);\n  }\n\n  CONSUME8(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 8, options);\n  }\n\n  CONSUME9(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 9, options);\n  }\n\n  SUBRULE<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 0, options);\n  }\n\n  SUBRULE1<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 1, options);\n  }\n\n  SUBRULE2<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 2, options);\n  }\n\n  SUBRULE3<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 3, options);\n  }\n\n  SUBRULE4<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 4, options);\n  }\n\n  SUBRULE5<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 5, options);\n  }\n\n  SUBRULE6<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 6, options);\n  }\n\n  SUBRULE7<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 7, options);\n  }\n\n  SUBRULE8<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 8, options);\n  }\n\n  SUBRULE9<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 9, options);\n  }\n\n  OPTION<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 0);\n  }\n\n  OPTION1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 1);\n  }\n\n  OPTION2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 2);\n  }\n\n  OPTION3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 3);\n  }\n\n  OPTION4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 4);\n  }\n\n  OPTION5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 5);\n  }\n\n  OPTION6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 6);\n  }\n\n  OPTION7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 7);\n  }\n\n  OPTION8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 8);\n  }\n\n  OPTION9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 9);\n  }\n\n  OR<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 0);\n  }\n\n  OR1<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 1);\n  }\n\n  OR2<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 2);\n  }\n\n  OR3<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 3);\n  }\n\n  OR4<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 4);\n  }\n\n  OR5<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 5);\n  }\n\n  OR6<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 6);\n  }\n\n  OR7<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 7);\n  }\n\n  OR8<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 8);\n  }\n\n  OR9<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 9);\n  }\n\n  MANY<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(0, actionORMethodDef);\n  }\n\n  MANY1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(1, actionORMethodDef);\n  }\n\n  MANY2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(2, actionORMethodDef);\n  }\n\n  MANY3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(3, actionORMethodDef);\n  }\n\n  MANY4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(4, actionORMethodDef);\n  }\n\n  MANY5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(5, actionORMethodDef);\n  }\n\n  MANY6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(6, actionORMethodDef);\n  }\n\n  MANY7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(7, actionORMethodDef);\n  }\n\n  MANY8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(8, actionORMethodDef);\n  }\n\n  MANY9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(9, actionORMethodDef);\n  }\n\n  MANY_SEP<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(0, options);\n  }\n\n  MANY_SEP1<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(1, options);\n  }\n\n  MANY_SEP2<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(2, options);\n  }\n\n  MANY_SEP3<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(3, options);\n  }\n\n  MANY_SEP4<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(4, options);\n  }\n\n  MANY_SEP5<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(5, options);\n  }\n\n  MANY_SEP6<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(6, options);\n  }\n\n  MANY_SEP7<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(7, options);\n  }\n\n  MANY_SEP8<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(8, options);\n  }\n\n  MANY_SEP9<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(9, options);\n  }\n\n  AT_LEAST_ONE<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(0, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    return this.atLeastOneInternal(1, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(2, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(3, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(4, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(5, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(6, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(7, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(8, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(9, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE_SEP<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(0, options);\n  }\n\n  AT_LEAST_ONE_SEP1<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(1, options);\n  }\n\n  AT_LEAST_ONE_SEP2<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(2, options);\n  }\n\n  AT_LEAST_ONE_SEP3<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(3, options);\n  }\n\n  AT_LEAST_ONE_SEP4<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(4, options);\n  }\n\n  AT_LEAST_ONE_SEP5<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(5, options);\n  }\n\n  AT_LEAST_ONE_SEP6<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(6, options);\n  }\n\n  AT_LEAST_ONE_SEP7<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(7, options);\n  }\n\n  AT_LEAST_ONE_SEP8<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(8, options);\n  }\n\n  AT_LEAST_ONE_SEP9<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(9, options);\n  }\n\n  RULE<T>(\n    this: MixedInParser,\n    name: string,\n    implementation: (...implArgs: any[]) => T,\n    config: IRuleConfig<T> = DEFAULT_RULE_CONFIG,\n  ): (idxInCallingRule?: number, ...args: any[]) => T | any {\n    if (includes(this.definedRulesNames, name)) {\n      const errMsg =\n        defaultGrammarValidatorErrorProvider.buildDuplicateRuleNameError({\n          topLevelRule: name,\n          grammarName: this.className,\n        });\n\n      const error = {\n        message: errMsg,\n        type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n        ruleName: name,\n      };\n      this.definitionErrors.push(error);\n    }\n\n    this.definedRulesNames.push(name);\n\n    const ruleImplementation = this.defineRule(name, implementation, config);\n    (this as any)[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n\n  OVERRIDE_RULE<T>(\n    this: MixedInParser,\n    name: string,\n    impl: (...implArgs: any[]) => T,\n    config: IRuleConfig<T> = DEFAULT_RULE_CONFIG,\n  ): (idxInCallingRule?: number, ...args: any[]) => T {\n    const ruleErrors: IParserDefinitionError[] = validateRuleIsOverridden(\n      name,\n      this.definedRulesNames,\n      this.className,\n    );\n    this.definitionErrors = this.definitionErrors.concat(ruleErrors);\n\n    const ruleImplementation = this.defineRule(name, impl, config);\n    (this as any)[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n\n  BACKTRACK<T>(\n    this: MixedInParser,\n    grammarRule: (...args: any[]) => T,\n    args?: any[],\n  ): () => boolean {\n    return function () {\n      // save org state\n      this.isBackTrackingStack.push(1);\n      const orgState = this.saveRecogState();\n      try {\n        grammarRule.apply(this, args);\n        // if no exception was thrown we have succeed parsing the rule.\n        return true;\n      } catch (e) {\n        if (isRecognitionException(e)) {\n          return false;\n        } else {\n          throw e;\n        }\n      } finally {\n        this.reloadRecogState(orgState);\n        this.isBackTrackingStack.pop();\n      }\n    };\n  }\n\n  // GAST export APIs\n  public getGAstProductions(this: MixedInParser): Record<string, Rule> {\n    return this.gastProductionsCache;\n  }\n\n  public getSerializedGastProductions(this: MixedInParser): ISerializedGast[] {\n    return serializeGrammar(values(this.gastProductionsCache));\n  }\n}\n","import {\n  IParserConfig,\n  IParserErrorMessageProvider,\n  IRecognitionException,\n} from \"@chevrotain/types\";\nimport {\n  EarlyExitException,\n  isRecognitionException,\n  NoViableAltException,\n} from \"../../exceptions_public.js\";\nimport { clone, has } from \"lodash-es\";\nimport {\n  getLookaheadPathsForOptionalProd,\n  getLookaheadPathsForOr,\n  PROD_TYPE,\n} from \"../../grammar/lookahead.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class ErrorHandler {\n  _errors: IRecognitionException[];\n  errorMessageProvider: IParserErrorMessageProvider;\n\n  initErrorHandler(config: IParserConfig) {\n    this._errors = [];\n    this.errorMessageProvider = has(config, \"errorMessageProvider\")\n      ? (config.errorMessageProvider as IParserErrorMessageProvider) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.errorMessageProvider;\n  }\n\n  SAVE_ERROR(\n    this: MixedInParser,\n    error: IRecognitionException,\n  ): IRecognitionException {\n    if (isRecognitionException(error)) {\n      error.context = {\n        ruleStack: this.getHumanReadableRuleStack(),\n        ruleOccurrenceStack: clone(this.RULE_OCCURRENCE_STACK),\n      };\n      this._errors.push(error);\n      return error;\n    } else {\n      throw Error(\n        \"Trying to save an Error which is not a RecognitionException\",\n      );\n    }\n  }\n\n  get errors(): IRecognitionException[] {\n    return clone(this._errors);\n  }\n\n  set errors(newErrors: IRecognitionException[]) {\n    this._errors = newErrors;\n  }\n\n  // TODO: consider caching the error message computed information\n  raiseEarlyExitException(\n    this: MixedInParser,\n    occurrence: number,\n    prodType: PROD_TYPE,\n    userDefinedErrMsg: string | undefined,\n  ): never {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOptionalProd(\n      occurrence,\n      ruleGrammar,\n      prodType,\n      this.maxLookahead,\n    );\n    const insideProdPaths = lookAheadPathsPerAlternative[0];\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const msg = this.errorMessageProvider.buildEarlyExitMessage({\n      expectedIterationPaths: insideProdPaths,\n      actual: actualTokens,\n      previous: this.LA(0),\n      customUserDescription: userDefinedErrMsg,\n      ruleName: ruleName,\n    });\n\n    throw this.SAVE_ERROR(new EarlyExitException(msg, this.LA(1), this.LA(0)));\n  }\n\n  // TODO: consider caching the error message computed information\n  raiseNoAltException(\n    this: MixedInParser,\n    occurrence: number,\n    errMsgTypes: string | undefined,\n  ): never {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    // TODO: getLookaheadPathsForOr can be slow for large enough maxLookahead and certain grammars, consider caching ?\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOr(\n      occurrence,\n      ruleGrammar,\n      this.maxLookahead,\n    );\n\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const previousToken = this.LA(0);\n\n    const errMsg = this.errorMessageProvider.buildNoViableAltMessage({\n      expectedPathsPerAlt: lookAheadPathsPerAlternative,\n      actual: actualTokens,\n      previous: previousToken,\n      customUserDescription: errMsgTypes,\n      ruleName: this.getCurrRuleFullName(),\n    });\n\n    throw this.SAVE_ERROR(\n      new NoViableAltException(errMsg, this.LA(1), previousToken),\n    );\n  }\n}\n","import {\n  ISyntacticContentAssistPath,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  NextAfterTokenWalker,\n  nextPossibleTokensAfter,\n} from \"../../grammar/interpreter.js\";\nimport { first, isUndefined } from \"lodash-es\";\nimport { MixedInParser } from \"./parser_traits.js\";\n\nexport class ContentAssist {\n  initContentAssist() {}\n\n  public computeContentAssist(\n    this: MixedInParser,\n    startRuleName: string,\n    precedingInput: IToken[],\n  ): ISyntacticContentAssistPath[] {\n    const startRuleGast = this.gastProductionsCache[startRuleName];\n\n    if (isUndefined(startRuleGast)) {\n      throw Error(`Rule ->${startRuleName}<- does not exist in this grammar.`);\n    }\n\n    return nextPossibleTokensAfter(\n      [startRuleGast],\n      precedingInput,\n      this.tokenMatcher,\n      this.maxLookahead,\n    );\n  }\n\n  // TODO: should this be a member method or a utility? it does not have any state or usage of 'this'...\n  // TODO: should this be more explicitly part of the public API?\n  public getNextPossibleTokenTypes(\n    this: MixedInParser,\n    grammarPath: ITokenGrammarPath,\n  ): TokenType[] {\n    const topRuleName = first(grammarPath.ruleStack)!;\n    const gastProductions = this.getGAstProductions();\n    const topProduction = gastProductions[topRuleName];\n    const nextPossibleTokenTypes = new NextAfterTokenWalker(\n      topProduction,\n      grammarPath,\n    ).startWalking();\n    return nextPossibleTokenTypes;\n  }\n}\n","import { IParserConfig } from \"@chevrotain/types\";\nimport { has } from \"lodash-es\";\nimport { timer } from \"@chevrotain/utils\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class PerformanceTracer {\n  traceInitPerf: boolean | number;\n  traceInitMaxIdent: number;\n  traceInitIndent: number;\n\n  initPerformanceTracer(config: IParserConfig) {\n    if (has(config, \"traceInitPerf\")) {\n      const userTraceInitPerf = config.traceInitPerf;\n      const traceIsNumber = typeof userTraceInitPerf === \"number\";\n      this.traceInitMaxIdent = traceIsNumber\n        ? <number>userTraceInitPerf\n        : Infinity;\n      this.traceInitPerf = traceIsNumber\n        ? userTraceInitPerf > 0\n        : (userTraceInitPerf as boolean); // assumes end user provides the correct config value/type\n    } else {\n      this.traceInitMaxIdent = 0;\n      this.traceInitPerf = DEFAULT_PARSER_CONFIG.traceInitPerf;\n    }\n\n    this.traceInitIndent = -1;\n  }\n\n  TRACE_INIT<T>(this: MixedInParser, phaseDesc: string, phaseImpl: () => T): T {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++;\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`);\n      }\n      const { time, value } = timer(phaseImpl);\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log;\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n      }\n      this.traceInitIndent--;\n      return value;\n    } else {\n      return phaseImpl();\n    }\n  }\n}\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport map from \"lodash-es/map.js\"\r\nimport filter from \"lodash-es/filter.js\"\r\nimport {\r\n    IProduction,\r\n    IProductionWithOccurrence,\r\n    TokenType,\r\n    Alternation,\r\n    NonTerminal,\r\n    Rule,\r\n    Option,\r\n    RepetitionMandatory,\r\n    Repetition,\r\n    Terminal,\r\n    Alternative,\r\n    RepetitionWithSeparator,\r\n    RepetitionMandatoryWithSeparator,\r\n    LookaheadProductionType\r\n} from \"chevrotain\"\r\n\r\nexport function buildATNKey(rule: Rule, type: LookaheadProductionType, occurrence: number): string {\r\n    return `${rule.name}_${type}_${occurrence}`;\r\n}\r\n\r\nexport interface ATN {\r\n    decisionMap: Record<string, DecisionState>\r\n    states: ATNState[]\r\n    decisionStates: DecisionState[]\r\n    ruleToStartState: Map<Rule, RuleStartState>\r\n    ruleToStopState: Map<Rule, RuleStopState>\r\n}\r\n\r\nexport const ATN_INVALID_TYPE = 0\r\nexport const ATN_BASIC = 1\r\nexport const ATN_RULE_START = 2\r\nexport const ATN_PLUS_BLOCK_START = 4\r\nexport const ATN_STAR_BLOCK_START = 5\r\n// Currently unused as the ATN is not used for lexing\r\nexport const ATN_TOKEN_START = 6\r\nexport const ATN_RULE_STOP = 7\r\nexport const ATN_BLOCK_END = 8\r\nexport const ATN_STAR_LOOP_BACK = 9\r\nexport const ATN_STAR_LOOP_ENTRY = 10\r\nexport const ATN_PLUS_LOOP_BACK = 11\r\nexport const ATN_LOOP_END = 12\r\n\r\nexport type ATNState =\r\n    | BasicState\r\n    | BasicBlockStartState\r\n    | PlusBlockStartState\r\n    | PlusLoopbackState\r\n    | StarBlockStartState\r\n    | StarLoopbackState\r\n    | StarLoopEntryState\r\n    | BlockEndState\r\n    | RuleStartState\r\n    | RuleStopState\r\n    | LoopEndState\r\n\r\nexport interface ATNBaseState {\r\n    atn: ATN\r\n    production: IProductionWithOccurrence\r\n    stateNumber: number\r\n    rule: Rule\r\n    epsilonOnlyTransitions: boolean\r\n    transitions: Transition[]\r\n    nextTokenWithinRule: number[]\r\n}\r\n\r\nexport interface BasicState extends ATNBaseState {\r\n    type: typeof ATN_BASIC\r\n}\r\n\r\nexport interface BlockStartState extends DecisionState {\r\n    end: BlockEndState\r\n}\r\n\r\nexport interface BasicBlockStartState extends BlockStartState {\r\n    type: typeof ATN_BASIC\r\n}\r\n\r\nexport interface PlusBlockStartState extends BlockStartState {\r\n    loopback: PlusLoopbackState\r\n    type: typeof ATN_PLUS_BLOCK_START\r\n}\r\n\r\nexport interface PlusLoopbackState extends DecisionState {\r\n    type: typeof ATN_PLUS_LOOP_BACK\r\n}\r\n\r\nexport interface StarBlockStartState extends BlockStartState {\r\n    type: typeof ATN_STAR_BLOCK_START\r\n}\r\n\r\nexport interface StarLoopbackState extends ATNBaseState {\r\n    type: typeof ATN_STAR_LOOP_BACK\r\n}\r\n\r\nexport interface StarLoopEntryState extends DecisionState {\r\n    loopback: StarLoopbackState\r\n    type: typeof ATN_STAR_LOOP_ENTRY\r\n}\r\n\r\nexport interface BlockEndState extends ATNBaseState {\r\n    start: BlockStartState\r\n    type: typeof ATN_BLOCK_END\r\n}\r\n\r\nexport interface DecisionState extends ATNBaseState {\r\n    decision: number\r\n}\r\n\r\nexport interface LoopEndState extends ATNBaseState {\r\n    loopback: ATNState\r\n    type: typeof ATN_LOOP_END\r\n}\r\n\r\nexport interface RuleStartState extends ATNBaseState {\r\n    stop: RuleStopState\r\n    type: typeof ATN_RULE_START\r\n}\r\n\r\nexport interface RuleStopState extends ATNBaseState {\r\n    type: typeof ATN_RULE_STOP\r\n}\r\n\r\nexport interface Transition {\r\n    target: ATNState\r\n    isEpsilon(): boolean\r\n}\r\n\r\nexport abstract class AbstractTransition implements Transition {\r\n    target: ATNState\r\n\r\n    constructor(target: ATNState) {\r\n        this.target = target\r\n    }\r\n\r\n    isEpsilon() {\r\n        return false\r\n    }\r\n}\r\n\r\nexport class AtomTransition extends AbstractTransition {\r\n    tokenType: TokenType\r\n\r\n    constructor(target: ATNState, tokenType: TokenType) {\r\n        super(target)\r\n        this.tokenType = tokenType\r\n    }\r\n}\r\n\r\nexport class EpsilonTransition extends AbstractTransition {\r\n    constructor(target: ATNState) {\r\n        super(target)\r\n    }\r\n\r\n    isEpsilon() {\r\n        return true\r\n    }\r\n}\r\n\r\nexport class RuleTransition extends AbstractTransition {\r\n    rule: Rule\r\n    followState: ATNState\r\n\r\n    constructor(ruleStart: RuleStartState, rule: Rule, followState: ATNState) {\r\n        super(ruleStart)\r\n        this.rule = rule\r\n        this.followState = followState\r\n    }\r\n\r\n    isEpsilon() {\r\n        return true\r\n    }\r\n}\r\n\r\ninterface ATNHandle {\r\n    left: ATNState\r\n    right: ATNState\r\n}\r\n\r\nexport function createATN(rules: Rule[]): ATN {\r\n    const atn: ATN = {\r\n        decisionMap: {},\r\n        decisionStates: [],\r\n        ruleToStartState: new Map(),\r\n        ruleToStopState: new Map(),\r\n        states: []\r\n    }\r\n    createRuleStartAndStopATNStates(atn, rules)\r\n    const ruleLength = rules.length\r\n    for (let i = 0; i < ruleLength; i++) {\r\n        const rule = rules[i]\r\n        const ruleBlock = block(atn, rule, rule)\r\n        if (ruleBlock === undefined) {\r\n            continue\r\n        }\r\n        buildRuleHandle(atn, rule, ruleBlock)\r\n    }\r\n    return atn\r\n}\r\n\r\nfunction createRuleStartAndStopATNStates(atn: ATN, rules: Rule[]): void {\r\n    const ruleLength = rules.length\r\n    for (let i = 0; i < ruleLength; i++) {\r\n        const rule = rules[i]\r\n        const start = newState<RuleStartState>(atn, rule, undefined, {\r\n            type: ATN_RULE_START\r\n        })\r\n        const stop = newState<RuleStopState>(atn, rule, undefined, {\r\n            type: ATN_RULE_STOP\r\n        })\r\n        start.stop = stop\r\n        atn.ruleToStartState.set(rule, start)\r\n        atn.ruleToStopState.set(rule, stop)\r\n    }\r\n}\r\n\r\nfunction atom(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    production: IProduction\r\n): ATNHandle | undefined {\r\n    if (production instanceof Terminal) {\r\n        return tokenRef(atn, rule, production.terminalType, production)\r\n    } else if (production instanceof NonTerminal) {\r\n        return ruleRef(atn, rule, production)\r\n    } else if (production instanceof Alternation) {\r\n        return alternation(atn, rule, production)\r\n    } else if (production instanceof Option) {\r\n        return option(atn, rule, production)\r\n    } else if (production instanceof Repetition) {\r\n        return repetition(atn, rule, production)\r\n    } else if (production instanceof RepetitionWithSeparator) {\r\n        return repetitionSep(atn, rule, production)\r\n    } else if (production instanceof RepetitionMandatory) {\r\n        return repetitionMandatory(atn, rule, production)\r\n    } else if (production instanceof RepetitionMandatoryWithSeparator) {\r\n        return repetitionMandatorySep(atn, rule, production)\r\n    } else {\r\n        return block(atn, rule, production as Alternative)\r\n    }\r\n}\r\n\r\nfunction repetition(atn: ATN, rule: Rule, repetition: Repetition): ATNHandle {\r\n    const starState = newState<StarBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_STAR_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, starState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        starState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    return star(atn, rule, repetition, handle)\r\n}\r\n\r\nfunction repetitionSep(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    repetition: RepetitionWithSeparator\r\n): ATNHandle {\r\n    const starState = newState<StarBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_STAR_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, starState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        starState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    const sep = tokenRef(atn, rule, repetition.separator, repetition)\r\n    return star(atn, rule, repetition, handle, sep)\r\n}\r\n\r\nfunction repetitionMandatory(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    repetition: RepetitionMandatory\r\n): ATNHandle {\r\n    const plusState = newState<PlusBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_PLUS_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, plusState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        plusState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    return plus(atn, rule, repetition, handle)\r\n}\r\n\r\nfunction repetitionMandatorySep(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    repetition: RepetitionMandatoryWithSeparator\r\n): ATNHandle {\r\n    const plusState = newState<PlusBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_PLUS_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, plusState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        plusState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    const sep = tokenRef(atn, rule, repetition.separator, repetition)\r\n    return plus(atn, rule, repetition, handle, sep)\r\n}\r\n\r\nfunction alternation(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    alternation: Alternation\r\n): ATNHandle {\r\n    const start = newState<BasicBlockStartState>(atn, rule, alternation, {\r\n        type: ATN_BASIC\r\n    })\r\n    defineDecisionState(atn, start)\r\n    const alts = map(alternation.definition, (e) => atom(atn, rule, e))\r\n    const handle = makeAlts(atn, rule, start, alternation, ...alts)\r\n    return handle\r\n}\r\n\r\nfunction option(atn: ATN, rule: Rule, option: Option): ATNHandle {\r\n    const start = newState<BasicBlockStartState>(atn, rule, option, {\r\n        type: ATN_BASIC\r\n    })\r\n    defineDecisionState(atn, start)\r\n    const handle = makeAlts(atn, rule, start, option, block(atn, rule, option))\r\n    return optional(atn, rule, option, handle)\r\n}\r\n\r\nfunction block(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    block: { definition: IProduction[] }\r\n): ATNHandle | undefined {\r\n    const handles = filter(\r\n        map(block.definition, (e) => atom(atn, rule, e)),\r\n        (e) => e !== undefined\r\n    ) as ATNHandle[]\r\n    if (handles.length === 1) {\r\n        return handles[0]\r\n    } else if (handles.length === 0) {\r\n        return undefined\r\n    } else {\r\n        return makeBlock(atn, handles)\r\n    }\r\n}\r\n\r\nfunction plus(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    plus: IProductionWithOccurrence,\r\n    handle: ATNHandle,\r\n    sep?: ATNHandle\r\n): ATNHandle {\r\n    const blkStart = handle.left as PlusBlockStartState\r\n    const blkEnd = handle.right\r\n\r\n    const loop = newState<PlusLoopbackState>(atn, rule, plus, {\r\n        type: ATN_PLUS_LOOP_BACK\r\n    })\r\n    defineDecisionState(atn, loop)\r\n    const end = newState<LoopEndState>(atn, rule, plus, {\r\n        type: ATN_LOOP_END\r\n    })\r\n    blkStart.loopback = loop\r\n    end.loopback = loop\r\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionMandatoryWithSeparator' : 'RepetitionMandatory', plus.idx)] = loop;\r\n    epsilon(blkEnd, loop) // block can see loop back\r\n\r\n    // Depending on whether we have a separator we put the exit transition at index 1 or 0\r\n    // This influences the chosen option in the lookahead DFA\r\n    if (sep === undefined) {\r\n        epsilon(loop, blkStart) // loop back to start\r\n        epsilon(loop, end) // exit\r\n    } else {\r\n        epsilon(loop, end) // exit\r\n        // loop back to start with separator\r\n        epsilon(loop, sep.left)\r\n        epsilon(sep.right, blkStart)\r\n    }\r\n\r\n    return {\r\n        left: blkStart,\r\n        right: end\r\n    }\r\n}\r\n\r\nfunction star(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    star: IProductionWithOccurrence,\r\n    handle: ATNHandle,\r\n    sep?: ATNHandle\r\n): ATNHandle {\r\n    const start = handle.left\r\n    const end = handle.right\r\n\r\n    const entry = newState<StarLoopEntryState>(atn, rule, star, {\r\n        type: ATN_STAR_LOOP_ENTRY\r\n    })\r\n    defineDecisionState(atn, entry)\r\n    const loopEnd = newState<LoopEndState>(atn, rule, star, {\r\n        type: ATN_LOOP_END\r\n    })\r\n    const loop = newState<StarLoopbackState>(atn, rule, star, {\r\n        type: ATN_STAR_LOOP_BACK\r\n    })\r\n    entry.loopback = loop\r\n    loopEnd.loopback = loop\r\n\r\n    epsilon(entry, start) // loop enter edge (alt 2)\r\n    epsilon(entry, loopEnd) // bypass loop edge (alt 1)\r\n    epsilon(end, loop) // block end hits loop back\r\n\r\n    if (sep !== undefined) {\r\n        epsilon(loop, loopEnd) // end loop\r\n        // loop back to start of handle using separator\r\n        epsilon(loop, sep.left)\r\n        epsilon(sep.right, start)\r\n    } else {\r\n        epsilon(loop, entry) // loop back to entry/exit decision\r\n    }\r\n\r\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionWithSeparator' : 'Repetition', star.idx)] = entry;\r\n    return {\r\n        left: entry,\r\n        right: loopEnd\r\n    }\r\n}\r\n\r\nfunction optional(atn: ATN, rule: Rule, optional: Option, handle: ATNHandle): ATNHandle {\r\n    const start = handle.left as DecisionState\r\n    const end = handle.right\r\n\r\n    epsilon(start, end)\r\n\r\n    atn.decisionMap[buildATNKey(rule, 'Option', optional.idx)] = start;\r\n    return handle\r\n}\r\n\r\nfunction defineDecisionState(atn: ATN, state: DecisionState): number {\r\n    atn.decisionStates.push(state)\r\n    state.decision = atn.decisionStates.length - 1\r\n    return state.decision\r\n}\r\n\r\nfunction makeAlts(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    start: BlockStartState,\r\n    production: IProductionWithOccurrence,\r\n    ...alts: (ATNHandle | undefined)[]\r\n): ATNHandle {\r\n    const end = newState<BlockEndState>(atn, rule, production, {\r\n        type: ATN_BLOCK_END,\r\n        start\r\n    })\r\n    start.end = end\r\n    for (const alt of alts) {\r\n        if (alt !== undefined) {\r\n            // hook alts up to decision block\r\n            epsilon(start, alt.left)\r\n            epsilon(alt.right, end)\r\n        } else {\r\n            epsilon(start, end)\r\n        }\r\n    }\r\n\r\n    const handle: ATNHandle = {\r\n        left: start as ATNState,\r\n        right: end\r\n    }\r\n    atn.decisionMap[buildATNKey(rule, getProdType(production), production.idx)] = start\r\n    return handle\r\n}\r\n\r\nfunction getProdType(production: IProduction): LookaheadProductionType {\r\n    if (production instanceof Alternation) {\r\n        return 'Alternation';\r\n    } else if (production instanceof Option) {\r\n        return 'Option';\r\n    } else if (production instanceof Repetition) {\r\n        return 'Repetition';\r\n    } else if (production instanceof RepetitionWithSeparator) {\r\n        return 'RepetitionWithSeparator';\r\n    } else if (production instanceof RepetitionMandatory) {\r\n        return 'RepetitionMandatory';\r\n    } else if (production instanceof RepetitionMandatoryWithSeparator) {\r\n        return 'RepetitionMandatoryWithSeparator';\r\n    } else {\r\n        throw new Error('Invalid production type encountered');\r\n    }\r\n}\r\n\r\nfunction makeBlock(atn: ATN, alts: ATNHandle[]): ATNHandle {\r\n    const altsLength = alts.length\r\n    for (let i = 0; i < altsLength - 1; i++) {\r\n        const handle = alts[i]\r\n        let transition: Transition | undefined\r\n        if (handle.left.transitions.length === 1) {\r\n            transition = handle.left.transitions[0]\r\n        }\r\n        const isRuleTransition = transition instanceof RuleTransition\r\n        const ruleTransition = transition as RuleTransition\r\n        const next = alts[i + 1].left\r\n        if (\r\n            handle.left.type === ATN_BASIC &&\r\n            handle.right.type === ATN_BASIC &&\r\n            transition !== undefined &&\r\n            ((isRuleTransition && ruleTransition.followState === handle.right) ||\r\n                transition.target === handle.right)\r\n        ) {\r\n            // we can avoid epsilon edge to next element\r\n            if (isRuleTransition) {\r\n                ruleTransition.followState = next\r\n            } else {\r\n                transition.target = next\r\n            }\r\n            removeState(atn, handle.right) // we skipped over this state\r\n        } else {\r\n            // need epsilon if previous block's right end node is complex\r\n            epsilon(handle.right, next)\r\n        }\r\n    }\r\n\r\n    const first = alts[0]\r\n    const last = alts[altsLength - 1]\r\n    return {\r\n        left: first.left,\r\n        right: last.right\r\n    }\r\n}\r\n\r\nfunction tokenRef(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    tokenType: TokenType,\r\n    production: IProductionWithOccurrence\r\n): ATNHandle {\r\n    const left = newState<BasicState>(atn, rule, production, {\r\n        type: ATN_BASIC\r\n    })\r\n    const right = newState<BasicState>(atn, rule, production, {\r\n        type: ATN_BASIC\r\n    })\r\n    addTransition(left, new AtomTransition(right, tokenType))\r\n    return {\r\n        left,\r\n        right\r\n    }\r\n}\r\n\r\nfunction ruleRef(\r\n    atn: ATN,\r\n    currentRule: Rule,\r\n    nonTerminal: NonTerminal\r\n): ATNHandle {\r\n    const rule = nonTerminal.referencedRule\r\n    const start = atn.ruleToStartState.get(rule)!\r\n    const left = newState<BasicBlockStartState>(atn, currentRule, nonTerminal, {\r\n        type: ATN_BASIC\r\n    })\r\n    const right = newState<BasicBlockStartState>(atn, currentRule, nonTerminal, {\r\n        type: ATN_BASIC\r\n    })\r\n\r\n    const call = new RuleTransition(start, rule, right)\r\n    addTransition(left, call)\r\n\r\n    return {\r\n        left,\r\n        right\r\n    }\r\n}\r\n\r\nfunction buildRuleHandle(atn: ATN, rule: Rule, block: ATNHandle): ATNHandle {\r\n    const start = atn.ruleToStartState.get(rule)!\r\n    epsilon(start, block.left)\r\n    const stop = atn.ruleToStopState.get(rule)!\r\n    epsilon(block.right, stop)\r\n    const handle: ATNHandle = {\r\n        left: start,\r\n        right: stop\r\n    }\r\n    return handle\r\n}\r\n\r\nfunction epsilon(a: ATNBaseState, b: ATNBaseState): void {\r\n    const transition = new EpsilonTransition(b as ATNState)\r\n    addTransition(a, transition)\r\n}\r\n\r\nfunction newState<T extends ATNState>(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    production: IProductionWithOccurrence | undefined,\r\n    partial: Partial<T>\r\n): T {\r\n    const t: T = {\r\n        atn,\r\n        production,\r\n        epsilonOnlyTransitions: false,\r\n        rule,\r\n        transitions: [],\r\n        nextTokenWithinRule: [],\r\n        stateNumber: atn.states.length,\r\n        ...partial\r\n    } as unknown as T\r\n    atn.states.push(t)\r\n    return t\r\n}\r\n\r\nfunction addTransition(state: ATNBaseState, transition: Transition) {\r\n    // A single ATN state can only contain epsilon transitions or non-epsilon transitions\r\n    // Because they are never mixed, only setting the property for the first transition is fine\r\n    if (state.transitions.length === 0) {\r\n        state.epsilonOnlyTransitions = transition.isEpsilon()\r\n    }\r\n    state.transitions.push(transition)\r\n}\r\n\r\nfunction removeState(atn: ATN, state: ATNState): void {\r\n    atn.states.splice(atn.states.indexOf(state), 1)\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport map from \"lodash-es/map.js\"\r\nimport { ATNState, DecisionState } from \"./atn.js\"\r\n\r\nexport interface DFA {\r\n  start?: DFAState\r\n  states: Record<string, DFAState>\r\n  decision: number\r\n  atnStartState: DecisionState\r\n}\r\n\r\nexport interface DFAState {\r\n  configs: ATNConfigSet\r\n  edges: Record<number, DFAState>\r\n  isAcceptState: boolean\r\n  prediction: number\r\n}\r\n\r\nexport const DFA_ERROR = {} as DFAState\r\n\r\nexport interface ATNConfig {\r\n  state: ATNState\r\n  alt: number\r\n  stack: ATNState[]\r\n}\r\n\r\nexport class ATNConfigSet {\r\n  private map: Record<string, number> = {}\r\n  private configs: ATNConfig[] = []\r\n\r\n  uniqueAlt: number | undefined\r\n\r\n  get size(): number {\r\n    return this.configs.length\r\n  }\r\n\r\n  finalize(): void {\r\n    // Empties the map to free up memory\r\n    this.map = {}\r\n  }\r\n\r\n  add(config: ATNConfig): void {\r\n    const key = getATNConfigKey(config)\r\n    // Only add configs which don't exist in our map already\r\n    // While this does not influence the actual algorithm, adding them anyway would massively increase memory consumption\r\n    if (!(key in this.map)) {\r\n      this.map[key] = this.configs.length\r\n      this.configs.push(config)\r\n    }\r\n  }\r\n\r\n  get elements(): readonly ATNConfig[] {\r\n    return this.configs\r\n  }\r\n\r\n  get alts(): number[] {\r\n    return map(this.configs, (e) => e.alt)\r\n  }\r\n\r\n  get key(): string {\r\n    let value = \"\"\r\n    for (const k in this.map) {\r\n      value += k + \":\"\r\n    }\r\n    return value\r\n  }\r\n}\r\n\r\nexport function getATNConfigKey(config: ATNConfig, alt = true) {\r\n  return `${alt ? `a${config.alt}` : \"\"}s${\r\n    config.state.stateNumber\r\n  }:${config.stack.map((e) => e.stateNumber.toString()).join(\"_\")}`\r\n}\r\n","import baseIteratee from './_baseIteratee.js';\nimport baseUniq from './_baseUniq.js';\n\n/**\n * This method is like `_.uniq` except that it accepts `iteratee` which is\n * invoked for each element in `array` to generate the criterion by which\n * uniqueness is computed. The order of result values is determined by the\n * order they occur in the array. The iteratee is invoked with one argument:\n * (value).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [iteratee=_.identity] The iteratee invoked per element.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniqBy([2.1, 1.2, 2.3], Math.floor);\n * // => [2.1, 1.2]\n *\n * // The `_.property` iteratee shorthand.\n * _.uniqBy([{ 'x': 1 }, { 'x': 2 }, { 'x': 1 }], 'x');\n * // => [{ 'x': 1 }, { 'x': 2 }]\n */\nfunction uniqBy(array, iteratee) {\n  return (array && array.length) ? baseUniq(array, baseIteratee(iteratee, 2)) : [];\n}\n\nexport default uniqBy;\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport {\r\n    IToken,\r\n    TokenType,\r\n    tokenMatcher,\r\n    tokenLabel,\r\n    Rule,\r\n    IProductionWithOccurrence,\r\n    NonTerminal,\r\n    Alternation,\r\n    Option,\r\n    RepetitionMandatory,\r\n    RepetitionMandatoryWithSeparator,\r\n    RepetitionWithSeparator,\r\n    Repetition,\r\n    Terminal,\r\n    BaseParser,\r\n    LLkLookaheadStrategy,\r\n    ILookaheadValidationError,\r\n    IOrAlt,\r\n    getLookaheadPaths,\r\n    OptionalProductionType\r\n} from \"chevrotain\";\r\nimport {\r\n    ATN,\r\n    ATNState,\r\n    ATN_RULE_STOP,\r\n    AtomTransition,\r\n    buildATNKey,\r\n    createATN,\r\n    DecisionState,\r\n    EpsilonTransition,\r\n    RuleTransition,\r\n    Transition\r\n} from \"./atn.js\";\r\nimport {\r\n    ATNConfig,\r\n    ATNConfigSet,\r\n    DFA,\r\n    DFAState,\r\n    DFA_ERROR,\r\n    getATNConfigKey\r\n} from \"./dfa.js\";\r\nimport min from \"lodash-es/min.js\";\r\nimport flatMap from \"lodash-es/flatMap.js\";\r\nimport uniqBy from \"lodash-es/uniqBy.js\";\r\nimport map from \"lodash-es/map.js\";\r\nimport flatten from \"lodash-es/flatten.js\";\r\nimport forEach from \"lodash-es/forEach.js\";\r\nimport isEmpty from \"lodash-es/isEmpty.js\";\r\nimport reduce from \"lodash-es/reduce.js\";\r\n\r\ntype DFACache = (predicateSet: PredicateSet) => DFA\r\n\r\nexport type AmbiguityReport = (message: string) => void;\r\n\r\nfunction createDFACache(startState: DecisionState, decision: number): DFACache {\r\n    const map: Record<string, DFA | undefined> = {}\r\n    return (predicateSet) => {\r\n        const key = predicateSet.toString()\r\n        let existing = map[key]\r\n        if (existing !== undefined) {\r\n            return existing\r\n        } else {\r\n            existing = {\r\n                atnStartState: startState,\r\n                decision,\r\n                states: {}\r\n            }\r\n            map[key] = existing\r\n            return existing\r\n        }\r\n    }\r\n}\r\n\r\nclass PredicateSet {\r\n    private predicates: boolean[] = []\r\n\r\n    is(index: number): boolean {\r\n        return index >= this.predicates.length || this.predicates[index]\r\n    }\r\n\r\n    set(index: number, value: boolean) {\r\n        this.predicates[index] = value\r\n    }\r\n\r\n    toString(): string {\r\n        let value = \"\"\r\n        const size = this.predicates.length\r\n        for (let i = 0; i < size; i++) {\r\n            value += this.predicates[i] === true ? \"1\" : \"0\"\r\n        }\r\n        return value\r\n    }\r\n}\r\n\r\ninterface AdaptivePredictError {\r\n    tokenPath: IToken[]\r\n    possibleTokenTypes: TokenType[]\r\n    actualToken: IToken\r\n}\r\n\r\nconst EMPTY_PREDICATES = new PredicateSet()\r\n\r\nexport interface LLStarLookaheadOptions {\r\n    logging?: AmbiguityReport\r\n}\r\n\r\nexport class LLStarLookaheadStrategy extends LLkLookaheadStrategy {\r\n\r\n    private atn: ATN;\r\n    private dfas: DFACache[];\r\n    private logging: AmbiguityReport;\r\n\r\n    constructor(options?: LLStarLookaheadOptions) {\r\n        super();\r\n        this.logging = options?.logging ?? ((message) => console.log(message));\r\n    }\r\n\r\n    override initialize(options: { rules: Rule[] }): void {\r\n        this.atn = createATN(options.rules);\r\n        this.dfas = initATNSimulator(this.atn);\r\n    }\r\n\r\n    override validateAmbiguousAlternationAlternatives(): ILookaheadValidationError[] {\r\n        return [];\r\n    }\r\n\r\n    override validateEmptyOrAlternatives(): ILookaheadValidationError[] {\r\n        return [];\r\n    }\r\n\r\n    override buildLookaheadForAlternation(options: {\r\n        prodOccurrence: number;\r\n        rule: Rule;\r\n        maxLookahead: number;\r\n        hasPredicates: boolean;\r\n        dynamicTokensEnabled: boolean\r\n    }): (this: BaseParser, orAlts?: IOrAlt<any>[] | undefined) => number | undefined {\r\n        const { prodOccurrence, rule, hasPredicates, dynamicTokensEnabled } = options;\r\n        const dfas = this.dfas;\r\n        const logging = this.logging;\r\n        const key = buildATNKey(rule, 'Alternation', prodOccurrence);\r\n        const decisionState = this.atn.decisionMap[key];\r\n        const decisionIndex = decisionState.decision;\r\n        const partialAlts: (TokenType | undefined)[][] = map(\r\n            getLookaheadPaths({\r\n                maxLookahead: 1,\r\n                occurrence: prodOccurrence,\r\n                prodType: \"Alternation\",\r\n                rule: rule\r\n            }),\r\n            (currAlt) => map(currAlt, (path) => path[0])\r\n        )\r\n\r\n        if (isLL1Sequence(partialAlts, false) && !dynamicTokensEnabled) {\r\n            const choiceToAlt = reduce(\r\n                partialAlts,\r\n                (result, currAlt, idx) => {\r\n                    forEach(currAlt, (currTokType) => {\r\n                        if (currTokType) {\r\n                            result[currTokType.tokenTypeIdx!] = idx\r\n                            forEach(currTokType.categoryMatches!, (currExtendingType) => {\r\n                                result[currExtendingType] = idx\r\n                            })\r\n                        }\r\n                    })\r\n                    return result\r\n                },\r\n                {} as Record<number, number>\r\n            )\r\n\r\n            if (hasPredicates) {\r\n                return function (this: BaseParser, orAlts) {\r\n                    const nextToken = this.LA(1)\r\n                    const prediction: number | undefined = choiceToAlt[nextToken.tokenTypeIdx]\r\n                    if (orAlts !== undefined && prediction !== undefined) {\r\n                        const gate = orAlts[prediction]?.GATE\r\n                        if (gate !== undefined && gate.call(this) === false) {\r\n                            return undefined;\r\n                        }\r\n                    }\r\n                    return prediction\r\n                }\r\n            } else {\r\n                return function (this: BaseParser): number | undefined {\r\n                    const nextToken = this.LA(1)\r\n                    return choiceToAlt[nextToken.tokenTypeIdx];\r\n                }\r\n            }\r\n        } else if (hasPredicates) {\r\n            return function (this: BaseParser, orAlts) {\r\n                const predicates = new PredicateSet()\r\n                const length = orAlts === undefined ? 0 : orAlts.length\r\n                for (let i = 0; i < length; i++) {\r\n                    const gate = orAlts?.[i].GATE\r\n                    predicates.set(i, gate === undefined || gate.call(this))\r\n                }\r\n                const result = adaptivePredict.call(this, dfas, decisionIndex, predicates, logging);\r\n                return typeof result === 'number' ? result : undefined;\r\n            }\r\n        } else {\r\n            return function (this: BaseParser) {\r\n                const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging);\r\n                return typeof result === 'number' ? result : undefined;\r\n            }\r\n        }\r\n    }\r\n\r\n    override buildLookaheadForOptional(options: {\r\n        prodOccurrence: number;\r\n        prodType: OptionalProductionType;\r\n        rule: Rule;\r\n        maxLookahead: number;\r\n        dynamicTokensEnabled: boolean\r\n    }): (this: BaseParser) => boolean {\r\n        const { prodOccurrence, rule, prodType, dynamicTokensEnabled } = options;\r\n        const dfas = this.dfas;\r\n        const logging = this.logging;\r\n        const key = buildATNKey(rule, prodType, prodOccurrence);\r\n        const decisionState = this.atn.decisionMap[key];\r\n        const decisionIndex = decisionState.decision;\r\n        const alts = map(\r\n            getLookaheadPaths({\r\n                maxLookahead: 1,\r\n                occurrence: prodOccurrence,\r\n                prodType,\r\n                rule\r\n            }),\r\n            (e) => {\r\n              return map(e, (g) => g[0])\r\n            }\r\n          )\r\n        \r\n          if (isLL1Sequence(alts) && alts[0][0] && !dynamicTokensEnabled) {\r\n            const alt = alts[0]\r\n            const singleTokensTypes = flatten(alt)\r\n        \r\n            if (\r\n              singleTokensTypes.length === 1 &&\r\n              isEmpty(singleTokensTypes[0].categoryMatches)\r\n            ) {\r\n              const expectedTokenType = singleTokensTypes[0]\r\n              const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx\r\n        \r\n              return function (this: BaseParser): boolean {\r\n                return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey\r\n              }\r\n            } else {\r\n              const choiceToAlt = reduce(\r\n                singleTokensTypes,\r\n                (result, currTokType) => {\r\n                  if (currTokType !== undefined) {\r\n                    result[currTokType.tokenTypeIdx!] = true\r\n                    forEach(currTokType.categoryMatches, (currExtendingType) => {\r\n                      result[currExtendingType] = true\r\n                    })\r\n                  }\r\n                  return result\r\n                },\r\n                {} as Record<number, boolean>\r\n              )\r\n        \r\n              return function (this: BaseParser): boolean {\r\n                const nextToken = this.LA(1)\r\n                return choiceToAlt[nextToken.tokenTypeIdx] === true\r\n              }\r\n            }\r\n          }\r\n          return function (this: BaseParser) {\r\n            const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging)\r\n              return typeof result === \"object\" ? false : result === 0;\r\n          }\r\n    }\r\n\r\n}\r\n\r\nfunction isLL1Sequence(sequences: (TokenType | undefined)[][], allowEmpty = true): boolean {\r\n    const fullSet = new Set<number>()\r\n\r\n    for (const alt of sequences) {\r\n        const altSet = new Set<number>()\r\n        for (const tokType of alt) {\r\n            if (tokType === undefined) {\r\n                if (allowEmpty) {\r\n                    // Epsilon production encountered\r\n                    break\r\n                } else {\r\n                    return false;\r\n                }\r\n            }\r\n            const indices = [tokType.tokenTypeIdx!].concat(tokType.categoryMatches!)\r\n            for (const index of indices) {\r\n                if (fullSet.has(index)) {\r\n                    if (!altSet.has(index)) {\r\n                        return false\r\n                    }\r\n                } else {\r\n                    fullSet.add(index)\r\n                    altSet.add(index)\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return true\r\n}\r\n\r\nfunction initATNSimulator(atn: ATN): DFACache[] {\r\n    const decisionLength = atn.decisionStates.length\r\n    const decisionToDFA: DFACache[] = Array(decisionLength)\r\n    for (let i = 0; i < decisionLength; i++) {\r\n        decisionToDFA[i] = createDFACache(atn.decisionStates[i], i)\r\n    }\r\n    return decisionToDFA;\r\n}\r\n\r\nfunction adaptivePredict(\r\n    this: BaseParser,\r\n    dfaCaches: DFACache[],\r\n    decision: number,\r\n    predicateSet: PredicateSet,\r\n    logging: AmbiguityReport\r\n): number | AdaptivePredictError {\r\n    const dfa = dfaCaches[decision](predicateSet)\r\n    let start = dfa.start\r\n    if (start === undefined) {\r\n        const closure = computeStartState(dfa.atnStartState as ATNState)\r\n        start = addDFAState(dfa, newDFAState(closure))\r\n        dfa.start = start\r\n    }\r\n\r\n    const alt = performLookahead.apply(this, [dfa, start, predicateSet, logging])\r\n    return alt\r\n}\r\n\r\nfunction performLookahead(\r\n    this: BaseParser,\r\n    dfa: DFA,\r\n    s0: DFAState,\r\n    predicateSet: PredicateSet,\r\n    logging: AmbiguityReport\r\n): number | AdaptivePredictError {\r\n    let previousD = s0\r\n\r\n    let i = 1\r\n    const path: IToken[] = []\r\n    let t = this.LA(i++)\r\n\r\n    while (true) {\r\n        let d = getExistingTargetState(previousD, t)\r\n        if (d === undefined) {\r\n            d = computeLookaheadTarget.apply(this, [dfa, previousD, t, i, predicateSet, logging])\r\n        }\r\n\r\n        if (d === DFA_ERROR) {\r\n            return buildAdaptivePredictError(path, previousD, t)\r\n        }\r\n\r\n        if (d.isAcceptState === true) {\r\n            return d.prediction\r\n        }\r\n\r\n        previousD = d\r\n        path.push(t)\r\n        t = this.LA(i++)\r\n    }\r\n}\r\n\r\nfunction computeLookaheadTarget(\r\n    this: BaseParser,\r\n    dfa: DFA,\r\n    previousD: DFAState,\r\n    token: IToken,\r\n    lookahead: number,\r\n    predicateSet: PredicateSet,\r\n    logging: AmbiguityReport\r\n): DFAState {\r\n    const reach = computeReachSet(previousD.configs, token, predicateSet)\r\n    if (reach.size === 0) {\r\n        addDFAEdge(dfa, previousD, token, DFA_ERROR)\r\n        return DFA_ERROR\r\n    }\r\n\r\n    let newState = newDFAState(reach)\r\n    const predictedAlt = getUniqueAlt(reach, predicateSet)\r\n\r\n    if (predictedAlt !== undefined) {\r\n        newState.isAcceptState = true\r\n        newState.prediction = predictedAlt\r\n        newState.configs.uniqueAlt = predictedAlt\r\n    } else if (hasConflictTerminatingPrediction(reach)) {\r\n        const prediction = min(reach.alts)!\r\n        newState.isAcceptState = true\r\n        newState.prediction = prediction\r\n        newState.configs.uniqueAlt = prediction\r\n        reportLookaheadAmbiguity.apply(this, [dfa, lookahead, reach.alts, logging])\r\n    }\r\n\r\n    newState = addDFAEdge(dfa, previousD, token, newState)\r\n    return newState\r\n}\r\n\r\nfunction reportLookaheadAmbiguity(\r\n    this: BaseParser,\r\n    dfa: DFA,\r\n    lookahead: number,\r\n    ambiguityIndices: number[],\r\n    logging: AmbiguityReport\r\n) {\r\n    const prefixPath: TokenType[] = []\r\n    for (let i = 1; i <= lookahead; i++) {\r\n        prefixPath.push(this.LA(i).tokenType)\r\n    }\r\n    const atnState = dfa.atnStartState\r\n    const topLevelRule = atnState.rule\r\n    const production = atnState.production\r\n    const message = buildAmbiguityError({\r\n        topLevelRule,\r\n        ambiguityIndices,\r\n        production,\r\n        prefixPath\r\n    })\r\n    logging(message)\r\n}\r\n\r\nfunction buildAmbiguityError(options: {\r\n    topLevelRule: Rule\r\n    prefixPath: TokenType[]\r\n    ambiguityIndices: number[]\r\n    production: IProductionWithOccurrence\r\n}): string {\r\n    const pathMsg = map(options.prefixPath, (currtok) =>\r\n        tokenLabel(currtok)\r\n    ).join(\", \")\r\n    const occurrence =\r\n        options.production.idx === 0 ? \"\" : options.production.idx\r\n    let currMessage =\r\n        `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\r\n            \", \"\r\n        )}> in <${getProductionDslName(options.production)}${occurrence}>` +\r\n        ` inside <${options.topLevelRule.name}> Rule,\\n` +\r\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`\r\n\r\n    currMessage =\r\n        currMessage +\r\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\r\n        `For Further details.`\r\n    return currMessage\r\n}\r\n\r\nfunction getProductionDslName(prod: IProductionWithOccurrence): string {\r\n    if (prod instanceof NonTerminal) {\r\n        return \"SUBRULE\"\r\n    } else if (prod instanceof Option) {\r\n        return \"OPTION\"\r\n    } else if (prod instanceof Alternation) {\r\n        return \"OR\"\r\n    } else if (prod instanceof RepetitionMandatory) {\r\n        return \"AT_LEAST_ONE\"\r\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\r\n        return \"AT_LEAST_ONE_SEP\"\r\n    } else if (prod instanceof RepetitionWithSeparator) {\r\n        return \"MANY_SEP\"\r\n    } else if (prod instanceof Repetition) {\r\n        return \"MANY\"\r\n    } else if (prod instanceof Terminal) {\r\n        return \"CONSUME\"\r\n    } else {\r\n        throw Error(\"non exhaustive match\")\r\n    }\r\n}\r\n\r\nfunction buildAdaptivePredictError(\r\n    path: IToken[],\r\n    previous: DFAState,\r\n    current: IToken\r\n): AdaptivePredictError {\r\n    const nextTransitions = flatMap(\r\n        previous.configs.elements,\r\n        (e) => e.state.transitions\r\n    )\r\n    const nextTokenTypes = uniqBy(\r\n        nextTransitions\r\n            .filter((e): e is AtomTransition => e instanceof AtomTransition)\r\n            .map((e) => e.tokenType),\r\n        (e) => e.tokenTypeIdx\r\n    )\r\n    return {\r\n        actualToken: current,\r\n        possibleTokenTypes: nextTokenTypes,\r\n        tokenPath: path\r\n    }\r\n}\r\n\r\nfunction getExistingTargetState(\r\n    state: DFAState,\r\n    token: IToken\r\n): DFAState | undefined {\r\n    return state.edges[token.tokenTypeIdx]\r\n}\r\n\r\nfunction computeReachSet(\r\n    configs: ATNConfigSet,\r\n    token: IToken,\r\n    predicateSet: PredicateSet\r\n): ATNConfigSet {\r\n    const intermediate = new ATNConfigSet()\r\n    const skippedStopStates: ATNConfig[] = []\r\n\r\n    for (const c of configs.elements) {\r\n        if (predicateSet.is(c.alt) === false) {\r\n            continue\r\n        }\r\n        if (c.state.type === ATN_RULE_STOP) {\r\n            skippedStopStates.push(c)\r\n            continue\r\n        }\r\n        const transitionLength = c.state.transitions.length\r\n        for (let i = 0; i < transitionLength; i++) {\r\n            const transition = c.state.transitions[i]\r\n            const target = getReachableTarget(transition, token)\r\n            if (target !== undefined) {\r\n                intermediate.add({\r\n                    state: target,\r\n                    alt: c.alt,\r\n                    stack: c.stack\r\n                })\r\n            }\r\n        }\r\n    }\r\n\r\n    let reach: ATNConfigSet | undefined\r\n\r\n    if (skippedStopStates.length === 0 && intermediate.size === 1) {\r\n        reach = intermediate\r\n    }\r\n\r\n    if (reach === undefined) {\r\n        reach = new ATNConfigSet()\r\n        for (const c of intermediate.elements) {\r\n            closure(c, reach)\r\n        }\r\n    }\r\n\r\n    if (skippedStopStates.length > 0 && !hasConfigInRuleStopState(reach)) {\r\n        for (const c of skippedStopStates) {\r\n            reach.add(c)\r\n        }\r\n    }\r\n\r\n    return reach\r\n}\r\n\r\nfunction getReachableTarget(\r\n    transition: Transition,\r\n    token: IToken\r\n): ATNState | undefined {\r\n    if (\r\n        transition instanceof AtomTransition &&\r\n        tokenMatcher(token, transition.tokenType)\r\n    ) {\r\n        return transition.target\r\n    }\r\n    return undefined\r\n}\r\n\r\nfunction getUniqueAlt(\r\n    configs: ATNConfigSet,\r\n    predicateSet: PredicateSet\r\n): number | undefined {\r\n    let alt: number | undefined\r\n    for (const c of configs.elements) {\r\n        if (predicateSet.is(c.alt) === true) {\r\n            if (alt === undefined) {\r\n                alt = c.alt\r\n            } else if (alt !== c.alt) {\r\n                return undefined\r\n            }\r\n        }\r\n    }\r\n    return alt\r\n}\r\n\r\nfunction newDFAState(closure: ATNConfigSet): DFAState {\r\n    return {\r\n        configs: closure,\r\n        edges: {},\r\n        isAcceptState: false,\r\n        prediction: -1\r\n    }\r\n}\r\n\r\nfunction addDFAEdge(\r\n    dfa: DFA,\r\n    from: DFAState,\r\n    token: IToken,\r\n    to: DFAState\r\n): DFAState {\r\n    to = addDFAState(dfa, to)\r\n    from.edges[token.tokenTypeIdx] = to\r\n    return to\r\n}\r\n\r\nfunction addDFAState(dfa: DFA, state: DFAState): DFAState {\r\n    if (state === DFA_ERROR) {\r\n        return state\r\n    }\r\n    // Repetitions have the same config set\r\n    // Therefore, storing the key of the config in a map allows us to create a loop in our DFA\r\n    const mapKey = state.configs.key\r\n    const existing = dfa.states[mapKey]\r\n    if (existing !== undefined) {\r\n        return existing\r\n    }\r\n    state.configs.finalize()\r\n    dfa.states[mapKey] = state\r\n    return state\r\n}\r\n\r\nfunction computeStartState(atnState: ATNState): ATNConfigSet {\r\n    const configs = new ATNConfigSet()\r\n\r\n    const numberOfTransitions = atnState.transitions.length\r\n    for (let i = 0; i < numberOfTransitions; i++) {\r\n        const target = atnState.transitions[i].target\r\n        const config: ATNConfig = {\r\n            state: target,\r\n            alt: i,\r\n            stack: []\r\n        }\r\n        closure(config, configs)\r\n    }\r\n\r\n    return configs\r\n}\r\n\r\nfunction closure(config: ATNConfig, configs: ATNConfigSet): void {\r\n    const p = config.state\r\n\r\n    if (p.type === ATN_RULE_STOP) {\r\n        if (config.stack.length > 0) {\r\n            const atnStack = [...config.stack]\r\n            const followState = atnStack.pop()!\r\n            const followConfig: ATNConfig = {\r\n                state: followState,\r\n                alt: config.alt,\r\n                stack: atnStack\r\n            }\r\n            closure(followConfig, configs)\r\n        } else {\r\n            // Dipping into outer context, simply add the config\r\n            // This will stop computation once every config is at the rule stop state\r\n            configs.add(config)\r\n        }\r\n        return\r\n    }\r\n\r\n    if (!p.epsilonOnlyTransitions) {\r\n        configs.add(config)\r\n    }\r\n\r\n    const transitionLength = p.transitions.length\r\n    for (let i = 0; i < transitionLength; i++) {\r\n        const transition = p.transitions[i]\r\n        const c = getEpsilonTarget(config, transition)\r\n\r\n        if (c !== undefined) {\r\n            closure(c, configs)\r\n        }\r\n    }\r\n}\r\n\r\nfunction getEpsilonTarget(\r\n    config: ATNConfig,\r\n    transition: Transition\r\n): ATNConfig | undefined {\r\n    if (transition instanceof EpsilonTransition) {\r\n        return {\r\n            state: transition.target,\r\n            alt: config.alt,\r\n            stack: config.stack\r\n        }\r\n    } else if (transition instanceof RuleTransition) {\r\n        const stack = [...config.stack, transition.followState]\r\n        return {\r\n            state: transition.target,\r\n            alt: config.alt,\r\n            stack\r\n        }\r\n    }\r\n    return undefined\r\n}\r\n\r\nfunction hasConfigInRuleStopState(configs: ATNConfigSet): boolean {\r\n    for (const c of configs.elements) {\r\n        if (c.state.type === ATN_RULE_STOP) {\r\n            return true\r\n        }\r\n    }\r\n    return false\r\n}\r\n\r\nfunction allConfigsInRuleStopStates(configs: ATNConfigSet): boolean {\r\n    for (const c of configs.elements) {\r\n        if (c.state.type !== ATN_RULE_STOP) {\r\n            return false\r\n        }\r\n    }\r\n    return true\r\n}\r\n\r\nfunction hasConflictTerminatingPrediction(configs: ATNConfigSet): boolean {\r\n    if (allConfigsInRuleStopStates(configs)) {\r\n        return true\r\n    }\r\n    const altSets = getConflictingAltSets(configs.elements)\r\n    const heuristic =\r\n        hasConflictingAltSet(altSets) && !hasStateAssociatedWithOneAlt(altSets)\r\n    return heuristic\r\n}\r\n\r\nfunction getConflictingAltSets(\r\n    configs: readonly ATNConfig[]\r\n): Map<string, Record<number, boolean>> {\r\n    const configToAlts = new Map<string, Record<number, boolean>>()\r\n    for (const c of configs) {\r\n        const key = getATNConfigKey(c, false)\r\n        let alts = configToAlts.get(key)\r\n        if (alts === undefined) {\r\n            alts = {}\r\n            configToAlts.set(key, alts)\r\n        }\r\n        alts[c.alt] = true\r\n    }\r\n    return configToAlts\r\n}\r\n\r\nfunction hasConflictingAltSet(\r\n    altSets: Map<string, Record<number, boolean>>\r\n): boolean {\r\n    for (const value of Array.from(altSets.values())) {\r\n        if (Object.keys(value).length > 1) {\r\n            return true\r\n        }\r\n    }\r\n    return false\r\n}\r\n\r\nfunction hasStateAssociatedWithOneAlt(\r\n    altSets: Map<string, Record<number, boolean>>\r\n): boolean {\r\n    for (const value of Array.from(altSets.values())) {\r\n        if (Object.keys(value).length === 1) {\r\n            return true\r\n        }\r\n    }\r\n    return false\r\n}\r\n","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nexport var DocumentUri;\n(function (DocumentUri) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    DocumentUri.is = is;\n})(DocumentUri || (DocumentUri = {}));\nexport var URI;\n(function (URI) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    URI.is = is;\n})(URI || (URI = {}));\nexport var integer;\n(function (integer) {\n    integer.MIN_VALUE = -2147483648;\n    integer.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && integer.MIN_VALUE <= value && value <= integer.MAX_VALUE;\n    }\n    integer.is = is;\n})(integer || (integer = {}));\nexport var uinteger;\n(function (uinteger) {\n    uinteger.MIN_VALUE = 0;\n    uinteger.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && uinteger.MIN_VALUE <= value && value <= uinteger.MAX_VALUE;\n    }\n    uinteger.is = is;\n})(uinteger || (uinteger = {}));\n/**\n * The Position namespace provides helper functions to work with\n * {@link Position} literals.\n */\nexport var Position;\n(function (Position) {\n    /**\n     * Creates a new Position literal from the given line and character.\n     * @param line The position's line.\n     * @param character The position's character.\n     */\n    function create(line, character) {\n        if (line === Number.MAX_VALUE) {\n            line = uinteger.MAX_VALUE;\n        }\n        if (character === Number.MAX_VALUE) {\n            character = uinteger.MAX_VALUE;\n        }\n        return { line, character };\n    }\n    Position.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Position} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.line) && Is.uinteger(candidate.character);\n    }\n    Position.is = is;\n})(Position || (Position = {}));\n/**\n * The Range namespace provides helper functions to work with\n * {@link Range} literals.\n */\nexport var Range;\n(function (Range) {\n    function create(one, two, three, four) {\n        if (Is.uinteger(one) && Is.uinteger(two) && Is.uinteger(three) && Is.uinteger(four)) {\n            return { start: Position.create(one, two), end: Position.create(three, four) };\n        }\n        else if (Position.is(one) && Position.is(two)) {\n            return { start: one, end: two };\n        }\n        else {\n            throw new Error(`Range#create called with invalid arguments[${one}, ${two}, ${three}, ${four}]`);\n        }\n    }\n    Range.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Range} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.start) && Position.is(candidate.end);\n    }\n    Range.is = is;\n})(Range || (Range = {}));\n/**\n * The Location namespace provides helper functions to work with\n * {@link Location} literals.\n */\nexport var Location;\n(function (Location) {\n    /**\n     * Creates a Location literal.\n     * @param uri The location's uri.\n     * @param range The location's range.\n     */\n    function create(uri, range) {\n        return { uri, range };\n    }\n    Location.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Location} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (Is.string(candidate.uri) || Is.undefined(candidate.uri));\n    }\n    Location.is = is;\n})(Location || (Location = {}));\n/**\n * The LocationLink namespace provides helper functions to work with\n * {@link LocationLink} literals.\n */\nexport var LocationLink;\n(function (LocationLink) {\n    /**\n     * Creates a LocationLink literal.\n     * @param targetUri The definition's uri.\n     * @param targetRange The full range of the definition.\n     * @param targetSelectionRange The span of the symbol definition at the target.\n     * @param originSelectionRange The span of the symbol being defined in the originating source file.\n     */\n    function create(targetUri, targetRange, targetSelectionRange, originSelectionRange) {\n        return { targetUri, targetRange, targetSelectionRange, originSelectionRange };\n    }\n    LocationLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link LocationLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.targetRange) && Is.string(candidate.targetUri)\n            && Range.is(candidate.targetSelectionRange)\n            && (Range.is(candidate.originSelectionRange) || Is.undefined(candidate.originSelectionRange));\n    }\n    LocationLink.is = is;\n})(LocationLink || (LocationLink = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link Color} literals.\n */\nexport var Color;\n(function (Color) {\n    /**\n     * Creates a new Color literal.\n     */\n    function create(red, green, blue, alpha) {\n        return {\n            red,\n            green,\n            blue,\n            alpha,\n        };\n    }\n    Color.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Color} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.numberRange(candidate.red, 0, 1)\n            && Is.numberRange(candidate.green, 0, 1)\n            && Is.numberRange(candidate.blue, 0, 1)\n            && Is.numberRange(candidate.alpha, 0, 1);\n    }\n    Color.is = is;\n})(Color || (Color = {}));\n/**\n * The ColorInformation namespace provides helper functions to work with\n * {@link ColorInformation} literals.\n */\nexport var ColorInformation;\n(function (ColorInformation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(range, color) {\n        return {\n            range,\n            color,\n        };\n    }\n    ColorInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && Color.is(candidate.color);\n    }\n    ColorInformation.is = is;\n})(ColorInformation || (ColorInformation = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link ColorPresentation} literals.\n */\nexport var ColorPresentation;\n(function (ColorPresentation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(label, textEdit, additionalTextEdits) {\n        return {\n            label,\n            textEdit,\n            additionalTextEdits,\n        };\n    }\n    ColorPresentation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label)\n            && (Is.undefined(candidate.textEdit) || TextEdit.is(candidate))\n            && (Is.undefined(candidate.additionalTextEdits) || Is.typedArray(candidate.additionalTextEdits, TextEdit.is));\n    }\n    ColorPresentation.is = is;\n})(ColorPresentation || (ColorPresentation = {}));\n/**\n * A set of predefined range kinds.\n */\nexport var FoldingRangeKind;\n(function (FoldingRangeKind) {\n    /**\n     * Folding range for a comment\n     */\n    FoldingRangeKind.Comment = 'comment';\n    /**\n     * Folding range for an import or include\n     */\n    FoldingRangeKind.Imports = 'imports';\n    /**\n     * Folding range for a region (e.g. `#region`)\n     */\n    FoldingRangeKind.Region = 'region';\n})(FoldingRangeKind || (FoldingRangeKind = {}));\n/**\n * The folding range namespace provides helper functions to work with\n * {@link FoldingRange} literals.\n */\nexport var FoldingRange;\n(function (FoldingRange) {\n    /**\n     * Creates a new FoldingRange literal.\n     */\n    function create(startLine, endLine, startCharacter, endCharacter, kind, collapsedText) {\n        const result = {\n            startLine,\n            endLine\n        };\n        if (Is.defined(startCharacter)) {\n            result.startCharacter = startCharacter;\n        }\n        if (Is.defined(endCharacter)) {\n            result.endCharacter = endCharacter;\n        }\n        if (Is.defined(kind)) {\n            result.kind = kind;\n        }\n        if (Is.defined(collapsedText)) {\n            result.collapsedText = collapsedText;\n        }\n        return result;\n    }\n    FoldingRange.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FoldingRange} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.startLine) && Is.uinteger(candidate.startLine)\n            && (Is.undefined(candidate.startCharacter) || Is.uinteger(candidate.startCharacter))\n            && (Is.undefined(candidate.endCharacter) || Is.uinteger(candidate.endCharacter))\n            && (Is.undefined(candidate.kind) || Is.string(candidate.kind));\n    }\n    FoldingRange.is = is;\n})(FoldingRange || (FoldingRange = {}));\n/**\n * The DiagnosticRelatedInformation namespace provides helper functions to work with\n * {@link DiagnosticRelatedInformation} literals.\n */\nexport var DiagnosticRelatedInformation;\n(function (DiagnosticRelatedInformation) {\n    /**\n     * Creates a new DiagnosticRelatedInformation literal.\n     */\n    function create(location, message) {\n        return {\n            location,\n            message\n        };\n    }\n    DiagnosticRelatedInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DiagnosticRelatedInformation} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Location.is(candidate.location) && Is.string(candidate.message);\n    }\n    DiagnosticRelatedInformation.is = is;\n})(DiagnosticRelatedInformation || (DiagnosticRelatedInformation = {}));\n/**\n * The diagnostic's severity.\n */\nexport var DiagnosticSeverity;\n(function (DiagnosticSeverity) {\n    /**\n     * Reports an error.\n     */\n    DiagnosticSeverity.Error = 1;\n    /**\n     * Reports a warning.\n     */\n    DiagnosticSeverity.Warning = 2;\n    /**\n     * Reports an information.\n     */\n    DiagnosticSeverity.Information = 3;\n    /**\n     * Reports a hint.\n     */\n    DiagnosticSeverity.Hint = 4;\n})(DiagnosticSeverity || (DiagnosticSeverity = {}));\n/**\n * The diagnostic tags.\n *\n * @since 3.15.0\n */\nexport var DiagnosticTag;\n(function (DiagnosticTag) {\n    /**\n     * Unused or unnecessary code.\n     *\n     * Clients are allowed to render diagnostics with this tag faded out instead of having\n     * an error squiggle.\n     */\n    DiagnosticTag.Unnecessary = 1;\n    /**\n     * Deprecated or obsolete code.\n     *\n     * Clients are allowed to rendered diagnostics with this tag strike through.\n     */\n    DiagnosticTag.Deprecated = 2;\n})(DiagnosticTag || (DiagnosticTag = {}));\n/**\n * The CodeDescription namespace provides functions to deal with descriptions for diagnostic codes.\n *\n * @since 3.16.0\n */\nexport var CodeDescription;\n(function (CodeDescription) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.href);\n    }\n    CodeDescription.is = is;\n})(CodeDescription || (CodeDescription = {}));\n/**\n * The Diagnostic namespace provides helper functions to work with\n * {@link Diagnostic} literals.\n */\nexport var Diagnostic;\n(function (Diagnostic) {\n    /**\n     * Creates a new Diagnostic literal.\n     */\n    function create(range, message, severity, code, source, relatedInformation) {\n        let result = { range, message };\n        if (Is.defined(severity)) {\n            result.severity = severity;\n        }\n        if (Is.defined(code)) {\n            result.code = code;\n        }\n        if (Is.defined(source)) {\n            result.source = source;\n        }\n        if (Is.defined(relatedInformation)) {\n            result.relatedInformation = relatedInformation;\n        }\n        return result;\n    }\n    Diagnostic.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Diagnostic} interface.\n     */\n    function is(value) {\n        var _a;\n        let candidate = value;\n        return Is.defined(candidate)\n            && Range.is(candidate.range)\n            && Is.string(candidate.message)\n            && (Is.number(candidate.severity) || Is.undefined(candidate.severity))\n            && (Is.integer(candidate.code) || Is.string(candidate.code) || Is.undefined(candidate.code))\n            && (Is.undefined(candidate.codeDescription) || (Is.string((_a = candidate.codeDescription) === null || _a === void 0 ? void 0 : _a.href)))\n            && (Is.string(candidate.source) || Is.undefined(candidate.source))\n            && (Is.undefined(candidate.relatedInformation) || Is.typedArray(candidate.relatedInformation, DiagnosticRelatedInformation.is));\n    }\n    Diagnostic.is = is;\n})(Diagnostic || (Diagnostic = {}));\n/**\n * The Command namespace provides helper functions to work with\n * {@link Command} literals.\n */\nexport var Command;\n(function (Command) {\n    /**\n     * Creates a new Command literal.\n     */\n    function create(title, command, ...args) {\n        let result = { title, command };\n        if (Is.defined(args) && args.length > 0) {\n            result.arguments = args;\n        }\n        return result;\n    }\n    Command.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Command} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.title) && Is.string(candidate.command);\n    }\n    Command.is = is;\n})(Command || (Command = {}));\n/**\n * The TextEdit namespace provides helper function to create replace,\n * insert and delete edits more easily.\n */\nexport var TextEdit;\n(function (TextEdit) {\n    /**\n     * Creates a replace text edit.\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     */\n    function replace(range, newText) {\n        return { range, newText };\n    }\n    TextEdit.replace = replace;\n    /**\n     * Creates an insert text edit.\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     */\n    function insert(position, newText) {\n        return { range: { start: position, end: position }, newText };\n    }\n    TextEdit.insert = insert;\n    /**\n     * Creates a delete text edit.\n     * @param range The range of text to be deleted.\n     */\n    function del(range) {\n        return { range, newText: '' };\n    }\n    TextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && Is.string(candidate.newText)\n            && Range.is(candidate.range);\n    }\n    TextEdit.is = is;\n})(TextEdit || (TextEdit = {}));\nexport var ChangeAnnotation;\n(function (ChangeAnnotation) {\n    function create(label, needsConfirmation, description) {\n        const result = { label };\n        if (needsConfirmation !== undefined) {\n            result.needsConfirmation = needsConfirmation;\n        }\n        if (description !== undefined) {\n            result.description = description;\n        }\n        return result;\n    }\n    ChangeAnnotation.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label) &&\n            (Is.boolean(candidate.needsConfirmation) || candidate.needsConfirmation === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    ChangeAnnotation.is = is;\n})(ChangeAnnotation || (ChangeAnnotation = {}));\nexport var ChangeAnnotationIdentifier;\n(function (ChangeAnnotationIdentifier) {\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate);\n    }\n    ChangeAnnotationIdentifier.is = is;\n})(ChangeAnnotationIdentifier || (ChangeAnnotationIdentifier = {}));\nexport var AnnotatedTextEdit;\n(function (AnnotatedTextEdit) {\n    /**\n     * Creates an annotated replace text edit.\n     *\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     * @param annotation The annotation.\n     */\n    function replace(range, newText, annotation) {\n        return { range, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.replace = replace;\n    /**\n     * Creates an annotated insert text edit.\n     *\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     * @param annotation The annotation.\n     */\n    function insert(position, newText, annotation) {\n        return { range: { start: position, end: position }, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.insert = insert;\n    /**\n     * Creates an annotated delete text edit.\n     *\n     * @param range The range of text to be deleted.\n     * @param annotation The annotation.\n     */\n    function del(range, annotation) {\n        return { range, newText: '', annotationId: annotation };\n    }\n    AnnotatedTextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return TextEdit.is(candidate) && (ChangeAnnotation.is(candidate.annotationId) || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    AnnotatedTextEdit.is = is;\n})(AnnotatedTextEdit || (AnnotatedTextEdit = {}));\n/**\n * The TextDocumentEdit namespace provides helper function to create\n * an edit that manipulates a text document.\n */\nexport var TextDocumentEdit;\n(function (TextDocumentEdit) {\n    /**\n     * Creates a new `TextDocumentEdit`\n     */\n    function create(textDocument, edits) {\n        return { textDocument, edits };\n    }\n    TextDocumentEdit.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate)\n            && OptionalVersionedTextDocumentIdentifier.is(candidate.textDocument)\n            && Array.isArray(candidate.edits);\n    }\n    TextDocumentEdit.is = is;\n})(TextDocumentEdit || (TextDocumentEdit = {}));\nexport var CreateFile;\n(function (CreateFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'create',\n            uri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    CreateFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'create' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    CreateFile.is = is;\n})(CreateFile || (CreateFile = {}));\nexport var RenameFile;\n(function (RenameFile) {\n    function create(oldUri, newUri, options, annotation) {\n        let result = {\n            kind: 'rename',\n            oldUri,\n            newUri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    RenameFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'rename' && Is.string(candidate.oldUri) && Is.string(candidate.newUri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    RenameFile.is = is;\n})(RenameFile || (RenameFile = {}));\nexport var DeleteFile;\n(function (DeleteFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'delete',\n            uri\n        };\n        if (options !== undefined && (options.recursive !== undefined || options.ignoreIfNotExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    DeleteFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'delete' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.recursive === undefined || Is.boolean(candidate.options.recursive)) && (candidate.options.ignoreIfNotExists === undefined || Is.boolean(candidate.options.ignoreIfNotExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    DeleteFile.is = is;\n})(DeleteFile || (DeleteFile = {}));\nexport var WorkspaceEdit;\n(function (WorkspaceEdit) {\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            (candidate.changes !== undefined || candidate.documentChanges !== undefined) &&\n            (candidate.documentChanges === undefined || candidate.documentChanges.every((change) => {\n                if (Is.string(change.kind)) {\n                    return CreateFile.is(change) || RenameFile.is(change) || DeleteFile.is(change);\n                }\n                else {\n                    return TextDocumentEdit.is(change);\n                }\n            }));\n    }\n    WorkspaceEdit.is = is;\n})(WorkspaceEdit || (WorkspaceEdit = {}));\nclass TextEditChangeImpl {\n    constructor(edits, changeAnnotations) {\n        this.edits = edits;\n        this.changeAnnotations = changeAnnotations;\n    }\n    insert(position, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.insert(position, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.insert(position, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.insert(position, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    replace(range, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.replace(range, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.replace(range, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.replace(range, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    delete(range, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.del(range);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.del(range, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.del(range, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    add(edit) {\n        this.edits.push(edit);\n    }\n    all() {\n        return this.edits;\n    }\n    clear() {\n        this.edits.splice(0, this.edits.length);\n    }\n    assertChangeAnnotations(value) {\n        if (value === undefined) {\n            throw new Error(`Text edit change is not configured to manage change annotations.`);\n        }\n    }\n}\n/**\n * A helper class\n */\nclass ChangeAnnotations {\n    constructor(annotations) {\n        this._annotations = annotations === undefined ? Object.create(null) : annotations;\n        this._counter = 0;\n        this._size = 0;\n    }\n    all() {\n        return this._annotations;\n    }\n    get size() {\n        return this._size;\n    }\n    manage(idOrAnnotation, annotation) {\n        let id;\n        if (ChangeAnnotationIdentifier.is(idOrAnnotation)) {\n            id = idOrAnnotation;\n        }\n        else {\n            id = this.nextId();\n            annotation = idOrAnnotation;\n        }\n        if (this._annotations[id] !== undefined) {\n            throw new Error(`Id ${id} is already in use.`);\n        }\n        if (annotation === undefined) {\n            throw new Error(`No annotation provided for id ${id}`);\n        }\n        this._annotations[id] = annotation;\n        this._size++;\n        return id;\n    }\n    nextId() {\n        this._counter++;\n        return this._counter.toString();\n    }\n}\n/**\n * A workspace change helps constructing changes to a workspace.\n */\nexport class WorkspaceChange {\n    constructor(workspaceEdit) {\n        this._textEditChanges = Object.create(null);\n        if (workspaceEdit !== undefined) {\n            this._workspaceEdit = workspaceEdit;\n            if (workspaceEdit.documentChanges) {\n                this._changeAnnotations = new ChangeAnnotations(workspaceEdit.changeAnnotations);\n                workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n                workspaceEdit.documentChanges.forEach((change) => {\n                    if (TextDocumentEdit.is(change)) {\n                        const textEditChange = new TextEditChangeImpl(change.edits, this._changeAnnotations);\n                        this._textEditChanges[change.textDocument.uri] = textEditChange;\n                    }\n                });\n            }\n            else if (workspaceEdit.changes) {\n                Object.keys(workspaceEdit.changes).forEach((key) => {\n                    const textEditChange = new TextEditChangeImpl(workspaceEdit.changes[key]);\n                    this._textEditChanges[key] = textEditChange;\n                });\n            }\n        }\n        else {\n            this._workspaceEdit = {};\n        }\n    }\n    /**\n     * Returns the underlying {@link WorkspaceEdit} literal\n     * use to be returned from a workspace edit operation like rename.\n     */\n    get edit() {\n        this.initDocumentChanges();\n        if (this._changeAnnotations !== undefined) {\n            if (this._changeAnnotations.size === 0) {\n                this._workspaceEdit.changeAnnotations = undefined;\n            }\n            else {\n                this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n            }\n        }\n        return this._workspaceEdit;\n    }\n    getTextEditChange(key) {\n        if (OptionalVersionedTextDocumentIdentifier.is(key)) {\n            this.initDocumentChanges();\n            if (this._workspaceEdit.documentChanges === undefined) {\n                throw new Error('Workspace edit is not configured for document changes.');\n            }\n            const textDocument = { uri: key.uri, version: key.version };\n            let result = this._textEditChanges[textDocument.uri];\n            if (!result) {\n                const edits = [];\n                const textDocumentEdit = {\n                    textDocument,\n                    edits\n                };\n                this._workspaceEdit.documentChanges.push(textDocumentEdit);\n                result = new TextEditChangeImpl(edits, this._changeAnnotations);\n                this._textEditChanges[textDocument.uri] = result;\n            }\n            return result;\n        }\n        else {\n            this.initChanges();\n            if (this._workspaceEdit.changes === undefined) {\n                throw new Error('Workspace edit is not configured for normal text edit changes.');\n            }\n            let result = this._textEditChanges[key];\n            if (!result) {\n                let edits = [];\n                this._workspaceEdit.changes[key] = edits;\n                result = new TextEditChangeImpl(edits);\n                this._textEditChanges[key] = result;\n            }\n            return result;\n        }\n    }\n    initDocumentChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._changeAnnotations = new ChangeAnnotations();\n            this._workspaceEdit.documentChanges = [];\n            this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n        }\n    }\n    initChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._workspaceEdit.changes = Object.create(null);\n        }\n    }\n    createFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = CreateFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = CreateFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    renameFile(oldUri, newUri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = RenameFile.create(oldUri, newUri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = RenameFile.create(oldUri, newUri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    deleteFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = DeleteFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = DeleteFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n}\n/**\n * The TextDocumentIdentifier namespace provides helper functions to work with\n * {@link TextDocumentIdentifier} literals.\n */\nexport var TextDocumentIdentifier;\n(function (TextDocumentIdentifier) {\n    /**\n     * Creates a new TextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     */\n    function create(uri) {\n        return { uri };\n    }\n    TextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri);\n    }\n    TextDocumentIdentifier.is = is;\n})(TextDocumentIdentifier || (TextDocumentIdentifier = {}));\n/**\n * The VersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link VersionedTextDocumentIdentifier} literals.\n */\nexport var VersionedTextDocumentIdentifier;\n(function (VersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new VersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    VersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link VersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.integer(candidate.version);\n    }\n    VersionedTextDocumentIdentifier.is = is;\n})(VersionedTextDocumentIdentifier || (VersionedTextDocumentIdentifier = {}));\n/**\n * The OptionalVersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link OptionalVersionedTextDocumentIdentifier} literals.\n */\nexport var OptionalVersionedTextDocumentIdentifier;\n(function (OptionalVersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new OptionalVersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    OptionalVersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link OptionalVersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (candidate.version === null || Is.integer(candidate.version));\n    }\n    OptionalVersionedTextDocumentIdentifier.is = is;\n})(OptionalVersionedTextDocumentIdentifier || (OptionalVersionedTextDocumentIdentifier = {}));\n/**\n * The TextDocumentItem namespace provides helper functions to work with\n * {@link TextDocumentItem} literals.\n */\nexport var TextDocumentItem;\n(function (TextDocumentItem) {\n    /**\n     * Creates a new TextDocumentItem literal.\n     * @param uri The document's uri.\n     * @param languageId The document's language identifier.\n     * @param version The document's version number.\n     * @param text The document's text.\n     */\n    function create(uri, languageId, version, text) {\n        return { uri, languageId, version, text };\n    }\n    TextDocumentItem.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentItem} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.string(candidate.languageId) && Is.integer(candidate.version) && Is.string(candidate.text);\n    }\n    TextDocumentItem.is = is;\n})(TextDocumentItem || (TextDocumentItem = {}));\n/**\n * Describes the content type that a client supports in various\n * result literals like `Hover`, `ParameterInfo` or `CompletionItem`.\n *\n * Please note that `MarkupKinds` must not start with a `$`. This kinds\n * are reserved for internal usage.\n */\nexport var MarkupKind;\n(function (MarkupKind) {\n    /**\n     * Plain text is supported as a content format\n     */\n    MarkupKind.PlainText = 'plaintext';\n    /**\n     * Markdown is supported as a content format\n     */\n    MarkupKind.Markdown = 'markdown';\n    /**\n     * Checks whether the given value is a value of the {@link MarkupKind} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate === MarkupKind.PlainText || candidate === MarkupKind.Markdown;\n    }\n    MarkupKind.is = is;\n})(MarkupKind || (MarkupKind = {}));\nexport var MarkupContent;\n(function (MarkupContent) {\n    /**\n     * Checks whether the given value conforms to the {@link MarkupContent} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(value) && MarkupKind.is(candidate.kind) && Is.string(candidate.value);\n    }\n    MarkupContent.is = is;\n})(MarkupContent || (MarkupContent = {}));\n/**\n * The kind of a completion entry.\n */\nexport var CompletionItemKind;\n(function (CompletionItemKind) {\n    CompletionItemKind.Text = 1;\n    CompletionItemKind.Method = 2;\n    CompletionItemKind.Function = 3;\n    CompletionItemKind.Constructor = 4;\n    CompletionItemKind.Field = 5;\n    CompletionItemKind.Variable = 6;\n    CompletionItemKind.Class = 7;\n    CompletionItemKind.Interface = 8;\n    CompletionItemKind.Module = 9;\n    CompletionItemKind.Property = 10;\n    CompletionItemKind.Unit = 11;\n    CompletionItemKind.Value = 12;\n    CompletionItemKind.Enum = 13;\n    CompletionItemKind.Keyword = 14;\n    CompletionItemKind.Snippet = 15;\n    CompletionItemKind.Color = 16;\n    CompletionItemKind.File = 17;\n    CompletionItemKind.Reference = 18;\n    CompletionItemKind.Folder = 19;\n    CompletionItemKind.EnumMember = 20;\n    CompletionItemKind.Constant = 21;\n    CompletionItemKind.Struct = 22;\n    CompletionItemKind.Event = 23;\n    CompletionItemKind.Operator = 24;\n    CompletionItemKind.TypeParameter = 25;\n})(CompletionItemKind || (CompletionItemKind = {}));\n/**\n * Defines whether the insert text in a completion item should be interpreted as\n * plain text or a snippet.\n */\nexport var InsertTextFormat;\n(function (InsertTextFormat) {\n    /**\n     * The primary text to be inserted is treated as a plain string.\n     */\n    InsertTextFormat.PlainText = 1;\n    /**\n     * The primary text to be inserted is treated as a snippet.\n     *\n     * A snippet can define tab stops and placeholders with `$1`, `$2`\n     * and `${3:foo}`. `$0` defines the final tab stop, it defaults to\n     * the end of the snippet. Placeholders with equal identifiers are linked,\n     * that is typing in one will update others too.\n     *\n     * See also: https://microsoft.github.io/language-server-protocol/specifications/specification-current/#snippet_syntax\n     */\n    InsertTextFormat.Snippet = 2;\n})(InsertTextFormat || (InsertTextFormat = {}));\n/**\n * Completion item tags are extra annotations that tweak the rendering of a completion\n * item.\n *\n * @since 3.15.0\n */\nexport var CompletionItemTag;\n(function (CompletionItemTag) {\n    /**\n     * Render a completion as obsolete, usually using a strike-out.\n     */\n    CompletionItemTag.Deprecated = 1;\n})(CompletionItemTag || (CompletionItemTag = {}));\n/**\n * The InsertReplaceEdit namespace provides functions to deal with insert / replace edits.\n *\n * @since 3.16.0\n */\nexport var InsertReplaceEdit;\n(function (InsertReplaceEdit) {\n    /**\n     * Creates a new insert / replace edit\n     */\n    function create(newText, insert, replace) {\n        return { newText, insert, replace };\n    }\n    InsertReplaceEdit.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InsertReplaceEdit} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate && Is.string(candidate.newText) && Range.is(candidate.insert) && Range.is(candidate.replace);\n    }\n    InsertReplaceEdit.is = is;\n})(InsertReplaceEdit || (InsertReplaceEdit = {}));\n/**\n * How whitespace and indentation is handled during completion\n * item insertion.\n *\n * @since 3.16.0\n */\nexport var InsertTextMode;\n(function (InsertTextMode) {\n    /**\n     * The insertion or replace strings is taken as it is. If the\n     * value is multi line the lines below the cursor will be\n     * inserted using the indentation defined in the string value.\n     * The client will not apply any kind of adjustments to the\n     * string.\n     */\n    InsertTextMode.asIs = 1;\n    /**\n     * The editor adjusts leading whitespace of new lines so that\n     * they match the indentation up to the cursor of the line for\n     * which the item is accepted.\n     *\n     * Consider a line like this: <2tabs><cursor><3tabs>foo. Accepting a\n     * multi line completion item is indented using 2 tabs and all\n     * following lines inserted will be indented using 2 tabs as well.\n     */\n    InsertTextMode.adjustIndentation = 2;\n})(InsertTextMode || (InsertTextMode = {}));\nexport var CompletionItemLabelDetails;\n(function (CompletionItemLabelDetails) {\n    function is(value) {\n        const candidate = value;\n        return candidate && (Is.string(candidate.detail) || candidate.detail === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    CompletionItemLabelDetails.is = is;\n})(CompletionItemLabelDetails || (CompletionItemLabelDetails = {}));\n/**\n * The CompletionItem namespace provides functions to deal with\n * completion items.\n */\nexport var CompletionItem;\n(function (CompletionItem) {\n    /**\n     * Create a completion item and seed it with a label.\n     * @param label The completion item's label\n     */\n    function create(label) {\n        return { label };\n    }\n    CompletionItem.create = create;\n})(CompletionItem || (CompletionItem = {}));\n/**\n * The CompletionList namespace provides functions to deal with\n * completion lists.\n */\nexport var CompletionList;\n(function (CompletionList) {\n    /**\n     * Creates a new completion list.\n     *\n     * @param items The completion items.\n     * @param isIncomplete The list is not complete.\n     */\n    function create(items, isIncomplete) {\n        return { items: items ? items : [], isIncomplete: !!isIncomplete };\n    }\n    CompletionList.create = create;\n})(CompletionList || (CompletionList = {}));\nexport var MarkedString;\n(function (MarkedString) {\n    /**\n     * Creates a marked string from plain text.\n     *\n     * @param plainText The plain text.\n     */\n    function fromPlainText(plainText) {\n        return plainText.replace(/[\\\\`*_{}[\\]()#+\\-.!]/g, '\\\\$&'); // escape markdown syntax tokens: http://daringfireball.net/projects/markdown/syntax#backslash\n    }\n    MarkedString.fromPlainText = fromPlainText;\n    /**\n     * Checks whether the given value conforms to the {@link MarkedString} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate) || (Is.objectLiteral(candidate) && Is.string(candidate.language) && Is.string(candidate.value));\n    }\n    MarkedString.is = is;\n})(MarkedString || (MarkedString = {}));\nexport var Hover;\n(function (Hover) {\n    /**\n     * Checks whether the given value conforms to the {@link Hover} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return !!candidate && Is.objectLiteral(candidate) && (MarkupContent.is(candidate.contents) ||\n            MarkedString.is(candidate.contents) ||\n            Is.typedArray(candidate.contents, MarkedString.is)) && (value.range === undefined || Range.is(value.range));\n    }\n    Hover.is = is;\n})(Hover || (Hover = {}));\n/**\n * The ParameterInformation namespace provides helper functions to work with\n * {@link ParameterInformation} literals.\n */\nexport var ParameterInformation;\n(function (ParameterInformation) {\n    /**\n     * Creates a new parameter information literal.\n     *\n     * @param label A label string.\n     * @param documentation A doc string.\n     */\n    function create(label, documentation) {\n        return documentation ? { label, documentation } : { label };\n    }\n    ParameterInformation.create = create;\n})(ParameterInformation || (ParameterInformation = {}));\n/**\n * The SignatureInformation namespace provides helper functions to work with\n * {@link SignatureInformation} literals.\n */\nexport var SignatureInformation;\n(function (SignatureInformation) {\n    function create(label, documentation, ...parameters) {\n        let result = { label };\n        if (Is.defined(documentation)) {\n            result.documentation = documentation;\n        }\n        if (Is.defined(parameters)) {\n            result.parameters = parameters;\n        }\n        else {\n            result.parameters = [];\n        }\n        return result;\n    }\n    SignatureInformation.create = create;\n})(SignatureInformation || (SignatureInformation = {}));\n/**\n * A document highlight kind.\n */\nexport var DocumentHighlightKind;\n(function (DocumentHighlightKind) {\n    /**\n     * A textual occurrence.\n     */\n    DocumentHighlightKind.Text = 1;\n    /**\n     * Read-access of a symbol, like reading a variable.\n     */\n    DocumentHighlightKind.Read = 2;\n    /**\n     * Write-access of a symbol, like writing to a variable.\n     */\n    DocumentHighlightKind.Write = 3;\n})(DocumentHighlightKind || (DocumentHighlightKind = {}));\n/**\n * DocumentHighlight namespace to provide helper functions to work with\n * {@link DocumentHighlight} literals.\n */\nexport var DocumentHighlight;\n(function (DocumentHighlight) {\n    /**\n     * Create a DocumentHighlight object.\n     * @param range The range the highlight applies to.\n     * @param kind The highlight kind\n     */\n    function create(range, kind) {\n        let result = { range };\n        if (Is.number(kind)) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    DocumentHighlight.create = create;\n})(DocumentHighlight || (DocumentHighlight = {}));\n/**\n * A symbol kind.\n */\nexport var SymbolKind;\n(function (SymbolKind) {\n    SymbolKind.File = 1;\n    SymbolKind.Module = 2;\n    SymbolKind.Namespace = 3;\n    SymbolKind.Package = 4;\n    SymbolKind.Class = 5;\n    SymbolKind.Method = 6;\n    SymbolKind.Property = 7;\n    SymbolKind.Field = 8;\n    SymbolKind.Constructor = 9;\n    SymbolKind.Enum = 10;\n    SymbolKind.Interface = 11;\n    SymbolKind.Function = 12;\n    SymbolKind.Variable = 13;\n    SymbolKind.Constant = 14;\n    SymbolKind.String = 15;\n    SymbolKind.Number = 16;\n    SymbolKind.Boolean = 17;\n    SymbolKind.Array = 18;\n    SymbolKind.Object = 19;\n    SymbolKind.Key = 20;\n    SymbolKind.Null = 21;\n    SymbolKind.EnumMember = 22;\n    SymbolKind.Struct = 23;\n    SymbolKind.Event = 24;\n    SymbolKind.Operator = 25;\n    SymbolKind.TypeParameter = 26;\n})(SymbolKind || (SymbolKind = {}));\n/**\n * Symbol tags are extra annotations that tweak the rendering of a symbol.\n *\n * @since 3.16\n */\nexport var SymbolTag;\n(function (SymbolTag) {\n    /**\n     * Render a symbol as obsolete, usually using a strike-out.\n     */\n    SymbolTag.Deprecated = 1;\n})(SymbolTag || (SymbolTag = {}));\nexport var SymbolInformation;\n(function (SymbolInformation) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the location of the symbol.\n     * @param uri The resource of the location of symbol.\n     * @param containerName The name of the symbol containing the symbol.\n     */\n    function create(name, kind, range, uri, containerName) {\n        let result = {\n            name,\n            kind,\n            location: { uri, range }\n        };\n        if (containerName) {\n            result.containerName = containerName;\n        }\n        return result;\n    }\n    SymbolInformation.create = create;\n})(SymbolInformation || (SymbolInformation = {}));\nexport var WorkspaceSymbol;\n(function (WorkspaceSymbol) {\n    /**\n     * Create a new workspace symbol.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param uri The resource of the location of the symbol.\n     * @param range An options range of the location.\n     * @returns A WorkspaceSymbol.\n     */\n    function create(name, kind, uri, range) {\n        return range !== undefined\n            ? { name, kind, location: { uri, range } }\n            : { name, kind, location: { uri } };\n    }\n    WorkspaceSymbol.create = create;\n})(WorkspaceSymbol || (WorkspaceSymbol = {}));\nexport var DocumentSymbol;\n(function (DocumentSymbol) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param detail The detail of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the symbol.\n     * @param selectionRange The selectionRange of the symbol.\n     * @param children Children of the symbol.\n     */\n    function create(name, detail, kind, range, selectionRange, children) {\n        let result = {\n            name,\n            detail,\n            kind,\n            range,\n            selectionRange\n        };\n        if (children !== undefined) {\n            result.children = children;\n        }\n        return result;\n    }\n    DocumentSymbol.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentSymbol} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            Is.string(candidate.name) && Is.number(candidate.kind) &&\n            Range.is(candidate.range) && Range.is(candidate.selectionRange) &&\n            (candidate.detail === undefined || Is.string(candidate.detail)) &&\n            (candidate.deprecated === undefined || Is.boolean(candidate.deprecated)) &&\n            (candidate.children === undefined || Array.isArray(candidate.children)) &&\n            (candidate.tags === undefined || Array.isArray(candidate.tags));\n    }\n    DocumentSymbol.is = is;\n})(DocumentSymbol || (DocumentSymbol = {}));\n/**\n * A set of predefined code action kinds\n */\nexport var CodeActionKind;\n(function (CodeActionKind) {\n    /**\n     * Empty kind.\n     */\n    CodeActionKind.Empty = '';\n    /**\n     * Base kind for quickfix actions: 'quickfix'\n     */\n    CodeActionKind.QuickFix = 'quickfix';\n    /**\n     * Base kind for refactoring actions: 'refactor'\n     */\n    CodeActionKind.Refactor = 'refactor';\n    /**\n     * Base kind for refactoring extraction actions: 'refactor.extract'\n     *\n     * Example extract actions:\n     *\n     * - Extract method\n     * - Extract function\n     * - Extract variable\n     * - Extract interface from class\n     * - ...\n     */\n    CodeActionKind.RefactorExtract = 'refactor.extract';\n    /**\n     * Base kind for refactoring inline actions: 'refactor.inline'\n     *\n     * Example inline actions:\n     *\n     * - Inline function\n     * - Inline variable\n     * - Inline constant\n     * - ...\n     */\n    CodeActionKind.RefactorInline = 'refactor.inline';\n    /**\n     * Base kind for refactoring rewrite actions: 'refactor.rewrite'\n     *\n     * Example rewrite actions:\n     *\n     * - Convert JavaScript function to class\n     * - Add or remove parameter\n     * - Encapsulate field\n     * - Make method static\n     * - Move method to base class\n     * - ...\n     */\n    CodeActionKind.RefactorRewrite = 'refactor.rewrite';\n    /**\n     * Base kind for source actions: `source`\n     *\n     * Source code actions apply to the entire file.\n     */\n    CodeActionKind.Source = 'source';\n    /**\n     * Base kind for an organize imports source action: `source.organizeImports`\n     */\n    CodeActionKind.SourceOrganizeImports = 'source.organizeImports';\n    /**\n     * Base kind for auto-fix source actions: `source.fixAll`.\n     *\n     * Fix all actions automatically fix errors that have a clear fix that do not require user input.\n     * They should not suppress errors or perform unsafe fixes such as generating new types or classes.\n     *\n     * @since 3.15.0\n     */\n    CodeActionKind.SourceFixAll = 'source.fixAll';\n})(CodeActionKind || (CodeActionKind = {}));\n/**\n * The reason why code actions were requested.\n *\n * @since 3.17.0\n */\nexport var CodeActionTriggerKind;\n(function (CodeActionTriggerKind) {\n    /**\n     * Code actions were explicitly requested by the user or by an extension.\n     */\n    CodeActionTriggerKind.Invoked = 1;\n    /**\n     * Code actions were requested automatically.\n     *\n     * This typically happens when current selection in a file changes, but can\n     * also be triggered when file content changes.\n     */\n    CodeActionTriggerKind.Automatic = 2;\n})(CodeActionTriggerKind || (CodeActionTriggerKind = {}));\n/**\n * The CodeActionContext namespace provides helper functions to work with\n * {@link CodeActionContext} literals.\n */\nexport var CodeActionContext;\n(function (CodeActionContext) {\n    /**\n     * Creates a new CodeActionContext literal.\n     */\n    function create(diagnostics, only, triggerKind) {\n        let result = { diagnostics };\n        if (only !== undefined && only !== null) {\n            result.only = only;\n        }\n        if (triggerKind !== undefined && triggerKind !== null) {\n            result.triggerKind = triggerKind;\n        }\n        return result;\n    }\n    CodeActionContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeActionContext} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.typedArray(candidate.diagnostics, Diagnostic.is)\n            && (candidate.only === undefined || Is.typedArray(candidate.only, Is.string))\n            && (candidate.triggerKind === undefined || candidate.triggerKind === CodeActionTriggerKind.Invoked || candidate.triggerKind === CodeActionTriggerKind.Automatic);\n    }\n    CodeActionContext.is = is;\n})(CodeActionContext || (CodeActionContext = {}));\nexport var CodeAction;\n(function (CodeAction) {\n    function create(title, kindOrCommandOrEdit, kind) {\n        let result = { title };\n        let checkKind = true;\n        if (typeof kindOrCommandOrEdit === 'string') {\n            checkKind = false;\n            result.kind = kindOrCommandOrEdit;\n        }\n        else if (Command.is(kindOrCommandOrEdit)) {\n            result.command = kindOrCommandOrEdit;\n        }\n        else {\n            result.edit = kindOrCommandOrEdit;\n        }\n        if (checkKind && kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    CodeAction.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && Is.string(candidate.title) &&\n            (candidate.diagnostics === undefined || Is.typedArray(candidate.diagnostics, Diagnostic.is)) &&\n            (candidate.kind === undefined || Is.string(candidate.kind)) &&\n            (candidate.edit !== undefined || candidate.command !== undefined) &&\n            (candidate.command === undefined || Command.is(candidate.command)) &&\n            (candidate.isPreferred === undefined || Is.boolean(candidate.isPreferred)) &&\n            (candidate.edit === undefined || WorkspaceEdit.is(candidate.edit));\n    }\n    CodeAction.is = is;\n})(CodeAction || (CodeAction = {}));\n/**\n * The CodeLens namespace provides helper functions to work with\n * {@link CodeLens} literals.\n */\nexport var CodeLens;\n(function (CodeLens) {\n    /**\n     * Creates a new CodeLens literal.\n     */\n    function create(range, data) {\n        let result = { range };\n        if (Is.defined(data)) {\n            result.data = data;\n        }\n        return result;\n    }\n    CodeLens.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeLens} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.command) || Command.is(candidate.command));\n    }\n    CodeLens.is = is;\n})(CodeLens || (CodeLens = {}));\n/**\n * The FormattingOptions namespace provides helper functions to work with\n * {@link FormattingOptions} literals.\n */\nexport var FormattingOptions;\n(function (FormattingOptions) {\n    /**\n     * Creates a new FormattingOptions literal.\n     */\n    function create(tabSize, insertSpaces) {\n        return { tabSize, insertSpaces };\n    }\n    FormattingOptions.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FormattingOptions} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.uinteger(candidate.tabSize) && Is.boolean(candidate.insertSpaces);\n    }\n    FormattingOptions.is = is;\n})(FormattingOptions || (FormattingOptions = {}));\n/**\n * The DocumentLink namespace provides helper functions to work with\n * {@link DocumentLink} literals.\n */\nexport var DocumentLink;\n(function (DocumentLink) {\n    /**\n     * Creates a new DocumentLink literal.\n     */\n    function create(range, target, data) {\n        return { range, target, data };\n    }\n    DocumentLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.target) || Is.string(candidate.target));\n    }\n    DocumentLink.is = is;\n})(DocumentLink || (DocumentLink = {}));\n/**\n * The SelectionRange namespace provides helper function to work with\n * SelectionRange literals.\n */\nexport var SelectionRange;\n(function (SelectionRange) {\n    /**\n     * Creates a new SelectionRange\n     * @param range the range.\n     * @param parent an optional parent.\n     */\n    function create(range, parent) {\n        return { range, parent };\n    }\n    SelectionRange.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (candidate.parent === undefined || SelectionRange.is(candidate.parent));\n    }\n    SelectionRange.is = is;\n})(SelectionRange || (SelectionRange = {}));\n/**\n * A set of predefined token types. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenTypes;\n(function (SemanticTokenTypes) {\n    SemanticTokenTypes[\"namespace\"] = \"namespace\";\n    /**\n     * Represents a generic type. Acts as a fallback for types which can't be mapped to\n     * a specific type like class or enum.\n     */\n    SemanticTokenTypes[\"type\"] = \"type\";\n    SemanticTokenTypes[\"class\"] = \"class\";\n    SemanticTokenTypes[\"enum\"] = \"enum\";\n    SemanticTokenTypes[\"interface\"] = \"interface\";\n    SemanticTokenTypes[\"struct\"] = \"struct\";\n    SemanticTokenTypes[\"typeParameter\"] = \"typeParameter\";\n    SemanticTokenTypes[\"parameter\"] = \"parameter\";\n    SemanticTokenTypes[\"variable\"] = \"variable\";\n    SemanticTokenTypes[\"property\"] = \"property\";\n    SemanticTokenTypes[\"enumMember\"] = \"enumMember\";\n    SemanticTokenTypes[\"event\"] = \"event\";\n    SemanticTokenTypes[\"function\"] = \"function\";\n    SemanticTokenTypes[\"method\"] = \"method\";\n    SemanticTokenTypes[\"macro\"] = \"macro\";\n    SemanticTokenTypes[\"keyword\"] = \"keyword\";\n    SemanticTokenTypes[\"modifier\"] = \"modifier\";\n    SemanticTokenTypes[\"comment\"] = \"comment\";\n    SemanticTokenTypes[\"string\"] = \"string\";\n    SemanticTokenTypes[\"number\"] = \"number\";\n    SemanticTokenTypes[\"regexp\"] = \"regexp\";\n    SemanticTokenTypes[\"operator\"] = \"operator\";\n    /**\n     * @since 3.17.0\n     */\n    SemanticTokenTypes[\"decorator\"] = \"decorator\";\n})(SemanticTokenTypes || (SemanticTokenTypes = {}));\n/**\n * A set of predefined token modifiers. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenModifiers;\n(function (SemanticTokenModifiers) {\n    SemanticTokenModifiers[\"declaration\"] = \"declaration\";\n    SemanticTokenModifiers[\"definition\"] = \"definition\";\n    SemanticTokenModifiers[\"readonly\"] = \"readonly\";\n    SemanticTokenModifiers[\"static\"] = \"static\";\n    SemanticTokenModifiers[\"deprecated\"] = \"deprecated\";\n    SemanticTokenModifiers[\"abstract\"] = \"abstract\";\n    SemanticTokenModifiers[\"async\"] = \"async\";\n    SemanticTokenModifiers[\"modification\"] = \"modification\";\n    SemanticTokenModifiers[\"documentation\"] = \"documentation\";\n    SemanticTokenModifiers[\"defaultLibrary\"] = \"defaultLibrary\";\n})(SemanticTokenModifiers || (SemanticTokenModifiers = {}));\n/**\n * @since 3.16.0\n */\nexport var SemanticTokens;\n(function (SemanticTokens) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && (candidate.resultId === undefined || typeof candidate.resultId === 'string') &&\n            Array.isArray(candidate.data) && (candidate.data.length === 0 || typeof candidate.data[0] === 'number');\n    }\n    SemanticTokens.is = is;\n})(SemanticTokens || (SemanticTokens = {}));\n/**\n * The InlineValueText namespace provides functions to deal with InlineValueTexts.\n *\n * @since 3.17.0\n */\nexport var InlineValueText;\n(function (InlineValueText) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, text) {\n        return { range, text };\n    }\n    InlineValueText.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.string(candidate.text);\n    }\n    InlineValueText.is = is;\n})(InlineValueText || (InlineValueText = {}));\n/**\n * The InlineValueVariableLookup namespace provides functions to deal with InlineValueVariableLookups.\n *\n * @since 3.17.0\n */\nexport var InlineValueVariableLookup;\n(function (InlineValueVariableLookup) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, variableName, caseSensitiveLookup) {\n        return { range, variableName, caseSensitiveLookup };\n    }\n    InlineValueVariableLookup.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.boolean(candidate.caseSensitiveLookup)\n            && (Is.string(candidate.variableName) || candidate.variableName === undefined);\n    }\n    InlineValueVariableLookup.is = is;\n})(InlineValueVariableLookup || (InlineValueVariableLookup = {}));\n/**\n * The InlineValueEvaluatableExpression namespace provides functions to deal with InlineValueEvaluatableExpression.\n *\n * @since 3.17.0\n */\nexport var InlineValueEvaluatableExpression;\n(function (InlineValueEvaluatableExpression) {\n    /**\n     * Creates a new InlineValueEvaluatableExpression literal.\n     */\n    function create(range, expression) {\n        return { range, expression };\n    }\n    InlineValueEvaluatableExpression.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range)\n            && (Is.string(candidate.expression) || candidate.expression === undefined);\n    }\n    InlineValueEvaluatableExpression.is = is;\n})(InlineValueEvaluatableExpression || (InlineValueEvaluatableExpression = {}));\n/**\n * The InlineValueContext namespace provides helper functions to work with\n * {@link InlineValueContext} literals.\n *\n * @since 3.17.0\n */\nexport var InlineValueContext;\n(function (InlineValueContext) {\n    /**\n     * Creates a new InlineValueContext literal.\n     */\n    function create(frameId, stoppedLocation) {\n        return { frameId, stoppedLocation };\n    }\n    InlineValueContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InlineValueContext} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.defined(candidate) && Range.is(value.stoppedLocation);\n    }\n    InlineValueContext.is = is;\n})(InlineValueContext || (InlineValueContext = {}));\n/**\n * Inlay hint kinds.\n *\n * @since 3.17.0\n */\nexport var InlayHintKind;\n(function (InlayHintKind) {\n    /**\n     * An inlay hint that for a type annotation.\n     */\n    InlayHintKind.Type = 1;\n    /**\n     * An inlay hint that is for a parameter.\n     */\n    InlayHintKind.Parameter = 2;\n    function is(value) {\n        return value === 1 || value === 2;\n    }\n    InlayHintKind.is = is;\n})(InlayHintKind || (InlayHintKind = {}));\nexport var InlayHintLabelPart;\n(function (InlayHintLabelPart) {\n    function create(value) {\n        return { value };\n    }\n    InlayHintLabelPart.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.location === undefined || Location.is(candidate.location))\n            && (candidate.command === undefined || Command.is(candidate.command));\n    }\n    InlayHintLabelPart.is = is;\n})(InlayHintLabelPart || (InlayHintLabelPart = {}));\nexport var InlayHint;\n(function (InlayHint) {\n    function create(position, label, kind) {\n        const result = { position, label };\n        if (kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    InlayHint.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.position)\n            && (Is.string(candidate.label) || Is.typedArray(candidate.label, InlayHintLabelPart.is))\n            && (candidate.kind === undefined || InlayHintKind.is(candidate.kind))\n            && (candidate.textEdits === undefined) || Is.typedArray(candidate.textEdits, TextEdit.is)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.paddingLeft === undefined || Is.boolean(candidate.paddingLeft))\n            && (candidate.paddingRight === undefined || Is.boolean(candidate.paddingRight));\n    }\n    InlayHint.is = is;\n})(InlayHint || (InlayHint = {}));\nexport var StringValue;\n(function (StringValue) {\n    function createSnippet(value) {\n        return { kind: 'snippet', value };\n    }\n    StringValue.createSnippet = createSnippet;\n})(StringValue || (StringValue = {}));\nexport var InlineCompletionItem;\n(function (InlineCompletionItem) {\n    function create(insertText, filterText, range, command) {\n        return { insertText, filterText, range, command };\n    }\n    InlineCompletionItem.create = create;\n})(InlineCompletionItem || (InlineCompletionItem = {}));\nexport var InlineCompletionList;\n(function (InlineCompletionList) {\n    function create(items) {\n        return { items };\n    }\n    InlineCompletionList.create = create;\n})(InlineCompletionList || (InlineCompletionList = {}));\n/**\n * Describes how an {@link InlineCompletionItemProvider inline completion provider} was triggered.\n *\n * @since 3.18.0\n * @proposed\n */\nexport var InlineCompletionTriggerKind;\n(function (InlineCompletionTriggerKind) {\n    /**\n     * Completion was triggered explicitly by a user gesture.\n     */\n    InlineCompletionTriggerKind.Invoked = 0;\n    /**\n     * Completion was triggered automatically while editing.\n     */\n    InlineCompletionTriggerKind.Automatic = 1;\n})(InlineCompletionTriggerKind || (InlineCompletionTriggerKind = {}));\nexport var SelectedCompletionInfo;\n(function (SelectedCompletionInfo) {\n    function create(range, text) {\n        return { range, text };\n    }\n    SelectedCompletionInfo.create = create;\n})(SelectedCompletionInfo || (SelectedCompletionInfo = {}));\nexport var InlineCompletionContext;\n(function (InlineCompletionContext) {\n    function create(triggerKind, selectedCompletionInfo) {\n        return { triggerKind, selectedCompletionInfo };\n    }\n    InlineCompletionContext.create = create;\n})(InlineCompletionContext || (InlineCompletionContext = {}));\nexport var WorkspaceFolder;\n(function (WorkspaceFolder) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && URI.is(candidate.uri) && Is.string(candidate.name);\n    }\n    WorkspaceFolder.is = is;\n})(WorkspaceFolder || (WorkspaceFolder = {}));\nexport const EOL = ['\\n', '\\r\\n', '\\r'];\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new ITextDocument literal from the given uri and content.\n     * @param uri The document's uri.\n     * @param languageId The document's language Id.\n     * @param version The document's version.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ITextDocument} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (Is.undefined(candidate.languageId) || Is.string(candidate.languageId)) && Is.uinteger(candidate.lineCount)\n            && Is.func(candidate.getText) && Is.func(candidate.positionAt) && Is.func(candidate.offsetAt) ? true : false;\n    }\n    TextDocument.is = is;\n    function applyEdits(document, edits) {\n        let text = document.getText();\n        let sortedEdits = mergeSort(edits, (a, b) => {\n            let diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = text.length;\n        for (let i = sortedEdits.length - 1; i >= 0; i--) {\n            let e = sortedEdits[i];\n            let startOffset = document.offsetAt(e.range.start);\n            let endOffset = document.offsetAt(e.range.end);\n            if (endOffset <= lastModifiedOffset) {\n                text = text.substring(0, startOffset) + e.newText + text.substring(endOffset, text.length);\n            }\n            else {\n                throw new Error('Overlapping edit');\n            }\n            lastModifiedOffset = startOffset;\n        }\n        return text;\n    }\n    TextDocument.applyEdits = applyEdits;\n    function mergeSort(data, compare) {\n        if (data.length <= 1) {\n            // sorted\n            return data;\n        }\n        const p = (data.length / 2) | 0;\n        const left = data.slice(0, p);\n        const right = data.slice(p);\n        mergeSort(left, compare);\n        mergeSort(right, compare);\n        let leftIdx = 0;\n        let rightIdx = 0;\n        let i = 0;\n        while (leftIdx < left.length && rightIdx < right.length) {\n            let ret = compare(left[leftIdx], right[rightIdx]);\n            if (ret <= 0) {\n                // smaller_equal -> take left to preserve order\n                data[i++] = left[leftIdx++];\n            }\n            else {\n                // greater -> take right\n                data[i++] = right[rightIdx++];\n            }\n        }\n        while (leftIdx < left.length) {\n            data[i++] = left[leftIdx++];\n        }\n        while (rightIdx < right.length) {\n            data[i++] = right[rightIdx++];\n        }\n        return data;\n    }\n})(TextDocument || (TextDocument = {}));\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            let start = this.offsetAt(range.start);\n            let end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(event, version) {\n        this._content = event.text;\n        this._version = version;\n        this._lineOffsets = undefined;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            let lineOffsets = [];\n            let text = this._content;\n            let isLineStart = true;\n            for (let i = 0; i < text.length; i++) {\n                if (isLineStart) {\n                    lineOffsets.push(i);\n                    isLineStart = false;\n                }\n                let ch = text.charAt(i);\n                isLineStart = (ch === '\\r' || ch === '\\n');\n                if (ch === '\\r' && i + 1 < text.length && text.charAt(i + 1) === '\\n') {\n                    i++;\n                }\n            }\n            if (isLineStart && text.length > 0) {\n                lineOffsets.push(text.length);\n            }\n            this._lineOffsets = lineOffsets;\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        let lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return Position.create(0, offset);\n        }\n        while (low < high) {\n            let mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        let line = low - 1;\n        return Position.create(line, offset - lineOffsets[line]);\n    }\n    offsetAt(position) {\n        let lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        let lineOffset = lineOffsets[position.line];\n        let nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        return Math.max(Math.min(lineOffset + position.character, nextLineOffset), lineOffset);\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n}\nvar Is;\n(function (Is) {\n    const toString = Object.prototype.toString;\n    function defined(value) {\n        return typeof value !== 'undefined';\n    }\n    Is.defined = defined;\n    function undefined(value) {\n        return typeof value === 'undefined';\n    }\n    Is.undefined = undefined;\n    function boolean(value) {\n        return value === true || value === false;\n    }\n    Is.boolean = boolean;\n    function string(value) {\n        return toString.call(value) === '[object String]';\n    }\n    Is.string = string;\n    function number(value) {\n        return toString.call(value) === '[object Number]';\n    }\n    Is.number = number;\n    function numberRange(value, min, max) {\n        return toString.call(value) === '[object Number]' && min <= value && value <= max;\n    }\n    Is.numberRange = numberRange;\n    function integer(value) {\n        return toString.call(value) === '[object Number]' && -2147483648 <= value && value <= 2147483647;\n    }\n    Is.integer = integer;\n    function uinteger(value) {\n        return toString.call(value) === '[object Number]' && 0 <= value && value <= 2147483647;\n    }\n    Is.uinteger = uinteger;\n    function func(value) {\n        return toString.call(value) === '[object Function]';\n    }\n    Is.func = func;\n    function objectLiteral(value) {\n        // Strictly speaking class instances pass this check as well. Since the LSP\n        // doesn't use classes we ignore this for now. If we do we need to add something\n        // like this: `Object.getPrototypeOf(Object.getPrototypeOf(x)) === null`\n        return value !== null && typeof value === 'object';\n    }\n    Is.objectLiteral = objectLiteral;\n    function typedArray(value, check) {\n        return Array.isArray(value) && value.every(check);\n    }\n    Is.typedArray = typedArray;\n})(Is || (Is = {}));\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { IToken, TokenType } from 'chevrotain';\nimport type { Range } from 'vscode-languageserver-types';\nimport type { AbstractElement } from '../languages/generated/ast.js';\nimport type { AstNode, CompositeCstNode, CstNode, LeafCstNode, RootCstNode } from '../syntax-tree.js';\nimport { Position } from 'vscode-languageserver-types';\nimport { isCompositeCstNode } from '../syntax-tree.js';\nimport { tokenToRange } from '../utils/cst-utils.js';\n\nexport class CstNodeBuilder {\n\n    private rootNode!: RootCstNodeImpl;\n    private nodeStack: CompositeCstNodeImpl[] = [];\n\n    private get current(): CompositeCstNodeImpl {\n        return this.nodeStack[this.nodeStack.length - 1];\n    }\n\n    buildRootNode(input: string): RootCstNode {\n        this.rootNode = new RootCstNodeImpl(input);\n        this.rootNode.root = this.rootNode;\n        this.nodeStack = [this.rootNode];\n        return this.rootNode;\n    }\n\n    buildCompositeNode(feature: AbstractElement): CompositeCstNode {\n        const compositeNode = new CompositeCstNodeImpl();\n        compositeNode.grammarSource = feature;\n        compositeNode.root = this.rootNode;\n        this.current.content.push(compositeNode);\n        this.nodeStack.push(compositeNode);\n        return compositeNode;\n    }\n\n    buildLeafNode(token: IToken, feature: AbstractElement): LeafCstNode {\n        const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, false);\n        leafNode.grammarSource = feature;\n        leafNode.root = this.rootNode;\n        this.current.content.push(leafNode);\n        return leafNode;\n    }\n\n    removeNode(node: CstNode): void {\n        const parent = node.container;\n        if (parent) {\n            const index = parent.content.indexOf(node);\n            if (index >= 0) {\n                parent.content.splice(index, 1);\n            }\n        }\n    }\n\n    construct(item: { $type: string | symbol | undefined, $cstNode: CstNode }): void {\n        const current: CstNode = this.current;\n        // The specified item could be a datatype ($type is symbol) or a fragment ($type is undefined)\n        // Only if the $type is a string, we actually assign the element\n        if (typeof item.$type === 'string') {\n            this.current.astNode = <AstNode>item;\n        }\n        item.$cstNode = current;\n        const node = this.nodeStack.pop();\n        // Empty composite nodes are not valid\n        // Simply remove the node from the tree\n        if (node?.content.length === 0) {\n            this.removeNode(node);\n        }\n    }\n\n    addHiddenTokens(hiddenTokens: IToken[]): void {\n        for (const token of hiddenTokens) {\n            const hiddenNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, true);\n            hiddenNode.root = this.rootNode;\n            this.addHiddenToken(this.rootNode, hiddenNode);\n        }\n    }\n\n    private addHiddenToken(node: CompositeCstNode, token: LeafCstNode): void {\n        const { offset: tokenStart, end: tokenEnd } = token;\n\n        for (let i = 0; i < node.content.length; i++) {\n            const child = node.content[i];\n            const { offset: childStart, end: childEnd } = child;\n            if (isCompositeCstNode(child) && tokenStart > childStart && tokenEnd < childEnd) {\n                this.addHiddenToken(child, token);\n                return;\n            } else if (tokenEnd <= childStart) {\n                node.content.splice(i, 0, token);\n                return;\n            }\n        }\n\n        // We know that we haven't found a suited position for the token\n        // So we simply add it to the end of the current node\n        node.content.push(token);\n    }\n}\n\nexport abstract class AbstractCstNode implements CstNode {\n    abstract get offset(): number;\n    abstract get length(): number;\n    abstract get end(): number;\n    abstract get range(): Range;\n\n    container?: CompositeCstNode;\n    grammarSource: AbstractElement;\n    root: RootCstNode;\n    private _astNode?: AstNode;\n\n    /** @deprecated use `container` instead. */\n    get parent(): CompositeCstNode | undefined {\n        return this.container;\n    }\n\n    /** @deprecated use `grammarSource` instead. */\n    get feature(): AbstractElement {\n        return this.grammarSource;\n    }\n\n    get hidden(): boolean {\n        return false;\n    }\n\n    get astNode(): AstNode {\n        const node = typeof this._astNode?.$type === 'string' ? this._astNode : this.container?.astNode;\n        if (!node) {\n            throw new Error('This node has no associated AST element');\n        }\n        return node;\n    }\n\n    set astNode(value: AstNode) {\n        this._astNode = value;\n    }\n\n    /** @deprecated use `astNode` instead. */\n    get element(): AstNode {\n        return this.astNode;\n    }\n\n    get text(): string {\n        return this.root.fullText.substring(this.offset, this.end);\n    }\n}\n\nexport class LeafCstNodeImpl extends AbstractCstNode implements LeafCstNode {\n    get offset(): number {\n        return this._offset;\n    }\n\n    get length(): number {\n        return this._length;\n    }\n\n    get end(): number {\n        return this._offset + this._length;\n    }\n\n    override get hidden(): boolean {\n        return this._hidden;\n    }\n\n    get tokenType(): TokenType {\n        return this._tokenType;\n    }\n\n    get range(): Range {\n        return this._range;\n    }\n\n    private _hidden: boolean;\n    private _offset: number;\n    private _length: number;\n    private _range: Range;\n    private _tokenType: TokenType;\n\n    constructor(offset: number, length: number, range: Range, tokenType: TokenType, hidden = false) {\n        super();\n        this._hidden = hidden;\n        this._offset = offset;\n        this._tokenType = tokenType;\n        this._length = length;\n        this._range = range;\n    }\n}\n\nexport class CompositeCstNodeImpl extends AbstractCstNode implements CompositeCstNode {\n    readonly content: CstNode[] = new CstNodeContainer(this);\n    private _rangeCache?: Range;\n\n    /** @deprecated use `content` instead. */\n    get children(): CstNode[] {\n        return this.content;\n    }\n\n    get offset(): number {\n        return this.firstNonHiddenNode?.offset ?? 0;\n    }\n\n    get length(): number {\n        return this.end - this.offset;\n    }\n\n    get end(): number {\n        return this.lastNonHiddenNode?.end ?? 0;\n    }\n\n    get range(): Range {\n        const firstNode = this.firstNonHiddenNode;\n        const lastNode = this.lastNonHiddenNode;\n        if (firstNode && lastNode) {\n            if (this._rangeCache === undefined) {\n                const { range: firstRange } = firstNode;\n                const { range: lastRange } = lastNode;\n                this._rangeCache = { start: firstRange.start, end: lastRange.end.line < firstRange.start.line ? firstRange.start : lastRange.end };\n            }\n            return this._rangeCache;\n        } else {\n            return { start: Position.create(0, 0), end: Position.create(0, 0) };\n        }\n    }\n\n    private get firstNonHiddenNode(): CstNode | undefined {\n        for (const child of this.content) {\n            if (!child.hidden) {\n                return child;\n            }\n        }\n        return this.content[0];\n    }\n\n    private get lastNonHiddenNode(): CstNode | undefined {\n        for (let i = this.content.length - 1; i >= 0; i--) {\n            const child = this.content[i];\n            if (!child.hidden) {\n                return child;\n            }\n        }\n        return this.content[this.content.length - 1];\n    }\n}\n\nclass CstNodeContainer extends Array<CstNode> {\n    readonly parent: CompositeCstNode;\n\n    constructor(parent: CompositeCstNode) {\n        super();\n        this.parent = parent;\n        Object.setPrototypeOf(this, CstNodeContainer.prototype);\n    }\n\n    override push(...items: CstNode[]): number {\n        this.addParents(items);\n        return super.push(...items);\n    }\n\n    override unshift(...items: CstNode[]): number {\n        this.addParents(items);\n        return super.unshift(...items);\n    }\n\n    override splice(start: number, count: number, ...items: CstNode[]): CstNode[] {\n        this.addParents(items);\n        return super.splice(start, count, ...items);\n    }\n\n    private addParents(items: CstNode[]): void {\n        for (const item of items) {\n            (<AbstractCstNode>item).container = this.parent;\n        }\n    }\n}\n\nexport class RootCstNodeImpl extends CompositeCstNodeImpl implements RootCstNode {\n    private _text = '';\n\n    override get text(): string {\n        return this._text.substring(this.offset, this.end);\n    }\n\n    get fullText(): string {\n        return this._text;\n    }\n\n    constructor(input?: string) {\n        super();\n        this._text = input ?? '';\n    }\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\n/* eslint-disable @typescript-eslint/no-explicit-any */\nimport type { DSLMethodOpts, ILexingError, IOrAlt, IParserErrorMessageProvider, IRecognitionException, IToken, TokenType, TokenVocabulary } from 'chevrotain';\nimport type { AbstractElement, Action, Assignment, ParserRule } from '../languages/generated/ast.js';\nimport type { Linker } from '../references/linker.js';\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, AstReflection, CompositeCstNode, CstNode } from '../syntax-tree.js';\nimport type { Lexer } from './lexer.js';\nimport type { IParserConfig } from './parser-config.js';\nimport type { ValueConverter } from './value-converter.js';\nimport { defaultParserErrorProvider, EmbeddedActionsParser, LLkLookaheadStrategy } from 'chevrotain';\nimport { LLStarLookaheadStrategy } from 'chevrotain-allstar';\nimport { isAssignment, isCrossReference, isKeyword } from '../languages/generated/ast.js';\nimport { getTypeName, isDataTypeRule } from '../utils/grammar-utils.js';\nimport { assignMandatoryProperties, getContainerOfType, linkContentToContainer } from '../utils/ast-utils.js';\nimport { CstNodeBuilder } from './cst-node-builder.js';\n\nexport type ParseResult<T = AstNode> = {\n    value: T,\n    parserErrors: IRecognitionException[],\n    lexerErrors: ILexingError[]\n}\n\nexport const DatatypeSymbol = Symbol('Datatype');\n\ninterface DataTypeNode {\n    $cstNode: CompositeCstNode\n    /** Instead of a string, this node is uniquely identified by the `Datatype` symbol */\n    $type: symbol\n    /** Used as a storage for all parsed terminals, keywords and sub-datatype rules */\n    value: string\n}\n\nfunction isDataTypeNode(node: { $type: string | symbol | undefined }): node is DataTypeNode {\n    return node.$type === DatatypeSymbol;\n}\n\ntype RuleResult = (args: Args) => any;\n\ntype Args = Record<string, boolean>;\n\ntype RuleImpl = (args: Args) => any;\n\ninterface AssignmentElement {\n    assignment?: Assignment\n    isCrossRef: boolean\n}\n\nexport interface BaseParser {\n    rule(rule: ParserRule, impl: RuleImpl): RuleResult;\n    alternatives(idx: number, choices: Array<IOrAlt<any>>): void;\n    optional(idx: number, callback: DSLMethodOpts<unknown>): void;\n    many(idx: number, callback: DSLMethodOpts<unknown>): void;\n    atLeastOne(idx: number, callback: DSLMethodOpts<unknown>): void;\n    consume(idx: number, tokenType: TokenType, feature: AbstractElement): void;\n    subrule(idx: number, rule: RuleResult, feature: AbstractElement, args: Args): void;\n    action($type: string, action: Action): void;\n    construct(): unknown;\n    isRecording(): boolean;\n    get unorderedGroups(): Map<string, boolean[]>;\n    getRuleStack(): number[];\n}\n\nconst ruleSuffix = '\\u200B';\nconst withRuleSuffix = (name: string): string => name.endsWith(ruleSuffix) ? name : name + ruleSuffix;\n\nexport abstract class AbstractLangiumParser implements BaseParser {\n\n    protected readonly lexer: Lexer;\n    protected readonly wrapper: ChevrotainWrapper;\n    protected _unorderedGroups: Map<string, boolean[]> = new Map<string, boolean[]>();\n\n    constructor(services: LangiumCoreServices) {\n        this.lexer = services.parser.Lexer;\n        const tokens = this.lexer.definition;\n        this.wrapper = new ChevrotainWrapper(tokens, {\n            ...services.parser.ParserConfig,\n            errorMessageProvider: services.parser.ParserErrorMessageProvider\n        });\n    }\n\n    alternatives(idx: number, choices: Array<IOrAlt<any>>): void {\n        this.wrapper.wrapOr(idx, choices);\n    }\n\n    optional(idx: number, callback: DSLMethodOpts<unknown>): void {\n        this.wrapper.wrapOption(idx, callback);\n    }\n\n    many(idx: number, callback: DSLMethodOpts<unknown>): void {\n        this.wrapper.wrapMany(idx, callback);\n    }\n\n    atLeastOne(idx: number, callback: DSLMethodOpts<unknown>): void {\n        this.wrapper.wrapAtLeastOne(idx, callback);\n    }\n\n    abstract rule(rule: ParserRule, impl: RuleImpl): RuleResult;\n    abstract consume(idx: number, tokenType: TokenType, feature: AbstractElement): void;\n    abstract subrule(idx: number, rule: RuleResult, feature: AbstractElement, args: Args): void;\n    abstract action($type: string, action: Action): void;\n    abstract construct(): unknown;\n\n    isRecording(): boolean {\n        return this.wrapper.IS_RECORDING;\n    }\n\n    get unorderedGroups(): Map<string, boolean[]> {\n        return this._unorderedGroups;\n    }\n\n    getRuleStack(): number[] {\n        return (this.wrapper as any).RULE_STACK;\n    }\n\n    finalize(): void {\n        this.wrapper.wrapSelfAnalysis();\n    }\n}\n\nexport class LangiumParser extends AbstractLangiumParser {\n    private readonly linker: Linker;\n    private readonly converter: ValueConverter;\n    private readonly astReflection: AstReflection;\n    private readonly nodeBuilder = new CstNodeBuilder();\n    private stack: any[] = [];\n    private mainRule!: RuleResult;\n    private assignmentMap = new Map<AbstractElement, AssignmentElement | undefined>();\n\n    private get current(): any {\n        return this.stack[this.stack.length - 1];\n    }\n\n    constructor(services: LangiumCoreServices) {\n        super(services);\n        this.linker = services.references.Linker;\n        this.converter = services.parser.ValueConverter;\n        this.astReflection = services.shared.AstReflection;\n    }\n\n    rule(rule: ParserRule, impl: RuleImpl): RuleResult {\n        const type = rule.fragment ? undefined : isDataTypeRule(rule) ? DatatypeSymbol : getTypeName(rule);\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(type, impl).bind(this));\n        if (rule.entry) {\n            this.mainRule = ruleMethod;\n        }\n        return ruleMethod;\n    }\n\n    parse<T extends AstNode = AstNode>(input: string): ParseResult<T> {\n        this.nodeBuilder.buildRootNode(input);\n        const lexerResult = this.lexer.tokenize(input);\n        this.wrapper.input = lexerResult.tokens;\n        const result = this.mainRule.call(this.wrapper, {});\n        this.nodeBuilder.addHiddenTokens(lexerResult.hidden);\n        this.unorderedGroups.clear();\n        return {\n            value: result,\n            lexerErrors: lexerResult.errors,\n            parserErrors: this.wrapper.errors\n        };\n    }\n\n    private startImplementation($type: string | symbol | undefined, implementation: RuleImpl): RuleImpl {\n        return (args) => {\n            if (!this.isRecording()) {\n                const node: any = { $type };\n                this.stack.push(node);\n                if ($type === DatatypeSymbol) {\n                    node.value = '';\n                }\n            }\n            let result: unknown;\n            try {\n                result = implementation(args);\n            } catch (err) {\n                result = undefined;\n            }\n            if (!this.isRecording() && result === undefined) {\n                result = this.construct();\n            }\n            return result;\n        };\n    }\n\n    consume(idx: number, tokenType: TokenType, feature: AbstractElement): void {\n        const token = this.wrapper.wrapConsume(idx, tokenType);\n        if (!this.isRecording() && this.isValidToken(token)) {\n            const leafNode = this.nodeBuilder.buildLeafNode(token, feature);\n            const { assignment, isCrossRef } = this.getAssignment(feature);\n            const current = this.current;\n            if (assignment) {\n                const convertedValue = isKeyword(feature) ? token.image : this.converter.convert(token.image, leafNode);\n                this.assign(assignment.operator, assignment.feature, convertedValue, leafNode, isCrossRef);\n            } else if (isDataTypeNode(current)) {\n                let text = token.image;\n                if (!isKeyword(feature)) {\n                    text = this.converter.convert(text, leafNode).toString();\n                }\n                current.value += text;\n            }\n        }\n    }\n\n    /**\n     * Most consumed parser tokens are valid. However there are two cases in which they are not valid:\n     *\n     * 1. They were inserted during error recovery by the parser. These tokens don't really exist and should not be further processed\n     * 2. They contain invalid token ranges. This might include the special EOF token, or other tokens produced by invalid token builders.\n     */\n    private isValidToken(token: IToken): boolean {\n        return !token.isInsertedInRecovery && !isNaN(token.startOffset) && typeof token.endOffset === 'number' && !isNaN(token.endOffset);\n    }\n\n    subrule(idx: number, rule: RuleResult, feature: AbstractElement, args: Args): void {\n        let cstNode: CompositeCstNode | undefined;\n        if (!this.isRecording()) {\n            cstNode = this.nodeBuilder.buildCompositeNode(feature);\n        }\n        const subruleResult = this.wrapper.wrapSubrule(idx, rule, args) as any;\n        if (!this.isRecording() && cstNode && cstNode.length > 0) {\n            this.performSubruleAssignment(subruleResult, feature, cstNode);\n        }\n    }\n\n    private performSubruleAssignment(result: any, feature: AbstractElement, cstNode: CompositeCstNode): void {\n        const { assignment, isCrossRef } = this.getAssignment(feature);\n        if (assignment) {\n            this.assign(assignment.operator, assignment.feature, result, cstNode, isCrossRef);\n        } else if (!assignment) {\n            // If we call a subrule without an assignment we either:\n            // 1. append the result of the subrule (data type rule)\n            // 2. override the current object with the newly parsed object\n            // If the current element is an AST node and the result of the subrule\n            // is a data type rule, we can safely discard the results.\n            const current = this.current;\n            if (isDataTypeNode(current)) {\n                current.value += result.toString();\n            } else if (typeof result === 'object' && result) {\n                const resultKind = result.$type;\n                const object = this.assignWithoutOverride(result, current);\n                if (resultKind) {\n                    object.$type = resultKind;\n                }\n                const newItem = object;\n                this.stack.pop();\n                this.stack.push(newItem);\n            }\n        }\n    }\n\n    action($type: string, action: Action): void {\n        if (!this.isRecording()) {\n            let last = this.current;\n            // This branch is used for left recursive grammar rules.\n            // Those don't call `construct` before another action.\n            // Therefore, we need to call it here.\n            if (!last.$cstNode && action.feature && action.operator) {\n                last = this.construct(false);\n                const feature = last.$cstNode.feature;\n                this.nodeBuilder.buildCompositeNode(feature);\n            }\n            const newItem = { $type };\n            this.stack.pop();\n            this.stack.push(newItem);\n            if (action.feature && action.operator) {\n                this.assign(action.operator, action.feature, last, last.$cstNode, false);\n            }\n        }\n    }\n\n    construct(pop = true): unknown {\n        if (this.isRecording()) {\n            return undefined;\n        }\n        const obj = this.current;\n        linkContentToContainer(obj);\n        this.nodeBuilder.construct(obj);\n        if (pop) {\n            this.stack.pop();\n        }\n        if (isDataTypeNode(obj)) {\n            return this.converter.convert(obj.value, obj.$cstNode);\n        } else {\n            assignMandatoryProperties(this.astReflection, obj);\n        }\n        return obj;\n    }\n\n    private getAssignment(feature: AbstractElement): AssignmentElement {\n        if (!this.assignmentMap.has(feature)) {\n            const assignment = getContainerOfType(feature, isAssignment);\n            this.assignmentMap.set(feature, {\n                assignment: assignment,\n                isCrossRef: assignment ? isCrossReference(assignment.terminal) : false\n            });\n        }\n        return this.assignmentMap.get(feature)!;\n    }\n\n    private assign(operator: string, feature: string, value: unknown, cstNode: CstNode, isCrossRef: boolean): void {\n        const obj = this.current;\n        let item: unknown;\n        if (isCrossRef && typeof value === 'string') {\n            item = this.linker.buildReference(obj, feature, cstNode, value);\n        } else {\n            item = value;\n        }\n        switch (operator) {\n            case '=': {\n                obj[feature] = item;\n                break;\n            }\n            case '?=': {\n                obj[feature] = true;\n                break;\n            }\n            case '+=': {\n                if (!Array.isArray(obj[feature])) {\n                    obj[feature] = [];\n                }\n                obj[feature].push(item);\n            }\n        }\n    }\n\n    private assignWithoutOverride(target: any, source: any): any {\n        for (const [name, existingValue] of Object.entries(source)) {\n            const newValue = target[name];\n            if (newValue === undefined) {\n                target[name] = existingValue;\n            } else if (Array.isArray(newValue) && Array.isArray(existingValue)) {\n                existingValue.push(...newValue);\n                target[name] = existingValue;\n            }\n        }\n        return target;\n    }\n\n    get definitionErrors(): IParserDefinitionError[] {\n        return this.wrapper.definitionErrors;\n    }\n}\n\nexport interface IParserDefinitionError {\n    message: string\n    type: number\n    ruleName?: string\n}\n\nexport abstract class AbstractParserErrorMessageProvider implements IParserErrorMessageProvider {\n\n    buildMismatchTokenMessage(options: {\n        expected: TokenType\n        actual: IToken\n        previous: IToken\n        ruleName: string\n    }): string {\n        return defaultParserErrorProvider.buildMismatchTokenMessage(options);\n    }\n\n    buildNotAllInputParsedMessage(options: {\n        firstRedundant: IToken\n        ruleName: string\n    }): string {\n        return defaultParserErrorProvider.buildNotAllInputParsedMessage(options);\n    }\n\n    buildNoViableAltMessage(options: {\n        expectedPathsPerAlt: TokenType[][][]\n        actual: IToken[]\n        previous: IToken\n        customUserDescription: string\n        ruleName: string\n    }): string {\n        return defaultParserErrorProvider.buildNoViableAltMessage(options);\n    }\n\n    buildEarlyExitMessage(options: {\n        expectedIterationPaths: TokenType[][]\n        actual: IToken[]\n        previous: IToken\n        customUserDescription: string\n        ruleName: string\n    }): string {\n        return defaultParserErrorProvider.buildEarlyExitMessage(options);\n    }\n\n}\n\nexport class LangiumParserErrorMessageProvider extends AbstractParserErrorMessageProvider {\n\n    override buildMismatchTokenMessage({ expected, actual }: {\n        expected: TokenType\n        actual: IToken\n        previous: IToken\n        ruleName: string\n    }): string {\n        const expectedMsg = expected.LABEL\n            ? '`' + expected.LABEL + '`'\n            : expected.name.endsWith(':KW')\n                ? `keyword '${expected.name.substring(0, expected.name.length - 3)}'`\n                : `token of type '${expected.name}'`;\n        return `Expecting ${expectedMsg} but found \\`${actual.image}\\`.`;\n    }\n\n    override buildNotAllInputParsedMessage({ firstRedundant }: {\n        firstRedundant: IToken\n        ruleName: string\n    }): string {\n        return `Expecting end of file but found \\`${firstRedundant.image}\\`.`;\n    }\n}\n\nexport interface CompletionParserResult {\n    tokens: IToken[]\n    elementStack: AbstractElement[]\n    tokenIndex: number\n}\n\nexport class LangiumCompletionParser extends AbstractLangiumParser {\n    private mainRule!: RuleResult;\n    private tokens: IToken[] = [];\n\n    private elementStack: AbstractElement[] = [];\n    private lastElementStack: AbstractElement[] = [];\n    private nextTokenIndex = 0;\n    private stackSize = 0;\n\n    action(): void {\n        // NOOP\n    }\n\n    construct(): unknown {\n        // NOOP\n        return undefined;\n    }\n\n    parse(input: string): CompletionParserResult {\n        this.resetState();\n        const tokens = this.lexer.tokenize(input);\n        this.tokens = tokens.tokens;\n        this.wrapper.input = [...this.tokens];\n        this.mainRule.call(this.wrapper, {});\n        this.unorderedGroups.clear();\n        return {\n            tokens: this.tokens,\n            elementStack: [...this.lastElementStack],\n            tokenIndex: this.nextTokenIndex\n        };\n    }\n\n    rule(rule: ParserRule, impl: RuleImpl): RuleResult {\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(impl).bind(this));\n        if (rule.entry) {\n            this.mainRule = ruleMethod;\n        }\n        return ruleMethod;\n    }\n\n    private resetState(): void {\n        this.elementStack = [];\n        this.lastElementStack = [];\n        this.nextTokenIndex = 0;\n        this.stackSize = 0;\n    }\n\n    private startImplementation(implementation: RuleImpl): RuleImpl {\n        return (args) => {\n            const size = this.keepStackSize();\n            try {\n                implementation(args);\n            } finally {\n                this.resetStackSize(size);\n            }\n        };\n    }\n\n    private removeUnexpectedElements(): void {\n        this.elementStack.splice(this.stackSize);\n    }\n\n    keepStackSize(): number {\n        const size = this.elementStack.length;\n        this.stackSize = size;\n        return size;\n    }\n\n    resetStackSize(size: number): void {\n        this.removeUnexpectedElements();\n        this.stackSize = size;\n    }\n\n    consume(idx: number, tokenType: TokenType, feature: AbstractElement): void {\n        this.wrapper.wrapConsume(idx, tokenType);\n        if (!this.isRecording()) {\n            this.lastElementStack = [...this.elementStack, feature];\n            this.nextTokenIndex = this.currIdx + 1;\n        }\n    }\n\n    subrule(idx: number, rule: RuleResult, feature: AbstractElement, args: Args): void {\n        this.before(feature);\n        this.wrapper.wrapSubrule(idx, rule, args);\n        this.after(feature);\n    }\n\n    before(element: AbstractElement): void {\n        if (!this.isRecording()) {\n            this.elementStack.push(element);\n        }\n    }\n\n    after(element: AbstractElement): void {\n        if (!this.isRecording()) {\n            const index = this.elementStack.lastIndexOf(element);\n            if (index >= 0) {\n                this.elementStack.splice(index);\n            }\n        }\n    }\n\n    get currIdx(): number {\n        return (this.wrapper as any).currIdx;\n    }\n}\n\nconst defaultConfig: IParserConfig = {\n    recoveryEnabled: true,\n    nodeLocationTracking: 'full',\n    skipValidations: true,\n    errorMessageProvider: new LangiumParserErrorMessageProvider()\n};\n\n/**\n * This class wraps the embedded actions parser of chevrotain and exposes protected methods.\n * This way, we can build the `LangiumParser` as a composition.\n */\nclass ChevrotainWrapper extends EmbeddedActionsParser {\n\n    // This array is set in the base implementation of Chevrotain.\n    definitionErrors: IParserDefinitionError[];\n\n    constructor(tokens: TokenVocabulary, config?: IParserConfig) {\n        const useDefaultLookahead = config && 'maxLookahead' in config;\n        super(tokens, {\n            ...defaultConfig,\n            lookaheadStrategy: useDefaultLookahead\n                ? new LLkLookaheadStrategy({ maxLookahead: config.maxLookahead })\n                : new LLStarLookaheadStrategy(),\n            ...config,\n        });\n    }\n\n    get IS_RECORDING(): boolean {\n        return this.RECORDING_PHASE;\n    }\n\n    DEFINE_RULE(name: string, impl: RuleImpl): RuleResult {\n        return this.RULE(name, impl);\n    }\n\n    wrapSelfAnalysis(): void {\n        this.performSelfAnalysis();\n    }\n\n    wrapConsume(idx: number, tokenType: TokenType): IToken {\n        return this.consume(idx, tokenType);\n    }\n\n    wrapSubrule(idx: number, rule: RuleResult, args: Args): unknown {\n        return this.subrule(idx, rule, {\n            ARGS: [args]\n        });\n    }\n\n    wrapOr(idx: number, choices: Array<IOrAlt<any>>): void {\n        this.or(idx, choices);\n    }\n\n    wrapOption(idx: number, callback: DSLMethodOpts<unknown>): void {\n        this.option(idx, callback);\n    }\n\n    wrapMany(idx: number, callback: DSLMethodOpts<unknown>): void {\n        this.many(idx, callback);\n    }\n\n    wrapAtLeastOne(idx: number, callback: DSLMethodOpts<unknown>): void {\n        this.atLeastOne(idx, callback);\n    }\n}\n","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { IOrAlt, TokenType, TokenTypeDictionary } from 'chevrotain';\nimport type { AbstractElement, Action, Alternatives, Condition, CrossReference, Grammar, Group, Keyword, NamedArgument, ParserRule, RuleCall, UnorderedGroup } from '../languages/generated/ast.js';\nimport type { BaseParser } from './langium-parser.js';\nimport type { AstNode } from '../syntax-tree.js';\nimport type { Cardinality } from '../utils/grammar-utils.js';\nimport { EMPTY_ALT, EOF } from 'chevrotain';\nimport { isAction, isAlternatives, isEndOfFile, isAssignment, isConjunction, isCrossReference, isDisjunction, isGroup, isKeyword, isNegation, isParameterReference, isParserRule, isRuleCall, isTerminalRule, isUnorderedGroup, isBooleanLiteral } from '../languages/generated/ast.js';\nimport { assertUnreachable, ErrorWithLocation } from '../utils/errors.js';\nimport { stream } from '../utils/stream.js';\nimport { findNameAssignment, getAllReachableRules, getTypeName } from '../utils/grammar-utils.js';\n\ntype RuleContext = {\n    optional: number,\n    consume: number,\n    subrule: number,\n    many: number,\n    or: number\n} & ParserContext;\n\ntype ParserContext = {\n    parser: BaseParser\n    tokens: TokenTypeDictionary\n    rules: Map<string, Rule>\n    ruleNames: Map<AstNode, string>\n}\n\ntype Rule = (args: Args) => unknown;\n\ntype Args = Record<string, boolean>;\n\ntype Predicate = (args: Args) => boolean;\n\ntype Method = (args: Args) => void;\n\nexport function createParser<T extends BaseParser>(grammar: Grammar, parser: T, tokens: TokenTypeDictionary): T {\n    const rules = new Map<string, Rule>();\n    const parserContext: ParserContext = {\n        parser,\n        tokens,\n        rules,\n        ruleNames: new Map()\n    };\n    buildRules(parserContext, grammar);\n    return parser;\n}\n\nfunction buildRules(parserContext: ParserContext, grammar: Grammar): void {\n    const reachable = getAllReachableRules(grammar, false);\n    const parserRules = stream(grammar.rules).filter(isParserRule).filter(rule => reachable.has(rule));\n    for (const rule of parserRules) {\n        const ctx: RuleContext = {\n            ...parserContext,\n            consume: 1,\n            optional: 1,\n            subrule: 1,\n            many: 1,\n            or: 1\n        };\n        ctx.rules.set(\n            rule.name,\n            parserContext.parser.rule(rule, buildElement(ctx, rule.definition))\n        );\n    }\n}\n\nfunction buildElement(ctx: RuleContext, element: AbstractElement, ignoreGuard = false): Method {\n    let method: Method;\n    if (isKeyword(element)) {\n        method = buildKeyword(ctx, element);\n    } else if (isAction(element)) {\n        method = buildAction(ctx, element);\n    } else if (isAssignment(element)) {\n        method = buildElement(ctx, element.terminal);\n    } else if (isCrossReference(element)) {\n        method = buildCrossReference(ctx, element);\n    } else if (isRuleCall(element)) {\n        method = buildRuleCall(ctx, element);\n    } else if (isAlternatives(element)) {\n        method = buildAlternatives(ctx, element);\n    } else if (isUnorderedGroup(element)) {\n        method = buildUnorderedGroup(ctx, element);\n    } else if (isGroup(element)) {\n        method = buildGroup(ctx, element);\n    } else if(isEndOfFile(element)) {\n        const idx = ctx.consume++;\n        method = () => ctx.parser.consume(idx, EOF, element);\n    } else {\n        throw new ErrorWithLocation(element.$cstNode, `Unexpected element type: ${element.$type}`);\n    }\n    return wrap(ctx, ignoreGuard ? undefined : getGuardCondition(element), method, element.cardinality);\n}\n\nfunction buildAction(ctx: RuleContext, action: Action): Method {\n    const actionType = getTypeName(action);\n    return () => ctx.parser.action(actionType, action);\n}\n\nfunction buildRuleCall(ctx: RuleContext, ruleCall: RuleCall): Method {\n    const rule = ruleCall.rule.ref;\n    if (isParserRule(rule)) {\n        const idx = ctx.subrule++;\n        const predicate = ruleCall.arguments.length > 0 ? buildRuleCallPredicate(rule, ruleCall.arguments) : () => ({});\n        return (args) => ctx.parser.subrule(idx, getRule(ctx, rule), ruleCall, predicate(args));\n    } else if (isTerminalRule(rule)) {\n        const idx = ctx.consume++;\n        const method = getToken(ctx, rule.name);\n        return () => ctx.parser.consume(idx, method, ruleCall);\n    } else if (!rule) {\n        throw new ErrorWithLocation(ruleCall.$cstNode, `Undefined rule type: ${ruleCall.$type}`);\n    } else {\n        assertUnreachable(rule);\n    }\n}\n\nfunction buildRuleCallPredicate(rule: ParserRule, namedArgs: NamedArgument[]): (args: Args) => Args {\n    const predicates = namedArgs.map(e => buildPredicate(e.value));\n    return (args) => {\n        const ruleArgs: Args = {};\n        for (let i = 0; i < predicates.length; i++) {\n            const ruleTarget = rule.parameters[i];\n            const predicate = predicates[i];\n            ruleArgs[ruleTarget.name] = predicate(args);\n        }\n        return ruleArgs;\n    };\n}\n\ninterface PredicatedMethod {\n    ALT: Method,\n    GATE?: Predicate\n}\n\nfunction buildPredicate(condition: Condition): Predicate {\n    if (isDisjunction(condition)) {\n        const left = buildPredicate(condition.left);\n        const right = buildPredicate(condition.right);\n        return (args) => (left(args) || right(args));\n    } else if (isConjunction(condition)) {\n        const left = buildPredicate(condition.left);\n        const right = buildPredicate(condition.right);\n        return (args) => (left(args) && right(args));\n    } else if (isNegation(condition)) {\n        const value = buildPredicate(condition.value);\n        return (args) => !value(args);\n    } else if (isParameterReference(condition)) {\n        const name = condition.parameter.ref!.name;\n        return (args) => args !== undefined && args[name] === true;\n    } else if (isBooleanLiteral(condition)) {\n        const value = Boolean(condition.true);\n        return () => value;\n    }\n    assertUnreachable(condition);\n}\n\nfunction buildAlternatives(ctx: RuleContext, alternatives: Alternatives): Method {\n    if (alternatives.elements.length === 1) {\n        return buildElement(ctx, alternatives.elements[0]);\n    } else {\n        const methods: PredicatedMethod[] = [];\n\n        for (const element of alternatives.elements) {\n            const predicatedMethod: PredicatedMethod = {\n                // Since we handle the guard condition in the alternative already\n                // We can ignore the group guard condition inside\n                ALT: buildElement(ctx, element, true)\n            };\n            const guard = getGuardCondition(element);\n            if (guard) {\n                predicatedMethod.GATE = buildPredicate(guard);\n            }\n            methods.push(predicatedMethod);\n        }\n\n        const idx = ctx.or++;\n        return (args) => ctx.parser.alternatives(idx, methods.map(method => {\n            const alt: IOrAlt<unknown> = {\n                ALT: () => method.ALT(args)\n            };\n            const gate = method.GATE;\n            if (gate) {\n                alt.GATE = () => gate(args);\n            }\n            return alt;\n        }));\n    }\n}\n\nfunction buildUnorderedGroup(ctx: RuleContext, group: UnorderedGroup): Method {\n    if (group.elements.length === 1) {\n        return buildElement(ctx, group.elements[0]);\n    }\n    const methods: PredicatedMethod[] = [];\n\n    for (const element of group.elements) {\n        const predicatedMethod: PredicatedMethod = {\n            // Since we handle the guard condition in the alternative already\n            // We can ignore the group guard condition inside\n            ALT: buildElement(ctx, element, true)\n        };\n        const guard = getGuardCondition(element);\n        if (guard) {\n            predicatedMethod.GATE = buildPredicate(guard);\n        }\n        methods.push(predicatedMethod);\n    }\n\n    const orIdx = ctx.or++;\n\n    const idFunc = (groupIdx: number, lParser: BaseParser) => {\n        const stackId = lParser.getRuleStack().join('-');\n        return `uGroup_${groupIdx}_${stackId}`;\n    };\n    const alternatives: Method = (args) => ctx.parser.alternatives(orIdx, methods.map((method, idx) => {\n        const alt: IOrAlt<unknown> = { ALT: () => true };\n        const parser = ctx.parser;\n        alt.ALT = () => {\n            method.ALT(args);\n            if (!parser.isRecording()) {\n                const key = idFunc(orIdx, parser);\n                if (!parser.unorderedGroups.get(key)) {\n                    // init after clear state\n                    parser.unorderedGroups.set(key, []);\n                }\n                const groupState = parser.unorderedGroups.get(key)!;\n                if (typeof groupState?.[idx] === 'undefined') {\n                    // Not accessed yet\n                    groupState[idx] = true;\n                }\n            }\n        };\n        const gate = method.GATE;\n        if (gate) {\n            alt.GATE = () => gate(args);\n        } else {\n            alt.GATE = () => {\n                const trackedAlternatives = parser.unorderedGroups.get(idFunc(orIdx, parser));\n                const allow = !trackedAlternatives?.[idx];\n                return allow;\n            };\n        }\n        return alt;\n    }));\n    const wrapped = wrap(ctx, getGuardCondition(group), alternatives, '*');\n    return (args) => {\n        wrapped(args);\n        if (!ctx.parser.isRecording()) {\n            ctx.parser.unorderedGroups.delete(idFunc(orIdx, ctx.parser));\n        }\n    };\n}\n\nfunction buildGroup(ctx: RuleContext, group: Group): Method {\n    const methods = group.elements.map(e => buildElement(ctx, e));\n    return (args) => methods.forEach(method => method(args));\n}\n\nfunction getGuardCondition(element: AbstractElement): Condition | undefined {\n    if (isGroup(element)) {\n        return element.guardCondition;\n    }\n    return undefined;\n}\n\nfunction buildCrossReference(ctx: RuleContext, crossRef: CrossReference, terminal = crossRef.terminal): Method {\n    if (!terminal) {\n        if (!crossRef.type.ref) {\n            throw new Error('Could not resolve reference to type: ' + crossRef.type.$refText);\n        }\n        const assignment = findNameAssignment(crossRef.type.ref);\n        const assignTerminal = assignment?.terminal;\n        if (!assignTerminal) {\n            throw new Error('Could not find name assignment for type: ' + getTypeName(crossRef.type.ref));\n        }\n        return buildCrossReference(ctx, crossRef, assignTerminal);\n    } else if (isRuleCall(terminal) && isParserRule(terminal.rule.ref)) {\n        const idx = ctx.subrule++;\n        return (args) => ctx.parser.subrule(idx, getRule(ctx, terminal.rule.ref as ParserRule), crossRef, args);\n    } else if (isRuleCall(terminal) && isTerminalRule(terminal.rule.ref)) {\n        const idx = ctx.consume++;\n        const terminalRule = getToken(ctx, terminal.rule.ref.name);\n        return () => ctx.parser.consume(idx, terminalRule, crossRef);\n    } else if (isKeyword(terminal)) {\n        const idx = ctx.consume++;\n        const keyword = getToken(ctx, terminal.value);\n        return () => ctx.parser.consume(idx, keyword, crossRef);\n    }\n    else {\n        throw new Error('Could not build cross reference parser');\n    }\n}\n\nfunction buildKeyword(ctx: RuleContext, keyword: Keyword): Method {\n    const idx = ctx.consume++;\n    const token = ctx.tokens[keyword.value];\n    if (!token) {\n        throw new Error('Could not find token for keyword: ' + keyword.value);\n    }\n    return () => ctx.parser.consume(idx, token, keyword);\n}\n\nfunction wrap(ctx: RuleContext, guard: Condition | undefined, method: Method, cardinality: Cardinality): Method {\n    const gate = guard && buildPredicate(guard);\n\n    if (!cardinality) {\n        if (gate) {\n            const idx = ctx.or++;\n            return (args) => ctx.parser.alternatives(idx, [\n                {\n                    ALT: () => method(args),\n                    GATE: () => gate(args)\n                },\n                {\n                    ALT: EMPTY_ALT(),\n                    GATE: () => !gate(args)\n                }\n            ]);\n        } else {\n            return method;\n        }\n    }\n\n    if (cardinality === '*') {\n        const idx = ctx.many++;\n        return (args) => ctx.parser.many(idx, {\n            DEF: () => method(args),\n            GATE: gate ? () => gate(args) : undefined\n        });\n    } else if (cardinality === '+') {\n        const idx = ctx.many++;\n        if (gate) {\n            const orIdx = ctx.or++;\n            // In the case of a guard condition for the `+` group\n            // We combine it with an empty alternative\n            // If the condition returns true, it needs to parse at least a single iteration\n            // If its false, it is not allowed to parse anything\n            return (args) => ctx.parser.alternatives(orIdx, [\n                {\n                    ALT: () => ctx.parser.atLeastOne(idx, {\n                        DEF: () => method(args)\n                    }),\n                    GATE: () => gate(args)\n                },\n                {\n                    ALT: EMPTY_ALT(),\n                    GATE: () => !gate(args)\n                }\n            ]);\n        } else {\n            return (args) => ctx.parser.atLeastOne(idx, {\n                DEF: () => method(args),\n            });\n        }\n    } else if (cardinality === '?') {\n        const idx = ctx.optional++;\n        return (args) => ctx.parser.optional(idx, {\n            DEF: () => method(args),\n            GATE: gate ? () => gate(args) : undefined\n        });\n    } else {\n        assertUnreachable(cardinality);\n    }\n}\n\nfunction getRule(ctx: ParserContext, element: ParserRule | AbstractElement): Rule {\n    const name = getRuleName(ctx, element);\n    const rule = ctx.rules.get(name);\n    if (!rule) throw new Error(`Rule \"${name}\" not found.\"`);\n    return rule;\n}\n\nfunction getRuleName(ctx: ParserContext, element: ParserRule | AbstractElement): string {\n    if (isParserRule(element)) {\n        return element.name;\n    } else if (ctx.ruleNames.has(element)) {\n        return ctx.ruleNames.get(element)!;\n    } else {\n        let item: AstNode = element;\n        let parent: AstNode = item.$container!;\n        let ruleName: string = element.$type;\n        while (!isParserRule(parent)) {\n            if (isGroup(parent) || isAlternatives(parent) || isUnorderedGroup(parent)) {\n                const index = parent.elements.indexOf(item as AbstractElement);\n                ruleName = index.toString() + ':' + ruleName;\n            }\n            item = parent;\n            parent = parent.$container!;\n        }\n        const rule = parent as ParserRule;\n        ruleName = rule.name + ':' + ruleName;\n        ctx.ruleNames.set(element, ruleName);\n        return ruleName;\n    }\n}\n\nfunction getToken(ctx: ParserContext, name: string): TokenType {\n    const token = ctx.tokens[name];\n    if (!token) throw new Error(`Token \"${name}\" not found.\"`);\n    return token;\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { LangiumCoreServices } from '../services.js';\nimport { LangiumParser } from './langium-parser.js';\nimport { createParser } from './parser-builder-base.js';\n\n/**\n * Create and finalize a Langium parser. The parser rules are derived from the grammar, which is\n * available at `services.Grammar`.\n */\nexport function createLangiumParser(services: LangiumCoreServices): LangiumParser {\n    const parser = prepareLangiumParser(services);\n    parser.finalize();\n    return parser;\n}\n\n/**\n * Create a Langium parser without finalizing it. This is used to extract more detailed error\n * information when the parser is initially validated.\n */\nexport function prepareLangiumParser(services: LangiumCoreServices): LangiumParser {\n    const grammar = services.Grammar;\n    const lexer = services.parser.Lexer;\n    const parser = new LangiumParser(services);\n    return createParser(grammar, parser, lexer.definition);\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { CustomPatternMatcherFunc, TokenPattern, TokenType, TokenVocabulary } from 'chevrotain';\nimport type { AbstractRule, Grammar, Keyword, TerminalRule } from '../languages/generated/ast.js';\nimport type { Stream } from '../utils/stream.js';\nimport { Lexer } from 'chevrotain';\nimport { isKeyword, isParserRule, isTerminalRule } from '../languages/generated/ast.js';\nimport { streamAllContents } from '../utils/ast-utils.js';\nimport { getAllReachableRules, terminalRegex } from '../utils/grammar-utils.js';\nimport { getCaseInsensitivePattern, isWhitespace, partialMatches } from '../utils/regexp-utils.js';\nimport { stream } from '../utils/stream.js';\n\nexport interface TokenBuilderOptions {\n    caseInsensitive?: boolean\n}\n\nexport interface TokenBuilder {\n    buildTokens(grammar: Grammar, options?: TokenBuilderOptions): TokenVocabulary;\n}\n\nexport class DefaultTokenBuilder implements TokenBuilder {\n\n    buildTokens(grammar: Grammar, options?: TokenBuilderOptions): TokenVocabulary {\n        const reachableRules = stream(getAllReachableRules(grammar, false));\n        const terminalTokens: TokenType[] = this.buildTerminalTokens(reachableRules);\n        const tokens: TokenType[] = this.buildKeywordTokens(reachableRules, terminalTokens, options);\n\n        terminalTokens.forEach(terminalToken => {\n            const pattern = terminalToken.PATTERN;\n            if (typeof pattern === 'object' && pattern && 'test' in pattern && isWhitespace(pattern)) {\n                tokens.unshift(terminalToken);\n            } else {\n                tokens.push(terminalToken);\n            }\n        });\n        // We don't need to add the EOF token explicitly.\n        // It is automatically available at the end of the token stream.\n        return tokens;\n    }\n\n    protected buildTerminalTokens(rules: Stream<AbstractRule>): TokenType[] {\n        return rules.filter(isTerminalRule).filter(e => !e.fragment)\n            .map(terminal => this.buildTerminalToken(terminal)).toArray();\n    }\n\n    protected buildTerminalToken(terminal: TerminalRule): TokenType {\n        const regex = terminalRegex(terminal);\n        const pattern = this.requiresCustomPattern(regex) ? this.regexPatternFunction(regex) : regex;\n        const tokenType: TokenType = {\n            name: terminal.name,\n            PATTERN: pattern,\n            LINE_BREAKS: true\n        };\n        if (terminal.hidden) {\n            // Only skip tokens that are able to accept whitespace\n            tokenType.GROUP = isWhitespace(regex) ? Lexer.SKIPPED : 'hidden';\n        }\n        return tokenType;\n    }\n\n    protected requiresCustomPattern(regex: RegExp): boolean {\n        if (regex.flags.includes('u')) {\n            // Unicode regexes are not supported by Chevrotain.\n            return true;\n        } else if (regex.source.includes('?<=') || regex.source.includes('?<!')) {\n            // Negative and positive lookbehind are not supported by Chevrotain yet.\n            return true;\n        } else {\n            return false;\n        }\n    }\n\n    protected regexPatternFunction(regex: RegExp): CustomPatternMatcherFunc {\n        const stickyRegex = new RegExp(regex, regex.flags + 'y');\n        return (text, offset) => {\n            stickyRegex.lastIndex = offset;\n            const execResult = stickyRegex.exec(text);\n            return execResult;\n        };\n    }\n\n    protected buildKeywordTokens(rules: Stream<AbstractRule>, terminalTokens: TokenType[], options?: TokenBuilderOptions): TokenType[] {\n        return rules\n            // We filter by parser rules, since keywords in terminal rules get transformed into regex and are not actual tokens\n            .filter(isParserRule)\n            .flatMap(rule => streamAllContents(rule).filter(isKeyword))\n            .distinct(e => e.value).toArray()\n            // Sort keywords by descending length\n            .sort((a, b) => b.value.length - a.value.length)\n            .map(keyword => this.buildKeywordToken(keyword, terminalTokens, Boolean(options?.caseInsensitive)));\n    }\n\n    protected buildKeywordToken(keyword: Keyword, terminalTokens: TokenType[], caseInsensitive: boolean): TokenType {\n        return {\n            name: keyword.value,\n            PATTERN: this.buildKeywordPattern(keyword, caseInsensitive),\n            LONGER_ALT: this.findLongerAlt(keyword, terminalTokens)\n        };\n    }\n\n    protected buildKeywordPattern(keyword: Keyword, caseInsensitive: boolean): TokenPattern {\n        return caseInsensitive ?\n            new RegExp(getCaseInsensitivePattern(keyword.value)) :\n            keyword.value;\n    }\n\n    protected findLongerAlt(keyword: Keyword, terminalTokens: TokenType[]): TokenType[] {\n        return terminalTokens.reduce((longerAlts: TokenType[], token) => {\n            const pattern = token?.PATTERN as RegExp;\n            if (pattern?.source && partialMatches('^' + pattern.source + '$', keyword.value)) {\n                longerAlts.push(token);\n            }\n            return longerAlts;\n        }, []);\n    }\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { AbstractElement, AbstractRule } from '../languages/generated/ast.js';\nimport type { CstNode } from '../syntax-tree.js';\nimport { isCrossReference, isRuleCall } from '../languages/generated/ast.js';\nimport { getCrossReferenceTerminal, getRuleType } from '../utils/grammar-utils.js';\n\n/**\n * Language-specific service for converting string values from the source text format into a value to be held in the AST.\n */\nexport interface ValueConverter {\n    /**\n     * Converts a string value from the source text format into a value to be held in the AST.\n     */\n    convert(input: string, cstNode: CstNode): ValueType;\n}\n\nexport type ValueType = string | number | boolean | bigint | Date;\n\nexport class DefaultValueConverter implements ValueConverter {\n\n    convert(input: string, cstNode: CstNode): ValueType {\n        let feature: AbstractElement | undefined = cstNode.grammarSource;\n        if (isCrossReference(feature)) {\n            feature = getCrossReferenceTerminal(feature);\n        }\n        if (isRuleCall(feature)) {\n            const rule = feature.rule.ref;\n            if (!rule) {\n                throw new Error('This cst node was not parsed by a rule.');\n            }\n            return this.runConverter(rule, input, cstNode);\n        }\n        return input;\n    }\n\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    protected runConverter(rule: AbstractRule, input: string, cstNode: CstNode): ValueType {\n        switch (rule.name.toUpperCase()) {\n            case 'INT': return ValueConverter.convertInt(input);\n            case 'STRING': return ValueConverter.convertString(input);\n            case 'ID': return ValueConverter.convertID(input);\n        }\n        switch (getRuleType(rule)?.toLowerCase()) {\n            case 'number': return ValueConverter.convertNumber(input);\n            case 'boolean': return ValueConverter.convertBoolean(input);\n            case 'bigint': return ValueConverter.convertBigint(input);\n            case 'date': return ValueConverter.convertDate(input);\n            default: return input;\n        }\n    }\n}\n\nexport namespace ValueConverter {\n\n    export function convertString(input: string): string {\n        let result = '';\n        for (let i = 1; i < input.length - 1; i++) {\n            const c = input.charAt(i);\n            if (c === '\\\\') {\n                const c1 = input.charAt(++i);\n                result += convertEscapeCharacter(c1);\n            } else {\n                result += c;\n            }\n        }\n        return result;\n    }\n\n    function convertEscapeCharacter(char: string): string {\n        switch (char) {\n            case 'b': return '\\b';\n            case 'f': return '\\f';\n            case 'n': return '\\n';\n            case 'r': return '\\r';\n            case 't': return '\\t';\n            case 'v': return '\\v';\n            case '0': return '\\0';\n            default: return char;\n        }\n    }\n\n    export function convertID(input: string): string {\n        if (input.charAt(0) === '^') {\n            return input.substring(1);\n        } else {\n            return input;\n        }\n    }\n\n    export function convertInt(input: string): number {\n        return parseInt(input);\n    }\n\n    export function convertBigint(input: string): bigint {\n        return BigInt(input);\n    }\n\n    export function convertDate(input: string): Date {\n        return new Date(input);\n    }\n\n    export function convertNumber(input: string): number {\n        return Number(input);\n    }\n\n    export function convertBoolean(input: string): boolean {\n        return input.toLowerCase() === 'true';\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport { CancellationToken, CancellationTokenSource, type AbstractCancellationTokenSource } from '../utils/cancellation.js';\n\nexport type MaybePromise<T> = T | Promise<T>\n\n/**\n * Delays the execution of the current code to the next tick of the event loop.\n * Don't call this method directly in a tight loop to prevent too many promises from being created.\n */\nexport function delayNextTick(): Promise<void> {\n    return new Promise(resolve => {\n        // In case we are running in a non-node environment, `setImmediate` isn't available.\n        // Using `setTimeout` of the browser API accomplishes the same result.\n        if (typeof setImmediate === 'undefined') {\n            setTimeout(resolve, 0);\n        } else {\n            setImmediate(resolve);\n        }\n    });\n}\n\nlet lastTick = 0;\nlet globalInterruptionPeriod = 10;\n\n/**\n * Reset the global interruption period and create a cancellation token source.\n */\nexport function startCancelableOperation(): AbstractCancellationTokenSource {\n    lastTick = Date.now();\n    return new CancellationTokenSource();\n}\n\n/**\n * Change the period duration for `interruptAndCheck` to the given number of milliseconds.\n * The default value is 10ms.\n */\nexport function setInterruptionPeriod(period: number): void {\n    globalInterruptionPeriod = period;\n}\n\n/**\n * This symbol may be thrown in an asynchronous context by any Langium service that receives\n * a `CancellationToken`. This means that the promise returned by such a service is rejected with\n * this symbol as rejection reason.\n */\nexport const OperationCancelled = Symbol('OperationCancelled');\n\n/**\n * Use this in a `catch` block to check whether the thrown object indicates that the operation\n * has been cancelled.\n */\nexport function isOperationCancelled(err: unknown): err is typeof OperationCancelled {\n    return err === OperationCancelled;\n}\n\n/**\n * This function does two things:\n *  1. Check the elapsed time since the last call to this function or to `startCancelableOperation`. If the predefined\n *     period (configured with `setInterruptionPeriod`) is exceeded, execution is delayed with `delayNextTick`.\n *  2. If the predefined period is not met yet or execution is resumed after an interruption, the given cancellation\n *     token is checked, and if cancellation is requested, `OperationCanceled` is thrown.\n *\n * All services in Langium that receive a `CancellationToken` may potentially call this function, so the\n * `CancellationToken` must be caught (with an `async` try-catch block or a `catch` callback attached to\n * the promise) to avoid that event being exposed as an error.\n */\nexport async function interruptAndCheck(token: CancellationToken): Promise<void> {\n    if (token === CancellationToken.None) {\n        // Early exit in case cancellation was disabled by the caller\n        return;\n    }\n    const current = Date.now();\n    if (current - lastTick >= globalInterruptionPeriod) {\n        lastTick = current;\n        await delayNextTick();\n    }\n    if (token.isCancellationRequested) {\n        throw OperationCancelled;\n    }\n}\n\n/**\n * Simple implementation of the deferred pattern.\n * An object that exposes a promise and functions to resolve and reject it.\n */\nexport class Deferred<T = void> {\n    resolve: (value: T) => this;\n    reject: (err?: unknown) => this;\n\n    promise = new Promise<T>((resolve, reject) => {\n        this.resolve = (arg) => {\n            resolve(arg);\n            return this;\n        };\n        this.reject = (err) => {\n            reject(err);\n            return this;\n        };\n    });\n}\n","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            const start = this.offsetAt(range.start);\n            const end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(changes, version) {\n        for (const change of changes) {\n            if (FullTextDocument.isIncremental(change)) {\n                // makes sure start is before end\n                const range = getWellformedRange(change.range);\n                // update content\n                const startOffset = this.offsetAt(range.start);\n                const endOffset = this.offsetAt(range.end);\n                this._content = this._content.substring(0, startOffset) + change.text + this._content.substring(endOffset, this._content.length);\n                // update the offsets\n                const startLine = Math.max(range.start.line, 0);\n                const endLine = Math.max(range.end.line, 0);\n                let lineOffsets = this._lineOffsets;\n                const addedLineOffsets = computeLineOffsets(change.text, false, startOffset);\n                if (endLine - startLine === addedLineOffsets.length) {\n                    for (let i = 0, len = addedLineOffsets.length; i < len; i++) {\n                        lineOffsets[i + startLine + 1] = addedLineOffsets[i];\n                    }\n                }\n                else {\n                    if (addedLineOffsets.length < 10000) {\n                        lineOffsets.splice(startLine + 1, endLine - startLine, ...addedLineOffsets);\n                    }\n                    else { // avoid too many arguments for splice\n                        this._lineOffsets = lineOffsets = lineOffsets.slice(0, startLine + 1).concat(addedLineOffsets, lineOffsets.slice(endLine + 1));\n                    }\n                }\n                const diff = change.text.length - (endOffset - startOffset);\n                if (diff !== 0) {\n                    for (let i = startLine + 1 + addedLineOffsets.length, len = lineOffsets.length; i < len; i++) {\n                        lineOffsets[i] = lineOffsets[i] + diff;\n                    }\n                }\n            }\n            else if (FullTextDocument.isFull(change)) {\n                this._content = change.text;\n                this._lineOffsets = undefined;\n            }\n            else {\n                throw new Error('Unknown change event received');\n            }\n        }\n        this._version = version;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            this._lineOffsets = computeLineOffsets(this._content, true);\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        const lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return { line: 0, character: offset };\n        }\n        while (low < high) {\n            const mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        const line = low - 1;\n        offset = this.ensureBeforeEOL(offset, lineOffsets[line]);\n        return { line, character: offset - lineOffsets[line] };\n    }\n    offsetAt(position) {\n        const lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        const lineOffset = lineOffsets[position.line];\n        if (position.character <= 0) {\n            return lineOffset;\n        }\n        const nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        const offset = Math.min(lineOffset + position.character, nextLineOffset);\n        return this.ensureBeforeEOL(offset, lineOffset);\n    }\n    ensureBeforeEOL(offset, lineOffset) {\n        while (offset > lineOffset && isEOL(this._content.charCodeAt(offset - 1))) {\n            offset--;\n        }\n        return offset;\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n    static isIncremental(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range !== undefined &&\n            (candidate.rangeLength === undefined || typeof candidate.rangeLength === 'number');\n    }\n    static isFull(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range === undefined && candidate.rangeLength === undefined;\n    }\n}\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new text document.\n     *\n     * @param uri The document's uri.\n     * @param languageId  The document's language Id.\n     * @param version The document's initial version number.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Updates a TextDocument by modifying its content.\n     *\n     * @param document the document to update. Only documents created by TextDocument.create are valid inputs.\n     * @param changes the changes to apply to the document.\n     * @param version the changes version for the document.\n     * @returns The updated TextDocument. Note: That's the same document instance passed in as first parameter.\n     *\n     */\n    function update(document, changes, version) {\n        if (document instanceof FullTextDocument) {\n            document.update(changes, version);\n            return document;\n        }\n        else {\n            throw new Error('TextDocument.update: document must be created by TextDocument.create');\n        }\n    }\n    TextDocument.update = update;\n    function applyEdits(document, edits) {\n        const text = document.getText();\n        const sortedEdits = mergeSort(edits.map(getWellformedEdit), (a, b) => {\n            const diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = 0;\n        const spans = [];\n        for (const e of sortedEdits) {\n            const startOffset = document.offsetAt(e.range.start);\n            if (startOffset < lastModifiedOffset) {\n                throw new Error('Overlapping edit');\n            }\n            else if (startOffset > lastModifiedOffset) {\n                spans.push(text.substring(lastModifiedOffset, startOffset));\n            }\n            if (e.newText.length) {\n                spans.push(e.newText);\n            }\n            lastModifiedOffset = document.offsetAt(e.range.end);\n        }\n        spans.push(text.substr(lastModifiedOffset));\n        return spans.join('');\n    }\n    TextDocument.applyEdits = applyEdits;\n})(TextDocument || (TextDocument = {}));\nfunction mergeSort(data, compare) {\n    if (data.length <= 1) {\n        // sorted\n        return data;\n    }\n    const p = (data.length / 2) | 0;\n    const left = data.slice(0, p);\n    const right = data.slice(p);\n    mergeSort(left, compare);\n    mergeSort(right, compare);\n    let leftIdx = 0;\n    let rightIdx = 0;\n    let i = 0;\n    while (leftIdx < left.length && rightIdx < right.length) {\n        const ret = compare(left[leftIdx], right[rightIdx]);\n        if (ret <= 0) {\n            // smaller_equal -> take left to preserve order\n            data[i++] = left[leftIdx++];\n        }\n        else {\n            // greater -> take right\n            data[i++] = right[rightIdx++];\n        }\n    }\n    while (leftIdx < left.length) {\n        data[i++] = left[leftIdx++];\n    }\n    while (rightIdx < right.length) {\n        data[i++] = right[rightIdx++];\n    }\n    return data;\n}\nfunction computeLineOffsets(text, isAtLineStart, textOffset = 0) {\n    const result = isAtLineStart ? [textOffset] : [];\n    for (let i = 0; i < text.length; i++) {\n        const ch = text.charCodeAt(i);\n        if (isEOL(ch)) {\n            if (ch === 13 /* CharCode.CarriageReturn */ && i + 1 < text.length && text.charCodeAt(i + 1) === 10 /* CharCode.LineFeed */) {\n                i++;\n            }\n            result.push(textOffset + i + 1);\n        }\n    }\n    return result;\n}\nfunction isEOL(char) {\n    return char === 13 /* CharCode.CarriageReturn */ || char === 10 /* CharCode.LineFeed */;\n}\nfunction getWellformedRange(range) {\n    const start = range.start;\n    const end = range.end;\n    if (start.line > end.line || (start.line === end.line && start.character > end.character)) {\n        return { start: end, end: start };\n    }\n    return range;\n}\nfunction getWellformedEdit(textEdit) {\n    const range = getWellformedRange(textEdit.range);\n    if (range !== textEdit.range) {\n        return { newText: textEdit.newText, range };\n    }\n    return textEdit;\n}\n","// 'path' module extracted from Node.js v8.11.1 (only the posix part)\n// transplited with Babel\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\nfunction assertPath(path) {\n  if (typeof path !== 'string') {\n    throw new TypeError('Path must be a string. Received ' + JSON.stringify(path));\n  }\n}\n\n// Resolves . and .. elements in a path with directory names\nfunction normalizeStringPosix(path, allowAboveRoot) {\n  var res = '';\n  var lastSegmentLength = 0;\n  var lastSlash = -1;\n  var dots = 0;\n  var code;\n  for (var i = 0; i <= path.length; ++i) {\n    if (i < path.length)\n      code = path.charCodeAt(i);\n    else if (code === 47 /*/*/)\n      break;\n    else\n      code = 47 /*/*/;\n    if (code === 47 /*/*/) {\n      if (lastSlash === i - 1 || dots === 1) {\n        // NOOP\n      } else if (lastSlash !== i - 1 && dots === 2) {\n        if (res.length < 2 || lastSegmentLength !== 2 || res.charCodeAt(res.length - 1) !== 46 /*.*/ || res.charCodeAt(res.length - 2) !== 46 /*.*/) {\n          if (res.length > 2) {\n            var lastSlashIndex = res.lastIndexOf('/');\n            if (lastSlashIndex !== res.length - 1) {\n              if (lastSlashIndex === -1) {\n                res = '';\n                lastSegmentLength = 0;\n              } else {\n                res = res.slice(0, lastSlashIndex);\n                lastSegmentLength = res.length - 1 - res.lastIndexOf('/');\n              }\n              lastSlash = i;\n              dots = 0;\n              continue;\n            }\n          } else if (res.length === 2 || res.length === 1) {\n            res = '';\n            lastSegmentLength = 0;\n            lastSlash = i;\n            dots = 0;\n            continue;\n          }\n        }\n        if (allowAboveRoot) {\n          if (res.length > 0)\n            res += '/..';\n          else\n            res = '..';\n          lastSegmentLength = 2;\n        }\n      } else {\n        if (res.length > 0)\n          res += '/' + path.slice(lastSlash + 1, i);\n        else\n          res = path.slice(lastSlash + 1, i);\n        lastSegmentLength = i - lastSlash - 1;\n      }\n      lastSlash = i;\n      dots = 0;\n    } else if (code === 46 /*.*/ && dots !== -1) {\n      ++dots;\n    } else {\n      dots = -1;\n    }\n  }\n  return res;\n}\n\nfunction _format(sep, pathObject) {\n  var dir = pathObject.dir || pathObject.root;\n  var base = pathObject.base || (pathObject.name || '') + (pathObject.ext || '');\n  if (!dir) {\n    return base;\n  }\n  if (dir === pathObject.root) {\n    return dir + base;\n  }\n  return dir + sep + base;\n}\n\nvar posix = {\n  // path.resolve([from ...], to)\n  resolve: function resolve() {\n    var resolvedPath = '';\n    var resolvedAbsolute = false;\n    var cwd;\n\n    for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {\n      var path;\n      if (i >= 0)\n        path = arguments[i];\n      else {\n        if (cwd === undefined)\n          cwd = process.cwd();\n        path = cwd;\n      }\n\n      assertPath(path);\n\n      // Skip empty entries\n      if (path.length === 0) {\n        continue;\n      }\n\n      resolvedPath = path + '/' + resolvedPath;\n      resolvedAbsolute = path.charCodeAt(0) === 47 /*/*/;\n    }\n\n    // At this point the path should be resolved to a full absolute path, but\n    // handle relative paths to be safe (might happen when process.cwd() fails)\n\n    // Normalize the path\n    resolvedPath = normalizeStringPosix(resolvedPath, !resolvedAbsolute);\n\n    if (resolvedAbsolute) {\n      if (resolvedPath.length > 0)\n        return '/' + resolvedPath;\n      else\n        return '/';\n    } else if (resolvedPath.length > 0) {\n      return resolvedPath;\n    } else {\n      return '.';\n    }\n  },\n\n  normalize: function normalize(path) {\n    assertPath(path);\n\n    if (path.length === 0) return '.';\n\n    var isAbsolute = path.charCodeAt(0) === 47 /*/*/;\n    var trailingSeparator = path.charCodeAt(path.length - 1) === 47 /*/*/;\n\n    // Normalize the path\n    path = normalizeStringPosix(path, !isAbsolute);\n\n    if (path.length === 0 && !isAbsolute) path = '.';\n    if (path.length > 0 && trailingSeparator) path += '/';\n\n    if (isAbsolute) return '/' + path;\n    return path;\n  },\n\n  isAbsolute: function isAbsolute(path) {\n    assertPath(path);\n    return path.length > 0 && path.charCodeAt(0) === 47 /*/*/;\n  },\n\n  join: function join() {\n    if (arguments.length === 0)\n      return '.';\n    var joined;\n    for (var i = 0; i < arguments.length; ++i) {\n      var arg = arguments[i];\n      assertPath(arg);\n      if (arg.length > 0) {\n        if (joined === undefined)\n          joined = arg;\n        else\n          joined += '/' + arg;\n      }\n    }\n    if (joined === undefined)\n      return '.';\n    return posix.normalize(joined);\n  },\n\n  relative: function relative(from, to) {\n    assertPath(from);\n    assertPath(to);\n\n    if (from === to) return '';\n\n    from = posix.resolve(from);\n    to = posix.resolve(to);\n\n    if (from === to) return '';\n\n    // Trim any leading backslashes\n    var fromStart = 1;\n    for (; fromStart < from.length; ++fromStart) {\n      if (from.charCodeAt(fromStart) !== 47 /*/*/)\n        break;\n    }\n    var fromEnd = from.length;\n    var fromLen = fromEnd - fromStart;\n\n    // Trim any leading backslashes\n    var toStart = 1;\n    for (; toStart < to.length; ++toStart) {\n      if (to.charCodeAt(toStart) !== 47 /*/*/)\n        break;\n    }\n    var toEnd = to.length;\n    var toLen = toEnd - toStart;\n\n    // Compare paths to find the longest common path from root\n    var length = fromLen < toLen ? fromLen : toLen;\n    var lastCommonSep = -1;\n    var i = 0;\n    for (; i <= length; ++i) {\n      if (i === length) {\n        if (toLen > length) {\n          if (to.charCodeAt(toStart + i) === 47 /*/*/) {\n            // We get here if `from` is the exact base path for `to`.\n            // For example: from='/foo/bar'; to='/foo/bar/baz'\n            return to.slice(toStart + i + 1);\n          } else if (i === 0) {\n            // We get here if `from` is the root\n            // For example: from='/'; to='/foo'\n            return to.slice(toStart + i);\n          }\n        } else if (fromLen > length) {\n          if (from.charCodeAt(fromStart + i) === 47 /*/*/) {\n            // We get here if `to` is the exact base path for `from`.\n            // For example: from='/foo/bar/baz'; to='/foo/bar'\n            lastCommonSep = i;\n          } else if (i === 0) {\n            // We get here if `to` is the root.\n            // For example: from='/foo'; to='/'\n            lastCommonSep = 0;\n          }\n        }\n        break;\n      }\n      var fromCode = from.charCodeAt(fromStart + i);\n      var toCode = to.charCodeAt(toStart + i);\n      if (fromCode !== toCode)\n        break;\n      else if (fromCode === 47 /*/*/)\n        lastCommonSep = i;\n    }\n\n    var out = '';\n    // Generate the relative path based on the path difference between `to`\n    // and `from`\n    for (i = fromStart + lastCommonSep + 1; i <= fromEnd; ++i) {\n      if (i === fromEnd || from.charCodeAt(i) === 47 /*/*/) {\n        if (out.length === 0)\n          out += '..';\n        else\n          out += '/..';\n      }\n    }\n\n    // Lastly, append the rest of the destination (`to`) path that comes after\n    // the common path parts\n    if (out.length > 0)\n      return out + to.slice(toStart + lastCommonSep);\n    else {\n      toStart += lastCommonSep;\n      if (to.charCodeAt(toStart) === 47 /*/*/)\n        ++toStart;\n      return to.slice(toStart);\n    }\n  },\n\n  _makeLong: function _makeLong(path) {\n    return path;\n  },\n\n  dirname: function dirname(path) {\n    assertPath(path);\n    if (path.length === 0) return '.';\n    var code = path.charCodeAt(0);\n    var hasRoot = code === 47 /*/*/;\n    var end = -1;\n    var matchedSlash = true;\n    for (var i = path.length - 1; i >= 1; --i) {\n      code = path.charCodeAt(i);\n      if (code === 47 /*/*/) {\n          if (!matchedSlash) {\n            end = i;\n            break;\n          }\n        } else {\n        // We saw the first non-path separator\n        matchedSlash = false;\n      }\n    }\n\n    if (end === -1) return hasRoot ? '/' : '.';\n    if (hasRoot && end === 1) return '//';\n    return path.slice(0, end);\n  },\n\n  basename: function basename(path, ext) {\n    if (ext !== undefined && typeof ext !== 'string') throw new TypeError('\"ext\" argument must be a string');\n    assertPath(path);\n\n    var start = 0;\n    var end = -1;\n    var matchedSlash = true;\n    var i;\n\n    if (ext !== undefined && ext.length > 0 && ext.length <= path.length) {\n      if (ext.length === path.length && ext === path) return '';\n      var extIdx = ext.length - 1;\n      var firstNonSlashEnd = -1;\n      for (i = path.length - 1; i >= 0; --i) {\n        var code = path.charCodeAt(i);\n        if (code === 47 /*/*/) {\n            // If we reached a path separator that was not part of a set of path\n            // separators at the end of the string, stop now\n            if (!matchedSlash) {\n              start = i + 1;\n              break;\n            }\n          } else {\n          if (firstNonSlashEnd === -1) {\n            // We saw the first non-path separator, remember this index in case\n            // we need it if the extension ends up not matching\n            matchedSlash = false;\n            firstNonSlashEnd = i + 1;\n          }\n          if (extIdx >= 0) {\n            // Try to match the explicit extension\n            if (code === ext.charCodeAt(extIdx)) {\n              if (--extIdx === -1) {\n                // We matched the extension, so mark this as the end of our path\n                // component\n                end = i;\n              }\n            } else {\n              // Extension does not match, so our result is the entire path\n              // component\n              extIdx = -1;\n              end = firstNonSlashEnd;\n            }\n          }\n        }\n      }\n\n      if (start === end) end = firstNonSlashEnd;else if (end === -1) end = path.length;\n      return path.slice(start, end);\n    } else {\n      for (i = path.length - 1; i >= 0; --i) {\n        if (path.charCodeAt(i) === 47 /*/*/) {\n            // If we reached a path separator that was not part of a set of path\n            // separators at the end of the string, stop now\n            if (!matchedSlash) {\n              start = i + 1;\n              break;\n            }\n          } else if (end === -1) {\n          // We saw the first non-path separator, mark this as the end of our\n          // path component\n          matchedSlash = false;\n          end = i + 1;\n        }\n      }\n\n      if (end === -1) return '';\n      return path.slice(start, end);\n    }\n  },\n\n  extname: function extname(path) {\n    assertPath(path);\n    var startDot = -1;\n    var startPart = 0;\n    var end = -1;\n    var matchedSlash = true;\n    // Track the state of characters (if any) we see before our first dot and\n    // after any path separator we find\n    var preDotState = 0;\n    for (var i = path.length - 1; i >= 0; --i) {\n      var code = path.charCodeAt(i);\n      if (code === 47 /*/*/) {\n          // If we reached a path separator that was not part of a set of path\n          // separators at the end of the string, stop now\n          if (!matchedSlash) {\n            startPart = i + 1;\n            break;\n          }\n          continue;\n        }\n      if (end === -1) {\n        // We saw the first non-path separator, mark this as the end of our\n        // extension\n        matchedSlash = false;\n        end = i + 1;\n      }\n      if (code === 46 /*.*/) {\n          // If this is our first dot, mark it as the start of our extension\n          if (startDot === -1)\n            startDot = i;\n          else if (preDotState !== 1)\n            preDotState = 1;\n      } else if (startDot !== -1) {\n        // We saw a non-dot and non-path separator before our dot, so we should\n        // have a good chance at having a non-empty extension\n        preDotState = -1;\n      }\n    }\n\n    if (startDot === -1 || end === -1 ||\n        // We saw a non-dot character immediately before the dot\n        preDotState === 0 ||\n        // The (right-most) trimmed path component is exactly '..'\n        preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {\n      return '';\n    }\n    return path.slice(startDot, end);\n  },\n\n  format: function format(pathObject) {\n    if (pathObject === null || typeof pathObject !== 'object') {\n      throw new TypeError('The \"pathObject\" argument must be of type Object. Received type ' + typeof pathObject);\n    }\n    return _format('/', pathObject);\n  },\n\n  parse: function parse(path) {\n    assertPath(path);\n\n    var ret = { root: '', dir: '', base: '', ext: '', name: '' };\n    if (path.length === 0) return ret;\n    var code = path.charCodeAt(0);\n    var isAbsolute = code === 47 /*/*/;\n    var start;\n    if (isAbsolute) {\n      ret.root = '/';\n      start = 1;\n    } else {\n      start = 0;\n    }\n    var startDot = -1;\n    var startPart = 0;\n    var end = -1;\n    var matchedSlash = true;\n    var i = path.length - 1;\n\n    // Track the state of characters (if any) we see before our first dot and\n    // after any path separator we find\n    var preDotState = 0;\n\n    // Get non-dir info\n    for (; i >= start; --i) {\n      code = path.charCodeAt(i);\n      if (code === 47 /*/*/) {\n          // If we reached a path separator that was not part of a set of path\n          // separators at the end of the string, stop now\n          if (!matchedSlash) {\n            startPart = i + 1;\n            break;\n          }\n          continue;\n        }\n      if (end === -1) {\n        // We saw the first non-path separator, mark this as the end of our\n        // extension\n        matchedSlash = false;\n        end = i + 1;\n      }\n      if (code === 46 /*.*/) {\n          // If this is our first dot, mark it as the start of our extension\n          if (startDot === -1) startDot = i;else if (preDotState !== 1) preDotState = 1;\n        } else if (startDot !== -1) {\n        // We saw a non-dot and non-path separator before our dot, so we should\n        // have a good chance at having a non-empty extension\n        preDotState = -1;\n      }\n    }\n\n    if (startDot === -1 || end === -1 ||\n    // We saw a non-dot character immediately before the dot\n    preDotState === 0 ||\n    // The (right-most) trimmed path component is exactly '..'\n    preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {\n      if (end !== -1) {\n        if (startPart === 0 && isAbsolute) ret.base = ret.name = path.slice(1, end);else ret.base = ret.name = path.slice(startPart, end);\n      }\n    } else {\n      if (startPart === 0 && isAbsolute) {\n        ret.name = path.slice(1, startDot);\n        ret.base = path.slice(1, end);\n      } else {\n        ret.name = path.slice(startPart, startDot);\n        ret.base = path.slice(startPart, end);\n      }\n      ret.ext = path.slice(startDot, end);\n    }\n\n    if (startPart > 0) ret.dir = path.slice(0, startPart - 1);else if (isAbsolute) ret.dir = '/';\n\n    return ret;\n  },\n\n  sep: '/',\n  delimiter: ':',\n  win32: null,\n  posix: null\n};\n\nposix.posix = posix;\n\nmodule.exports = posix;\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n'use strict';\n\n// !!!!!\n// SEE https://github.com/microsoft/vscode/blob/master/src/vs/base/common/platform.ts\n// !!!!!\n\ndeclare const process: { platform: 'win32' };\ndeclare const navigator: { userAgent: string };\n\nexport let isWindows: boolean;\n\nif (typeof process === 'object') {\n\tisWindows = process.platform === 'win32';\n} else if (typeof navigator === 'object') {\n\tlet userAgent = navigator.userAgent;\n\tisWindows = userAgent.indexOf('Windows') >= 0;\n}\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n'use strict';\n\nimport { CharCode } from './charCode'\nimport { isWindows } from './platform';\n\nconst _schemePattern = /^\\w[\\w\\d+.-]*$/;\nconst _singleSlashStart = /^\\//;\nconst _doubleSlashStart = /^\\/\\//;\n\nfunction _validateUri(ret: URI, _strict?: boolean): void {\n\n\t// scheme, must be set\n\tif (!ret.scheme && _strict) {\n\t\tthrow new Error(`[UriError]: Scheme is missing: {scheme: \"\", authority: \"${ret.authority}\", path: \"${ret.path}\", query: \"${ret.query}\", fragment: \"${ret.fragment}\"}`);\n\t}\n\n\t// scheme, https://tools.ietf.org/html/rfc3986#section-3.1\n\t// ALPHA *( ALPHA / DIGIT / \"+\" / \"-\" / \".\" )\n\tif (ret.scheme && !_schemePattern.test(ret.scheme)) {\n\t\tthrow new Error('[UriError]: Scheme contains illegal characters.');\n\t}\n\n\t// path, http://tools.ietf.org/html/rfc3986#section-3.3\n\t// If a URI contains an authority component, then the path component\n\t// must either be empty or begin with a slash (\"/\") character.  If a URI\n\t// does not contain an authority component, then the path cannot begin\n\t// with two slash characters (\"//\").\n\tif (ret.path) {\n\t\tif (ret.authority) {\n\t\t\tif (!_singleSlashStart.test(ret.path)) {\n\t\t\t\tthrow new Error('[UriError]: If a URI contains an authority component, then the path component must either be empty or begin with a slash (\"/\") character');\n\t\t\t}\n\t\t} else {\n\t\t\tif (_doubleSlashStart.test(ret.path)) {\n\t\t\t\tthrow new Error('[UriError]: If a URI does not contain an authority component, then the path cannot begin with two slash characters (\"//\")');\n\t\t\t}\n\t\t}\n\t}\n}\n\n// for a while we allowed uris *without* schemes and this is the migration\n// for them, e.g. an uri without scheme and without strict-mode warns and falls\n// back to the file-scheme. that should cause the least carnage and still be a\n// clear warning\nfunction _schemeFix(scheme: string, _strict: boolean): string {\n\tif (!scheme && !_strict) {\n\t\treturn 'file';\n\t}\n\treturn scheme;\n}\n\n// implements a bit of https://tools.ietf.org/html/rfc3986#section-5\nfunction _referenceResolution(scheme: string, path: string): string {\n\n\t// the slash-character is our 'default base' as we don't\n\t// support constructing URIs relative to other URIs. This\n\t// also means that we alter and potentially break paths.\n\t// see https://tools.ietf.org/html/rfc3986#section-5.1.4\n\tswitch (scheme) {\n\t\tcase 'https':\n\t\tcase 'http':\n\t\tcase 'file':\n\t\t\tif (!path) {\n\t\t\t\tpath = _slash;\n\t\t\t} else if (path[0] !== _slash) {\n\t\t\t\tpath = _slash + path;\n\t\t\t}\n\t\t\tbreak;\n\t}\n\treturn path;\n}\n\nconst _empty = '';\nconst _slash = '/';\nconst _regexp = /^(([^:/?#]+?):)?(\\/\\/([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?/;\n\n/**\n * Uniform Resource Identifier (URI) http://tools.ietf.org/html/rfc3986.\n * This class is a simple parser which creates the basic component parts\n * (http://tools.ietf.org/html/rfc3986#section-3) with minimal validation\n * and encoding.\n *\n * ```txt\n *       foo://example.com:8042/over/there?name=ferret#nose\n *       \\_/   \\______________/\\_________/ \\_________/ \\__/\n *        |           |            |            |        |\n *     scheme     authority       path        query   fragment\n *        |   _____________________|__\n *       / \\ /                        \\\n *       urn:example:animal:ferret:nose\n * ```\n */\nexport class URI implements UriComponents {\n\n\tstatic isUri(thing: any): thing is URI {\n\t\tif (thing instanceof URI) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!thing) {\n\t\t\treturn false;\n\t\t}\n\t\treturn typeof (<URI>thing).authority === 'string'\n\t\t\t&& typeof (<URI>thing).fragment === 'string'\n\t\t\t&& typeof (<URI>thing).path === 'string'\n\t\t\t&& typeof (<URI>thing).query === 'string'\n\t\t\t&& typeof (<URI>thing).scheme === 'string'\n\t\t\t&& typeof (<URI>thing).fsPath === 'string'\n\t\t\t&& typeof (<URI>thing).with === 'function'\n\t\t\t&& typeof (<URI>thing).toString === 'function';\n\t}\n\n\t/**\n\t * scheme is the 'http' part of 'http://www.example.com/some/path?query#fragment'.\n\t * The part before the first colon.\n\t */\n\treadonly scheme: string;\n\n\t/**\n\t * authority is the 'www.example.com' part of 'http://www.example.com/some/path?query#fragment'.\n\t * The part between the first double slashes and the next slash.\n\t */\n\treadonly authority: string;\n\n\t/**\n\t * path is the '/some/path' part of 'http://www.example.com/some/path?query#fragment'.\n\t */\n\treadonly path: string;\n\n\t/**\n\t * query is the 'query' part of 'http://www.example.com/some/path?query#fragment'.\n\t */\n\treadonly query: string;\n\n\t/**\n\t * fragment is the 'fragment' part of 'http://www.example.com/some/path?query#fragment'.\n\t */\n\treadonly fragment: string;\n\n\t/**\n\t * @internal\n\t */\n\tprotected constructor(scheme: string, authority?: string, path?: string, query?: string, fragment?: string, _strict?: boolean);\n\n\t/**\n\t * @internal\n\t */\n\tprotected constructor(components: UriComponents);\n\n\t/**\n\t * @internal\n\t */\n\tprotected constructor(schemeOrData: string | UriComponents, authority?: string, path?: string, query?: string, fragment?: string, _strict: boolean = false) {\n\n\t\tif (typeof schemeOrData === 'object') {\n\t\t\tthis.scheme = schemeOrData.scheme || _empty;\n\t\t\tthis.authority = schemeOrData.authority || _empty;\n\t\t\tthis.path = schemeOrData.path || _empty;\n\t\t\tthis.query = schemeOrData.query || _empty;\n\t\t\tthis.fragment = schemeOrData.fragment || _empty;\n\t\t\t// no validation because it's this URI\n\t\t\t// that creates uri components.\n\t\t\t// _validateUri(this);\n\t\t} else {\n\t\t\tthis.scheme = _schemeFix(schemeOrData, _strict);\n\t\t\tthis.authority = authority || _empty;\n\t\t\tthis.path = _referenceResolution(this.scheme, path || _empty);\n\t\t\tthis.query = query || _empty;\n\t\t\tthis.fragment = fragment || _empty;\n\n\t\t\t_validateUri(this, _strict);\n\t\t}\n\t}\n\n\t// ---- filesystem path -----------------------\n\n\t/**\n\t * Returns a string representing the corresponding file system path of this URI.\n\t * Will handle UNC paths, normalizes windows drive letters to lower-case, and uses the\n\t * platform specific path separator.\n\t *\n\t * * Will *not* validate the path for invalid characters and semantics.\n\t * * Will *not* look at the scheme of this URI.\n\t * * The result shall *not* be used for display purposes but for accessing a file on disk.\n\t *\n\t *\n\t * The *difference* to `URI#path` is the use of the platform specific separator and the handling\n\t * of UNC paths. See the below sample of a file-uri with an authority (UNC path).\n\t *\n\t * ```ts\n\t\tconst u = URI.parse('file://server/c$/folder/file.txt')\n\t\tu.authority === 'server'\n\t\tu.path === '/shares/c$/file.txt'\n\t\tu.fsPath === '\\\\server\\c$\\folder\\file.txt'\n\t```\n\t *\n\t * Using `URI#path` to read a file (using fs-apis) would not be enough because parts of the path,\n\t * namely the server name, would be missing. Therefore `URI#fsPath` exists - it's sugar to ease working\n\t * with URIs that represent files on disk (`file` scheme).\n\t */\n\tget fsPath(): string {\n\t\t// if (this.scheme !== 'file') {\n\t\t// \tconsole.warn(`[UriError] calling fsPath with scheme ${this.scheme}`);\n\t\t// }\n\t\treturn uriToFsPath(this, false);\n\t}\n\n\t// ---- modify to new -------------------------\n\n\twith(change: { scheme?: string; authority?: string | null; path?: string | null; query?: string | null; fragment?: string | null }): URI {\n\n\t\tif (!change) {\n\t\t\treturn this;\n\t\t}\n\n\t\tlet { scheme, authority, path, query, fragment } = change;\n\t\tif (scheme === undefined) {\n\t\t\tscheme = this.scheme;\n\t\t} else if (scheme === null) {\n\t\t\tscheme = _empty;\n\t\t}\n\t\tif (authority === undefined) {\n\t\t\tauthority = this.authority;\n\t\t} else if (authority === null) {\n\t\t\tauthority = _empty;\n\t\t}\n\t\tif (path === undefined) {\n\t\t\tpath = this.path;\n\t\t} else if (path === null) {\n\t\t\tpath = _empty;\n\t\t}\n\t\tif (query === undefined) {\n\t\t\tquery = this.query;\n\t\t} else if (query === null) {\n\t\t\tquery = _empty;\n\t\t}\n\t\tif (fragment === undefined) {\n\t\t\tfragment = this.fragment;\n\t\t} else if (fragment === null) {\n\t\t\tfragment = _empty;\n\t\t}\n\n\t\tif (scheme === this.scheme\n\t\t\t&& authority === this.authority\n\t\t\t&& path === this.path\n\t\t\t&& query === this.query\n\t\t\t&& fragment === this.fragment) {\n\n\t\t\treturn this;\n\t\t}\n\n\t\treturn new Uri(scheme, authority, path, query, fragment);\n\t}\n\n\t// ---- parse & validate ------------------------\n\n\t/**\n\t * Creates a new URI from a string, e.g. `http://www.example.com/some/path`,\n\t * `file:///usr/home`, or `scheme:with/path`.\n\t *\n\t * @param value A string which represents an URI (see `URI#toString`).\n\t */\n\tstatic parse(value: string, _strict: boolean = false): URI {\n\t\tconst match = _regexp.exec(value);\n\t\tif (!match) {\n\t\t\treturn new Uri(_empty, _empty, _empty, _empty, _empty);\n\t\t}\n\t\treturn new Uri(\n\t\t\tmatch[2] || _empty,\n\t\t\tpercentDecode(match[4] || _empty),\n\t\t\tpercentDecode(match[5] || _empty),\n\t\t\tpercentDecode(match[7] || _empty),\n\t\t\tpercentDecode(match[9] || _empty),\n\t\t\t_strict\n\t\t);\n\t}\n\n\t/**\n\t * Creates a new URI from a file system path, e.g. `c:\\my\\files`,\n\t * `/usr/home`, or `\\\\server\\share\\some\\path`.\n\t *\n\t * The *difference* between `URI#parse` and `URI#file` is that the latter treats the argument\n\t * as path, not as stringified-uri. E.g. `URI.file(path)` is **not the same as**\n\t * `URI.parse('file://' + path)` because the path might contain characters that are\n\t * interpreted (# and ?). See the following sample:\n\t * ```ts\n\tconst good = URI.file('/coding/c#/project1');\n\tgood.scheme === 'file';\n\tgood.path === '/coding/c#/project1';\n\tgood.fragment === '';\n\tconst bad = URI.parse('file://' + '/coding/c#/project1');\n\tbad.scheme === 'file';\n\tbad.path === '/coding/c'; // path is now broken\n\tbad.fragment === '/project1';\n\t```\n\t *\n\t * @param path A file system path (see `URI#fsPath`)\n\t */\n\tstatic file(path: string): URI {\n\n\t\tlet authority = _empty;\n\n\t\t// normalize to fwd-slashes on windows,\n\t\t// on other systems bwd-slashes are valid\n\t\t// filename character, eg /f\\oo/ba\\r.txt\n\t\tif (isWindows) {\n\t\t\tpath = path.replace(/\\\\/g, _slash);\n\t\t}\n\n\t\t// check for authority as used in UNC shares\n\t\t// or use the path as given\n\t\tif (path[0] === _slash && path[1] === _slash) {\n\t\t\tconst idx = path.indexOf(_slash, 2);\n\t\t\tif (idx === -1) {\n\t\t\t\tauthority = path.substring(2);\n\t\t\t\tpath = _slash;\n\t\t\t} else {\n\t\t\t\tauthority = path.substring(2, idx);\n\t\t\t\tpath = path.substring(idx) || _slash;\n\t\t\t}\n\t\t}\n\n\t\treturn new Uri('file', authority, path, _empty, _empty);\n\t}\n\n\tstatic from(components: { scheme: string; authority?: string; path?: string; query?: string; fragment?: string }): URI {\n\t\tconst result = new Uri(\n\t\t\tcomponents.scheme,\n\t\t\tcomponents.authority,\n\t\t\tcomponents.path,\n\t\t\tcomponents.query,\n\t\t\tcomponents.fragment,\n\t\t);\n\t\t_validateUri(result, true);\n\t\treturn result;\n\t}\n\n\t// ---- printing/externalize ---------------------------\n\n\t/**\n\t * Creates a string representation for this URI. It's guaranteed that calling\n\t * `URI.parse` with the result of this function creates an URI which is equal\n\t * to this URI.\n\t *\n\t * * The result shall *not* be used for display purposes but for externalization or transport.\n\t * * The result will be encoded using the percentage encoding and encoding happens mostly\n\t * ignore the scheme-specific encoding rules.\n\t *\n\t * @param skipEncoding Do not encode the result, default is `false`\n\t */\n\ttoString(skipEncoding: boolean = false): string {\n\t\treturn _asFormatted(this, skipEncoding);\n\t}\n\n\ttoJSON(): UriComponents {\n\t\treturn this;\n\t}\n\n\tstatic revive(data: UriComponents | URI): URI;\n\tstatic revive(data: UriComponents | URI | undefined): URI | undefined;\n\tstatic revive(data: UriComponents | URI | null): URI | null;\n\tstatic revive(data: UriComponents | URI | undefined | null): URI | undefined | null;\n\tstatic revive(data: UriComponents | URI | undefined | null): URI | undefined | null {\n\t\tif (!data) {\n\t\t\treturn <any>data;\n\t\t} else if (data instanceof URI) {\n\t\t\treturn data;\n\t\t} else {\n\t\t\tconst result = new Uri(data);\n\t\t\tresult._formatted = (<UriState>data).external;\n\t\t\tresult._fsPath = (<UriState>data)._sep === _pathSepMarker ? (<UriState>data).fsPath : null;\n\t\t\treturn result;\n\t\t}\n\t}\n}\n\nexport interface UriComponents {\n\tscheme: string;\n\tauthority: string;\n\tpath: string;\n\tquery: string;\n\tfragment: string;\n}\n\ninterface UriState extends UriComponents {\n\t$mid: number;\n\texternal: string;\n\tfsPath: string;\n\t_sep: 1 | undefined;\n}\n\nconst _pathSepMarker = isWindows ? 1 : undefined;\n\n// This class exists so that URI is compatible with vscode.Uri (API).\nclass Uri extends URI {\n\n\t_formatted: string | null = null;\n\t_fsPath: string | null = null;\n\n\toverride get fsPath(): string {\n\t\tif (!this._fsPath) {\n\t\t\tthis._fsPath = uriToFsPath(this, false);\n\t\t}\n\t\treturn this._fsPath;\n\t}\n\n\toverride toString(skipEncoding: boolean = false): string {\n\t\tif (!skipEncoding) {\n\t\t\tif (!this._formatted) {\n\t\t\t\tthis._formatted = _asFormatted(this, false);\n\t\t\t}\n\t\t\treturn this._formatted;\n\t\t} else {\n\t\t\t// we don't cache that\n\t\t\treturn _asFormatted(this, true);\n\t\t}\n\t}\n\n\toverride toJSON(): UriComponents {\n\t\tconst res = <UriState>{\n\t\t\t$mid: 1\n\t\t};\n\t\t// cached state\n\t\tif (this._fsPath) {\n\t\t\tres.fsPath = this._fsPath;\n\t\t\tres._sep = _pathSepMarker;\n\t\t}\n\t\tif (this._formatted) {\n\t\t\tres.external = this._formatted;\n\t\t}\n\t\t// uri components\n\t\tif (this.path) {\n\t\t\tres.path = this.path;\n\t\t}\n\t\tif (this.scheme) {\n\t\t\tres.scheme = this.scheme;\n\t\t}\n\t\tif (this.authority) {\n\t\t\tres.authority = this.authority;\n\t\t}\n\t\tif (this.query) {\n\t\t\tres.query = this.query;\n\t\t}\n\t\tif (this.fragment) {\n\t\t\tres.fragment = this.fragment;\n\t\t}\n\t\treturn res;\n\t}\n}\n\n// reserved characters: https://tools.ietf.org/html/rfc3986#section-2.2\nconst encodeTable: { [ch: number]: string } = {\n\t[CharCode.Colon]: '%3A', // gen-delims\n\t[CharCode.Slash]: '%2F',\n\t[CharCode.QuestionMark]: '%3F',\n\t[CharCode.Hash]: '%23',\n\t[CharCode.OpenSquareBracket]: '%5B',\n\t[CharCode.CloseSquareBracket]: '%5D',\n\t[CharCode.AtSign]: '%40',\n\n\t[CharCode.ExclamationMark]: '%21', // sub-delims\n\t[CharCode.DollarSign]: '%24',\n\t[CharCode.Ampersand]: '%26',\n\t[CharCode.SingleQuote]: '%27',\n\t[CharCode.OpenParen]: '%28',\n\t[CharCode.CloseParen]: '%29',\n\t[CharCode.Asterisk]: '%2A',\n\t[CharCode.Plus]: '%2B',\n\t[CharCode.Comma]: '%2C',\n\t[CharCode.Semicolon]: '%3B',\n\t[CharCode.Equals]: '%3D',\n\n\t[CharCode.Space]: '%20',\n};\n\nfunction encodeURIComponentFast(uriComponent: string, isPath: boolean, isAuthority: boolean): string {\n\tlet res: string | undefined = undefined;\n\tlet nativeEncodePos = -1;\n\n\tfor (let pos = 0; pos < uriComponent.length; pos++) {\n\t\tconst code = uriComponent.charCodeAt(pos);\n\n\t\t// unreserved characters: https://tools.ietf.org/html/rfc3986#section-2.3\n\t\tif (\n\t\t\t(code >= CharCode.a && code <= CharCode.z)\n\t\t\t|| (code >= CharCode.A && code <= CharCode.Z)\n\t\t\t|| (code >= CharCode.Digit0 && code <= CharCode.Digit9)\n\t\t\t|| code === CharCode.Dash\n\t\t\t|| code === CharCode.Period\n\t\t\t|| code === CharCode.Underline\n\t\t\t|| code === CharCode.Tilde\n\t\t\t|| (isPath && code === CharCode.Slash)\n\t\t\t|| (isAuthority && code === CharCode.OpenSquareBracket)\n\t\t\t|| (isAuthority && code === CharCode.CloseSquareBracket)\n\t\t\t|| (isAuthority && code === CharCode.Colon)\n\t\t) {\n\t\t\t// check if we are delaying native encode\n\t\t\tif (nativeEncodePos !== -1) {\n\t\t\t\tres += encodeURIComponent(uriComponent.substring(nativeEncodePos, pos));\n\t\t\t\tnativeEncodePos = -1;\n\t\t\t}\n\t\t\t// check if we write into a new string (by default we try to return the param)\n\t\t\tif (res !== undefined) {\n\t\t\t\tres += uriComponent.charAt(pos);\n\t\t\t}\n\n\t\t} else {\n\t\t\t// encoding needed, we need to allocate a new string\n\t\t\tif (res === undefined) {\n\t\t\t\tres = uriComponent.substr(0, pos);\n\t\t\t}\n\n\t\t\t// check with default table first\n\t\t\tconst escaped = encodeTable[code];\n\t\t\tif (escaped !== undefined) {\n\n\t\t\t\t// check if we are delaying native encode\n\t\t\t\tif (nativeEncodePos !== -1) {\n\t\t\t\t\tres += encodeURIComponent(uriComponent.substring(nativeEncodePos, pos));\n\t\t\t\t\tnativeEncodePos = -1;\n\t\t\t\t}\n\n\t\t\t\t// append escaped variant to result\n\t\t\t\tres += escaped;\n\n\t\t\t} else if (nativeEncodePos === -1) {\n\t\t\t\t// use native encode only when needed\n\t\t\t\tnativeEncodePos = pos;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nativeEncodePos !== -1) {\n\t\tres += encodeURIComponent(uriComponent.substring(nativeEncodePos));\n\t}\n\n\treturn res !== undefined ? res : uriComponent;\n}\n\nfunction encodeURIComponentMinimal(path: string): string {\n\tlet res: string | undefined = undefined;\n\tfor (let pos = 0; pos < path.length; pos++) {\n\t\tconst code = path.charCodeAt(pos);\n\t\tif (code === CharCode.Hash || code === CharCode.QuestionMark) {\n\t\t\tif (res === undefined) {\n\t\t\t\tres = path.substr(0, pos);\n\t\t\t}\n\t\t\tres += encodeTable[code];\n\t\t} else {\n\t\t\tif (res !== undefined) {\n\t\t\t\tres += path[pos];\n\t\t\t}\n\t\t}\n\t}\n\treturn res !== undefined ? res : path;\n}\n\n/**\n * Compute `fsPath` for the given uri\n */\nexport function uriToFsPath(uri: URI, keepDriveLetterCasing: boolean): string {\n\n\tlet value: string;\n\tif (uri.authority && uri.path.length > 1 && uri.scheme === 'file') {\n\t\t// unc path: file://shares/c$/far/boo\n\t\tvalue = `//${uri.authority}${uri.path}`;\n\t} else if (\n\t\turi.path.charCodeAt(0) === CharCode.Slash\n\t\t&& (uri.path.charCodeAt(1) >= CharCode.A && uri.path.charCodeAt(1) <= CharCode.Z || uri.path.charCodeAt(1) >= CharCode.a && uri.path.charCodeAt(1) <= CharCode.z)\n\t\t&& uri.path.charCodeAt(2) === CharCode.Colon\n\t) {\n\t\tif (!keepDriveLetterCasing) {\n\t\t\t// windows drive letter: file:///c:/far/boo\n\t\t\tvalue = uri.path[1].toLowerCase() + uri.path.substr(2);\n\t\t} else {\n\t\t\tvalue = uri.path.substr(1);\n\t\t}\n\t} else {\n\t\t// other path\n\t\tvalue = uri.path;\n\t}\n\tif (isWindows) {\n\t\tvalue = value.replace(/\\//g, '\\\\');\n\t}\n\treturn value;\n}\n\n/**\n * Create the external version of a uri\n */\nfunction _asFormatted(uri: URI, skipEncoding: boolean): string {\n\n\tconst encoder = !skipEncoding\n\t\t? encodeURIComponentFast\n\t\t: encodeURIComponentMinimal;\n\n\tlet res = '';\n\tlet { scheme, authority, path, query, fragment } = uri;\n\tif (scheme) {\n\t\tres += scheme;\n\t\tres += ':';\n\t}\n\tif (authority || scheme === 'file') {\n\t\tres += _slash;\n\t\tres += _slash;\n\t}\n\tif (authority) {\n\t\tlet idx = authority.indexOf('@');\n\t\tif (idx !== -1) {\n\t\t\t// <user>@<auth>\n\t\t\tconst userinfo = authority.substr(0, idx);\n\t\t\tauthority = authority.substr(idx + 1);\n\t\t\tidx = userinfo.lastIndexOf(':');\n\t\t\tif (idx === -1) {\n\t\t\t\tres += encoder(userinfo, false, false);\n\t\t\t} else {\n\t\t\t\t// <user>:<pass>@<auth>\n\t\t\t\tres += encoder(userinfo.substr(0, idx), false, false);\n\t\t\t\tres += ':';\n\t\t\t\tres += encoder(userinfo.substr(idx + 1), false, true);\n\t\t\t}\n\t\t\tres += '@';\n\t\t}\n\t\tauthority = authority.toLowerCase();\n\t\tidx = authority.lastIndexOf(':');\n\t\tif (idx === -1) {\n\t\t\tres += encoder(authority, false, true);\n\t\t} else {\n\t\t\t// <auth>:<port>\n\t\t\tres += encoder(authority.substr(0, idx), false, true);\n\t\t\tres += authority.substr(idx);\n\t\t}\n\t}\n\tif (path) {\n\t\t// lower-case windows drive letters in /C:/fff or C:/fff\n\t\tif (path.length >= 3 && path.charCodeAt(0) === CharCode.Slash && path.charCodeAt(2) === CharCode.Colon) {\n\t\t\tconst code = path.charCodeAt(1);\n\t\t\tif (code >= CharCode.A && code <= CharCode.Z) {\n\t\t\t\tpath = `/${String.fromCharCode(code + 32)}:${path.substr(3)}`; // \"/c:\".length === 3\n\t\t\t}\n\t\t} else if (path.length >= 2 && path.charCodeAt(1) === CharCode.Colon) {\n\t\t\tconst code = path.charCodeAt(0);\n\t\t\tif (code >= CharCode.A && code <= CharCode.Z) {\n\t\t\t\tpath = `${String.fromCharCode(code + 32)}:${path.substr(2)}`; // \"/c:\".length === 3\n\t\t\t}\n\t\t}\n\t\t// encode the rest of the path\n\t\tres += encoder(path, true, false);\n\t}\n\tif (query) {\n\t\tres += '?';\n\t\tres += encoder(query, false, false);\n\t}\n\tif (fragment) {\n\t\tres += '#';\n\t\tres += !skipEncoding ? encodeURIComponentFast(fragment, false, false) : fragment;\n\t}\n\treturn res;\n}\n\n// --- decode\n\nfunction decodeURIComponentGraceful(str: string): string {\n\ttry {\n\t\treturn decodeURIComponent(str);\n\t} catch {\n\t\tif (str.length > 3) {\n\t\t\treturn str.substr(0, 3) + decodeURIComponentGraceful(str.substr(3));\n\t\t} else {\n\t\t\treturn str;\n\t\t}\n\t}\n}\n\nconst _rEncodedAsHex = /(%[0-9A-Za-z][0-9A-Za-z])+/g;\n\nfunction percentDecode(str: string): string {\n\tif (!str.match(_rEncodedAsHex)) {\n\t\treturn str;\n\t}\n\treturn str.replace(_rEncodedAsHex, (match) => decodeURIComponentGraceful(match));\n}\n\n/**\n * Mapped-type that replaces all occurrences of URI with UriComponents\n */\nexport type UriDto<T> = { [K in keyof T]: T[K] extends URI\n\t? UriComponents\n\t: UriDto<T[K]> };\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\n'use strict';\n\nimport { CharCode } from './charCode';\nimport { URI } from './uri';\nimport * as nodePath from 'path';\n\nconst posixPath = nodePath.posix || nodePath;\nconst slash = '/';\n\nexport namespace Utils {\n\n    /**\n     * Joins one or more input paths to the path of URI. \n     * '/' is used as the directory separation character. \n     * \n     * The resolved path will be normalized. That means:\n     *  - all '..' and '.' segments are resolved.\n     *  - multiple, sequential occurences of '/' are replaced by a single instance of '/'.\n     *  - trailing separators are preserved.\n     * \n     * @param uri The input URI.\n     * @param paths The paths to be joined with the path of URI.\n     * @returns A URI with the joined path. All other properties of the URI (scheme, authority, query, fragments, ...) will be taken from the input URI.\n     */\n    export function joinPath(uri: URI, ...paths: string[]): URI {\n        return uri.with({ path: posixPath.join(uri.path, ...paths) });\n    }\n\n\n    /**\n     * Resolves one or more paths against the path of a URI. \n     * '/' is used as the directory separation character. \n     * \n     * The resolved path will be normalized. That means:\n     *  - all '..' and '.' segments are resolved. \n     *  - multiple, sequential occurences of '/' are replaced by a single instance of '/'.\n     *  - trailing separators are removed.\n     * \n     * @param uri The input URI.\n     * @param paths The paths to resolve against the path of URI.\n     * @returns A URI with the resolved path. All other properties of the URI (scheme, authority, query, fragments, ...) will be taken from the input URI.\n     */\n    export function resolvePath(uri: URI, ...paths: string[]): URI {\n        let path = uri.path; \n        let slashAdded = false;\n        if (path[0] !== slash) {\n            path = slash + path; // make the path abstract: for posixPath.resolve the first segments has to be absolute or cwd is used.\n            slashAdded = true;\n        }\n        let resolvedPath = posixPath.resolve(path, ...paths);\n        if (slashAdded && resolvedPath[0] === slash && !uri.authority) {\n            resolvedPath = resolvedPath.substring(1);\n        }\n        return uri.with({ path: resolvedPath });\n    }\n\n    /**\n     * Returns a URI where the path is the directory name of the input uri, similar to the Unix dirname command. \n     * In the path, '/' is recognized as the directory separation character. Trailing directory separators are ignored.\n     * The orignal URI is returned if the URIs path is empty or does not contain any path segments.\n     * \n     * @param uri The input URI.\n     * @return The last segment of the URIs path.\n     */\n    export function dirname(uri: URI): URI {\n        if (uri.path.length === 0 || uri.path === slash) {\n            return uri;\n        }\n        let path = posixPath.dirname(uri.path);\n        if (path.length === 1 && path.charCodeAt(0) === CharCode.Period) {\n            path = '';\n        }\n        return uri.with({ path });\n    }\n\n    /**\n     * Returns the last segment of the path of a URI, similar to the Unix basename command. \n     * In the path, '/' is recognized as the directory separation character. Trailing directory separators are ignored.\n     * The empty string is returned if the URIs path is empty or does not contain any path segments.\n     * \n     * @param uri The input URI.\n     * @return The base name of the URIs path.\n     */\n    export function basename(uri: URI): string {\n        return posixPath.basename(uri.path);\n    }\n\n    /**\n     * Returns the extension name of the path of a URI, similar to the Unix extname command. \n     * In the path, '/' is recognized as the directory separation character. Trailing directory separators are ignored.\n     * The empty string is returned if the URIs path is empty or does not contain any path segments.\n     * \n     * @param uri The input URI.\n     * @return The extension name of the URIs path.\n     */\n    export function extname(uri: URI): string {\n        return posixPath.extname(uri.path);\n    }\n}","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport { URI, Utils } from 'vscode-uri';\n\nexport { URI };\n\nexport namespace UriUtils {\n\n    export const basename = Utils.basename;\n    export const dirname = Utils.dirname;\n    export const extname = Utils.extname;\n    export const joinPath = Utils.joinPath;\n    export const resolvePath = Utils.resolvePath;\n\n    export function equals(a?: URI | string, b?: URI | string): boolean {\n        return a?.toString() === b?.toString();\n    }\n\n    export function relative(from: URI | string, to: URI | string): string {\n        const fromPath = typeof from === 'string' ? from : from.path;\n        const toPath = typeof to === 'string' ? to : to.path;\n        const fromParts = fromPath.split('/').filter(e => e.length > 0);\n        const toParts = toPath.split('/').filter(e => e.length > 0);\n        let i = 0;\n        for (; i < fromParts.length; i++) {\n            if (fromParts[i] !== toParts[i]) {\n                break;\n            }\n        }\n        const backPart = '../'.repeat(fromParts.length - i);\n        const toPart = toParts.slice(i).join('/');\n        return backPart + toPart;\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\n/**\n * Re-export 'TextDocument' from 'vscode-languageserver-textdocument' for convenience,\n *  including both type _and_ symbol (namespace), as we here and there also refer to the symbol,\n *  the overhead is very small, just a few kilobytes.\n * Everything else of that package (at the time contributing) is also defined\n *  in 'vscode-languageserver-protocol' or 'vscode-languageserver-types'.\n */\nexport { TextDocument } from 'vscode-languageserver-textdocument';\n\nimport type { Diagnostic, Range } from 'vscode-languageserver-types';\nimport type { FileSystemProvider } from './file-system-provider.js';\nimport type { ParseResult } from '../parser/langium-parser.js';\nimport type { ServiceRegistry } from '../service-registry.js';\nimport type { LangiumSharedCoreServices } from '../services.js';\nimport type { AstNode, AstNodeDescription, Mutable, Reference } from '../syntax-tree.js';\nimport type { MultiMap } from '../utils/collections.js';\nimport type { Stream } from '../utils/stream.js';\nimport { TextDocument } from './documents.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { stream } from '../utils/stream.js';\nimport { URI } from '../utils/uri-utils.js';\n\n/**\n * A Langium document holds the parse result (AST and CST) and any additional state that is derived\n * from the AST, e.g. the result of scope precomputation.\n */\nexport interface LangiumDocument<T extends AstNode = AstNode> {\n    /** The Uniform Resource Identifier (URI) of the document */\n    readonly uri: URI;\n    /** The text document used to convert between offsets and positions */\n    readonly textDocument: TextDocument;\n    /** The current state of the document */\n    state: DocumentState;\n    /** The parse result holds the Abstract Syntax Tree (AST) and potentially also parser / lexer errors */\n    parseResult: ParseResult<T>;\n    /** Result of the scope precomputation phase */\n    precomputedScopes?: PrecomputedScopes;\n    /** An array of all cross-references found in the AST while linking */\n    references: Reference[];\n    /** Result of the validation phase */\n    diagnostics?: Diagnostic[]\n}\n\n/**\n * A document is subject to several phases that are run in predefined order. Any state value implies that\n * smaller state values are finished as well.\n */\nexport enum DocumentState {\n    /**\n     * The text content has changed and needs to be parsed again. The AST held by this outdated\n     * document instance is no longer valid.\n     */\n    Changed = 0,\n    /**\n     * An AST has been created from the text content. The document structure can be traversed,\n     * but cross-references cannot be resolved yet. If necessary, the structure can be manipulated\n     * at this stage as a preprocessing step.\n     */\n    Parsed = 1,\n    /**\n     * The `IndexManager` service has processed AST nodes of this document. This means the\n     * exported symbols are available in the global scope and can be resolved from other documents.\n     */\n    IndexedContent = 2,\n    /**\n     * The `ScopeComputation` service has processed this document. This means the local symbols\n     * are stored in a MultiMap so they can be looked up by the `ScopeProvider` service.\n     * Once a document has reached this state, you may follow every reference - it will lazily\n     * resolve its `ref` property and yield either the target AST node or `undefined` in case\n     * the target is not in scope.\n     */\n    ComputedScopes = 3,\n    /**\n     * The `Linker` service has processed this document. All outgoing references have been\n     * resolved or marked as erroneous.\n     */\n    Linked = 4,\n    /**\n     * The `IndexManager` service has processed AST node references of this document. This is\n     * necessary to determine which documents are affected by a change in one of the workspace\n     * documents.\n     */\n    IndexedReferences = 5,\n    /**\n     * The `DocumentValidator` service has processed this document. The language server listens\n     * to the results of this phase and sends diagnostics to the client.\n     */\n    Validated = 6\n}\n\n/**\n * Result of the scope precomputation phase (`ScopeComputation` service).\n * It maps every AST node to the set of symbols that are visible in the subtree of that node.\n */\nexport type PrecomputedScopes = MultiMap<AstNode, AstNodeDescription>\n\nexport interface DocumentSegment {\n    readonly range: Range\n    readonly offset: number\n    readonly length: number\n    readonly end: number\n}\n\n/**\n * Surrogate definition of the `TextDocuments` interface from the `vscode-languageserver` package.\n * No implementation object is expected to be offered by `LangiumCoreServices`, but only by `LangiumLSPServices`.\n */\nexport type TextDocumentProvider = {\n    get(uri: string): TextDocument | undefined\n}\n\n/**\n * Shared service for creating `LangiumDocument` instances.\n *\n * Register a custom implementation if special (additional) behavior is required for your language(s).\n * Note: If you specialize {@link fromString} or {@link fromTextDocument} you probably might want to\n * specialize {@link update}, too!\n */\nexport interface LangiumDocumentFactory {\n    /**\n     * Create a Langium document from a `TextDocument` (usually associated with a file).\n     */\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri?: URI): LangiumDocument<T>;\n    /**\n     * Create a Langium document from a `TextDocument` asynchronously. This action can be cancelled if a cancellable parser implementation has been provided.\n     */\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri: URI | undefined, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\n\n    /**\n     * Create an Langium document from an in-memory string.\n     */\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI): LangiumDocument<T>;\n    /**\n     * Create a Langium document from an in-memory string asynchronously. This action can be cancelled if a cancellable parser implementation has been provided.\n     */\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\n\n    /**\n     * Create an Langium document from a model that has been constructed in memory.\n     */\n    fromModel<T extends AstNode = AstNode>(model: T, uri: URI): LangiumDocument<T>;\n\n    /**\n     * Create an Langium document from a specified `URI`. The factory will use the `FileSystemAccess` service to read the file.\n     */\n    fromUri<T extends AstNode = AstNode>(uri: URI, cancellationToken?: CancellationToken): Promise<LangiumDocument<T>>;\n\n    /**\n     * Update the given document after changes in the corresponding textual representation.\n     * Method is called by the document builder after it has been requested to build an existing\n     * document and the document's state is {@link DocumentState.Changed}.\n     * The text parsing is expected to be done the same way as in {@link fromTextDocument}\n     * and {@link fromString}.\n     */\n    update<T extends AstNode = AstNode>(document: LangiumDocument<T>, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>\n}\n\nexport class DefaultLangiumDocumentFactory implements LangiumDocumentFactory {\n\n    protected readonly serviceRegistry: ServiceRegistry;\n    protected readonly textDocuments?: TextDocumentProvider;\n    protected readonly fileSystemProvider: FileSystemProvider;\n\n    constructor(services: LangiumSharedCoreServices) {\n        this.serviceRegistry = services.ServiceRegistry;\n        this.textDocuments = services.workspace.TextDocuments;\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\n    }\n\n    async fromUri<T extends AstNode = AstNode>(uri: URI, cancellationToken = CancellationToken.None): Promise<LangiumDocument<T>> {\n        const content = await this.fileSystemProvider.readFile(uri);\n        return this.createAsync<T>(uri, content, cancellationToken);\n    }\n\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri?: URI): LangiumDocument<T>;\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri: URI | undefined, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri?: URI, cancellationToken?: CancellationToken): LangiumDocument<T> | Promise<LangiumDocument<T>> {\n        uri = uri ?? URI.parse(textDocument.uri);\n        if (cancellationToken) {\n            return this.createAsync<T>(uri, textDocument, cancellationToken);\n        } else {\n            return this.create<T>(uri, textDocument);\n        }\n    }\n\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI): LangiumDocument<T>;\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, cancellationToken?: CancellationToken): LangiumDocument<T> | Promise<LangiumDocument<T>> {\n        if (cancellationToken) {\n            return this.createAsync<T>(uri, text, cancellationToken);\n        } else {\n            return this.create<T>(uri, text);\n        }\n    }\n\n    fromModel<T extends AstNode = AstNode>(model: T, uri: URI): LangiumDocument<T> {\n        return this.create<T>(uri, { $model: model });\n    }\n\n    protected create<T extends AstNode = AstNode>(uri: URI, content: string | TextDocument | { $model: T }): LangiumDocument<T> {\n        if (typeof content === 'string') {\n            const parseResult = this.parse<T>(uri, content);\n            return this.createLangiumDocument<T>(parseResult, uri, undefined, content);\n\n        } else if ('$model' in content) {\n            const parseResult = { value: content.$model, parserErrors: [], lexerErrors: [] };\n            return this.createLangiumDocument<T>(parseResult, uri);\n\n        } else {\n            const parseResult = this.parse<T>(uri, content.getText());\n            return this.createLangiumDocument(parseResult, uri, content);\n        }\n    }\n\n    protected async createAsync<T extends AstNode = AstNode>(uri: URI, content: string | TextDocument, cancelToken: CancellationToken): Promise<LangiumDocument<T>> {\n        if (typeof content === 'string') {\n            const parseResult = await this.parseAsync<T>(uri, content, cancelToken);\n            return this.createLangiumDocument<T>(parseResult, uri, undefined, content);\n        } else {\n            const parseResult = await this.parseAsync<T>(uri, content.getText(), cancelToken);\n            return this.createLangiumDocument(parseResult, uri, content);\n        }\n    }\n\n    /**\n     * Create a LangiumDocument from a given parse result.\n     *\n     * A TextDocument is created on demand if it is not provided as argument here. Usually this\n     * should not be necessary because the main purpose of the TextDocument is to convert between\n     * text ranges and offsets, which is done solely in LSP request handling.\n     *\n     * With the introduction of {@link update} below this method is supposed to be mainly called\n     * during workspace initialization and on addition/recognition of new files, while changes in\n     * existing documents are processed via {@link update}.\n     */\n    protected createLangiumDocument<T extends AstNode = AstNode>(parseResult: ParseResult<T>, uri: URI, textDocument?: TextDocument, text?: string): LangiumDocument<T> {\n        let document: LangiumDocument<T>;\n        if (textDocument) {\n            document = {\n                parseResult,\n                uri,\n                state: DocumentState.Parsed,\n                references: [],\n                textDocument\n            };\n        } else {\n            const textDocumentGetter = this.createTextDocumentGetter(uri, text);\n            document = {\n                parseResult,\n                uri,\n                state: DocumentState.Parsed,\n                references: [],\n                get textDocument() {\n                    return textDocumentGetter();\n                }\n            };\n        }\n        (parseResult.value as Mutable<AstNode>).$document = document;\n        return document;\n    }\n\n    async update<T extends AstNode = AstNode>(document: Mutable<LangiumDocument<T>>, cancellationToken: CancellationToken): Promise<LangiumDocument<T>> {\n        // The CST full text property contains the original text that was used to create the AST.\n        const oldText = document.parseResult.value.$cstNode?.root.fullText;\n        const textDocument = this.textDocuments?.get(document.uri.toString());\n        const text = textDocument ? textDocument.getText() : await this.fileSystemProvider.readFile(document.uri);\n\n        if (textDocument) {\n            Object.defineProperty(\n                document,\n                'textDocument',\n                {\n                    value: textDocument\n                }\n            );\n        } else {\n            const textDocumentGetter = this.createTextDocumentGetter(document.uri, text);\n            Object.defineProperty(\n                document,\n                'textDocument',\n                {\n                    get: textDocumentGetter\n                }\n            );\n        }\n\n        // Some of these documents can be pretty large, so parsing them again can be quite expensive.\n        // Therefore, we only parse if the text has actually changed.\n        if (oldText !== text) {\n            document.parseResult = await this.parseAsync(document.uri, text, cancellationToken);\n            (document.parseResult.value as Mutable<AstNode>).$document = document;\n        }\n        document.state = DocumentState.Parsed;\n        return document;\n    }\n\n    protected parse<T extends AstNode>(uri: URI, text: string): ParseResult<T> {\n        const services = this.serviceRegistry.getServices(uri);\n        return services.parser.LangiumParser.parse<T>(text);\n    }\n\n    protected parseAsync<T extends AstNode>(uri: URI, text: string, cancellationToken: CancellationToken): Promise<ParseResult<T>> {\n        const services = this.serviceRegistry.getServices(uri);\n        return services.parser.AsyncParser.parse<T>(text, cancellationToken);\n    }\n\n    protected createTextDocumentGetter(uri: URI, text?: string): () => TextDocument {\n        const serviceRegistry = this.serviceRegistry;\n        let textDoc: TextDocument | undefined = undefined;\n        return () => {\n            return textDoc ??= TextDocument.create(\n                uri.toString(), serviceRegistry.getServices(uri).LanguageMetaData.languageId, 0, text ?? ''\n            );\n        };\n    }\n}\n\n/**\n * Shared service for managing Langium documents.\n */\nexport interface LangiumDocuments {\n\n    /**\n     * A stream of all documents managed under this service.\n     */\n    readonly all: Stream<LangiumDocument>\n\n    /**\n     * Manage a new document under this service.\n     * @throws an error if a document with the same URI is already present.\n     */\n    addDocument(document: LangiumDocument): void;\n\n    /**\n     * Retrieve the document with the given URI, if present. Otherwise returns `undefined`.\n     */\n    getDocument(uri: URI): LangiumDocument | undefined;\n\n    /**\n     * Retrieve the document with the given URI. If not present, a new one will be created using the file system access.\n     * The new document will be added to the list of documents managed under this service.\n     */\n    getOrCreateDocument(uri: URI, cancellationToken?: CancellationToken): Promise<LangiumDocument>;\n\n    /**\n     * Creates a new document with the given URI and text content.\n     * The new document is automatically added to this service and can be retrieved using {@link getDocument}.\n     *\n     * @throws an error if a document with the same URI is already present.\n     */\n    createDocument(uri: URI, text: string): LangiumDocument;\n\n    /**\n     * Creates a new document with the given URI and text content asynchronously.\n     * The process can be interrupted with a cancellation token.\n     * The new document is automatically added to this service and can be retrieved using {@link getDocument}.\n     *\n     * @throws an error if a document with the same URI is already present.\n     */\n    createDocument(uri: URI, text: string, cancellationToken: CancellationToken): Promise<LangiumDocument>;\n\n    /**\n     * Returns `true` if a document with the given URI is managed under this service.\n     */\n    hasDocument(uri: URI): boolean;\n\n    /**\n     * Flag the document with the given URI as `Changed`, if present, meaning that its content\n     * is no longer valid. The content (parseResult) stays untouched, while internal data may\n     * be dropped to reduce memory footprint.\n     *\n     * @returns the affected {@link LangiumDocument} if existing for convenience\n     */\n    invalidateDocument(uri: URI): LangiumDocument | undefined;\n\n    /**\n     * Remove the document with the given URI, if present, and mark it as `Changed`, meaning\n     * that its content is no longer valid. The next call to `getOrCreateDocument` with the same\n     * URI will create a new document instance.\n     *\n     * @returns the affected {@link LangiumDocument} if existing for convenience\n     */\n    deleteDocument(uri: URI): LangiumDocument | undefined;\n}\n\nexport class DefaultLangiumDocuments implements LangiumDocuments {\n\n    protected readonly langiumDocumentFactory: LangiumDocumentFactory;\n\n    protected readonly documentMap: Map<string, LangiumDocument> = new Map();\n\n    constructor(services: LangiumSharedCoreServices) {\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\n    }\n\n    get all(): Stream<LangiumDocument> {\n        return stream(this.documentMap.values());\n    }\n\n    addDocument(document: LangiumDocument): void {\n        const uriString = document.uri.toString();\n        if (this.documentMap.has(uriString)) {\n            throw new Error(`A document with the URI '${uriString}' is already present.`);\n        }\n        this.documentMap.set(uriString, document);\n    }\n\n    getDocument(uri: URI): LangiumDocument | undefined {\n        const uriString = uri.toString();\n        return this.documentMap.get(uriString);\n    }\n\n    async getOrCreateDocument(uri: URI, cancellationToken?: CancellationToken): Promise<LangiumDocument> {\n        let document = this.getDocument(uri);\n        if (document) {\n            return document;\n        }\n        document = await this.langiumDocumentFactory.fromUri(uri, cancellationToken);\n        this.addDocument(document);\n        return document;\n    }\n\n    createDocument(uri: URI, text: string): LangiumDocument;\n    createDocument(uri: URI, text: string, cancellationToken: CancellationToken): Promise<LangiumDocument>;\n    createDocument(uri: URI, text: string, cancellationToken?: CancellationToken): LangiumDocument | Promise<LangiumDocument> {\n        if (cancellationToken) {\n            return this.langiumDocumentFactory.fromString(text, uri, cancellationToken).then(document => {\n                this.addDocument(document);\n                return document;\n            });\n        } else {\n            const document = this.langiumDocumentFactory.fromString(text, uri);\n            this.addDocument(document);\n            return document;\n        }\n    }\n\n    hasDocument(uri: URI): boolean {\n        return this.documentMap.has(uri.toString());\n    }\n\n    invalidateDocument(uri: URI): LangiumDocument | undefined {\n        const uriString = uri.toString();\n        const langiumDoc = this.documentMap.get(uriString);\n        if (langiumDoc) {\n            langiumDoc.state = DocumentState.Changed;\n            langiumDoc.precomputedScopes = undefined;\n            langiumDoc.references = [];\n            langiumDoc.diagnostics = undefined;\n        }\n        return langiumDoc;\n    }\n\n    deleteDocument(uri: URI): LangiumDocument | undefined {\n        const uriString = uri.toString();\n        const langiumDoc = this.documentMap.get(uriString);\n        if (langiumDoc) {\n            langiumDoc.state = DocumentState.Changed;\n            this.documentMap.delete(uriString);\n        }\n        return langiumDoc;\n    }\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, AstNodeDescription, AstReflection, CstNode, LinkingError, Reference, ReferenceInfo } from '../syntax-tree.js';\nimport type { AstNodeLocator } from '../workspace/ast-node-locator.js';\nimport type { LangiumDocument, LangiumDocuments } from '../workspace/documents.js';\nimport type { ScopeProvider } from './scope-provider.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { isAstNode, isAstNodeDescription, isLinkingError } from '../syntax-tree.js';\nimport { getDocument, streamAst, streamReferences } from '../utils/ast-utils.js';\nimport { interruptAndCheck } from '../utils/promise-utils.js';\nimport { DocumentState } from '../workspace/documents.js';\n\n/**\n * Language-specific service for resolving cross-references in the AST.\n */\nexport interface Linker {\n\n    /**\n     * Links all cross-references within the specified document. The default implementation loads only target\n     * elements from documents that are present in the `LangiumDocuments` service. The linked references are\n     * stored in the document's `references` property.\n     *\n     * @param document A LangiumDocument that shall be linked.\n     * @param cancelToken A token for cancelling the operation.\n     */\n    link(document: LangiumDocument, cancelToken?: CancellationToken): Promise<void>;\n\n    /**\n     * Unlinks all references within the specified document and removes them from the list of `references`.\n     *\n     * @param document A LangiumDocument that shall be unlinked.\n     */\n    unlink(document: LangiumDocument): void;\n\n    /**\n     * Determines a candidate AST node description for linking the given reference.\n     *\n     * @param node The AST node containing the reference.\n     * @param refId The reference identifier used to build a scope.\n     * @param reference The actual reference to resolve.\n     */\n    getCandidate(refInfo: ReferenceInfo): AstNodeDescription | LinkingError;\n\n    /**\n     * Creates a cross reference node being aware of its containing AstNode, the corresponding CstNode,\n     * the cross reference text denoting the target AstNode being already extracted of the document text,\n     * as well as the unique cross reference identifier.\n     *\n     * Default behavior:\n     *  - The returned Reference's 'ref' property pointing to the target AstNode is populated lazily on its\n     *    first visit.\n     *  - If the target AstNode cannot be resolved on the first visit, an error indicator will be installed\n     *    and further resolution attempts will *not* be performed.\n     *\n     * @param node The containing AST node\n     * @param refNode The corresponding CST node\n     * @param refId The cross reference identifier like '<entityTypeName>:<propertyName>'\n     * @param refText The cross reference text denoting the target AstNode\n     * @returns the desired Reference node, whose behavior wrt. resolving the cross reference is implementation specific.\n     */\n    buildReference(node: AstNode, property: string, refNode: CstNode | undefined, refText: string): Reference;\n\n}\n\ninterface DefaultReference extends Reference {\n    _ref?: AstNode | LinkingError;\n    _nodeDescription?: AstNodeDescription;\n}\n\nexport class DefaultLinker implements Linker {\n    protected readonly reflection: AstReflection;\n    protected readonly scopeProvider: ScopeProvider;\n    protected readonly astNodeLocator: AstNodeLocator;\n    protected readonly langiumDocuments: () => LangiumDocuments;\n\n    constructor(services: LangiumCoreServices) {\n        this.reflection = services.shared.AstReflection;\n        this.langiumDocuments = () => services.shared.workspace.LangiumDocuments;\n        this.scopeProvider = services.references.ScopeProvider;\n        this.astNodeLocator = services.workspace.AstNodeLocator;\n    }\n\n    async link(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<void> {\n        for (const node of streamAst(document.parseResult.value)) {\n            await interruptAndCheck(cancelToken);\n            streamReferences(node).forEach(ref => this.doLink(ref, document));\n        }\n    }\n\n    protected doLink(refInfo: ReferenceInfo, document: LangiumDocument): void {\n        const ref = refInfo.reference as DefaultReference;\n        // The reference may already have been resolved lazily by accessing its `ref` property.\n        if (ref._ref === undefined) {\n            try {\n                const description = this.getCandidate(refInfo);\n                if (isLinkingError(description)) {\n                    ref._ref = description;\n                } else {\n                    ref._nodeDescription = description;\n                    if (this.langiumDocuments().hasDocument(description.documentUri)) {\n                        // The target document is already loaded\n                        const linkedNode = this.loadAstNode(description);\n                        ref._ref = linkedNode ?? this.createLinkingError(refInfo, description);\n                    }\n                }\n            } catch (err) {\n                ref._ref = {\n                    ...refInfo,\n                    message: `An error occurred while resolving reference to '${ref.$refText}': ${err}`\n                };\n            }\n        }\n        // Add the reference to the document's array of references\n        document.references.push(ref);\n    }\n\n    unlink(document: LangiumDocument): void {\n        for (const ref of document.references) {\n            delete (ref as DefaultReference)._ref;\n            delete (ref as DefaultReference)._nodeDescription;\n        }\n        document.references = [];\n    }\n\n    getCandidate(refInfo: ReferenceInfo): AstNodeDescription | LinkingError {\n        const scope = this.scopeProvider.getScope(refInfo);\n        const description = scope.getElement(refInfo.reference.$refText);\n        return description ?? this.createLinkingError(refInfo);\n    }\n\n    buildReference(node: AstNode, property: string, refNode: CstNode | undefined, refText: string): Reference {\n        // See behavior description in doc of Linker, update that on changes in here.\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        const linker = this;\n        const reference: DefaultReference = {\n            $refNode: refNode,\n            $refText: refText,\n\n            get ref() {\n                if (isAstNode(this._ref)) {\n                    // Most frequent case: the target is already resolved.\n                    return this._ref;\n                } else if (isAstNodeDescription(this._nodeDescription)) {\n                    // A candidate has been found before, but it is not loaded yet.\n                    const linkedNode = linker.loadAstNode(this._nodeDescription);\n                    this._ref = linkedNode ??\n                        linker.createLinkingError({ reference, container: node, property }, this._nodeDescription);\n                } else if (this._ref === undefined) {\n                    // The reference has not been linked yet, so do that now.\n                    const refData = linker.getLinkedNode({ reference, container: node, property });\n                    if (refData.error && getDocument(node).state < DocumentState.ComputedScopes) {\n                        // Document scope is not ready, don't set `this._ref` so linker can retry later.\n                        return undefined;\n                    }\n                    this._ref = refData.node ?? refData.error;\n                    this._nodeDescription = refData.descr;\n                }\n                return isAstNode(this._ref) ? this._ref : undefined;\n            },\n            get $nodeDescription() {\n                return this._nodeDescription;\n            },\n            get error() {\n                return isLinkingError(this._ref) ? this._ref : undefined;\n            }\n        };\n        return reference;\n    }\n\n    protected getLinkedNode(refInfo: ReferenceInfo): { node?: AstNode, descr?: AstNodeDescription, error?: LinkingError } {\n        try {\n            const description = this.getCandidate(refInfo);\n            if (isLinkingError(description)) {\n                return { error: description };\n            }\n            const linkedNode = this.loadAstNode(description);\n            if (linkedNode) {\n                return { node: linkedNode, descr: description };\n            }\n            else {\n                return {\n                    descr: description,\n                    error:\n                        this.createLinkingError(refInfo, description)\n                };\n            }\n        } catch (err) {\n            return {\n                error: {\n                    ...refInfo,\n                    message: `An error occurred while resolving reference to '${refInfo.reference.$refText}': ${err}`\n                }\n            };\n        }\n    }\n\n    protected loadAstNode(nodeDescription: AstNodeDescription): AstNode | undefined {\n        if (nodeDescription.node) {\n            return nodeDescription.node;\n        }\n        const doc = this.langiumDocuments().getDocument(nodeDescription.documentUri);\n        if (!doc) {\n            return undefined;\n        }\n        return this.astNodeLocator.getAstNode(doc.parseResult.value, nodeDescription.path);\n    }\n\n    protected createLinkingError(refInfo: ReferenceInfo, targetDescription?: AstNodeDescription): LinkingError {\n        // Check whether the document is sufficiently processed by the DocumentBuilder. If not, this is a hint for a bug\n        // in the language implementation.\n        const document = getDocument(refInfo.container);\n        if (document.state < DocumentState.ComputedScopes) {\n            console.warn(`Attempted reference resolution before document reached ComputedScopes state (${document.uri}).`);\n        }\n        const referenceType = this.reflection.getReferenceType(refInfo);\n        return {\n            ...refInfo,\n            message: `Could not resolve reference to ${referenceType} named '${refInfo.reference.$refText}'.`,\n            targetDescription\n        };\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { AstNode, CstNode } from '../syntax-tree.js';\nimport { findNodeForProperty } from '../utils/grammar-utils.js';\n\nexport interface NamedAstNode extends AstNode {\n    name: string;\n}\n\nexport function isNamed(node: AstNode): node is NamedAstNode {\n    return typeof (node as NamedAstNode).name === 'string';\n}\n\n/**\n * Utility service for retrieving the `name` of an `AstNode` or the `CstNode` containing a `name`.\n */\nexport interface NameProvider {\n    /**\n     * Returns the `name` of a given AstNode.\n     * @param node Specified `AstNode` whose name node shall be retrieved.\n     */\n    getName(node: AstNode): string | undefined;\n    /**\n     * Returns the `CstNode` which contains the parsed value of the `name` assignment.\n     * @param node Specified `AstNode` whose name node shall be retrieved.\n     */\n    getNameNode(node: AstNode): CstNode | undefined;\n}\n\nexport class DefaultNameProvider implements NameProvider {\n    getName(node: AstNode): string | undefined {\n        if (isNamed(node)) {\n            return node.name;\n        }\n        return undefined;\n    }\n\n    getNameNode(node: AstNode): CstNode | undefined {\n        return findNodeForProperty(node.$cstNode, 'name');\n    }\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, CstNode, GenericAstNode } from '../syntax-tree.js';\nimport type { Stream } from '../utils/stream.js';\nimport type { ReferenceDescription } from '../workspace/ast-descriptions.js';\nimport type { AstNodeLocator } from '../workspace/ast-node-locator.js';\nimport type { IndexManager } from '../workspace/index-manager.js';\nimport type { NameProvider } from './name-provider.js';\nimport type { URI } from '../utils/uri-utils.js';\nimport { findAssignment } from '../utils/grammar-utils.js';\nimport { isReference } from '../syntax-tree.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { isChildNode, toDocumentSegment } from '../utils/cst-utils.js';\nimport { stream } from '../utils/stream.js';\nimport { UriUtils } from '../utils/uri-utils.js';\n\n/**\n * Language-specific service for finding references and declaration of a given `CstNode`.\n */\nexport interface References {\n\n    /**\n     * If the CstNode is a reference node the target CstNode will be returned.\n     * If the CstNode is a significant node of the CstNode this CstNode will be returned.\n     *\n     * @param sourceCstNode CstNode that points to a AstNode\n     */\n    findDeclaration(sourceCstNode: CstNode): AstNode | undefined;\n\n    /**\n     * If the CstNode is a reference node the target CstNode will be returned.\n     * If the CstNode is a significant node of the CstNode this CstNode will be returned.\n     *\n     * @param sourceCstNode CstNode that points to a AstNode\n     */\n    findDeclarationNode(sourceCstNode: CstNode): CstNode | undefined;\n\n    /**\n     * Finds all references to the target node as references (local references) or reference descriptions.\n     *\n     * @param targetNode Specified target node whose references should be returned\n     */\n    findReferences(targetNode: AstNode, options: FindReferencesOptions): Stream<ReferenceDescription>;\n}\n\nexport interface FindReferencesOptions {\n    /**\n     * @deprecated Since v1.2.0. Please use `documentUri` instead.\n     */\n    onlyLocal?: boolean;\n    /**\n     * When set, the `findReferences` method will only return references/declarations from the specified document.\n     */\n    documentUri?: URI;\n    /**\n     * Whether the returned list of references should include the declaration.\n     */\n    includeDeclaration?: boolean;\n}\n\nexport class DefaultReferences implements References {\n    protected readonly nameProvider: NameProvider;\n    protected readonly index: IndexManager;\n    protected readonly nodeLocator: AstNodeLocator;\n\n    constructor(services: LangiumCoreServices) {\n        this.nameProvider = services.references.NameProvider;\n        this.index = services.shared.workspace.IndexManager;\n        this.nodeLocator = services.workspace.AstNodeLocator;\n    }\n\n    findDeclaration(sourceCstNode: CstNode): AstNode | undefined {\n        if (sourceCstNode) {\n            const assignment = findAssignment(sourceCstNode);\n            const nodeElem = sourceCstNode.astNode;\n            if (assignment && nodeElem) {\n                const reference = (nodeElem as GenericAstNode)[assignment.feature];\n\n                if (isReference(reference)) {\n                    return reference.ref;\n                } else if (Array.isArray(reference)) {\n                    for (const ref of reference) {\n                        if (isReference(ref) && ref.$refNode\n                            && ref.$refNode.offset <= sourceCstNode.offset\n                            && ref.$refNode.end >= sourceCstNode.end) {\n                            return ref.ref;\n                        }\n                    }\n                }\n            }\n            if (nodeElem) {\n                const nameNode = this.nameProvider.getNameNode(nodeElem);\n                // Only return the targeted node in case the targeted cst node is the name node or part of it\n                if (nameNode && (nameNode === sourceCstNode || isChildNode(sourceCstNode, nameNode))) {\n                    return nodeElem;\n                }\n            }\n        }\n        return undefined;\n    }\n\n    findDeclarationNode(sourceCstNode: CstNode): CstNode | undefined {\n        const astNode = this.findDeclaration(sourceCstNode);\n        if (astNode?.$cstNode) {\n            const targetNode = this.nameProvider.getNameNode(astNode);\n            return targetNode ?? astNode.$cstNode;\n        }\n        return undefined;\n    }\n\n    findReferences(targetNode: AstNode, options: FindReferencesOptions): Stream<ReferenceDescription> {\n        const refs: ReferenceDescription[] = [];\n        if (options.includeDeclaration) {\n            const ref = this.getReferenceToSelf(targetNode);\n            if (ref) {\n                refs.push(ref);\n            }\n        }\n        let indexReferences = this.index.findAllReferences(targetNode, this.nodeLocator.getAstNodePath(targetNode));\n        if (options.documentUri) {\n            indexReferences = indexReferences.filter(ref => UriUtils.equals(ref.sourceUri, options.documentUri));\n        }\n        refs.push(...indexReferences);\n        return stream(refs);\n    }\n\n    protected getReferenceToSelf(targetNode: AstNode): ReferenceDescription | undefined {\n        const nameNode = this.nameProvider.getNameNode(targetNode);\n        if (nameNode) {\n            const doc = getDocument(targetNode);\n            const path = this.nodeLocator.getAstNodePath(targetNode);\n            return {\n                sourceUri: doc.uri,\n                sourcePath: path,\n                targetUri: doc.uri,\n                targetPath: path,\n                segment: toDocumentSegment(nameNode),\n                local: true\n            };\n        }\n        return undefined;\n    }\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { Stream } from './stream.js';\nimport { Reduction, stream } from './stream.js';\n\n/**\n * A multimap is a variation of a Map that has potentially multiple values for every key.\n */\nexport class MultiMap<K, V> {\n\n    private map = new Map<K, V[]>();\n\n    constructor()\n    constructor(elements: Array<[K, V]>)\n    constructor(elements?: Array<[K, V]>) {\n        if (elements) {\n            for (const [key, value] of elements) {\n                this.add(key, value);\n            }\n        }\n    }\n\n    /**\n     * The total number of values in the multimap.\n     */\n    get size(): number {\n        return Reduction.sum(stream(this.map.values()).map(a => a.length));\n    }\n\n    /**\n     * Clear all entries in the multimap.\n     */\n    clear(): void {\n        this.map.clear();\n    }\n\n    /**\n     * Operates differently depending on whether a `value` is given:\n     *  * With a value, this method deletes the specific key / value pair from the multimap.\n     *  * Without a value, all values associated with the given key are deleted.\n     *\n     * @returns `true` if a value existed and has been removed, or `false` if the specified\n     *     key / value does not exist.\n     */\n    delete(key: K, value?: V): boolean {\n        if (value === undefined) {\n            return this.map.delete(key);\n        } else {\n            const values = this.map.get(key);\n            if (values) {\n                const index = values.indexOf(value);\n                if (index >= 0) {\n                    if (values.length === 1) {\n                        this.map.delete(key);\n                    } else {\n                        values.splice(index, 1);\n                    }\n                    return true;\n                }\n            }\n            return false;\n        }\n    }\n\n    /**\n     * Returns an array of all values associated with the given key. If no value exists,\n     * an empty array is returned.\n     *\n     * _Note:_ The returned array is assumed not to be modified. Use the `set` method to add a\n     * value and `delete` to remove a value from the multimap.\n     */\n    get(key: K): readonly V[] {\n        return this.map.get(key) ?? [];\n    }\n\n    /**\n     * Operates differently depending on whether a `value` is given:\n     *  * With a value, this method returns `true` if the specific key / value pair is present in the multimap.\n     *  * Without a value, this method returns `true` if the given key is present in the multimap.\n     */\n    has(key: K, value?: V): boolean {\n        if (value === undefined) {\n            return this.map.has(key);\n        } else {\n            const values = this.map.get(key);\n            if (values) {\n                return values.indexOf(value) >= 0;\n            }\n            return false;\n        }\n    }\n\n    /**\n     * Add the given key / value pair to the multimap.\n     */\n    add(key: K, value: V): this {\n        if (this.map.has(key)) {\n            this.map.get(key)!.push(value);\n        } else {\n            this.map.set(key, [value]);\n        }\n        return this;\n    }\n\n    /**\n     * Add the given set of key / value pairs to the multimap.\n     */\n    addAll(key: K, values: Iterable<V>): this {\n        if (this.map.has(key)) {\n            this.map.get(key)!.push(...values);\n        } else {\n            this.map.set(key, Array.from(values));\n        }\n        return this;\n    }\n\n    /**\n     * Invokes the given callback function for every key / value pair in the multimap.\n     */\n    forEach(callbackfn: (value: V, key: K, map: this) => void): void {\n        this.map.forEach((array, key) =>\n            array.forEach(value => callbackfn(value, key, this))\n        );\n    }\n\n    /**\n     * Returns an iterator of key, value pairs for every entry in the map.\n     */\n    [Symbol.iterator](): Iterator<[K, V]> {\n        return this.entries().iterator();\n    }\n\n    /**\n     * Returns a stream of key, value pairs for every entry in the map.\n     */\n    entries(): Stream<[K, V]> {\n        return stream(this.map.entries())\n            .flatMap(([key, array]) => array.map(value => [key, value] as [K, V]));\n    }\n\n    /**\n     * Returns a stream of keys in the map.\n     */\n    keys(): Stream<K> {\n        return stream(this.map.keys());\n    }\n\n    /**\n     * Returns a stream of values in the map.\n     */\n    values(): Stream<V> {\n        return stream(this.map.values()).flat();\n    }\n\n    /**\n     * Returns a stream of key, value set pairs for every key in the map.\n     */\n    entriesGroupedByKey(): Stream<[K, V[]]> {\n        return stream(this.map.entries());\n    }\n\n}\n\nexport class BiMap<K, V> {\n\n    private map = new Map<K, V>();\n    private inverse = new Map<V, K>();\n\n    get size(): number {\n        return this.map.size;\n    }\n\n    constructor()\n    constructor(elements: Array<[K, V]>)\n    constructor(elements?: Array<[K, V]>) {\n        if (elements) {\n            for (const [key, value] of elements) {\n                this.set(key, value);\n            }\n        }\n    }\n\n    clear(): void {\n        this.map.clear();\n        this.inverse.clear();\n    }\n\n    set(key: K, value: V): this {\n        this.map.set(key, value);\n        this.inverse.set(value, key);\n        return this;\n    }\n\n    get(key: K): V | undefined {\n        return this.map.get(key);\n    }\n\n    getKey(value: V): K | undefined {\n        return this.inverse.get(value);\n    }\n\n    delete(key: K): boolean {\n        const value = this.map.get(key);\n        if (value !== undefined) {\n            this.map.delete(key);\n            this.inverse.delete(value);\n            return true;\n        }\n        return false;\n    }\n}\n","/******************************************************************************\n * Copyright 2021-2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, AstNodeDescription } from '../syntax-tree.js';\nimport type { AstNodeDescriptionProvider } from '../workspace/ast-descriptions.js';\nimport type { LangiumDocument, PrecomputedScopes } from '../workspace/documents.js';\nimport type { NameProvider } from './name-provider.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { streamAllContents, streamContents } from '../utils/ast-utils.js';\nimport { MultiMap } from '../utils/collections.js';\nimport { interruptAndCheck } from '../utils/promise-utils.js';\n\n/**\n * Language-specific service for precomputing global and local scopes. The service methods are executed\n * as the first and second phase in the `DocumentBuilder`.\n */\nexport interface ScopeComputation {\n\n    /**\n     * Creates descriptions of all AST nodes that shall be exported into the _global_ scope from the given\n     * document. These descriptions are gathered by the `IndexManager` and stored in the global index so\n     * they can be referenced from other documents.\n     *\n     * _Note:_ You should not resolve any cross-references in this service method. Cross-reference resolution\n     * depends on the scope computation phase to be completed (`computeScope` method), which runs after the\n     * initial indexing where this method is used.\n     *\n     * @param document The document from which to gather exported AST nodes.\n     * @param cancelToken Indicates when to cancel the current operation.\n     * @throws `OperationCanceled` if a user action occurs during execution\n     */\n    computeExports(document: LangiumDocument, cancelToken?: CancellationToken): Promise<AstNodeDescription[]>;\n\n    /**\n     * Precomputes the _local_ scopes for a document, which are necessary for the default way of\n     * resolving references to symbols in the same document. The result is a multimap assigning a\n     * set of AST node descriptions to every level of the AST. These data are used by the `ScopeProvider`\n     * service to determine which target nodes are visible in the context of a specific cross-reference.\n     *\n     * _Note:_ You should not resolve any cross-references in this service method. Cross-reference\n     * resolution depends on the scope computation phase to be completed.\n     *\n     * @param document The document in which to compute scopes.\n     * @param cancelToken Indicates when to cancel the current operation.\n     * @throws `OperationCanceled` if a user action occurs during execution\n     */\n    computeLocalScopes(document: LangiumDocument, cancelToken?: CancellationToken): Promise<PrecomputedScopes>;\n\n}\n\n/**\n * The default scope computation creates and collectes descriptions of the AST nodes to be exported into the\n * _global_ scope from the given document. By default those are the document's root AST node and its directly\n * contained child nodes.\n *\n * Besides, it gathers all AST nodes that have a name (according to the `NameProvider` service) and includes them\n * in the local scope of their particular container nodes. As a result, for every cross-reference in the AST,\n * target elements from the same level (siblings) and further up towards the root (parents and siblings of parents)\n * are visible. Elements being nested inside lower levels (children, children of siblings and parents' siblings)\n * are _invisible_ by default, but that can be changed by customizing this service.\n */\nexport class DefaultScopeComputation implements ScopeComputation {\n\n    protected readonly nameProvider: NameProvider;\n    protected readonly descriptions: AstNodeDescriptionProvider;\n\n    constructor(services: LangiumCoreServices) {\n        this.nameProvider = services.references.NameProvider;\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\n    }\n\n    async computeExports(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<AstNodeDescription[]> {\n        return this.computeExportsForNode(document.parseResult.value, document, undefined, cancelToken);\n    }\n\n    /**\n     * Creates {@link AstNodeDescription AstNodeDescriptions} for the given {@link AstNode parentNode} and its children.\n     * The list of children to be considered is determined by the function parameter {@link children}.\n     * By default only the direct children of {@link parentNode} are visited, nested nodes are not exported.\n     *\n     * @param parentNode AST node to be exported, i.e., of which an {@link AstNodeDescription} shall be added to the returned list.\n     * @param document The document containing the AST node to be exported.\n     * @param children A function called with {@link parentNode} as single argument and returning an {@link Iterable} supplying the children to be visited, which must be directly or transitively contained in {@link parentNode}.\n     * @param cancelToken Indicates when to cancel the current operation.\n     * @throws `OperationCanceled` if a user action occurs during execution.\n     * @returns A list of {@link AstNodeDescription AstNodeDescriptions} to be published to index.\n     */\n    async computeExportsForNode(parentNode: AstNode, document: LangiumDocument<AstNode>, children: (root: AstNode) => Iterable<AstNode> = streamContents, cancelToken: CancellationToken = CancellationToken.None): Promise<AstNodeDescription[]> {\n        const exports: AstNodeDescription[] = [];\n\n        this.exportNode(parentNode, exports, document);\n        for (const node of children(parentNode)) {\n            await interruptAndCheck(cancelToken);\n            this.exportNode(node, exports, document);\n        }\n        return exports;\n    }\n\n    /**\n     * Add a single node to the list of exports if it has a name. Override this method to change how\n     * symbols are exported, e.g. by modifying their exported name.\n     */\n    protected exportNode(node: AstNode, exports: AstNodeDescription[], document: LangiumDocument): void {\n        const name = this.nameProvider.getName(node);\n        if (name) {\n            exports.push(this.descriptions.createDescription(node, name, document));\n        }\n    }\n\n    async computeLocalScopes(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<PrecomputedScopes> {\n        const rootNode = document.parseResult.value;\n        const scopes = new MultiMap<AstNode, AstNodeDescription>();\n        // Here we navigate the full AST - local scopes shall be available in the whole document\n        for (const node of streamAllContents(rootNode)) {\n            await interruptAndCheck(cancelToken);\n            this.processNode(node, document, scopes);\n        }\n        return scopes;\n    }\n\n    /**\n     * Process a single node during scopes computation. The default implementation makes the node visible\n     * in the subtree of its container (if the node has a name). Override this method to change this,\n     * e.g. by increasing the visibility to a higher level in the AST.\n     */\n    protected processNode(node: AstNode, document: LangiumDocument, scopes: PrecomputedScopes): void {\n        const container = node.$container;\n        if (container) {\n            const name = this.nameProvider.getName(node);\n            if (name) {\n                scopes.add(container, this.descriptions.createDescription(node, name, document));\n            }\n        }\n    }\n\n}\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { AstNodeDescription } from '../syntax-tree.js';\nimport type { Stream } from '../utils/stream.js';\nimport { EMPTY_STREAM, stream } from '../utils/stream.js';\n\n/**\n * A scope describes what target elements are visible from a specific cross-reference context.\n */\nexport interface Scope {\n\n    /**\n     * Find a target element matching the given name. If no element is found, `undefined` is returned.\n     * If multiple matching elements are present, the selection of the returned element should be done\n     * according to the semantics of your language. Usually it is the element that is most closely defined.\n     *\n     * @param name Name of the cross-reference target as it appears in the source text.\n     */\n    getElement(name: string): AstNodeDescription | undefined;\n\n    /**\n     * Create a stream of all elements in the scope. This is used to compute completion proposals to be\n     * shown in the editor.\n     */\n    getAllElements(): Stream<AstNodeDescription>;\n\n}\n\nexport interface ScopeOptions {\n    caseInsensitive?: boolean;\n}\n\n/**\n * The default scope implementation is based on a `Stream`. It has an optional _outer scope_ describing\n * the next level of elements, which are queried when a target element is not found in the stream provided\n * to this scope.\n */\nexport class StreamScope implements Scope {\n    readonly elements: Stream<AstNodeDescription>;\n    readonly outerScope?: Scope;\n    readonly caseInsensitive: boolean;\n\n    constructor(elements: Stream<AstNodeDescription>, outerScope?: Scope, options?: ScopeOptions) {\n        this.elements = elements;\n        this.outerScope = outerScope;\n        this.caseInsensitive = options?.caseInsensitive ?? false;\n    }\n\n    getAllElements(): Stream<AstNodeDescription> {\n        if (this.outerScope) {\n            return this.elements.concat(this.outerScope.getAllElements());\n        } else {\n            return this.elements;\n        }\n    }\n\n    getElement(name: string): AstNodeDescription | undefined {\n        const local = this.caseInsensitive\n            ? this.elements.find(e => e.name.toLowerCase() === name.toLowerCase())\n            : this.elements.find(e => e.name === name);\n        if (local) {\n            return local;\n        }\n        if (this.outerScope) {\n            return this.outerScope.getElement(name);\n        }\n        return undefined;\n    }\n}\n\nexport class MapScope implements Scope {\n    readonly elements: Map<string, AstNodeDescription>;\n    readonly outerScope?: Scope;\n    readonly caseInsensitive: boolean;\n\n    constructor(elements: Iterable<AstNodeDescription>, outerScope?: Scope, options?: ScopeOptions) {\n        this.elements = new Map();\n        this.caseInsensitive = options?.caseInsensitive ?? false;\n        for (const element of elements) {\n            const name = this.caseInsensitive\n                ? element.name.toLowerCase()\n                : element.name;\n            this.elements.set(name, element);\n        }\n        this.outerScope = outerScope;\n    }\n\n    getElement(name: string): AstNodeDescription | undefined {\n        const localName = this.caseInsensitive ? name.toLowerCase() : name;\n        const local = this.elements.get(localName);\n        if (local) {\n            return local;\n        }\n        if (this.outerScope) {\n            return this.outerScope.getElement(name);\n        }\n        return undefined;\n    }\n\n    getAllElements(): Stream<AstNodeDescription> {\n        let elementStream = stream(this.elements.values());\n        if (this.outerScope) {\n            elementStream = elementStream.concat(this.outerScope.getAllElements());\n        }\n        return elementStream;\n    }\n\n}\n\nexport const EMPTY_SCOPE: Scope = {\n    getElement(): undefined {\n        return undefined;\n    },\n    getAllElements(): Stream<AstNodeDescription> {\n        return EMPTY_STREAM;\n    }\n};\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { Disposable } from './disposable.js';\nimport type { URI } from './uri-utils.js';\nimport type { LangiumSharedCoreServices } from '../services.js';\n\nexport abstract class DisposableCache implements Disposable {\n\n    protected toDispose: Disposable[] = [];\n    protected isDisposed = false;\n\n    onDispose(disposable: Disposable): void {\n        this.toDispose.push(disposable);\n    }\n\n    dispose(): void {\n        this.throwIfDisposed();\n        this.clear();\n        this.isDisposed = true;\n        this.toDispose.forEach(disposable => disposable.dispose());\n    }\n\n    protected throwIfDisposed(): void {\n        if (this.isDisposed) {\n            throw new Error('This cache has already been disposed');\n        }\n    }\n\n    abstract clear(): void;\n}\n\nexport class SimpleCache<K, V> extends DisposableCache {\n    protected readonly cache = new Map<K, V>();\n\n    has(key: K): boolean {\n        this.throwIfDisposed();\n        return this.cache.has(key);\n    }\n\n    set(key: K, value: V): void {\n        this.throwIfDisposed();\n        this.cache.set(key, value);\n    }\n\n    get(key: K): V | undefined;\n    get(key: K, provider: () => V): V;\n    get(key: K, provider?: () => V): V | undefined {\n        this.throwIfDisposed();\n        if (this.cache.has(key)) {\n            return this.cache.get(key);\n        } else if (provider) {\n            const value = provider();\n            this.cache.set(key, value);\n            return value;\n        } else {\n            return undefined;\n        }\n    }\n\n    delete(key: K): boolean {\n        this.throwIfDisposed();\n        return this.cache.delete(key);\n    }\n\n    clear(): void {\n        this.throwIfDisposed();\n        this.cache.clear();\n    }\n}\n\nexport class ContextCache<Context, Key, Value, ContextKey = Context> extends DisposableCache {\n\n    private readonly cache = new Map<ContextKey | Context, Map<Key, Value>>();\n    private readonly converter: (input: Context) => ContextKey | Context;\n\n    constructor(converter?: (input: Context) => ContextKey) {\n        super();\n        this.converter = converter ?? (value => value);\n    }\n\n    has(contextKey: Context, key: Key): boolean {\n        this.throwIfDisposed();\n        return this.cacheForContext(contextKey).has(key);\n    }\n\n    set(contextKey: Context, key: Key, value: Value): void {\n        this.throwIfDisposed();\n        this.cacheForContext(contextKey).set(key, value);\n    }\n\n    get(contextKey: Context, key: Key): Value | undefined;\n    get(contextKey: Context, key: Key, provider: () => Value): Value;\n    get(contextKey: Context, key: Key, provider?: () => Value): Value | undefined {\n        this.throwIfDisposed();\n        const contextCache = this.cacheForContext(contextKey);\n        if (contextCache.has(key)) {\n            return contextCache.get(key);\n        } else if (provider) {\n            const value = provider();\n            contextCache.set(key, value);\n            return value;\n        } else {\n            return undefined;\n        }\n    }\n\n    delete(contextKey: Context, key: Key): boolean {\n        this.throwIfDisposed();\n        return this.cacheForContext(contextKey).delete(key);\n    }\n\n    clear(): void;\n    clear(contextKey: Context): void;\n    clear(contextKey?: Context): void {\n        this.throwIfDisposed();\n        if (contextKey) {\n            const mapKey = this.converter(contextKey);\n            this.cache.delete(mapKey);\n        } else {\n            this.cache.clear();\n        }\n    }\n\n    protected cacheForContext(contextKey: Context): Map<Key, Value> {\n        const mapKey = this.converter(contextKey);\n        let documentCache = this.cache.get(mapKey);\n        if (!documentCache) {\n            documentCache = new Map();\n            this.cache.set(mapKey, documentCache);\n        }\n        return documentCache;\n    }\n}\n\n/**\n * Every key/value pair in this cache is scoped to a document.\n * If this document is changed or deleted, all associated key/value pairs are deleted.\n */\nexport class DocumentCache<K, V> extends ContextCache<URI | string, K, V, string> {\n    constructor(sharedServices: LangiumSharedCoreServices) {\n        super(uri => uri.toString());\n        this.onDispose(sharedServices.workspace.DocumentBuilder.onUpdate((changed, deleted) => {\n            const allUris = changed.concat(deleted);\n            for (const uri of allUris) {\n                this.clear(uri);\n            }\n        }));\n    }\n}\n\n/**\n * Every key/value pair in this cache is scoped to the whole workspace.\n * If any document in the workspace changes, the whole cache is evicted.\n */\nexport class WorkspaceCache<K, V> extends SimpleCache<K, V> {\n    constructor(sharedServices: LangiumSharedCoreServices) {\n        super();\n        this.onDispose(sharedServices.workspace.DocumentBuilder.onUpdate(() => {\n            this.clear();\n        }));\n    }\n}\n","/******************************************************************************\n * Copyright 2021-2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, AstNodeDescription, AstReflection, ReferenceInfo } from '../syntax-tree.js';\nimport type { Stream } from '../utils/stream.js';\nimport type { AstNodeDescriptionProvider } from '../workspace/ast-descriptions.js';\nimport type { IndexManager } from '../workspace/index-manager.js';\nimport type { NameProvider } from './name-provider.js';\nimport type { Scope, ScopeOptions} from './scope.js';\nimport { MapScope, StreamScope } from './scope.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { stream } from '../utils/stream.js';\nimport { WorkspaceCache } from '../utils/caching.js';\n\n/**\n * Language-specific service for determining the scope of target elements visible in a specific cross-reference context.\n */\nexport interface ScopeProvider {\n\n    /**\n     * Return a scope describing what elements are visible for the given AST node and cross-reference\n     * identifier.\n     *\n     * @param context Information about the reference for which a scope is requested.\n     */\n    getScope(context: ReferenceInfo): Scope;\n\n}\n\nexport class DefaultScopeProvider implements ScopeProvider {\n\n    protected readonly reflection: AstReflection;\n    protected readonly nameProvider: NameProvider;\n    protected readonly descriptions: AstNodeDescriptionProvider;\n    protected readonly indexManager: IndexManager;\n\n    protected readonly globalScopeCache: WorkspaceCache<string, Scope>;\n\n    constructor(services: LangiumCoreServices) {\n        this.reflection = services.shared.AstReflection;\n        this.nameProvider = services.references.NameProvider;\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\n        this.indexManager = services.shared.workspace.IndexManager;\n        this.globalScopeCache = new WorkspaceCache<string, Scope>(services.shared);\n    }\n\n    getScope(context: ReferenceInfo): Scope {\n        const scopes: Array<Stream<AstNodeDescription>> = [];\n        const referenceType = this.reflection.getReferenceType(context);\n\n        const precomputed = getDocument(context.container).precomputedScopes;\n        if (precomputed) {\n            let currentNode: AstNode | undefined = context.container;\n            do {\n                const allDescriptions = precomputed.get(currentNode);\n                if (allDescriptions.length > 0) {\n                    scopes.push(stream(allDescriptions).filter(\n                        desc => this.reflection.isSubtype(desc.type, referenceType)));\n                }\n                currentNode = currentNode.$container;\n            } while (currentNode);\n        }\n\n        let result: Scope = this.getGlobalScope(referenceType, context);\n        for (let i = scopes.length - 1; i >= 0; i--) {\n            result = this.createScope(scopes[i], result);\n        }\n        return result;\n    }\n\n    /**\n     * Create a scope for the given collection of AST node descriptions.\n     */\n    protected createScope(elements: Iterable<AstNodeDescription>, outerScope?: Scope, options?: ScopeOptions): Scope {\n        return new StreamScope(stream(elements), outerScope, options);\n    }\n\n    /**\n     * Create a scope for the given collection of AST nodes, which need to be transformed into respective\n     * descriptions first. This is done using the `NameProvider` and `AstNodeDescriptionProvider` services.\n     */\n    protected createScopeForNodes(elements: Iterable<AstNode>, outerScope?: Scope, options?: ScopeOptions): Scope {\n        const s = stream(elements).map(e => {\n            const name = this.nameProvider.getName(e);\n            if (name) {\n                return this.descriptions.createDescription(e, name);\n            }\n            return undefined;\n        }).nonNullable();\n        return new StreamScope(s, outerScope, options);\n    }\n\n    /**\n     * Create a global scope filtered for the given reference type.\n     */\n    protected getGlobalScope(referenceType: string, _context: ReferenceInfo): Scope {\n        return this.globalScopeCache.get(referenceType, () => new MapScope(this.indexManager.allElements(referenceType)));\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport { URI } from 'vscode-uri';\nimport type { CommentProvider } from '../documentation/comment-provider.js';\nimport type { NameProvider } from '../references/name-provider.js';\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, CstNode, GenericAstNode, Mutable, Reference } from '../syntax-tree.js';\nimport { isAstNode, isReference } from '../syntax-tree.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { findNodesForProperty } from '../utils/grammar-utils.js';\nimport type { AstNodeLocator } from '../workspace/ast-node-locator.js';\nimport type { DocumentSegment, LangiumDocument, LangiumDocuments } from '../workspace/documents.js';\n\nexport interface JsonSerializeOptions {\n    /** The space parameter for `JSON.stringify`, controlling whether and how to pretty-print the output. */\n    space?: string | number;\n    /** Whether to include the `$refText` property for references (the name used to identify the target node). */\n    refText?: boolean;\n    /** Whether to include the `$sourceText` property, which holds the full source text from which an AST node was parsed. */\n    sourceText?: boolean;\n    /** Whether to include the `$textRegion` property, which holds information to trace AST node properties to their respective source text regions. */\n    textRegions?: boolean;\n    /** Whether to include the `$comment` property, which holds comments according to the CommentProvider service. */\n    comments?: boolean;\n    /** The replacer parameter for `JSON.stringify`; the default replacer given as parameter should be used to apply basic replacements. */\n    replacer?: (key: string, value: unknown, defaultReplacer: (key: string, value: unknown) => unknown) => unknown\n    /** Used to convert and serialize URIs when the target of a cross-reference is in a different document. */\n    uriConverter?: (uri: URI, reference: Reference) => string\n}\n\nexport interface JsonDeserializeOptions {\n    /** Used to parse and convert URIs when the target of a cross-reference is in a different document. */\n    uriConverter?: (uri: string) => URI\n}\n\n/**\n * {@link AstNode}s that may carry information on their definition area within the DSL text.\n */\nexport interface AstNodeWithTextRegion extends AstNode {\n    $sourceText?: string;\n    $textRegion?: AstNodeRegionWithAssignments;\n}\n\n/**\n * {@link AstNode}s that may carry a semantically relevant comment.\n */\nexport interface AstNodeWithComment extends AstNode {\n    $comment?: string;\n}\n\nexport function isAstNodeWithComment(node: AstNode): node is AstNodeWithComment {\n    return typeof (node as AstNodeWithComment).$comment === 'string';\n}\n\n/**\n * A {@DocumentSegment} representing the definition area of an AstNode within the DSL text.\n * Usually contains text region information on all assigned property values of the AstNode,\n * and may contain the defining file's URI as string.\n */\nexport interface AstNodeRegionWithAssignments extends DocumentSegment {\n    /**\n     * A record containing an entry for each assigned property of the AstNode.\n     * The key is equal to the property name and the value is an array of the property values'\n     * text regions, regardless of whether the property is a single value or list property.\n     */\n    assignments?: Record<string, DocumentSegment[]>;\n    /**\n     * The AstNode defining file's URI as string\n     */\n    documentURI?: string;\n}\n\n/**\n * Utility service for transforming an `AstNode` into a JSON string and vice versa.\n */\nexport interface JsonSerializer {\n    /**\n     * Serialize an `AstNode` into a JSON `string`.\n     * @param node The `AstNode` to be serialized.\n     * @param space Adds indentation, white space, and line break characters to the return-value JSON text to make it easier to read.\n     */\n    serialize(node: AstNode, options?: JsonSerializeOptions): string;\n    /**\n     * Deserialize (parse) a JSON `string` into an `AstNode`.\n     */\n    deserialize<T extends AstNode = AstNode>(content: string, options?: JsonDeserializeOptions): T;\n}\n\n/**\n * A cross-reference in the serialized JSON representation of an AstNode.\n */\ninterface IntermediateReference {\n    /** URI pointing to the target element. This is either `#${path}` if the target is in the same document, or `${documentURI}#${path}` otherwise. */\n    $ref?: string\n    /** The actual text used to look up the reference target in the surrounding scope. */\n    $refText?: string\n    /** If any problem occurred while resolving the reference, it is described by this property. */\n    $error?: string\n}\n\nfunction isIntermediateReference(obj: unknown): obj is IntermediateReference {\n    return typeof obj === 'object' && !!obj && ('$ref' in obj || '$error' in obj);\n}\n\nexport class DefaultJsonSerializer implements JsonSerializer {\n\n    /** The set of AstNode properties to be ignored by the serializer. */\n    ignoreProperties = new Set(['$container', '$containerProperty', '$containerIndex', '$document', '$cstNode']);\n\n    /** The document that is currently processed by the serializer; this is used by the replacer function.  */\n    protected currentDocument: LangiumDocument | undefined;\n\n    protected readonly langiumDocuments: LangiumDocuments;\n    protected readonly astNodeLocator: AstNodeLocator;\n    protected readonly nameProvider: NameProvider;\n    protected readonly commentProvider: CommentProvider;\n\n    constructor(services: LangiumCoreServices) {\n        this.langiumDocuments = services.shared.workspace.LangiumDocuments;\n        this.astNodeLocator = services.workspace.AstNodeLocator;\n        this.nameProvider = services.references.NameProvider;\n        this.commentProvider = services.documentation.CommentProvider;\n    }\n\n    serialize(node: AstNode, options: JsonSerializeOptions = {}): string {\n        const specificReplacer = options?.replacer;\n        const defaultReplacer = (key: string, value: unknown) => this.replacer(key, value, options);\n        const replacer = specificReplacer ? (key: string, value: unknown) => specificReplacer(key, value, defaultReplacer) : defaultReplacer;\n\n        try {\n            this.currentDocument = getDocument(node);\n            return JSON.stringify(node, replacer, options?.space);\n        } finally {\n            this.currentDocument = undefined;\n        }\n    }\n\n    deserialize<T extends AstNode = AstNode>(content: string, options: JsonDeserializeOptions = {}): T {\n        const root = JSON.parse(content);\n        this.linkNode(root, root, options);\n        return root;\n    }\n\n    protected replacer(key: string, value: unknown, { refText, sourceText, textRegions, comments, uriConverter }: JsonSerializeOptions): unknown {\n        if (this.ignoreProperties.has(key)) {\n            return undefined;\n        } else if (isReference(value)) {\n            const refValue = value.ref;\n            const $refText = refText ? value.$refText : undefined;\n            if (refValue) {\n                const targetDocument = getDocument(refValue);\n                let targetUri = '';\n                if (this.currentDocument && this.currentDocument !== targetDocument) {\n                    if (uriConverter) {\n                        targetUri = uriConverter(targetDocument.uri, value);\n                    } else {\n                        targetUri = targetDocument.uri.toString();\n                    }\n                }\n                const targetPath = this.astNodeLocator.getAstNodePath(refValue);\n                return {\n                    $ref: `${targetUri}#${targetPath}`,\n                    $refText\n                } satisfies IntermediateReference;\n            } else {\n                return {\n                    $error: value.error?.message ?? 'Could not resolve reference',\n                    $refText\n                } satisfies IntermediateReference;\n            }\n        } else if (isAstNode(value)) {\n            let astNode: AstNodeWithTextRegion | undefined = undefined;\n            if (textRegions) {\n                astNode = this.addAstNodeRegionWithAssignmentsTo({ ...value });\n                if ((!key || value.$document) && astNode?.$textRegion) {\n                    // The document URI is added to the root node of the resulting JSON tree\n                    astNode.$textRegion.documentURI = this.currentDocument?.uri.toString();\n                }\n            }\n            if (sourceText && !key) {\n                astNode ??= { ...value };\n                astNode.$sourceText = value.$cstNode?.text;\n            }\n            if (comments) {\n                astNode ??= { ...value };\n                const comment = this.commentProvider.getComment(value);\n                if (comment) {\n                    (astNode as AstNodeWithComment).$comment = comment.replace(/\\r/g, '');\n                }\n            }\n            return astNode ?? value;\n        } else {\n            return value;\n        }\n    }\n\n    protected addAstNodeRegionWithAssignmentsTo(node: AstNodeWithTextRegion) {\n        const createDocumentSegment: (cstNode: CstNode) => AstNodeRegionWithAssignments = cstNode => <DocumentSegment>{\n            offset: cstNode.offset,\n            end: cstNode.end,\n            length: cstNode.length,\n            range: cstNode.range,\n        };\n\n        if (node.$cstNode) {\n            const textRegion = node.$textRegion = createDocumentSegment(node.$cstNode);\n            const assignments: Record<string, DocumentSegment[]> = textRegion.assignments = {};\n\n            Object.keys(node).filter(key => !key.startsWith('$')).forEach(key => {\n                const propertyAssignments = findNodesForProperty(node.$cstNode, key).map(createDocumentSegment);\n                if (propertyAssignments.length !== 0) {\n                    assignments[key] = propertyAssignments;\n                }\n            });\n\n            return node;\n        }\n        return undefined;\n    }\n\n    protected linkNode(node: GenericAstNode, root: AstNode, options: JsonDeserializeOptions, container?: AstNode, containerProperty?: string, containerIndex?: number) {\n        for (const [propertyName, item] of Object.entries(node)) {\n            if (Array.isArray(item)) {\n                for (let index = 0; index < item.length; index++) {\n                    const element = item[index];\n                    if (isIntermediateReference(element)) {\n                        item[index] = this.reviveReference(node, propertyName, root, element, options);\n                    } else if (isAstNode(element)) {\n                        this.linkNode(element as GenericAstNode, root, options, node, propertyName, index);\n                    }\n                }\n            } else if (isIntermediateReference(item)) {\n                node[propertyName] = this.reviveReference(node, propertyName, root, item, options);\n            } else if (isAstNode(item)) {\n                this.linkNode(item as GenericAstNode, root, options, node, propertyName);\n            }\n        }\n        const mutable = node as Mutable<AstNode>;\n        mutable.$container = container;\n        mutable.$containerProperty = containerProperty;\n        mutable.$containerIndex = containerIndex;\n    }\n\n    protected reviveReference(container: AstNode, property: string, root: AstNode, reference: IntermediateReference, options: JsonDeserializeOptions): Reference | undefined {\n        let refText = reference.$refText;\n        let error = reference.$error;\n        if (reference.$ref) {\n            const ref = this.getRefNode(root, reference.$ref, options.uriConverter);\n            if (isAstNode(ref)) {\n                if (!refText) {\n                    refText = this.nameProvider.getName(ref);\n                }\n                return {\n                    $refText: refText ?? '',\n                    ref\n                };\n            } else {\n                error = ref;\n            }\n        }\n        if (error) {\n            const ref: Mutable<Reference> = {\n                $refText: refText ?? ''\n            };\n            ref.error = {\n                container,\n                property,\n                message: error,\n                reference: ref\n            };\n            return ref;\n        } else {\n            return undefined;\n        }\n    }\n\n    protected getRefNode(root: AstNode, uri: string, uriConverter?: (uri: string) => URI): AstNode | string {\n        try {\n            const fragmentIndex = uri.indexOf('#');\n            if (fragmentIndex === 0) {\n                const node = this.astNodeLocator.getAstNode(root, uri.substring(1));\n                if (!node) {\n                    return 'Could not resolve path: ' + uri;\n                }\n                return node;\n            }\n            if (fragmentIndex < 0) {\n                const documentUri = uriConverter ? uriConverter(uri) : URI.parse(uri);\n                const document = this.langiumDocuments.getDocument(documentUri);\n                if (!document) {\n                    return 'Could not find document for URI: ' + uri;\n                }\n                return document.parseResult.value;\n            }\n            const documentUri = uriConverter ? uriConverter(uri.substring(0, fragmentIndex)) : URI.parse(uri.substring(0, fragmentIndex));\n            const document = this.langiumDocuments.getDocument(documentUri);\n            if (!document) {\n                return 'Could not find document for URI: ' + uri;\n            }\n            if (fragmentIndex === uri.length - 1) {\n                return document.parseResult.value;\n            }\n            const node = this.astNodeLocator.getAstNode(document.parseResult.value, uri.substring(fragmentIndex + 1));\n            if (!node) {\n                return 'Could not resolve URI: ' + uri;\n            }\n            return node;\n        } catch (err) {\n            return String(err);\n        }\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { LangiumCoreServices } from './services.js';\nimport { UriUtils, type URI } from './utils/uri-utils.js';\n\n/**\n * The service registry provides access to the language-specific {@link LangiumCoreServices} optionally including LSP-related services.\n * These are resolved via the URI of a text document.\n */\nexport interface ServiceRegistry {\n\n    /**\n     * Register a language via its injected services.\n     */\n    register(language: LangiumCoreServices): void;\n\n    /**\n     * Retrieve the language-specific services for the given URI. In case only one language is\n     * registered, it may be used regardless of the URI format.\n     */\n    getServices(uri: URI): LangiumCoreServices;\n\n    /**\n     * The full set of registered language services.\n     */\n    readonly all: readonly LangiumCoreServices[];\n}\n\n/**\n * Generic registry for Langium services, but capable of being used with extending service sets as well (such as the lsp-complete LangiumCoreServices set)\n */\nexport class DefaultServiceRegistry implements ServiceRegistry {\n\n    protected singleton?: LangiumCoreServices;\n    protected map?: Record<string, LangiumCoreServices>;\n\n    register(language: LangiumCoreServices): void {\n        if (!this.singleton && !this.map) {\n            // This is the first language to be registered; store it as singleton.\n            this.singleton = language;\n            return;\n        }\n        if (!this.map) {\n            this.map = {};\n            if (this.singleton) {\n                // Move the previous singleton instance to the new map.\n                for (const ext of this.singleton.LanguageMetaData.fileExtensions) {\n                    this.map[ext] = this.singleton;\n                }\n                this.singleton = undefined;\n            }\n        }\n        // Store the language services in the map.\n        for (const ext of language.LanguageMetaData.fileExtensions) {\n            if (this.map[ext] !== undefined && this.map[ext] !== language) {\n                console.warn(`The file extension ${ext} is used by multiple languages. It is now assigned to '${language.LanguageMetaData.languageId}'.`);\n            }\n            this.map[ext] = language;\n        }\n    }\n\n    getServices(uri: URI): LangiumCoreServices {\n        if (this.singleton !== undefined) {\n            return this.singleton;\n        }\n        if (this.map === undefined) {\n            throw new Error('The service registry is empty. Use `register` to register the services of a language.');\n        }\n        const ext = UriUtils.extname(uri);\n        const services = this.map[ext];\n        if (!services) {\n            throw new Error(`The service registry contains no services for the extension '${ext}'.`);\n        }\n        return services;\n    }\n\n    get all(): readonly LangiumCoreServices[] {\n        if (this.singleton !== undefined) {\n            return [this.singleton];\n        }\n        if (this.map !== undefined) {\n            return Object.values(this.map);\n        }\n        return [];\n    }\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { CodeDescription, DiagnosticRelatedInformation, DiagnosticTag, integer, Range } from 'vscode-languageserver-types';\nimport type { CancellationToken } from '../utils/cancellation.js';\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, AstReflection, Properties } from '../syntax-tree.js';\nimport type { MaybePromise } from '../utils/promise-utils.js';\nimport type { Stream } from '../utils/stream.js';\nimport type { DocumentSegment } from '../workspace/documents.js';\nimport { MultiMap } from '../utils/collections.js';\nimport { isOperationCancelled } from '../utils/promise-utils.js';\nimport { stream } from '../utils/stream.js';\n\nexport type DiagnosticInfo<N extends AstNode, P extends string = Properties<N>> = {\n    /** The AST node to which the diagnostic is attached. */\n    node: N;\n    /** If a property name is given, the diagnostic is restricted to the corresponding text region. */\n    property?: P;\n    /** If the value of a keyword is given, the diagnostic will appear at its corresponding text region */\n    keyword?: string;\n    /** In case of a multi-value property (array), an index can be given to select a specific element. */\n    index?: number;\n    /** If you want to create a diagnostic independent to any property, use the range property. */\n    range?: Range;\n    /** The diagnostic's code, which usually appear in the user interface. */\n    code?: integer | string;\n    /** An optional property to describe the error code. */\n    codeDescription?: CodeDescription;\n    /** Additional metadata about the diagnostic. */\n    tags?: DiagnosticTag[];\n    /** An array of related diagnostic information, e.g. when symbol-names within a scope collide all definitions can be marked via this property. */\n    relatedInformation?: DiagnosticRelatedInformation[];\n    /** A data entry field that is preserved between a `textDocument/publishDiagnostics` notification and `textDocument/codeAction` request. */\n    data?: unknown;\n}\n\n/**\n * Shape of information commonly used in the `data` field of diagnostics.\n */\nexport interface DiagnosticData {\n    /** Diagnostic code for identifying which code action to apply. This code is _not_ shown in the user interface. */\n    code: string\n    /** Specifies where to apply the code action in the form of a `DocumentSegment`. */\n    actionSegment?: DocumentSegment\n    /** Specifies where to apply the code action in the form of a `Range`. */\n    actionRange?: Range\n}\n\n/**\n * Create DiagnosticData for a given diagnostic code. The result can be put into the `data` field of a DiagnosticInfo.\n */\nexport function diagnosticData(code: string): DiagnosticData {\n    return { code };\n}\n\nexport type ValidationAcceptor = <N extends AstNode>(severity: 'error' | 'warning' | 'info' | 'hint', message: string, info: DiagnosticInfo<N>) => void\n\nexport type ValidationCheck<T extends AstNode = AstNode> = (node: T, accept: ValidationAcceptor, cancelToken: CancellationToken) => MaybePromise<void>;\n\n/**\n * A utility type for associating non-primitive AST types to corresponding validation checks. For example:\n *\n * ```ts\n *   const checks: ValidationChecks<StatemachineAstType> = {\n *       State: validator.checkStateNameStartsWithCapital\n *    };\n * ```\n *\n * If an AST type does not extend AstNode, e.g. if it describes a union of string literals, that type's name must not occur as a key in objects of type `ValidationCheck<...>`.\n *\n * @param T a type definition mapping language specific type names (keys) to the corresponding types (values)\n */\nexport type ValidationChecks<T> = {\n    [K in keyof T]?: T[K] extends AstNode ? ValidationCheck<T[K]> | Array<ValidationCheck<T[K]>> : never\n} & {\n    AstNode?: ValidationCheck<AstNode> | Array<ValidationCheck<AstNode>>;\n}\n\n/**\n * `fast` checks can be executed after every document change (i.e. as the user is typing). If a check\n * is too slow it can delay the response to document changes, yielding bad user experience. By marking\n * it as `slow`, it will be skipped for normal as-you-type validation. Then it's up to you when to\n * schedule these long-running checks: after the fast checks are done, or after saving a document,\n * or with an explicit command, etc.\n *\n * `built-in` checks are errors produced by the lexer, the parser, or the linker. They cannot be used\n * for custom validation checks.\n */\nexport type ValidationCategory = 'fast' | 'slow' | 'built-in'\n\nexport namespace ValidationCategory {\n    export const all: readonly ValidationCategory[] = ['fast', 'slow', 'built-in'];\n}\n\ntype ValidationCheckEntry = {\n    check: ValidationCheck\n    category: ValidationCategory\n}\n\n/**\n * Manages a set of `ValidationCheck`s to be applied when documents are validated.\n */\nexport class ValidationRegistry {\n    private readonly entries = new MultiMap<string, ValidationCheckEntry>();\n    private readonly reflection: AstReflection;\n\n    constructor(services: LangiumCoreServices) {\n        this.reflection = services.shared.AstReflection;\n    }\n\n    /**\n     * Register a set of validation checks. Each value in the record can be either a single validation check (i.e. a function)\n     * or an array of validation checks.\n     *\n     * @param checksRecord Set of validation checks to register.\n     * @param category Optional category for the validation checks (defaults to `'fast'`).\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n     */\n    register<T>(checksRecord: ValidationChecks<T>, thisObj: ThisParameterType<unknown> = this, category: ValidationCategory = 'fast'): void {\n        if (category === 'built-in') {\n            throw new Error(\"The 'built-in' category is reserved for lexer, parser, and linker errors.\");\n        }\n        for (const [type, ch] of Object.entries(checksRecord)) {\n            const callbacks = ch as ValidationCheck | ValidationCheck[];\n            if (Array.isArray(callbacks)) {\n                for (const check of callbacks) {\n                    const entry: ValidationCheckEntry = {\n                        check: this.wrapValidationException(check, thisObj),\n                        category\n                    };\n                    this.addEntry(type, entry);\n                }\n            } else if (typeof callbacks === 'function') {\n                const entry: ValidationCheckEntry = {\n                    check: this.wrapValidationException(callbacks, thisObj),\n                    category\n                };\n                this.addEntry(type, entry);\n            }\n        }\n    }\n\n    protected wrapValidationException(check: ValidationCheck, thisObj: unknown): ValidationCheck {\n        return async (node, accept, cancelToken) => {\n            try {\n                await check.call(thisObj, node, accept, cancelToken);\n            } catch (err) {\n                if (isOperationCancelled(err)) {\n                    throw err;\n                }\n                console.error('An error occurred during validation:', err);\n                const message = err instanceof Error ? err.message : String(err);\n                if (err instanceof Error && err.stack) {\n                    console.error(err.stack);\n                }\n                accept('error', 'An error occurred during validation: ' + message, { node });\n            }\n        };\n    }\n\n    protected addEntry(type: string, entry: ValidationCheckEntry): void {\n        if (type === 'AstNode') {\n            this.entries.add('AstNode', entry);\n            return;\n        }\n        for (const subtype of this.reflection.getAllSubTypes(type)) {\n            this.entries.add(subtype, entry);\n        }\n    }\n\n    getChecks(type: string, categories?: ValidationCategory[]): Stream<ValidationCheck> {\n        let checks = stream(this.entries.get(type))\n            .concat(this.entries.get('AstNode'));\n        if (categories) {\n            checks = checks.filter(entry => categories.includes(entry.category));\n        }\n        return checks.map(entry => entry.check);\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { MismatchedTokenException } from 'chevrotain';\nimport type { DiagnosticSeverity, Position, Range, Diagnostic } from 'vscode-languageserver-types';\nimport type { LanguageMetaData } from '../languages/language-meta-data.js';\nimport type { ParseResult } from '../parser/langium-parser.js';\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, CstNode } from '../syntax-tree.js';\nimport type { LangiumDocument } from '../workspace/documents.js';\nimport type { DiagnosticData, DiagnosticInfo, ValidationAcceptor, ValidationCategory, ValidationRegistry } from './validation-registry.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { findNodeForKeyword, findNodeForProperty } from '../utils/grammar-utils.js';\nimport { streamAst } from '../utils/ast-utils.js';\nimport { tokenToRange } from '../utils/cst-utils.js';\nimport { interruptAndCheck, isOperationCancelled } from '../utils/promise-utils.js';\nimport { diagnosticData } from './validation-registry.js';\n\nexport interface ValidationOptions {\n    /**\n     * If this is set, only the checks associated with these categories are executed; otherwise\n     * all checks are executed. The default category if not specified to the registry is `'fast'`.\n     */\n    categories?: ValidationCategory[];\n    /** If true, no further diagnostics are reported if there are lexing errors. */\n    stopAfterLexingErrors?: boolean\n    /** If true, no further diagnostics are reported if there are parsing errors. */\n    stopAfterParsingErrors?: boolean\n    /** If true, no further diagnostics are reported if there are linking errors. */\n    stopAfterLinkingErrors?: boolean\n}\n\n/**\n * Language-specific service for validating `LangiumDocument`s.\n */\nexport interface DocumentValidator {\n    /**\n     * Validates the whole specified document.\n     *\n     * @param document specified document to validate\n     * @param options options to control the validation process\n     * @param cancelToken allows to cancel the current operation\n     * @throws `OperationCanceled` if a user action occurs during execution\n     */\n    validateDocument(document: LangiumDocument, options?: ValidationOptions, cancelToken?: CancellationToken): Promise<Diagnostic[]>;\n}\n\nexport class DefaultDocumentValidator implements DocumentValidator {\n\n    protected readonly validationRegistry: ValidationRegistry;\n    protected readonly metadata: LanguageMetaData;\n\n    constructor(services: LangiumCoreServices) {\n        this.validationRegistry = services.validation.ValidationRegistry;\n        this.metadata = services.LanguageMetaData;\n    }\n\n    async validateDocument(document: LangiumDocument, options: ValidationOptions = {}, cancelToken = CancellationToken.None): Promise<Diagnostic[]> {\n        const parseResult = document.parseResult;\n        const diagnostics: Diagnostic[] = [];\n\n        await interruptAndCheck(cancelToken);\n\n        if (!options.categories || options.categories.includes('built-in')) {\n            this.processLexingErrors(parseResult, diagnostics, options);\n            if (options.stopAfterLexingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.LexingError)) {\n                return diagnostics;\n            }\n\n            this.processParsingErrors(parseResult, diagnostics, options);\n            if (options.stopAfterParsingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.ParsingError)) {\n                return diagnostics;\n            }\n\n            this.processLinkingErrors(document, diagnostics, options);\n            if (options.stopAfterLinkingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.LinkingError)) {\n                return diagnostics;\n            }\n        }\n\n        // Process custom validations\n        try {\n            diagnostics.push(...await this.validateAst(parseResult.value, options, cancelToken));\n        } catch (err) {\n            if (isOperationCancelled(err)) {\n                throw err;\n            }\n            console.error('An error occurred during validation:', err);\n        }\n\n        await interruptAndCheck(cancelToken);\n\n        return diagnostics;\n    }\n\n    protected processLexingErrors(parseResult: ParseResult, diagnostics: Diagnostic[], _options: ValidationOptions): void {\n        for (const lexerError of parseResult.lexerErrors) {\n            const diagnostic: Diagnostic = {\n                severity: toDiagnosticSeverity('error'),\n                range: {\n                    start: {\n                        line: lexerError.line! - 1,\n                        character: lexerError.column! - 1\n                    },\n                    end: {\n                        line: lexerError.line! - 1,\n                        character: lexerError.column! + lexerError.length - 1\n                    }\n                },\n                message: lexerError.message,\n                data: diagnosticData(DocumentValidator.LexingError),\n                source: this.getSource()\n            };\n            diagnostics.push(diagnostic);\n        }\n    }\n\n    protected processParsingErrors(parseResult: ParseResult, diagnostics: Diagnostic[], _options: ValidationOptions): void {\n        for (const parserError of parseResult.parserErrors) {\n            let range: Range | undefined = undefined;\n            // We can run into the chevrotain error recovery here\n            // The token contained in the parser error might be automatically inserted\n            // In this case every position value will be `NaN`\n            if (isNaN(parserError.token.startOffset)) {\n                // Some special parser error types contain a `previousToken`\n                // We can simply append our diagnostic to that token\n                if ('previousToken' in parserError) {\n                    const token = (parserError as MismatchedTokenException).previousToken;\n                    if (!isNaN(token.startOffset)) {\n                        const position: Position = { line: token.endLine! - 1, character: token.endColumn! };\n                        range = { start: position, end: position};\n                    } else {\n                        // No valid prev token. Might be empty document or containing only hidden tokens.\n                        // Point to document start\n                        const position: Position = { line: 0, character: 0 };\n                        range = { start: position, end: position};\n                    }\n                }\n            } else {\n                range = tokenToRange(parserError.token);\n            }\n            if (range) {\n                const diagnostic: Diagnostic = {\n                    severity: toDiagnosticSeverity('error'),\n                    range,\n                    message: parserError.message,\n                    data: diagnosticData(DocumentValidator.ParsingError),\n                    source: this.getSource()\n                };\n                diagnostics.push(diagnostic);\n            }\n        }\n    }\n\n    protected processLinkingErrors(document: LangiumDocument, diagnostics: Diagnostic[], _options: ValidationOptions): void {\n        for (const reference of document.references) {\n            const linkingError = reference.error;\n            if (linkingError) {\n                const info: DiagnosticInfo<AstNode, string> = {\n                    node: linkingError.container,\n                    property: linkingError.property,\n                    index: linkingError.index,\n                    data: {\n                        code: DocumentValidator.LinkingError,\n                        containerType: linkingError.container.$type,\n                        property: linkingError.property,\n                        refText: linkingError.reference.$refText\n                    } satisfies LinkingErrorData\n                };\n                diagnostics.push(this.toDiagnostic('error', linkingError.message, info));\n            }\n        }\n    }\n\n    protected async validateAst(rootNode: AstNode, options: ValidationOptions, cancelToken = CancellationToken.None): Promise<Diagnostic[]> {\n        const validationItems: Diagnostic[] = [];\n        const acceptor: ValidationAcceptor = <N extends AstNode>(severity: 'error' | 'warning' | 'info' | 'hint', message: string, info: DiagnosticInfo<N>) => {\n            validationItems.push(this.toDiagnostic(severity, message, info));\n        };\n\n        await Promise.all(streamAst(rootNode).map(async node => {\n            await interruptAndCheck(cancelToken);\n            const checks = this.validationRegistry.getChecks(node.$type, options.categories);\n            for (const check of checks) {\n                await check(node, acceptor, cancelToken);\n            }\n        }));\n        return validationItems;\n    }\n\n    protected toDiagnostic<N extends AstNode>(severity: 'error' | 'warning' | 'info' | 'hint', message: string, info: DiagnosticInfo<N, string>): Diagnostic {\n        return {\n            message,\n            range: getDiagnosticRange(info),\n            severity: toDiagnosticSeverity(severity),\n            code: info.code,\n            codeDescription: info.codeDescription,\n            tags: info.tags,\n            relatedInformation: info.relatedInformation,\n            data: info.data,\n            source: this.getSource()\n        };\n    }\n\n    protected getSource(): string | undefined {\n        return this.metadata.languageId;\n    }\n}\n\nexport function getDiagnosticRange<N extends AstNode>(info: DiagnosticInfo<N, string>): Range {\n    if (info.range) {\n        return info.range;\n    }\n    let cstNode: CstNode | undefined;\n    if (typeof info.property === 'string') {\n        cstNode = findNodeForProperty(info.node.$cstNode, info.property, info.index);\n    } else if (typeof info.keyword === 'string') {\n        cstNode = findNodeForKeyword(info.node.$cstNode, info.keyword, info.index);\n    }\n    cstNode ??= info.node.$cstNode;\n    if (!cstNode) {\n        return {\n            start: { line: 0, character: 0 },\n            end: { line: 0, character: 0 }\n        };\n    }\n    return cstNode.range;\n}\n\nexport function toDiagnosticSeverity(severity: 'error' | 'warning' | 'info' | 'hint'): DiagnosticSeverity {\n    switch (severity) {\n        case 'error':\n            return 1; // according to vscode-languageserver-types/lib/esm/main.js#DiagnosticSeverity.Error\n        case 'warning':\n            return 2; // according to vscode-languageserver-types/lib/esm/main.js#DiagnosticSeverity.Warning\n        case 'info':\n            return 3; // according to vscode-languageserver-types/lib/esm/main.js#DiagnosticSeverity.Information\n        case 'hint':\n            return 4; // according to vscode-languageserver-types/lib/esm/main.js#DiagnosticSeverity.Hint\n        default:\n            throw new Error('Invalid diagnostic severity: ' + severity);\n    }\n}\n\nexport namespace DocumentValidator {\n    export const LexingError = 'lexing-error';\n    export const ParsingError = 'parsing-error';\n    export const LinkingError = 'linking-error';\n}\n\nexport interface LinkingErrorData extends DiagnosticData {\n    containerType: string\n    property: string\n    refText: string\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nexport interface Disposable {\n    /**\n     * Dispose this object.\n     */\n    dispose(): void;\n}\n\nexport interface AsyncDisposable {\n    /**\n     * Dispose this object.\n     */\n    dispose(): Promise<void>;\n}\n\nexport namespace Disposable {\n    export function create(callback: () => Promise<void>): AsyncDisposable;\n    export function create(callback: () => void): Disposable;\n    export function create(callback: () => void | Promise<void>): Disposable | AsyncDisposable {\n        return {\n            dispose: async () => await callback()\n        };\n    }\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { URI } from '../utils/uri-utils.js';\nimport type { NameProvider } from '../references/name-provider.js';\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, AstNodeDescription, ReferenceInfo } from '../syntax-tree.js';\nimport type { AstNodeLocator } from './ast-node-locator.js';\nimport type { DocumentSegment, LangiumDocument } from './documents.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { isLinkingError } from '../syntax-tree.js';\nimport { getDocument, streamAst, streamReferences } from '../utils/ast-utils.js';\nimport { toDocumentSegment } from '../utils/cst-utils.js';\nimport { interruptAndCheck } from '../utils/promise-utils.js';\nimport { UriUtils } from '../utils/uri-utils.js';\n\n/**\n * Language-specific service for creating descriptions of AST nodes to be used for cross-reference resolutions.\n */\nexport interface AstNodeDescriptionProvider {\n\n    /**\n     * Create a description for the given AST node. This service method is typically used while indexing\n     * the contents of a document and during scope computation.\n     *\n     * @param node An AST node.\n     * @param name The name to be used to refer to the AST node. By default, this is determined by the\n     *     `NameProvider` service, but alternative names may be provided according to the semantics\n     *     of your language.\n     * @param document The document containing the AST node. If omitted, it is taken from the root AST node.\n     */\n    createDescription(node: AstNode, name: string | undefined, document?: LangiumDocument): AstNodeDescription;\n\n}\n\nexport class DefaultAstNodeDescriptionProvider implements AstNodeDescriptionProvider {\n\n    protected readonly astNodeLocator: AstNodeLocator;\n    protected readonly nameProvider: NameProvider;\n\n    constructor(services: LangiumCoreServices) {\n        this.astNodeLocator = services.workspace.AstNodeLocator;\n        this.nameProvider = services.references.NameProvider;\n    }\n\n    createDescription(node: AstNode, name: string | undefined, document: LangiumDocument = getDocument(node)): AstNodeDescription {\n        name ??= this.nameProvider.getName(node);\n        const path = this.astNodeLocator.getAstNodePath(node);\n        if (!name) {\n            throw new Error(`Node at path ${path} has no name.`);\n        }\n        let nameNodeSegment: DocumentSegment | undefined;\n        const nameSegmentGetter = () => nameNodeSegment ??= toDocumentSegment(this.nameProvider.getNameNode(node) ?? node.$cstNode);\n        return {\n            node,\n            name,\n            get nameSegment() {\n                return nameSegmentGetter();\n            },\n            selectionSegment: toDocumentSegment(node.$cstNode),\n            type: node.$type,\n            documentUri: document.uri,\n            path\n        };\n    }\n\n}\n\n/**\n * Describes a cross-reference within a document or between two documents.\n */\nexport interface ReferenceDescription {\n    /** URI of the document that holds a reference */\n    sourceUri: URI\n    /** Path to AstNode that holds a reference */\n    sourcePath: string\n    /** Target document uri */\n    targetUri: URI\n    /** Path to the target AstNode inside the document */\n    targetPath: string\n    /** Segment of the reference text. */\n    segment: DocumentSegment\n    /** Marks a local reference i.e. a cross reference inside a document.   */\n    local?: boolean\n}\n\n/**\n * Language-specific service to create descriptions of all cross-references in a document. These are used by the `IndexManager`\n * to determine which documents are affected and should be rebuilt when a document is changed.\n */\nexport interface ReferenceDescriptionProvider {\n    /**\n     * Create descriptions of all cross-references found in the given document. These descriptions are\n     * gathered by the `IndexManager` and stored in the global index so they can be considered when\n     * a document change is reported by the client.\n     *\n     * @param document The document in which to gather cross-references.\n     * @param cancelToken Indicates when to cancel the current operation.\n     * @throws `OperationCanceled` if a user action occurs during execution\n     */\n    createDescriptions(document: LangiumDocument, cancelToken?: CancellationToken): Promise<ReferenceDescription[]>;\n}\n\nexport class DefaultReferenceDescriptionProvider implements ReferenceDescriptionProvider {\n\n    protected readonly nodeLocator: AstNodeLocator;\n\n    constructor(services: LangiumCoreServices) {\n        this.nodeLocator = services.workspace.AstNodeLocator;\n    }\n\n    async createDescriptions(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<ReferenceDescription[]> {\n        const descr: ReferenceDescription[] = [];\n        const rootNode = document.parseResult.value;\n        for (const astNode of streamAst(rootNode)) {\n            await interruptAndCheck(cancelToken);\n            streamReferences(astNode).filter(refInfo => !isLinkingError(refInfo)).forEach(refInfo => {\n                // TODO: Consider logging a warning or throw an exception when DocumentState is < than Linked\n                const description = this.createDescription(refInfo);\n                if (description) {\n                    descr.push(description);\n                }\n            });\n        }\n        return descr;\n    }\n\n    protected createDescription(refInfo: ReferenceInfo): ReferenceDescription | undefined {\n        const targetNodeDescr = refInfo.reference.$nodeDescription;\n        const refCstNode = refInfo.reference.$refNode;\n        if (!targetNodeDescr || !refCstNode) {\n            return undefined;\n        }\n        const docUri = getDocument(refInfo.container).uri;\n        return {\n            sourceUri: docUri,\n            sourcePath: this.nodeLocator.getAstNodePath(refInfo.container),\n            targetUri: targetNodeDescr.documentUri,\n            targetPath: targetNodeDescr.path,\n            segment: toDocumentSegment(refCstNode),\n            local: UriUtils.equals(targetNodeDescr.documentUri, docUri)\n        };\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { AstNode } from '../syntax-tree.js';\n\n/**\n * Language-specific service for locating an `AstNode` in a document.\n */\nexport interface AstNodeLocator {\n\n    /**\n     * Creates a path represented by a `string` that identifies an `AstNode` inside its document.\n     * It must be possible to retrieve exactly the same `AstNode` from the document using this path.\n     *\n     * @param node The `AstNode` for which to create the path.\n     * @returns a path represented by a `string` that identifies `node` inside its document.\n     * @see AstNodeLocator.getAstNode\n     */\n    getAstNodePath(node: AstNode): string;\n\n    /**\n     * Locates an `AstNode` inside another node by following the given path.\n     *\n     * @param node Parent element.\n     * @param path Describes how to locate the `AstNode` inside the given `node`.\n     * @returns The `AstNode` located under the given path, or `undefined` if the path cannot be resolved.\n     * @see AstNodeLocator.getAstNodePath\n     */\n    getAstNode<T extends AstNode = AstNode>(node: AstNode, path: string): T | undefined;\n\n}\n\nexport class DefaultAstNodeLocator implements AstNodeLocator {\n    protected segmentSeparator = '/';\n    protected indexSeparator = '@';\n\n    getAstNodePath(node: AstNode): string {\n        if (node.$container) {\n            const containerPath = this.getAstNodePath(node.$container);\n            const newSegment = this.getPathSegment(node);\n            const nodePath = containerPath + this.segmentSeparator + newSegment;\n            return nodePath;\n        }\n        return '';\n    }\n\n    protected getPathSegment({ $containerProperty, $containerIndex }: AstNode): string {\n        if (!$containerProperty) {\n            throw new Error(\"Missing '$containerProperty' in AST node.\");\n        }\n        if ($containerIndex !== undefined) {\n            return $containerProperty + this.indexSeparator + $containerIndex;\n        }\n        return $containerProperty;\n    }\n\n    getAstNode<T extends AstNode = AstNode>(node: AstNode, path: string): T | undefined {\n        const segments = path.split(this.segmentSeparator);\n        return segments.reduce((previousValue, currentValue) => {\n            if (!previousValue || currentValue.length === 0) {\n                return previousValue;\n            }\n            const propertyIndex = currentValue.indexOf(this.indexSeparator);\n            if (propertyIndex > 0) {\n                const property = currentValue.substring(0, propertyIndex);\n                const arrayIndex = parseInt(currentValue.substring(propertyIndex + 1));\n                const array = (previousValue as unknown as Record<string, AstNode[]>)[property];\n                return array?.[arrayIndex];\n            }\n            return (previousValue as unknown as Record<string, AstNode>)[currentValue];\n        }, node) as T;\n    }\n\n}\n","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { ConfigurationItem, DidChangeConfigurationParams, DidChangeConfigurationRegistrationOptions, InitializeParams, InitializedParams } from 'vscode-languageserver-protocol';\nimport type { ServiceRegistry } from '../service-registry.js';\nimport type { LangiumSharedCoreServices } from '../services.js';\nimport { Deferred } from '../utils/promise-utils.js';\n\n/* eslint-disable @typescript-eslint/no-explicit-any */\n\nexport interface ConfigurationProvider {\n\n    /**\n     * A promise that resolves when the configuration provider is ready to be used.\n     */\n    readonly ready: Promise<void>;\n\n    /**\n     * When used in a language server context, this method is called when the server receives\n     * the `initialize` request.\n     */\n    initialize(params: InitializeParams): void;\n\n    /**\n     * When used in a language server context, this method is called when the server receives\n     * the `initialized` notification.\n     */\n    initialized(params: ConfigurationInitializedParams): Promise<void>;\n\n    /**\n     * Returns a configuration value stored for the given language.\n     *\n     * @param language The language id\n     * @param configuration Configuration name\n     */\n    getConfiguration(language: string, configuration: string): Promise<any>;\n\n    /**\n     *  Updates the cached configurations using the `change` notification parameters.\n     *\n     * @param change The parameters of a change configuration notification.\n     * `settings` property of the change object could be expressed as `Record<string, Record<string, any>>`\n     */\n    updateConfiguration(change: DidChangeConfigurationParams): void;\n}\n\nexport interface ConfigurationInitializedParams extends InitializedParams {\n    register?: (params: DidChangeConfigurationRegistrationOptions) => void,\n    fetchConfiguration?: (configuration: ConfigurationItem[]) => Promise<any>\n}\n\n/**\n * Base configuration provider for building up other configuration providers\n */\nexport class DefaultConfigurationProvider implements ConfigurationProvider {\n\n    protected readonly serviceRegistry: ServiceRegistry;\n    protected readonly _ready = new Deferred<void>();\n    protected settings: Record<string, Record<string, any>> = {};\n    protected workspaceConfig = false;\n\n    constructor(services: LangiumSharedCoreServices) {\n        this.serviceRegistry = services.ServiceRegistry;\n    }\n\n    get ready(): Promise<void> {\n        return this._ready.promise;\n    }\n\n    initialize(params: InitializeParams): void {\n        this.workspaceConfig = params.capabilities.workspace?.configuration ?? false;\n    }\n\n    async initialized(params: ConfigurationInitializedParams): Promise<void> {\n        if (this.workspaceConfig) {\n            if (params.register) {\n                // params.register(...) is a function to be provided by the calling language server for the sake of\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\n\n                const languages = this.serviceRegistry.all;\n                params.register({\n                    // Listen to configuration changes for all languages\n                    section: languages.map(lang => this.toSectionName(lang.LanguageMetaData.languageId))\n                });\n            }\n\n            if (params.fetchConfiguration) {\n                // params.fetchConfiguration(...) is a function to be provided by the calling language server for the sake of\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\n                const configToUpdate = this.serviceRegistry.all.map(lang => <ConfigurationItem>{\n                    // Fetch the configuration changes for all languages\n                    section: this.toSectionName(lang.LanguageMetaData.languageId)\n                });\n\n                // get workspace configurations (default scope URI)\n                const configs = await params.fetchConfiguration(configToUpdate);\n                configToUpdate.forEach((conf, idx) => {\n                    this.updateSectionConfiguration(conf.section!, configs[idx]);\n                });\n            }\n        }\n        this._ready.resolve();\n    }\n\n    /**\n     *  Updates the cached configurations using the `change` notification parameters.\n     *\n     * @param change The parameters of a change configuration notification.\n     * `settings` property of the change object could be expressed as `Record<string, Record<string, any>>`\n     */\n    updateConfiguration(change: DidChangeConfigurationParams): void {\n        if (!change.settings) {\n            return;\n        }\n        Object.keys(change.settings).forEach(section => {\n            this.updateSectionConfiguration(section, change.settings[section]);\n        });\n    }\n\n    protected updateSectionConfiguration(section: string, configuration: any): void {\n        this.settings[section] = configuration;\n    }\n\n    /**\n    * Returns a configuration value stored for the given language.\n    *\n    * @param language The language id\n    * @param configuration Configuration name\n    */\n    async getConfiguration(language: string, configuration: string): Promise<any> {\n        await this.ready;\n\n        const sectionName = this.toSectionName(language);\n        if (this.settings[sectionName]) {\n            return this.settings[sectionName][configuration];\n        }\n    }\n\n    protected toSectionName(languageId: string): string {\n        return `${languageId}`;\n    }\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { Disposable } from '../utils/disposable.js';\nimport type { ServiceRegistry } from '../service-registry.js';\nimport type { LangiumSharedCoreServices } from '../services.js';\nimport type { AstNode } from '../syntax-tree.js';\nimport type { MaybePromise } from '../utils/promise-utils.js';\nimport type { Deferred } from '../utils/promise-utils.js';\nimport type { ValidationOptions } from '../validation/document-validator.js';\nimport type { IndexManager } from '../workspace/index-manager.js';\nimport type { LangiumDocument, LangiumDocuments, LangiumDocumentFactory } from './documents.js';\nimport { MultiMap } from '../utils/collections.js';\nimport { OperationCancelled, interruptAndCheck } from '../utils/promise-utils.js';\nimport { stream } from '../utils/stream.js';\nimport type { URI } from '../utils/uri-utils.js';\nimport { ValidationCategory } from '../validation/validation-registry.js';\nimport { DocumentState } from './documents.js';\n\nexport interface BuildOptions {\n    /**\n     * Control the validation phase with this option:\n     *  - `true` enables all validation checks and forces revalidating the documents\n     *  - `false` or `undefined` disables all validation checks\n     *  - An object runs only the necessary validation checks; the `categories` property restricts this to a specific subset\n     */\n    validation?: boolean | ValidationOptions\n}\n\nexport interface DocumentBuildState {\n    /** Whether a document has completed its last build process. */\n    completed: boolean\n    /** The options used for the last build process. */\n    options: BuildOptions\n    /** Additional information about the last build result. */\n    result?: {\n        validationChecks?: ValidationCategory[]\n    }\n}\n\n/**\n * Shared-service for building and updating `LangiumDocument`s.\n */\nexport interface DocumentBuilder {\n\n    /** The options used for rebuilding documents after an update. */\n    updateBuildOptions: BuildOptions;\n\n    /**\n     * Execute all necessary build steps for the given documents.\n     *\n     * @param documents Set of documents to be built.\n     * @param options Options for the document builder.\n     * @param cancelToken Indicates when to cancel the current operation.\n     * @throws `OperationCanceled` if a user action occurs during execution\n     */\n    build<T extends AstNode>(documents: Array<LangiumDocument<T>>, options?: BuildOptions, cancelToken?: CancellationToken): Promise<void>;\n\n    /**\n     * This method is called when a document change is detected. It updates the state of all\n     * affected documents, including those with references to the changed ones, so they are rebuilt.\n     *\n     * @param changed URIs of changed or created documents\n     * @param deleted URIs of deleted documents\n     * @param cancelToken allows to cancel the current operation\n     * @throws `OperationCancelled` if cancellation is detected during execution\n     */\n    update(changed: URI[], deleted: URI[], cancelToken?: CancellationToken): Promise<void>;\n\n    /**\n     * Notify the given callback when a document update was triggered, but before any document\n     * is rebuilt. Listeners to this event should not perform any long-running task.\n     */\n    onUpdate(callback: DocumentUpdateListener): Disposable;\n\n    /**\n     * Notify the given callback when a set of documents has been built reaching a desired target state.\n     */\n    onBuildPhase(targetState: DocumentState, callback: DocumentBuildListener): Disposable;\n\n    /**\n     * Wait until the workspace has reached the specified state for all documents.\n     *\n     * @param state The desired state. The promise won't resolve until all documents have reached this state\n     * @param cancelToken Optionally allows to cancel the wait operation, disposing any listeners in the process\n     * @throws `OperationCancelled` if cancellation has been requested before the state has been reached\n     */\n    waitUntil(state: DocumentState, cancelToken?: CancellationToken): Promise<void>;\n\n    /**\n     * Wait until the document specified by the {@link uri} has reached the specified state.\n     *\n     * @param state The desired state. The promise won't resolve until the document has reached this state.\n     * @param uri The specified URI that points to the document. If the URI does not exist, the promise will resolve once the workspace has reached the specified state.\n     * @param cancelToken Optionally allows to cancel the wait operation, disposing any listeners in the process.\n     * @return The URI of the document that has reached the desired state, or `undefined` if the document does not exist.\n     * @throws `OperationCancelled` if cancellation has been requested before the state has been reached\n     */\n    waitUntil(state: DocumentState, uri?: URI, cancelToken?: CancellationToken): Promise<URI | undefined>;\n}\n\nexport type DocumentUpdateListener = (changed: URI[], deleted: URI[]) => void | Promise<void>\nexport type DocumentBuildListener = (built: LangiumDocument[], cancelToken: CancellationToken) => void | Promise<void>\nexport class DefaultDocumentBuilder implements DocumentBuilder {\n\n    updateBuildOptions: BuildOptions = {\n        // Default: run only the built-in validation checks and those in the _fast_ category (includes those without category)\n        validation: {\n            categories: ['built-in', 'fast']\n        }\n    };\n\n    protected readonly langiumDocuments: LangiumDocuments;\n    protected readonly langiumDocumentFactory: LangiumDocumentFactory;\n    protected readonly indexManager: IndexManager;\n    protected readonly serviceRegistry: ServiceRegistry;\n    protected readonly updateListeners: DocumentUpdateListener[] = [];\n    protected readonly buildPhaseListeners = new MultiMap<DocumentState, DocumentBuildListener>();\n    protected readonly buildState = new Map<string, DocumentBuildState>();\n    protected readonly documentBuildWaiters = new Map<string, Deferred<void>>();\n    protected currentState = DocumentState.Changed;\n\n    constructor(services: LangiumSharedCoreServices) {\n        this.langiumDocuments = services.workspace.LangiumDocuments;\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\n        this.indexManager = services.workspace.IndexManager;\n        this.serviceRegistry = services.ServiceRegistry;\n    }\n\n    async build<T extends AstNode>(documents: Array<LangiumDocument<T>>, options: BuildOptions = {}, cancelToken = CancellationToken.None): Promise<void> {\n        for (const document of documents) {\n            const key = document.uri.toString();\n            if (document.state === DocumentState.Validated) {\n                if (typeof options.validation === 'boolean' && options.validation) {\n                    // Force re-running all validation checks\n                    document.state = DocumentState.IndexedReferences;\n                    document.diagnostics = undefined;\n                    this.buildState.delete(key);\n                } else if (typeof options.validation === 'object') {\n                    const buildState = this.buildState.get(key);\n                    const previousCategories = buildState?.result?.validationChecks;\n                    if (previousCategories) {\n                        // Validation with explicit options was requested for a document that has already been partly validated.\n                        // In this case, we need to merge the previous validation categories with the new ones.\n                        const newCategories = options.validation.categories ?? ValidationCategory.all as ValidationCategory[];\n                        const categories = newCategories.filter(c => !previousCategories.includes(c));\n                        if (categories.length > 0) {\n                            this.buildState.set(key, {\n                                completed: false,\n                                options: {\n                                    validation: {\n                                        ...options.validation,\n                                        categories\n                                    }\n                                },\n                                result: buildState.result\n                            });\n                            document.state = DocumentState.IndexedReferences;\n                        }\n                    }\n                }\n            } else {\n                // Default: forget any previous build options\n                this.buildState.delete(key);\n            }\n        }\n        this.currentState = DocumentState.Changed;\n        await this.emitUpdate(documents.map(e => e.uri), []);\n        await this.buildDocuments(documents, options, cancelToken);\n    }\n\n    async update(changed: URI[], deleted: URI[], cancelToken = CancellationToken.None): Promise<void> {\n        this.currentState = DocumentState.Changed;\n        // Remove all metadata of documents that are reported as deleted\n        for (const deletedUri of deleted) {\n            this.langiumDocuments.deleteDocument(deletedUri);\n            this.buildState.delete(deletedUri.toString());\n            this.indexManager.remove(deletedUri);\n        }\n        // Set the state of all changed documents to `Changed` so they are completely rebuilt\n        for (const changedUri of changed) {\n            const invalidated = this.langiumDocuments.invalidateDocument(changedUri);\n            if (!invalidated) {\n                // We create an unparsed, invalid document.\n                // This will be parsed as soon as we reach the first document builder phase.\n                // This allows to cancel the parsing process later in case we need it.\n                const newDocument = this.langiumDocumentFactory.fromModel({ $type: 'INVALID' }, changedUri);\n                newDocument.state = DocumentState.Changed;\n                this.langiumDocuments.addDocument(newDocument);\n            }\n            this.buildState.delete(changedUri.toString());\n        }\n        // Set the state of all documents that should be relinked to `ComputedScopes` (if not already lower)\n        const allChangedUris = stream(changed).concat(deleted).map(uri => uri.toString()).toSet();\n        this.langiumDocuments.all\n            .filter(doc => !allChangedUris.has(doc.uri.toString()) && this.shouldRelink(doc, allChangedUris))\n            .forEach(doc => {\n                const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\n                linker.unlink(doc);\n                doc.state = Math.min(doc.state, DocumentState.ComputedScopes);\n                doc.diagnostics = undefined;\n            });\n        // Notify listeners of the update\n        await this.emitUpdate(changed, deleted);\n        // Only allow interrupting the execution after all state changes are done\n        await interruptAndCheck(cancelToken);\n\n        // Collect all documents that we should rebuild\n        const rebuildDocuments = this.langiumDocuments.all\n            .filter(doc =>\n                // This includes those that were reported as changed and those that we selected for relinking\n                doc.state < DocumentState.Linked\n                // This includes those for which a previous build has been cancelled\n                || !this.buildState.get(doc.uri.toString())?.completed\n            )\n            .toArray();\n        await this.buildDocuments(rebuildDocuments, this.updateBuildOptions, cancelToken);\n    }\n\n    protected async emitUpdate(changed: URI[], deleted: URI[]): Promise<void> {\n        await Promise.all(this.updateListeners.map(listener => listener(changed, deleted)));\n    }\n\n    /**\n     * Check whether the given document should be relinked after changes were found in the given URIs.\n     */\n    protected shouldRelink(document: LangiumDocument, changedUris: Set<string>): boolean {\n        // Relink documents with linking errors -- maybe those references can be resolved now\n        if (document.references.some(ref => ref.error !== undefined)) {\n            return true;\n        }\n        // Check whether the document is affected by any of the changed URIs\n        return this.indexManager.isAffected(document, changedUris);\n    }\n\n    onUpdate(callback: DocumentUpdateListener): Disposable {\n        this.updateListeners.push(callback);\n        return Disposable.create(() => {\n            const index = this.updateListeners.indexOf(callback);\n            if (index >= 0) {\n                this.updateListeners.splice(index, 1);\n            }\n        });\n    }\n\n    /**\n     * Build the given documents by stepping through all build phases. If a document's state indicates\n     * that a certain build phase is already done, the phase is skipped for that document.\n     */\n    protected async buildDocuments(documents: LangiumDocument[], options: BuildOptions, cancelToken: CancellationToken): Promise<void> {\n        this.prepareBuild(documents, options);\n        // 0. Parse content\n        await this.runCancelable(documents, DocumentState.Parsed, cancelToken, doc =>\n            this.langiumDocumentFactory.update(doc, cancelToken)\n        );\n        // 1. Index content\n        await this.runCancelable(documents, DocumentState.IndexedContent, cancelToken, doc =>\n            this.indexManager.updateContent(doc, cancelToken)\n        );\n        // 2. Compute scopes\n        await this.runCancelable(documents, DocumentState.ComputedScopes, cancelToken, async doc => {\n            const scopeComputation = this.serviceRegistry.getServices(doc.uri).references.ScopeComputation;\n            doc.precomputedScopes = await scopeComputation.computeLocalScopes(doc, cancelToken);\n        });\n        // 3. Linking\n        await this.runCancelable(documents, DocumentState.Linked, cancelToken, doc => {\n            const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\n            return linker.link(doc, cancelToken);\n        });\n        // 4. Index references\n        await this.runCancelable(documents, DocumentState.IndexedReferences, cancelToken, doc =>\n            this.indexManager.updateReferences(doc, cancelToken)\n        );\n        // 5. Validation\n        const toBeValidated = documents.filter(doc => this.shouldValidate(doc));\n        await this.runCancelable(toBeValidated, DocumentState.Validated, cancelToken, doc =>\n            this.validate(doc, cancelToken)\n        );\n\n        // If we've made it to this point without being cancelled, we can mark the build state as completed.\n        for (const doc of documents) {\n            const state = this.buildState.get(doc.uri.toString());\n            if (state) {\n                state.completed = true;\n            }\n        }\n    }\n\n    protected prepareBuild(documents: LangiumDocument[], options: BuildOptions): void {\n        for (const doc of documents) {\n            const key = doc.uri.toString();\n            const state = this.buildState.get(key);\n            // If the document has no previous build state, we set it. If it has one, but it's already marked\n            // as completed, we overwrite it. If the previous build was not completed, we keep its state\n            // and continue where it was cancelled.\n            if (!state || state.completed) {\n                this.buildState.set(key, {\n                    completed: false,\n                    options,\n                    result: state?.result\n                });\n            }\n        }\n    }\n\n    protected async runCancelable(documents: LangiumDocument[], targetState: DocumentState, cancelToken: CancellationToken,\n        callback: (document: LangiumDocument) => MaybePromise<unknown>): Promise<void> {\n        const filtered = documents.filter(e => e.state < targetState);\n        for (const document of filtered) {\n            await interruptAndCheck(cancelToken);\n            await callback(document);\n            document.state = targetState;\n        }\n        await this.notifyBuildPhase(filtered, targetState, cancelToken);\n        this.currentState = targetState;\n    }\n\n    onBuildPhase(targetState: DocumentState, callback: DocumentBuildListener): Disposable {\n        this.buildPhaseListeners.add(targetState, callback);\n        return Disposable.create(() => {\n            this.buildPhaseListeners.delete(targetState, callback);\n        });\n    }\n\n    waitUntil(state: DocumentState, cancelToken?: CancellationToken): Promise<void>;\n    waitUntil(state: DocumentState, uri?: URI, cancelToken?: CancellationToken): Promise<URI | undefined>;\n    waitUntil(state: DocumentState, uriOrToken?: URI | CancellationToken, cancelToken?: CancellationToken): Promise<URI | undefined | void> {\n        let uri: URI | undefined = undefined;\n        if (uriOrToken && 'path' in uriOrToken) {\n            uri = uriOrToken;\n        } else {\n            cancelToken = uriOrToken;\n        }\n        cancelToken ??= CancellationToken.None;\n        if (uri) {\n            const document = this.langiumDocuments.getDocument(uri);\n            if (document && document.state > state) {\n                return Promise.resolve(uri);\n            }\n        }\n        if (this.currentState >= state) {\n            return Promise.resolve(undefined);\n        } else if (cancelToken.isCancellationRequested) {\n            return Promise.reject(OperationCancelled);\n        }\n        return new Promise((resolve, reject) => {\n            const buildDisposable = this.onBuildPhase(state, () => {\n                buildDisposable.dispose();\n                cancelDisposable.dispose();\n                if (uri) {\n                    const document = this.langiumDocuments.getDocument(uri);\n                    resolve(document?.uri);\n                } else {\n                    resolve(undefined);\n                }\n            });\n            const cancelDisposable = cancelToken!.onCancellationRequested(() => {\n                buildDisposable.dispose();\n                cancelDisposable.dispose();\n                reject(OperationCancelled);\n            });\n        });\n    }\n\n    protected async notifyBuildPhase(documents: LangiumDocument[], state: DocumentState, cancelToken: CancellationToken): Promise<void> {\n        if (documents.length === 0) {\n            // Don't notify when no document has been processed\n            return;\n        }\n        const listeners = this.buildPhaseListeners.get(state);\n        for (const listener of listeners) {\n            await interruptAndCheck(cancelToken);\n            await listener(documents, cancelToken);\n        }\n    }\n\n    /**\n     * Determine whether the given document should be validated during a build. The default\n     * implementation checks the `validation` property of the build options. If it's set to `true`\n     * or a `ValidationOptions` object, the document is included in the validation phase.\n     */\n    protected shouldValidate(document: LangiumDocument): boolean {\n        return Boolean(this.getBuildOptions(document).validation);\n    }\n\n    /**\n     * Run validation checks on the given document and store the resulting diagnostics in the document.\n     * If the document already contains diagnostics, the new ones are added to the list.\n     */\n    protected async validate(document: LangiumDocument, cancelToken: CancellationToken): Promise<void> {\n        const validator = this.serviceRegistry.getServices(document.uri).validation.DocumentValidator;\n        const validationSetting = this.getBuildOptions(document).validation;\n        const options = typeof validationSetting === 'object' ? validationSetting : undefined;\n        const diagnostics = await validator.validateDocument(document, options, cancelToken);\n        if (document.diagnostics) {\n            document.diagnostics.push(...diagnostics);\n        } else {\n            document.diagnostics = diagnostics;\n        }\n\n        // Store information about the executed validation in the build state\n        const state = this.buildState.get(document.uri.toString());\n        if (state) {\n            state.result ??= {};\n            const newCategories = options?.categories ?? ValidationCategory.all;\n            if (state.result.validationChecks) {\n                state.result.validationChecks.push(...newCategories);\n            } else {\n                state.result.validationChecks = [...newCategories];\n            }\n        }\n    }\n\n    protected getBuildOptions(document: LangiumDocument): BuildOptions {\n        return this.buildState.get(document.uri.toString())?.options ?? {};\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { ServiceRegistry } from '../service-registry.js';\nimport type { LangiumSharedCoreServices } from '../services.js';\nimport type { AstNode, AstNodeDescription, AstReflection } from '../syntax-tree.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { ContextCache } from '../utils/caching.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport type { Stream } from '../utils/stream.js';\nimport { stream } from '../utils/stream.js';\nimport type { URI } from '../utils/uri-utils.js';\nimport { UriUtils } from '../utils/uri-utils.js';\nimport type { ReferenceDescription } from './ast-descriptions.js';\nimport type { LangiumDocument, LangiumDocuments } from './documents.js';\n\n/**\n * The index manager is responsible for keeping metadata about symbols and cross-references\n * in the workspace. It is used to look up symbols in the global scope, mostly during linking\n * and completion. This service is shared between all languages of a language server.\n */\nexport interface IndexManager {\n\n    /**\n     * Removes the specified document URI from the index.\n     * Necessary when documents are deleted and not referenceable anymore.\n     *\n     * @param uri The URI of the document for which index data shall be removed\n     */\n    remove(uri: URI): void;\n\n    /**\n     * Updates the information about the exportable content of a document inside the index.\n     *\n     * @param document Document to be updated\n     * @param cancelToken Indicates when to cancel the current operation.\n     * @throws `OperationCanceled` if a user action occurs during execution\n     */\n    updateContent(document: LangiumDocument, cancelToken?: CancellationToken): Promise<void>;\n\n    /**\n     * Updates the information about the cross-references of a document inside the index.\n     *\n     * @param document Document to be updated\n     * @param cancelToken Indicates when to cancel the current operation.\n     * @throws `OperationCanceled` if a user action occurs during execution\n     */\n    updateReferences(document: LangiumDocument, cancelToken?: CancellationToken): Promise<void>;\n\n    /**\n     * Determine whether the given document could be affected by changes of the documents\n     * identified by the given URIs (second parameter). The document is typically regarded as\n     * affected if it contains a reference to any of the changed files.\n     *\n     * @param document Document to check whether it's affected\n     * @param changedUris URIs of the changed documents\n     */\n    isAffected(document: LangiumDocument, changedUris: Set<string>): boolean;\n\n    /**\n     * Compute a list of all exported elements, optionally filtered using a type identifier and document URIs.\n     *\n     * @param nodeType The type to filter with, or `undefined` to return descriptions of all types.\n     * @param uris If specified, only returns elements from the given URIs.\n     * @returns a `Stream` containing all globally visible nodes (of a given type).\n     */\n    allElements(nodeType?: string, uris?: Set<string>): Stream<AstNodeDescription>;\n\n    /**\n     * Returns all known references that are pointing to the given `targetNode`.\n     *\n     * @param targetNode the `AstNode` to look up references for\n     * @param astNodePath the path that points to the `targetNode` inside the document. See also `AstNodeLocator`\n     *\n     * @returns a `Stream` of references that are targeting the `targetNode`\n     */\n    findAllReferences(targetNode: AstNode, astNodePath: string): Stream<ReferenceDescription>;\n\n}\n\nexport class DefaultIndexManager implements IndexManager {\n\n    protected readonly serviceRegistry: ServiceRegistry;\n    protected readonly documents: LangiumDocuments;\n    protected readonly astReflection: AstReflection;\n\n    /**\n     * The symbol index stores all `AstNodeDescription` items exported by a document.\n     * The key used in this map is the string representation of the specific document URI.\n     */\n    protected readonly symbolIndex = new Map<string, AstNodeDescription[]>();\n    /**\n     * This is a cache for the `allElements()` method.\n     * It caches the descriptions from `symbolIndex` grouped by types.\n     */\n    protected readonly symbolByTypeIndex = new ContextCache<string, string, AstNodeDescription[]>();\n    /**\n     * This index keeps track of all `ReferenceDescription` items exported by a document.\n     * This is used to compute which elements are affected by a document change\n     * and for finding references to an AST node.\n     */\n    protected readonly referenceIndex = new Map<string, ReferenceDescription[]>();\n\n    constructor(services: LangiumSharedCoreServices) {\n        this.documents = services.workspace.LangiumDocuments;\n        this.serviceRegistry = services.ServiceRegistry;\n        this.astReflection = services.AstReflection;\n    }\n\n    findAllReferences(targetNode: AstNode, astNodePath: string): Stream<ReferenceDescription> {\n        const targetDocUri = getDocument(targetNode).uri;\n        const result: ReferenceDescription[] = [];\n        this.referenceIndex.forEach(docRefs => {\n            docRefs.forEach(refDescr => {\n                if (UriUtils.equals(refDescr.targetUri, targetDocUri) && refDescr.targetPath === astNodePath) {\n                    result.push(refDescr);\n                }\n            });\n        });\n        return stream(result);\n    }\n\n    allElements(nodeType?: string, uris?: Set<string>): Stream<AstNodeDescription> {\n        let documentUris = stream(this.symbolIndex.keys());\n        if (uris) {\n            documentUris = documentUris.filter(uri => !uris || uris.has(uri));\n        }\n        return documentUris\n            .map(uri => this.getFileDescriptions(uri, nodeType))\n            .flat();\n    }\n\n    protected getFileDescriptions(uri: string, nodeType?: string): AstNodeDescription[] {\n        if (!nodeType) {\n            return this.symbolIndex.get(uri) ?? [];\n        }\n        const descriptions = this.symbolByTypeIndex.get(uri, nodeType, () => {\n            const allFileDescriptions = this.symbolIndex.get(uri) ?? [];\n            return allFileDescriptions.filter(e => this.astReflection.isSubtype(e.type, nodeType));\n        });\n        return descriptions;\n    }\n\n    remove(uri: URI): void {\n        const uriString = uri.toString();\n        this.symbolIndex.delete(uriString);\n        this.symbolByTypeIndex.clear(uriString);\n        this.referenceIndex.delete(uriString);\n    }\n\n    async updateContent(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<void> {\n        const services = this.serviceRegistry.getServices(document.uri);\n        const exports = await services.references.ScopeComputation.computeExports(document, cancelToken);\n        const uri = document.uri.toString();\n        this.symbolIndex.set(uri, exports);\n        this.symbolByTypeIndex.clear(uri);\n    }\n\n    async updateReferences(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<void> {\n        const services = this.serviceRegistry.getServices(document.uri);\n        const indexData = await services.workspace.ReferenceDescriptionProvider.createDescriptions(document, cancelToken);\n        this.referenceIndex.set(document.uri.toString(), indexData);\n    }\n\n    isAffected(document: LangiumDocument, changedUris: Set<string>): boolean {\n        const references = this.referenceIndex.get(document.uri.toString());\n        if (!references) {\n            return false;\n        }\n        return references.some(ref => !ref.local && changedUris.has(ref.targetUri.toString()));\n    }\n\n}\n","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { InitializeParams, InitializedParams } from 'vscode-languageserver-protocol';\nimport type { WorkspaceFolder } from 'vscode-languageserver-types';\nimport type { ServiceRegistry } from '../service-registry.js';\nimport type { LangiumSharedCoreServices } from '../services.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { Deferred, interruptAndCheck } from '../utils/promise-utils.js';\nimport { URI, UriUtils } from '../utils/uri-utils.js';\nimport type { BuildOptions, DocumentBuilder } from './document-builder.js';\nimport type { LangiumDocument, LangiumDocuments } from './documents.js';\nimport type { FileSystemNode, FileSystemProvider } from './file-system-provider.js';\nimport type { WorkspaceLock } from './workspace-lock.js';\n\n// export type WorkspaceFolder from 'vscode-languageserver-types' for convenience,\n//  is supposed to avoid confusion as 'WorkspaceFolder' might accidentally be imported via 'vscode-languageclient'\nexport type { WorkspaceFolder };\n\n/**\n * The workspace manager is responsible for finding source files in the workspace.\n * This service is shared between all languages of a language server.\n */\nexport interface WorkspaceManager {\n\n    /** The options used for the initial workspace build. */\n    initialBuildOptions: BuildOptions | undefined;\n\n    /**\n     * A promise that resolves when the workspace manager is ready to be used.\n     * Use this to ensure that the workspace manager has finished its initialization.\n     */\n    readonly ready: Promise<void>;\n\n    /**\n     * When used in a language server context, this method is called when the server receives\n     * the `initialize` request.\n     */\n    initialize(params: InitializeParams): void;\n\n    /**\n     * When used in a language server context, this method is called when the server receives\n     * the `initialized` notification.\n     */\n    initialized(params: InitializedParams): Promise<void>;\n\n    /**\n     * Does the initial indexing of workspace folders.\n     * Collects information about exported and referenced AstNodes in\n     * each language file and stores it locally.\n     *\n     * @param folders The set of workspace folders to be indexed.\n     */\n    initializeWorkspace(folders: WorkspaceFolder[], cancelToken?: CancellationToken): Promise<void>;\n\n}\n\nexport class DefaultWorkspaceManager implements WorkspaceManager {\n\n    initialBuildOptions: BuildOptions = {};\n\n    protected readonly serviceRegistry: ServiceRegistry;\n    protected readonly langiumDocuments: LangiumDocuments;\n    protected readonly documentBuilder: DocumentBuilder;\n    protected readonly fileSystemProvider: FileSystemProvider;\n    protected readonly mutex: WorkspaceLock;\n    protected readonly _ready = new Deferred<void>();\n    protected folders?: WorkspaceFolder[];\n\n    constructor(services: LangiumSharedCoreServices) {\n        this.serviceRegistry = services.ServiceRegistry;\n        this.langiumDocuments = services.workspace.LangiumDocuments;\n        this.documentBuilder = services.workspace.DocumentBuilder;\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\n        this.mutex = services.workspace.WorkspaceLock;\n    }\n\n    get ready(): Promise<void> {\n        return this._ready.promise;\n    }\n\n    initialize(params: InitializeParams): void {\n        this.folders = params.workspaceFolders ?? undefined;\n    }\n\n    initialized(_params: InitializedParams): Promise<void> {\n        // Initialize the workspace even if there are no workspace folders\n        // We still want to load additional documents (language library or similar) during initialization\n        return this.mutex.write(token => this.initializeWorkspace(this.folders ?? [], token));\n    }\n\n    async initializeWorkspace(folders: WorkspaceFolder[], cancelToken = CancellationToken.None): Promise<void> {\n        const documents = await this.performStartup(folders);\n        // Only after creating all documents do we check whether we need to cancel the initialization\n        // The document builder will later pick up on all unprocessed documents\n        await interruptAndCheck(cancelToken);\n        await this.documentBuilder.build(documents, this.initialBuildOptions, cancelToken);\n    }\n\n    /**\n     * Performs the uninterruptable startup sequence of the workspace manager.\n     * This methods loads all documents in the workspace and other documents and returns them.\n     */\n    protected async performStartup(folders: WorkspaceFolder[]): Promise<LangiumDocument[]> {\n        const fileExtensions = this.serviceRegistry.all.flatMap(e => e.LanguageMetaData.fileExtensions);\n        const documents: LangiumDocument[] = [];\n        const collector = (document: LangiumDocument) => {\n            documents.push(document);\n            if (!this.langiumDocuments.hasDocument(document.uri)) {\n                this.langiumDocuments.addDocument(document);\n            }\n        };\n        // Even though we don't await the initialization of the workspace manager,\n        // we can still assume that all library documents and file documents are loaded by the time we start building documents.\n        // The mutex prevents anything from performing a workspace build until we check the cancellation token\n        await this.loadAdditionalDocuments(folders, collector);\n        await Promise.all(\n            folders.map(wf => [wf, this.getRootFolder(wf)] as [WorkspaceFolder, URI])\n                .map(async entry => this.traverseFolder(...entry, fileExtensions, collector))\n        );\n        this._ready.resolve();\n        return documents;\n    }\n\n    /**\n     * Load all additional documents that shall be visible in the context of the given workspace\n     * folders and add them to the collector. This can be used to include built-in libraries of\n     * your language, which can be either loaded from provided files or constructed in memory.\n     */\n    protected loadAdditionalDocuments(_folders: WorkspaceFolder[], _collector: (document: LangiumDocument) => void): Promise<void> {\n        return Promise.resolve();\n    }\n\n    /**\n     * Determine the root folder of the source documents in the given workspace folder.\n     * The default implementation returns the URI of the workspace folder, but you can override\n     * this to return a subfolder like `src` instead.\n     */\n    protected getRootFolder(workspaceFolder: WorkspaceFolder): URI {\n        return URI.parse(workspaceFolder.uri);\n    }\n\n    /**\n     * Traverse the file system folder identified by the given URI and its subfolders. All\n     * contained files that match the file extensions are added to the collector.\n     */\n    protected async traverseFolder(workspaceFolder: WorkspaceFolder, folderPath: URI, fileExtensions: string[], collector: (document: LangiumDocument) => void): Promise<void> {\n        const content = await this.fileSystemProvider.readDirectory(folderPath);\n        await Promise.all(content.map(async entry => {\n            if (this.includeEntry(workspaceFolder, entry, fileExtensions)) {\n                if (entry.isDirectory) {\n                    await this.traverseFolder(workspaceFolder, entry.uri, fileExtensions, collector);\n                } else if (entry.isFile) {\n                    const document = await this.langiumDocuments.getOrCreateDocument(entry.uri);\n                    collector(document);\n                }\n            }\n        }));\n    }\n\n    /**\n     * Determine whether the given folder entry shall be included while indexing the workspace.\n     */\n    protected includeEntry(_workspaceFolder: WorkspaceFolder, entry: FileSystemNode, fileExtensions: string[]): boolean {\n        const name = UriUtils.basename(entry.uri);\n        if (name.startsWith('.')) {\n            return false;\n        }\n        if (entry.isDirectory) {\n            return name !== 'node_modules' && name !== 'out';\n        } else if (entry.isFile) {\n            const extname = UriUtils.extname(entry.uri);\n            return fileExtensions.includes(extname);\n        }\n        return false;\n    }\n\n}\n","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { ILexingError, IMultiModeLexerDefinition, IToken, TokenType, TokenTypeDictionary, TokenVocabulary } from 'chevrotain';\nimport type { LangiumCoreServices } from '../services.js';\nimport { Lexer as ChevrotainLexer } from 'chevrotain';\n\nexport interface LexerResult {\n    /**\n     * A list of all tokens that were lexed from the input.\n     *\n     * Note that Langium requires the optional properties\n     * `startLine`, `startColumn`, `endOffset`, `endLine` and `endColumn` to be set on each token.\n     */\n    tokens: IToken[];\n    /**\n     * Contains hidden tokens, usually comments.\n     */\n    hidden: IToken[];\n    errors: ILexingError[];\n}\n\nexport interface Lexer {\n    readonly definition: TokenTypeDictionary;\n    tokenize(text: string): LexerResult;\n}\n\nexport class DefaultLexer implements Lexer {\n\n    protected chevrotainLexer: ChevrotainLexer;\n    protected tokenTypes: TokenTypeDictionary;\n\n    constructor(services: LangiumCoreServices) {\n        const tokens = services.parser.TokenBuilder.buildTokens(services.Grammar, {\n            caseInsensitive: services.LanguageMetaData.caseInsensitive\n        });\n        this.tokenTypes = this.toTokenTypeDictionary(tokens);\n        const lexerTokens = isTokenTypeDictionary(tokens) ? Object.values(tokens) : tokens;\n        this.chevrotainLexer = new ChevrotainLexer(lexerTokens, {\n            positionTracking: 'full'\n        });\n    }\n\n    get definition(): TokenTypeDictionary {\n        return this.tokenTypes;\n    }\n\n    tokenize(text: string): LexerResult {\n        const chevrotainResult = this.chevrotainLexer.tokenize(text);\n        return {\n            tokens: chevrotainResult.tokens,\n            errors: chevrotainResult.errors,\n            hidden: chevrotainResult.groups.hidden ?? []\n        };\n    }\n\n    protected toTokenTypeDictionary(buildTokens: TokenVocabulary): TokenTypeDictionary {\n        if (isTokenTypeDictionary(buildTokens)) return buildTokens;\n        const tokens = isIMultiModeLexerDefinition(buildTokens) ? Object.values(buildTokens.modes).flat() : buildTokens;\n        const res: TokenTypeDictionary = {};\n        tokens.forEach(token => res[token.name] = token);\n        return res;\n    }\n}\n\n/**\n * Returns a check whether the given TokenVocabulary is TokenType array\n */\nexport function isTokenTypeArray(tokenVocabulary: TokenVocabulary): tokenVocabulary is TokenType[] {\n    return Array.isArray(tokenVocabulary) && (tokenVocabulary.length === 0 || 'name' in tokenVocabulary[0]);\n}\n\n/**\n * Returns a check whether the given TokenVocabulary is IMultiModeLexerDefinition\n */\nexport function isIMultiModeLexerDefinition(tokenVocabulary: TokenVocabulary): tokenVocabulary is IMultiModeLexerDefinition {\n    return tokenVocabulary && 'modes' in tokenVocabulary && 'defaultMode' in tokenVocabulary;\n}\n\n/**\n * Returns a check whether the given TokenVocabulary is TokenTypeDictionary\n */\nexport function isTokenTypeDictionary(tokenVocabulary: TokenVocabulary): tokenVocabulary is TokenTypeDictionary {\n    return !isTokenTypeArray(tokenVocabulary) && !isIMultiModeLexerDefinition(tokenVocabulary);\n}\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport { Position, Range } from 'vscode-languageserver-types';\nimport type { CstNode } from '../syntax-tree.js';\nimport { NEWLINE_REGEXP, escapeRegExp } from '../utils/regexp-utils.js';\nimport { URI } from '../utils/uri-utils.js';\n\nexport interface JSDocComment extends JSDocValue {\n    readonly elements: JSDocElement[]\n    getTag(name: string): JSDocTag | undefined\n    getTags(name: string): JSDocTag[]\n}\n\nexport type JSDocElement = JSDocParagraph | JSDocTag;\n\nexport type JSDocInline = JSDocTag | JSDocLine;\n\nexport interface JSDocValue {\n    /**\n     * Represents the range that this JSDoc element occupies.\n     * If the JSDoc was parsed from a `CstNode`, the range will represent the location in the source document.\n     */\n    readonly range: Range\n    /**\n     * Renders this JSDoc element to a plain text representation.\n     */\n    toString(): string\n    /**\n     * Renders this JSDoc element to a markdown representation.\n     *\n     * @param options Rendering options to customize the markdown result.\n     */\n    toMarkdown(options?: JSDocRenderOptions): string\n}\n\nexport interface JSDocParagraph extends JSDocValue {\n    readonly inlines: JSDocInline[]\n}\n\nexport interface JSDocLine extends JSDocValue {\n    readonly text: string\n}\n\nexport interface JSDocTag extends JSDocValue {\n    readonly name: string\n    readonly content: JSDocParagraph\n    readonly inline: boolean\n}\n\nexport interface JSDocParseOptions {\n    /**\n     * The start symbol of your comment format. Defaults to `/**`.\n     */\n    readonly start?: RegExp | string\n    /**\n     * The symbol that start a line of your comment format. Defaults to `*`.\n     */\n    readonly line?: RegExp | string\n    /**\n     * The end symbol of your comment format. Defaults to `*\\/`.\n     */\n    readonly end?: RegExp | string\n}\n\nexport interface JSDocRenderOptions {\n    /**\n     * Determines the style for rendering tags. Defaults to `italic`.\n     */\n    tag?: 'plain' | 'italic' | 'bold' | 'bold-italic'\n    /**\n     * Determines the default for rendering `@link` tags. Defaults to `plain`.\n     */\n    link?: 'code' | 'plain'\n    /**\n     * Custom tag rendering function.\n     * Return a markdown formatted tag or `undefined` to fall back to the default rendering.\n     */\n    renderTag?(tag: JSDocTag): string | undefined\n    /**\n     * Custom link rendering function. Accepts a link target and a display value for the link.\n     * Return a markdown formatted link with the format `[$display]($link)` or `undefined` if the link is not a valid target.\n     */\n    renderLink?(link: string, display: string): string | undefined\n}\n\n/**\n * Parses a JSDoc from a `CstNode` containing a comment.\n *\n * @param node A `CstNode` from a parsed Langium document.\n * @param options Parsing options specialized to your language. See {@link JSDocParseOptions}.\n */\nexport function parseJSDoc(node: CstNode, options?: JSDocParseOptions): JSDocComment;\n/**\n * Parses a JSDoc from a string comment.\n *\n * @param content A string containing the source of the JSDoc comment.\n * @param start The start position the comment occupies in the source document.\n * @param options Parsing options specialized to your language. See {@link JSDocParseOptions}.\n */\nexport function parseJSDoc(content: string, start?: Position, options?: JSDocParseOptions): JSDocComment;\nexport function parseJSDoc(node: CstNode | string, start?: Position | JSDocParseOptions, options?: JSDocParseOptions): JSDocComment {\n    let opts: JSDocParseOptions | undefined;\n    let position: Position | undefined;\n    if (typeof node === 'string') {\n        position = start as Position | undefined;\n        opts = options as JSDocParseOptions | undefined;\n    } else {\n        position = node.range.start;\n        opts = start as JSDocParseOptions | undefined;\n    }\n    if (!position) {\n        position = Position.create(0, 0);\n    }\n\n    const lines = getLines(node);\n    const normalizedOptions = normalizeOptions(opts);\n\n    const tokens = tokenize({\n        lines,\n        position,\n        options: normalizedOptions\n    });\n\n    return parseJSDocComment({\n        index: 0,\n        tokens,\n        position\n    });\n}\n\nexport function isJSDoc(node: CstNode | string, options?: JSDocParseOptions): boolean {\n    const normalizedOptions = normalizeOptions(options);\n    const lines = getLines(node);\n    if (lines.length === 0) {\n        return false;\n    }\n\n    const first = lines[0];\n    const last = lines[lines.length - 1];\n    const firstRegex = normalizedOptions.start;\n    const lastRegex = normalizedOptions.end;\n\n    return Boolean(firstRegex?.exec(first)) && Boolean(lastRegex?.exec(last));\n}\n\nfunction getLines(node: CstNode | string): string[] {\n    let content = '';\n    if (typeof node === 'string') {\n        content = node;\n    } else {\n        content = node.text;\n    }\n    const lines = content.split(NEWLINE_REGEXP);\n    return lines;\n}\n\n// Tokenization\n\ninterface JSDocToken {\n    type: 'text' | 'tag' | 'inline-tag' | 'break'\n    content: string\n    range: Range\n}\n\nconst tagRegex = /\\s*(@([\\p{L}][\\p{L}\\p{N}]*)?)/uy;\nconst inlineTagRegex = /\\{(@[\\p{L}][\\p{L}\\p{N}]*)(\\s*)([^\\r\\n}]+)?\\}/gu;\n\nfunction tokenize(context: TokenizationContext): JSDocToken[] {\n    const tokens: JSDocToken[] = [];\n    let currentLine = context.position.line;\n    let currentCharacter = context.position.character;\n    for (let i = 0; i < context.lines.length; i++) {\n        const first = i === 0;\n        const last = i === context.lines.length - 1;\n        let line = context.lines[i];\n        let index = 0;\n\n        if (first && context.options.start) {\n            const match = context.options.start?.exec(line);\n            if (match) {\n                index = match.index + match[0].length;\n            }\n        } else {\n            const match = context.options.line?.exec(line);\n            if (match) {\n                index = match.index + match[0].length;\n            }\n        }\n        if (last) {\n            const match = context.options.end?.exec(line);\n            if (match) {\n                line = line.substring(0, match.index);\n            }\n        }\n\n        line = line.substring(0, lastCharacter(line));\n        const whitespaceEnd = skipWhitespace(line, index);\n\n        if (whitespaceEnd >= line.length) {\n            // Only create a break token when we already have previous tokens\n            if (tokens.length > 0) {\n                const position = Position.create(currentLine, currentCharacter);\n                tokens.push({\n                    type: 'break',\n                    content: '',\n                    range: Range.create(position, position)\n                });\n            }\n        } else {\n            tagRegex.lastIndex = index;\n            const tagMatch = tagRegex.exec(line);\n            if (tagMatch) {\n                const fullMatch = tagMatch[0];\n                const value = tagMatch[1];\n                const start = Position.create(currentLine, currentCharacter + index);\n                const end = Position.create(currentLine, currentCharacter + index + fullMatch.length);\n                tokens.push({\n                    type: 'tag',\n                    content: value,\n                    range: Range.create(start, end)\n                });\n                index += fullMatch.length;\n                index = skipWhitespace(line, index);\n            }\n\n            if (index < line.length) {\n                const rest = line.substring(index);\n                const inlineTagMatches = Array.from(rest.matchAll(inlineTagRegex));\n                tokens.push(...buildInlineTokens(inlineTagMatches, rest, currentLine, currentCharacter + index));\n            }\n        }\n\n        currentLine++;\n        currentCharacter = 0;\n    }\n\n    // Remove last break token if there is one\n    if (tokens.length > 0 && tokens[tokens.length - 1].type === 'break') {\n        return tokens.slice(0, -1);\n    }\n\n    return tokens;\n}\n\nfunction buildInlineTokens(tags: RegExpMatchArray[], line: string, lineIndex: number, characterIndex: number): JSDocToken[] {\n    const tokens: JSDocToken[] = [];\n\n    if (tags.length === 0) {\n        const start = Position.create(lineIndex, characterIndex);\n        const end = Position.create(lineIndex, characterIndex + line.length);\n        tokens.push({\n            type: 'text',\n            content: line,\n            range: Range.create(start, end)\n        });\n    } else {\n        let lastIndex = 0;\n        for (const match of tags) {\n            const matchIndex = match.index!;\n            const startContent = line.substring(lastIndex, matchIndex);\n            if (startContent.length > 0) {\n                tokens.push({\n                    type: 'text',\n                    content: line.substring(lastIndex, matchIndex),\n                    range: Range.create(\n                        Position.create(lineIndex, lastIndex + characterIndex),\n                        Position.create(lineIndex, matchIndex + characterIndex)\n                    )\n                });\n            }\n            let offset = startContent.length + 1;\n            const tagName = match[1];\n            tokens.push({\n                type: 'inline-tag',\n                content: tagName,\n                range: Range.create(\n                    Position.create(lineIndex, lastIndex + offset + characterIndex),\n                    Position.create(lineIndex, lastIndex + offset + tagName.length + characterIndex)\n                )\n            });\n            offset += tagName.length;\n            if (match.length === 4) {\n                offset += match[2].length;\n                const value = match[3];\n                tokens.push({\n                    type: 'text',\n                    content: value,\n                    range: Range.create(\n                        Position.create(lineIndex, lastIndex + offset + characterIndex),\n                        Position.create(lineIndex, lastIndex + offset + value.length + characterIndex)\n                    )\n                });\n            } else {\n                tokens.push({\n                    type: 'text',\n                    content: '',\n                    range: Range.create(\n                        Position.create(lineIndex, lastIndex + offset + characterIndex),\n                        Position.create(lineIndex, lastIndex + offset + characterIndex)\n                    )\n                });\n            }\n            lastIndex = matchIndex + match[0].length;\n        }\n        const endContent = line.substring(lastIndex);\n        if (endContent.length > 0) {\n            tokens.push({\n                type: 'text',\n                content: endContent,\n                range: Range.create(\n                    Position.create(lineIndex, lastIndex + characterIndex),\n                    Position.create(lineIndex, lastIndex + characterIndex + endContent.length)\n                )\n            });\n        }\n    }\n\n    return tokens;\n}\n\nconst nonWhitespaceRegex = /\\S/;\nconst whitespaceEndRegex = /\\s*$/;\n\nfunction skipWhitespace(line: string, index: number): number {\n    const match = line.substring(index).match(nonWhitespaceRegex);\n    if (match) {\n        return index + match.index!;\n    } else {\n        return line.length;\n    }\n}\n\nfunction lastCharacter(line: string): number | undefined {\n    const match = line.match(whitespaceEndRegex);\n    if (match && typeof match.index === 'number') {\n        return match.index;\n    }\n    return undefined;\n}\n\n// Parsing\n\nfunction parseJSDocComment(context: ParseContext): JSDocComment {\n    const startPosition: Position = Position.create(context.position.line, context.position.character);\n    if (context.tokens.length === 0) {\n        return new JSDocCommentImpl([], Range.create(startPosition, startPosition));\n    }\n    const elements: JSDocElement[] = [];\n    while (context.index < context.tokens.length) {\n        const element = parseJSDocElement(context, elements[elements.length - 1]);\n        if (element) {\n            elements.push(element);\n        }\n    }\n    const start = elements[0]?.range.start ?? startPosition;\n    const end = elements[elements.length - 1]?.range.end ?? startPosition;\n    return new JSDocCommentImpl(elements, Range.create(start, end));\n}\n\nfunction parseJSDocElement(context: ParseContext, last?: JSDocElement): JSDocElement | undefined {\n    const next = context.tokens[context.index];\n    if (next.type === 'tag') {\n        return parseJSDocTag(context, false);\n    } else if (next.type === 'text' || next.type === 'inline-tag') {\n        return parseJSDocText(context);\n    } else {\n        appendEmptyLine(next, last);\n        context.index++;\n        return undefined;\n    }\n}\n\nfunction appendEmptyLine(token: JSDocToken, element?: JSDocElement): void {\n    if (element) {\n        const line = new JSDocLineImpl('', token.range);\n        if ('inlines' in element) {\n            element.inlines.push(line);\n        } else {\n            element.content.inlines.push(line);\n        }\n    }\n}\n\nfunction parseJSDocText(context: ParseContext): JSDocParagraph {\n    let token = context.tokens[context.index];\n    const firstToken = token;\n    let lastToken = token;\n    const lines: JSDocInline[] = [];\n    while (token && token.type !== 'break' && token.type !== 'tag') {\n        lines.push(parseJSDocInline(context));\n        lastToken = token;\n        token = context.tokens[context.index];\n    }\n    return new JSDocTextImpl(lines, Range.create(firstToken.range.start, lastToken.range.end));\n}\n\nfunction parseJSDocInline(context: ParseContext): JSDocInline {\n    const token = context.tokens[context.index];\n    if (token.type === 'inline-tag') {\n        return parseJSDocTag(context, true);\n    } else {\n        return parseJSDocLine(context);\n    }\n}\n\nfunction parseJSDocTag(context: ParseContext, inline: boolean): JSDocTag {\n    const tagToken = context.tokens[context.index++];\n    const name = tagToken.content.substring(1);\n    const nextToken = context.tokens[context.index];\n    if (nextToken?.type === 'text') {\n        if (inline) {\n            const docLine = parseJSDocLine(context);\n            return new JSDocTagImpl(\n                name,\n                new JSDocTextImpl([docLine], docLine.range),\n                inline,\n                Range.create(tagToken.range.start, docLine.range.end)\n            );\n        } else {\n            const textDoc = parseJSDocText(context);\n            return new JSDocTagImpl(\n                name,\n                textDoc,\n                inline,\n                Range.create(tagToken.range.start, textDoc.range.end)\n            );\n        }\n    } else {\n        const range = tagToken.range;\n        return new JSDocTagImpl(name, new JSDocTextImpl([], range), inline, range);\n    }\n}\n\nfunction parseJSDocLine(context: ParseContext): JSDocLine {\n    const token = context.tokens[context.index++];\n    return new JSDocLineImpl(token.content, token.range);\n}\n\ninterface NormalizedOptions {\n    start?: RegExp\n    end?: RegExp\n    line?: RegExp\n}\n\ninterface TokenizationContext {\n    position: Position\n    lines: string[]\n    options: NormalizedOptions\n}\n\ninterface ParseContext {\n    position: Position\n    tokens: JSDocToken[]\n    index: number\n}\n\nfunction normalizeOptions(options?: JSDocParseOptions): NormalizedOptions {\n    if (!options) {\n        return normalizeOptions({\n            start: '/**',\n            end: '*/',\n            line: '*'\n        });\n    }\n    const { start, end, line } = options;\n    return {\n        start: normalizeOption(start, true),\n        end: normalizeOption(end, false),\n        line: normalizeOption(line, true)\n    };\n}\n\nfunction normalizeOption(option: RegExp | string | undefined, start: boolean): RegExp | undefined {\n    if (typeof option === 'string' || typeof option === 'object') {\n        const escaped = typeof option === 'string' ? escapeRegExp(option) : option.source;\n        if (start) {\n            return new RegExp(`^\\\\s*${escaped}`);\n        } else {\n            return new RegExp(`\\\\s*${escaped}\\\\s*$`);\n        }\n    } else {\n        return option;\n    }\n}\n\nclass JSDocCommentImpl implements JSDocComment {\n\n    readonly elements: JSDocElement[];\n    readonly range: Range;\n\n    constructor(elements: JSDocElement[], range: Range) {\n        this.elements = elements;\n        this.range = range;\n    }\n\n    getTag(name: string): JSDocTag | undefined {\n        return this.getAllTags().find(e => e.name === name);\n    }\n\n    getTags(name: string): JSDocTag[] {\n        return this.getAllTags().filter(e => e.name === name);\n    }\n\n    private getAllTags(): JSDocTag[] {\n        return this.elements.filter((e): e is JSDocTag => 'name' in e);\n    }\n\n    toString(): string {\n        let value = '';\n        for (const element of this.elements) {\n            if (value.length === 0) {\n                value = element.toString();\n            } else {\n                const text = element.toString();\n                value += fillNewlines(value) + text;\n            }\n        }\n        return value.trim();\n    }\n\n    toMarkdown(options?: JSDocRenderOptions): string {\n        let value = '';\n        for (const element of this.elements) {\n            if (value.length === 0) {\n                value = element.toMarkdown(options);\n            } else {\n                const text = element.toMarkdown(options);\n                value += fillNewlines(value) + text;\n            }\n        }\n        return value.trim();\n    }\n}\n\nclass JSDocTagImpl implements JSDocTag {\n    name: string;\n    content: JSDocParagraph;\n    range: Range;\n    inline: boolean;\n\n    constructor(name: string, content: JSDocParagraph, inline: boolean, range: Range) {\n        this.name = name;\n        this.content = content;\n        this.inline = inline;\n        this.range = range;\n    }\n\n    toString(): string {\n        let text = `@${this.name}`;\n        const content = this.content.toString();\n        if (this.content.inlines.length === 1) {\n            text = `${text} ${content}`;\n        } else if (this.content.inlines.length > 1) {\n            text = `${text}\\n${content}`;\n        }\n        if (this.inline) {\n            // Inline tags are surrounded by curly braces\n            return `{${text}}`;\n        } else {\n            return text;\n        }\n    }\n\n    toMarkdown(options?: JSDocRenderOptions): string {\n        return options?.renderTag?.(this) ?? this.toMarkdownDefault(options);\n    }\n\n    private toMarkdownDefault(options?: JSDocRenderOptions): string {\n        const content = this.content.toMarkdown(options);\n        if (this.inline) {\n            const rendered = renderInlineTag(this.name, content, options ?? {});\n            if (typeof rendered === 'string') {\n                return rendered;\n            }\n        }\n        let marker = '';\n        if (options?.tag === 'italic' || options?.tag === undefined) {\n            marker = '*';\n        } else if (options?.tag === 'bold') {\n            marker = '**';\n        } else if (options?.tag === 'bold-italic') {\n            marker = '***';\n        }\n        let text = `${marker}@${this.name}${marker}`;\n        if (this.content.inlines.length === 1) {\n            text = `${text} — ${content}`;\n        } else if (this.content.inlines.length > 1) {\n            text = `${text}\\n${content}`;\n        }\n        if (this.inline) {\n            // Inline tags are surrounded by curly braces\n            return `{${text}}`;\n        } else {\n            return text;\n        }\n    }\n}\n\nfunction renderInlineTag(tag: string, content: string, options: JSDocRenderOptions): string | undefined {\n    if (tag === 'linkplain' || tag === 'linkcode' || tag === 'link') {\n        const index = content.indexOf(' ');\n        let display = content;\n        if (index > 0) {\n            const displayStart = skipWhitespace(content, index);\n            display = content.substring(displayStart);\n            content = content.substring(0, index);\n        }\n        if (tag === 'linkcode' || (tag === 'link' && options.link === 'code')) {\n            // Surround the display value in a markdown inline code block\n            display = `\\`${display}\\``;\n        }\n        const renderedLink = options.renderLink?.(content, display) ?? renderLinkDefault(content, display);\n        return renderedLink;\n    }\n    return undefined;\n}\n\nfunction renderLinkDefault(content: string, display: string): string {\n    try {\n        URI.parse(content, true);\n        return `[${display}](${content})`;\n    } catch {\n        return content;\n    }\n}\n\nclass JSDocTextImpl implements JSDocParagraph {\n    inlines: JSDocInline[];\n    range: Range;\n\n    constructor(lines: JSDocInline[], range: Range) {\n        this.inlines = lines;\n        this.range = range;\n    }\n\n    toString(): string {\n        let text = '';\n        for (let i = 0; i < this.inlines.length; i++) {\n            const inline = this.inlines[i];\n            const next = this.inlines[i + 1];\n            text += inline.toString();\n            if (next && next.range.start.line > inline.range.start.line) {\n                text += '\\n';\n            }\n        }\n        return text;\n    }\n\n    toMarkdown(options?: JSDocRenderOptions): string {\n        let text = '';\n        for (let i = 0; i < this.inlines.length; i++) {\n            const inline = this.inlines[i];\n            const next = this.inlines[i + 1];\n            text += inline.toMarkdown(options);\n            if (next && next.range.start.line > inline.range.start.line) {\n                text += '\\n';\n            }\n        }\n        return text;\n    }\n}\n\nclass JSDocLineImpl implements JSDocLine {\n    text: string;\n    range: Range;\n\n    constructor(text: string, range: Range) {\n        this.text = text;\n        this.range = range;\n    }\n\n    toString(): string {\n        return this.text;\n    }\n    toMarkdown(): string {\n        return this.text;\n    }\n\n}\n\nfunction fillNewlines(text: string): string {\n    if (text.endsWith('\\n')) {\n        return '\\n';\n    } else {\n        return '\\n\\n';\n    }\n}\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode, AstNodeDescription } from '../syntax-tree.js';\nimport type { IndexManager } from '../workspace/index-manager.js';\nimport type { CommentProvider } from './comment-provider.js';\nimport type { JSDocTag } from './jsdoc.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { isJSDoc, parseJSDoc } from './jsdoc.js';\n\n/**\n * Provides documentation for AST nodes.\n */\nexport interface DocumentationProvider {\n    /**\n     * Returns a markdown documentation string for the specified AST node.\n     *\n     * The default implementation `JSDocDocumentationProvider` will inspect the comment associated with the specified node.\n     */\n    getDocumentation(node: AstNode): string | undefined;\n}\n\nexport class JSDocDocumentationProvider implements DocumentationProvider {\n\n    protected readonly indexManager: IndexManager;\n    protected readonly commentProvider: CommentProvider;\n\n    constructor(services: LangiumCoreServices) {\n        this.indexManager = services.shared.workspace.IndexManager;\n        this.commentProvider = services.documentation.CommentProvider;\n    }\n\n    getDocumentation(node: AstNode): string | undefined {\n        const comment = this.commentProvider.getComment(node);\n        if (comment && isJSDoc(comment)) {\n            const parsedJSDoc = parseJSDoc(comment);\n            return parsedJSDoc.toMarkdown({\n                renderLink: (link, display) => {\n                    return this.documentationLinkRenderer(node, link, display);\n                },\n                renderTag: (tag) => {\n                    return this.documentationTagRenderer(node, tag);\n                }\n            });\n        }\n        return undefined;\n    }\n\n    protected documentationLinkRenderer(node: AstNode, name: string, display: string): string | undefined {\n        const description = this.findNameInPrecomputedScopes(node, name) ?? this.findNameInGlobalScope(node, name);\n        if (description && description.nameSegment) {\n            const line = description.nameSegment.range.start.line + 1;\n            const character = description.nameSegment.range.start.character + 1;\n            const uri = description.documentUri.with({ fragment: `L${line},${character}` });\n            return `[${display}](${uri.toString()})`;\n        } else {\n            return undefined;\n        }\n    }\n\n    protected documentationTagRenderer(_node: AstNode, _tag: JSDocTag): string | undefined {\n        // Fall back to the default tag rendering\n        return undefined;\n    }\n\n    protected findNameInPrecomputedScopes(node: AstNode, name: string): AstNodeDescription | undefined {\n        const document = getDocument(node);\n        const precomputed = document.precomputedScopes;\n        if (!precomputed) {\n            return undefined;\n        }\n        let currentNode: AstNode | undefined = node;\n        do {\n            const allDescriptions = precomputed.get(currentNode);\n            const description = allDescriptions.find(e => e.name === name);\n            if (description) {\n                return description;\n            }\n            currentNode = currentNode.$container;\n        } while (currentNode);\n\n        return undefined;\n    }\n\n    protected findNameInGlobalScope(node: AstNode, name: string): AstNodeDescription | undefined {\n        const description = this.indexManager.allElements().find(e => e.name === name);\n        return description;\n    }\n}\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { GrammarConfig } from '../languages/grammar-config.js';\nimport { isAstNodeWithComment } from '../serializer/json-serializer.js';\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode } from '../syntax-tree.js';\nimport { findCommentNode } from '../utils/cst-utils.js';\n\n/**\n * Provides comments for AST nodes.\n */\nexport interface CommentProvider {\n    /**\n     * Returns the comment associated with the specified AST node.\n     * @param node The AST node to get the comment for.\n     * @returns The comment associated with the specified AST node or `undefined` if there is no comment.\n     */\n    getComment(node: AstNode): string | undefined;\n}\n\nexport class DefaultCommentProvider implements CommentProvider {\n    protected readonly grammarConfig: () => GrammarConfig;\n    constructor(services: LangiumCoreServices) {\n        this.grammarConfig = () => services.parser.GrammarConfig;\n    }\n    getComment(node: AstNode): string | undefined {\n        if(isAstNodeWithComment(node)) {\n            return node.$comment;\n        }\n        return findCommentNode(node.$cstNode, this.grammarConfig().multilineCommentRules)?.text;\n    }\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\n/* eslint-disable @typescript-eslint/no-explicit-any */\n\n/**\n * A `Module<I>` is a description of possibly grouped service factories.\n *\n * Given a type I = { group: { service: A } },\n * Module<I> := { group: { service: (injector: I) => A } }\n *\n * Making `I` available during the creation of `I` allows us to create cyclic\n * dependencies.\n */\nexport type Module<I, T = I> = {\n    [K in keyof T]: Module<I, T[K]> | ((injector: I) => T[K])\n}\n\nexport namespace Module {\n    export const merge = <M1, M2, R extends M1 & M2>(m1: Module<R, M1>, m2: Module<R, M2>) => (_merge(_merge({}, m1), m2) as Module<R, M1 & M2>);\n}\n\n/**\n * Given a set of modules, the inject function returns a lazily evaluated injector\n * that injects dependencies into the requested service when it is requested the\n * first time. Subsequent requests will return the same service.\n *\n * In the case of cyclic dependencies, an Error will be thrown. This can be fixed\n * by injecting a provider `() => T` instead of a `T`.\n *\n * Please note that the arguments may be objects or arrays. However, the result will\n * be an object. Using it with for..of will have no effect.\n *\n * @param module1 first Module\n * @param module2 (optional) second Module\n * @param module3 (optional) third Module\n * @param module4 (optional) fourth Module\n * @param module5 (optional) fifth Module\n * @param module6 (optional) sixth Module\n * @param module7 (optional) seventh Module\n * @param module8 (optional) eighth Module\n * @param module9 (optional) ninth Module\n * @returns a new object of type I\n */\nexport function inject<I1, I2, I3, I4, I5, I6, I7, I8, I9, I extends I1 & I2 & I3 & I4 & I5 & I6 & I7 & I8 & I9>(\n    module1: Module<I, I1>, module2?: Module<I, I2>, module3?: Module<I, I3>, module4?: Module<I, I4>, module5?: Module<I, I5>, module6?: Module<I, I6>, module7?: Module<I, I7>, module8?: Module<I, I8>, module9?: Module<I, I9>\n): I {\n    const module = [module1, module2, module3, module4, module5, module6, module7, module8, module9].reduce(_merge, {}) as Module<I>;\n    return _inject(module);\n}\n\nconst isProxy = Symbol('isProxy');\n\n/**\n * Eagerly load all services in the given dependency injection container. This is sometimes\n * necessary because services can register event listeners in their constructors.\n */\nexport function eagerLoad<T>(item: T): T {\n    if (item && (item as any)[isProxy]) {\n        for (const value of Object.values(item)) {\n            eagerLoad(value);\n        }\n    }\n    return item;\n}\n\n/**\n * Helper function that returns an injector by creating a proxy.\n * Invariant: injector is of type I. If injector is undefined, then T = I.\n */\nfunction _inject<I, T>(module: Module<I, T>, injector?: any): T {\n    const proxy: any = new Proxy({} as any, {\n        deleteProperty: () => false,\n        get: (obj, prop) => _resolve(obj, prop, module, injector || proxy),\n        getOwnPropertyDescriptor: (obj, prop) => (_resolve(obj, prop, module, injector || proxy), Object.getOwnPropertyDescriptor(obj, prop)), // used by for..in\n        has: (_, prop) => prop in module, // used by ..in..\n        ownKeys: () => [...Reflect.ownKeys(module), isProxy] // used by for..in\n    });\n    proxy[isProxy] = true;\n    return proxy;\n}\n\n/**\n * Internally used to tag a requested dependency, directly before calling the factory.\n * This allows us to find cycles during instance creation.\n */\nconst __requested__ = Symbol();\n\n/**\n * Returns the value `obj[prop]`. If the value does not exist, yet, it is resolved from\n * the module description. The result of service factories is cached. Groups are\n * recursively proxied.\n *\n * @param obj an object holding all group proxies and services\n * @param prop the key of a value within obj\n * @param module an object containing groups and service factories\n * @param injector the first level proxy that provides access to all values\n * @returns the requested value `obj[prop]`\n * @throws Error if a dependency cycle is detected\n */\nfunction _resolve<I, T>(obj: any, prop: string | symbol | number, module: Module<I, T>, injector: I): T[keyof T] | undefined {\n    if (prop in obj) {\n        if (obj[prop] instanceof Error) {\n            throw new Error('Construction failure. Please make sure that your dependencies are constructable.', {cause: obj[prop]});\n        }\n        if (obj[prop] === __requested__) {\n            throw new Error('Cycle detected. Please make \"' + String(prop) + '\" lazy. See https://langium.org/docs/configuration-services/#resolving-cyclic-dependencies');\n        }\n        return obj[prop];\n    } else if (prop in module) {\n        const value: Module<I, T[keyof T]> | ((injector: I) => T[keyof T]) = module[prop as keyof T];\n        obj[prop] = __requested__;\n        try {\n            obj[prop] = (typeof value === 'function') ? value(injector) : _inject(value, injector);\n        } catch (error) {\n            obj[prop] = error instanceof Error ? error : undefined;\n            throw error;\n        }\n        return obj[prop];\n    } else {\n        return undefined;\n    }\n}\n\n/**\n * Performs a deep-merge of two modules by writing source entries into the target module.\n *\n * @param target the module which is written\n * @param source the module which is read\n * @returns the target module\n */\nfunction _merge(target: Module<any>, source?: Module<any>): Module<unknown> {\n    if (source) {\n        for (const [key, value2] of Object.entries(source)) {\n            if (value2 !== undefined) {\n                const value1 = target[key];\n                if (value1 !== null && value2 !== null && typeof value1 === 'object' && typeof value2 === 'object') {\n                    target[key] = _merge(value1, value2);\n                } else {\n                    target[key] = value2;\n                }\n            }\n        }\n    }\n    return target;\n}\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { CancellationToken } from '../utils/cancellation.js';\nimport type { LangiumCoreServices } from '../services.js';\nimport type { AstNode } from '../syntax-tree.js';\nimport type { LangiumParser, ParseResult } from './langium-parser.js';\nimport type { Hydrator } from '../serializer/hydrator.js';\nimport type { Event } from '../utils/event.js';\nimport { Deferred, OperationCancelled } from '../utils/promise-utils.js';\nimport { Emitter } from '../utils/event.js';\n\n/**\n * Async parser that allows to cancel the current parsing process.\n * The sync parser implementation is blocking the event loop, which can become quite problematic for large files.\n *\n * Note that the default implementation is not actually async. It just wraps the sync parser in a promise.\n * A real implementation would create worker threads or web workers to offload the parsing work.\n */\nexport interface AsyncParser {\n    parse<T extends AstNode>(text: string, cancelToken: CancellationToken): Promise<ParseResult<T>>;\n}\n\n/**\n * Default implementation of the async parser. This implementation only wraps the sync parser in a promise.\n *\n * A real implementation would create worker threads or web workers to offload the parsing work.\n */\nexport class DefaultAsyncParser implements AsyncParser {\n\n    protected readonly syncParser: LangiumParser;\n\n    constructor(services: LangiumCoreServices) {\n        this.syncParser = services.parser.LangiumParser;\n    }\n\n    parse<T extends AstNode>(text: string): Promise<ParseResult<T>> {\n        return Promise.resolve(this.syncParser.parse<T>(text));\n    }\n}\n\nexport abstract class AbstractThreadedAsyncParser implements AsyncParser {\n\n    /**\n     * The thread count determines how many threads are used to parse files in parallel.\n     * The default value is 8. Decreasing this value increases startup performance, but decreases parallel parsing performance.\n     */\n    protected threadCount = 8;\n    /**\n     * The termination delay determines how long the parser waits for a thread to finish after a cancellation request.\n     * The default value is 200(ms).\n     */\n    protected terminationDelay = 200;\n    protected workerPool: ParserWorker[] = [];\n    protected queue: Array<Deferred<ParserWorker>> = [];\n\n    protected readonly hydrator: Hydrator;\n\n    constructor(services: LangiumCoreServices) {\n        this.hydrator = services.serializer.Hydrator;\n    }\n\n    protected initializeWorkers(): void {\n        while (this.workerPool.length < this.threadCount) {\n            const worker = this.createWorker();\n            worker.onReady(() => {\n                if (this.queue.length > 0) {\n                    const deferred = this.queue.shift();\n                    if (deferred) {\n                        worker.lock();\n                        deferred.resolve(worker);\n                    }\n                }\n            });\n            this.workerPool.push(worker);\n        }\n    }\n\n    async parse<T extends AstNode>(text: string, cancelToken: CancellationToken): Promise<ParseResult<T>> {\n        const worker = await this.acquireParserWorker(cancelToken);\n        const deferred = new Deferred<ParseResult<T>>();\n        let timeout: NodeJS.Timeout | undefined;\n        // If the cancellation token is requested, we wait for a certain time before terminating the worker.\n        // Since the cancellation token lives longer than the parsing process, we need to dispose the event listener.\n        // Otherwise, we might accidentally terminate the worker after the parsing process has finished.\n        const cancellation = cancelToken.onCancellationRequested(() => {\n            timeout = setTimeout(() => {\n                this.terminateWorker(worker);\n            }, this.terminationDelay);\n        });\n        worker.parse(text).then(result => {\n            const hydrated = this.hydrator.hydrate<T>(result);\n            deferred.resolve(hydrated);\n        }).catch(err => {\n            deferred.reject(err);\n        }).finally(() => {\n            cancellation.dispose();\n            clearTimeout(timeout);\n        });\n        return deferred.promise;\n    }\n\n    protected terminateWorker(worker: ParserWorker): void {\n        worker.terminate();\n        const index = this.workerPool.indexOf(worker);\n        if (index >= 0) {\n            this.workerPool.splice(index, 1);\n        }\n    }\n\n    protected async acquireParserWorker(cancelToken: CancellationToken): Promise<ParserWorker> {\n        this.initializeWorkers();\n        for (const worker of this.workerPool) {\n            if (worker.ready) {\n                worker.lock();\n                return worker;\n            }\n        }\n        const deferred = new Deferred<ParserWorker>();\n        cancelToken.onCancellationRequested(() => {\n            const index = this.queue.indexOf(deferred);\n            if (index >= 0) {\n                this.queue.splice(index, 1);\n            }\n            deferred.reject(OperationCancelled);\n        });\n        this.queue.push(deferred);\n        return deferred.promise;\n    }\n\n    protected abstract createWorker(): ParserWorker;\n}\n\nexport type WorkerMessagePost = (message: unknown) => void;\nexport type WorkerMessageCallback = (cb: (message: unknown) => void) => void;\n\nexport class ParserWorker {\n\n    protected readonly sendMessage: WorkerMessagePost;\n    protected readonly _terminate: () => void;\n    protected readonly onReadyEmitter = new Emitter<void>();\n\n    protected deferred = new Deferred<ParseResult>();\n    protected _ready = true;\n    protected _parsing = false;\n\n    get ready(): boolean {\n        return this._ready;\n    }\n\n    get onReady(): Event<void> {\n        return this.onReadyEmitter.event;\n    }\n\n    constructor(sendMessage: WorkerMessagePost, onMessage: WorkerMessageCallback, onError: WorkerMessageCallback, terminate: () => void) {\n        this.sendMessage = sendMessage;\n        this._terminate = terminate;\n        onMessage(result => {\n            const parseResult = result as ParseResult;\n            this.deferred.resolve(parseResult);\n            this.unlock();\n        });\n        onError(error => {\n            this.deferred.reject(error);\n            this.unlock();\n        });\n    }\n\n    terminate(): void {\n        this.deferred.reject(OperationCancelled);\n        this._terminate();\n    }\n\n    lock(): void {\n        this._ready = false;\n    }\n\n    unlock(): void {\n        this._parsing = false;\n        this._ready = true;\n        this.onReadyEmitter.fire();\n    }\n\n    parse(text: string): Promise<ParseResult> {\n        if (this._parsing) {\n            throw new Error('Parser worker is busy');\n        }\n        this._parsing = true;\n        this.deferred = new Deferred();\n        this.sendMessage(text);\n        return this.deferred.promise;\n    }\n}\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport { CancellationToken, CancellationTokenSource } from '../utils/cancellation.js';\nimport { Deferred, isOperationCancelled, type MaybePromise } from '../utils/promise-utils.js';\n\n/**\n * Utility service to execute mutually exclusive actions.\n */\nexport interface WorkspaceLock {\n    /**\n     * Performs a single async action, like initializing the workspace or processing document changes.\n     * Only one action will be executed at a time.\n     *\n     * When another action is queued up, the token provided for the action will be cancelled.\n     * Assuming the action makes use of this token, the next action only has to wait for the current action to finish cancellation.\n     */\n    write(action: (token: CancellationToken) => MaybePromise<void>): Promise<void>;\n\n    /**\n     * Performs a single action, like computing completion results or providing workspace symbols.\n     * Read actions will only be executed after all write actions have finished. They will be executed in parallel if possible.\n     *\n     * If a write action is currently running, the read action will be queued up and executed afterwards.\n     * If a new write action is queued up while a read action is waiting, the write action will receive priority and will be handled before the read action.\n     *\n     * Note that read actions are not allowed to modify anything in the workspace. Please use {@link write} instead.\n     */\n    read<T>(action: () => MaybePromise<T>): Promise<T>;\n\n    /**\n     * Cancels the last queued write action. All previous write actions already have been cancelled.\n     */\n    cancelWrite(): void;\n}\n\ntype LockAction<T = void> = (token: CancellationToken) => MaybePromise<T>;\n\ninterface LockEntry {\n    action: LockAction<unknown>;\n    deferred: Deferred<unknown>;\n    cancellationToken: CancellationToken;\n}\n\nexport class DefaultWorkspaceLock implements WorkspaceLock {\n\n    private previousTokenSource = new CancellationTokenSource();\n    private writeQueue: LockEntry[] = [];\n    private readQueue: LockEntry[] = [];\n    private done = true;\n\n    write(action: (token: CancellationToken) => MaybePromise<void>): Promise<void> {\n        this.cancelWrite();\n        const tokenSource = new CancellationTokenSource();\n        this.previousTokenSource = tokenSource;\n        return this.enqueue(this.writeQueue, action, tokenSource.token);\n    }\n\n    read<T>(action: () => MaybePromise<T>): Promise<T> {\n        return this.enqueue(this.readQueue, action);\n    }\n\n    private enqueue<T = void>(queue: LockEntry[], action: LockAction<T>, cancellationToken?: CancellationToken): Promise<T> {\n        const deferred = new Deferred<unknown>();\n        const entry: LockEntry = {\n            action,\n            deferred,\n            cancellationToken: cancellationToken ?? CancellationToken.None\n        };\n        queue.push(entry);\n        this.performNextOperation();\n        return deferred.promise as Promise<T>;\n    }\n\n    private async performNextOperation(): Promise<void> {\n        if (!this.done) {\n            return;\n        }\n        const entries: LockEntry[] = [];\n        if (this.writeQueue.length > 0) {\n            // Just perform the next write action\n            entries.push(this.writeQueue.shift()!);\n        } else if (this.readQueue.length > 0) {\n            // Empty the read queue and perform all actions in parallel\n            entries.push(...this.readQueue.splice(0, this.readQueue.length));\n        } else {\n            return;\n        }\n        this.done = false;\n        await Promise.all(entries.map(async ({ action, deferred, cancellationToken }) => {\n            try {\n                // Move the execution of the action to the next event loop tick via `Promise.resolve()`\n                const result = await Promise.resolve().then(() => action(cancellationToken));\n                deferred.resolve(result);\n            } catch (err) {\n                if (isOperationCancelled(err)) {\n                    // If the operation was cancelled, we don't want to reject the promise\n                    deferred.resolve(undefined);\n                } else {\n                    deferred.reject(err);\n                }\n            }\n        }));\n        this.done = true;\n        this.performNextOperation();\n    }\n\n    cancelWrite(): void {\n        this.previousTokenSource.cancel();\n    }\n}\n","/******************************************************************************\n * Copyright 2024 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\n/* eslint-disable @typescript-eslint/no-explicit-any */\n\nimport type { TokenType } from 'chevrotain';\nimport { CompositeCstNodeImpl, LeafCstNodeImpl, RootCstNodeImpl } from '../parser/cst-node-builder.js';\nimport { isAbstractElement, type AbstractElement, type Grammar } from '../languages/generated/ast.js';\nimport type { Linker } from '../references/linker.js';\nimport type { Lexer } from '../parser/lexer.js';\nimport type { LangiumCoreServices } from '../services.js';\nimport type { ParseResult } from '../parser/langium-parser.js';\nimport type { Reference, AstNode, CstNode, LeafCstNode, GenericAstNode, Mutable, RootCstNode } from '../syntax-tree.js';\nimport { isRootCstNode, isCompositeCstNode, isLeafCstNode, isAstNode, isReference } from '../syntax-tree.js';\nimport { streamAst } from '../utils/ast-utils.js';\nimport { BiMap } from '../utils/collections.js';\nimport { streamCst } from '../utils/cst-utils.js';\n\n/**\n * The hydrator service is responsible for allowing AST parse results to be sent across worker threads.\n */\nexport interface Hydrator {\n    /**\n     * Converts a parse result to a plain object. The resulting object can be sent across worker threads.\n     */\n    dehydrate(result: ParseResult<AstNode>): ParseResult<object>;\n    /**\n     * Converts a plain object to a parse result. The included AST node can then be used in the main thread.\n     * Calling this method on objects that have not been dehydrated first will result in undefined behavior.\n     */\n    hydrate<T extends AstNode = AstNode>(result: ParseResult<object>): ParseResult<T>;\n}\n\nexport interface DehydrateContext {\n    astNodes: Map<AstNode, any>;\n    cstNodes: Map<CstNode, any>;\n}\n\nexport interface HydrateContext {\n    astNodes: Map<any, AstNode>;\n    cstNodes: Map<any, CstNode>;\n}\n\nexport class DefaultHydrator implements Hydrator {\n\n    protected readonly grammar: Grammar;\n    protected readonly lexer: Lexer;\n    protected readonly linker: Linker;\n\n    protected readonly grammarElementIdMap = new BiMap<AbstractElement, number>();\n    protected readonly tokenTypeIdMap = new BiMap<number, TokenType>();\n\n    constructor(services: LangiumCoreServices) {\n        this.grammar = services.Grammar;\n        this.lexer = services.parser.Lexer;\n        this.linker = services.references.Linker;\n    }\n\n    dehydrate(result: ParseResult<AstNode>): ParseResult<object> {\n        return {\n            // We need to create shallow copies of the errors\n            // The original errors inherit from the `Error` class, which is not transferable across worker threads\n            lexerErrors: result.lexerErrors.map(e => ({ ...e })),\n            parserErrors: result.parserErrors.map(e => ({ ...e })),\n            value: this.dehydrateAstNode(result.value, this.createDehyrationContext(result.value))\n        };\n    }\n\n    protected createDehyrationContext(node: AstNode): DehydrateContext {\n        const astNodes = new Map<AstNode, any>();\n        const cstNodes = new Map<CstNode, any>();\n        for (const astNode of streamAst(node)) {\n            astNodes.set(astNode, {});\n        }\n        if (node.$cstNode) {\n            for (const cstNode of streamCst(node.$cstNode)) {\n                cstNodes.set(cstNode, {});\n            }\n        }\n        return {\n            astNodes,\n            cstNodes\n        };\n    }\n\n    protected dehydrateAstNode(node: AstNode, context: DehydrateContext): object {\n        const obj = context.astNodes.get(node) as Record<string, any>;\n        obj.$type = node.$type;\n        obj.$containerIndex = node.$containerIndex;\n        obj.$containerProperty = node.$containerProperty;\n        if (node.$cstNode !== undefined) {\n            obj.$cstNode = this.dehydrateCstNode(node.$cstNode, context);\n        }\n        for (const [name, value] of Object.entries(node)) {\n            if (name.startsWith('$')) {\n                continue;\n            }\n            if (Array.isArray(value)) {\n                const arr: any[] = [];\n                obj[name] = arr;\n                for (const item of value) {\n                    if (isAstNode(item)) {\n                        arr.push(this.dehydrateAstNode(item, context));\n                    } else if (isReference(item)) {\n                        arr.push(this.dehydrateReference(item, context));\n                    } else {\n                        arr.push(item);\n                    }\n                }\n            } else if (isAstNode(value)) {\n                obj[name] = this.dehydrateAstNode(value, context);\n            } else if (isReference(value)) {\n                obj[name] = this.dehydrateReference(value, context);\n            } else if (value !== undefined) {\n                obj[name] = value;\n            }\n        }\n        return obj;\n    }\n\n    protected dehydrateReference(reference: Reference, context: DehydrateContext): any {\n        const obj: Record<string, unknown> = {};\n        obj.$refText = reference.$refText;\n        if (reference.$refNode) {\n            obj.$refNode = context.cstNodes.get(reference.$refNode);\n        }\n        return obj;\n    }\n\n    protected dehydrateCstNode(node: CstNode, context: DehydrateContext): any {\n        const cstNode = context.cstNodes.get(node) as Record<string, any>;\n        if (isRootCstNode(node)) {\n            cstNode.fullText = node.fullText;\n        } else {\n            // Note: This returns undefined for hidden nodes (i.e. comments)\n            cstNode.grammarSource = this.getGrammarElementId(node.grammarSource);\n        }\n        cstNode.hidden = node.hidden;\n        cstNode.astNode = context.astNodes.get(node.astNode);\n        if (isCompositeCstNode(node)) {\n            cstNode.content = node.content.map(child => this.dehydrateCstNode(child, context));\n        } else if (isLeafCstNode(node)) {\n            cstNode.tokenType = node.tokenType.name;\n            cstNode.offset = node.offset;\n            cstNode.length = node.length;\n            cstNode.startLine = node.range.start.line;\n            cstNode.startColumn = node.range.start.character;\n            cstNode.endLine = node.range.end.line;\n            cstNode.endColumn = node.range.end.character;\n        }\n        return cstNode;\n    }\n\n    hydrate<T extends AstNode = AstNode>(result: ParseResult<object>): ParseResult<T> {\n        const node = result.value;\n        const context = this.createHydrationContext(node);\n        if ('$cstNode' in node) {\n            this.hydrateCstNode(node.$cstNode, context);\n        }\n        return {\n            lexerErrors: result.lexerErrors,\n            parserErrors: result.parserErrors,\n            value: this.hydrateAstNode(node, context) as T\n        };\n    }\n\n    protected createHydrationContext(node: any): HydrateContext {\n        const astNodes = new Map<any, AstNode>();\n        const cstNodes = new Map<any, CstNode>();\n        for (const astNode of streamAst(node)) {\n            astNodes.set(astNode, {} as AstNode);\n        }\n        let root: RootCstNode;\n        if (node.$cstNode) {\n            for (const cstNode of streamCst(node.$cstNode)) {\n                let cst: Mutable<CstNode> | undefined;\n                if ('fullText' in cstNode) {\n                    cst = new RootCstNodeImpl(cstNode.fullText as string);\n                    root = cst as RootCstNode;\n                } else if ('content' in cstNode) {\n                    cst = new CompositeCstNodeImpl();\n                } else if ('tokenType' in cstNode) {\n                    cst = this.hydrateCstLeafNode(cstNode);\n                }\n                if (cst) {\n                    cstNodes.set(cstNode, cst);\n                    cst.root = root!;\n                }\n            }\n        }\n        return {\n            astNodes,\n            cstNodes\n        };\n    }\n\n    protected hydrateAstNode(node: any, context: HydrateContext): AstNode {\n        const astNode = context.astNodes.get(node) as Mutable<GenericAstNode>;\n        astNode.$type = node.$type;\n        astNode.$containerIndex = node.$containerIndex;\n        astNode.$containerProperty = node.$containerProperty;\n        if (node.$cstNode) {\n            astNode.$cstNode = context.cstNodes.get(node.$cstNode);\n        }\n        for (const [name, value] of Object.entries(node)) {\n            if (name.startsWith('$')) {\n                continue;\n            }\n            if (Array.isArray(value)) {\n                const arr: unknown[] = [];\n                astNode[name] = arr;\n                for (const item of value) {\n                    if (isAstNode(item)) {\n                        arr.push(this.setParent(this.hydrateAstNode(item, context), astNode));\n                    } else if (isReference(item)) {\n                        arr.push(this.hydrateReference(item, astNode, name, context));\n                    } else {\n                        arr.push(item);\n                    }\n                }\n            } else if (isAstNode(value)) {\n                astNode[name] = this.setParent(this.hydrateAstNode(value, context), astNode);\n            } else if (isReference(value)) {\n                astNode[name] = this.hydrateReference(value, astNode, name, context);\n            } else if (value !== undefined) {\n                astNode[name] = value;\n            }\n        }\n        return astNode;\n    }\n\n    protected setParent(node: any, parent: any): any {\n        node.$container = parent as AstNode;\n        return node;\n    }\n\n    protected hydrateReference(reference: any, node: AstNode, name: string, context: HydrateContext): Reference {\n        return this.linker.buildReference(node, name, context.cstNodes.get(reference.$refNode)!, reference.$refText);\n    }\n\n    protected hydrateCstNode(cstNode: any, context: HydrateContext, num = 0): CstNode {\n        const cstNodeObj = context.cstNodes.get(cstNode) as Mutable<CstNode>;\n        if (typeof cstNode.grammarSource === 'number') {\n            cstNodeObj.grammarSource = this.getGrammarElement(cstNode.grammarSource);\n        }\n        cstNodeObj.astNode = context.astNodes.get(cstNode.astNode)!;\n        if (isCompositeCstNode(cstNodeObj)) {\n            for (const child of cstNode.content) {\n                const hydrated = this.hydrateCstNode(child, context, num++);\n                cstNodeObj.content.push(hydrated);\n            }\n        }\n        return cstNodeObj;\n    }\n\n    protected hydrateCstLeafNode(cstNode: any): LeafCstNode {\n        const tokenType = this.getTokenType(cstNode.tokenType);\n        const offset = cstNode.offset;\n        const length = cstNode.length;\n        const startLine = cstNode.startLine;\n        const startColumn = cstNode.startColumn;\n        const endLine = cstNode.endLine;\n        const endColumn = cstNode.endColumn;\n        const hidden = cstNode.hidden;\n        const node = new LeafCstNodeImpl(\n            offset,\n            length,\n            {\n                start: {\n                    line: startLine,\n                    character: startColumn\n                },\n                end: {\n                    line: endLine,\n                    character: endColumn\n                }\n            },\n            tokenType,\n            hidden\n        );\n        return node;\n    }\n\n    protected getTokenType(name: string): TokenType {\n        return this.lexer.definition[name];\n    }\n\n    protected getGrammarElementId(node: AbstractElement): number | undefined {\n        if (this.grammarElementIdMap.size === 0) {\n            this.createGrammarElementIdMap();\n        }\n        return this.grammarElementIdMap.get(node);\n    }\n\n    protected getGrammarElement(id: number): AbstractElement {\n        if (this.grammarElementIdMap.size === 0) {\n            this.createGrammarElementIdMap();\n        }\n        const element = this.grammarElementIdMap.getKey(id);\n        if (element) {\n            return element;\n        } else {\n            throw new Error('Invalid grammar element id: ' + id);\n        }\n    }\n\n    protected createGrammarElementIdMap(): void {\n        let id = 0;\n        for (const element of streamAst(this.grammar)) {\n            if (isAbstractElement(element)) {\n                this.grammarElementIdMap.set(element, id++);\n            }\n        }\n    }\n\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n******************************************************************************/\n\nimport type { Module } from './dependency-injection.js';\nimport type { LangiumDefaultCoreServices, LangiumDefaultSharedCoreServices, LangiumCoreServices, LangiumSharedCoreServices } from './services.js';\nimport type { FileSystemProvider } from './workspace/file-system-provider.js';\nimport { createGrammarConfig } from './languages/grammar-config.js';\nimport { createCompletionParser } from './parser/completion-parser-builder.js';\nimport { createLangiumParser } from './parser/langium-parser-builder.js';\nimport { DefaultTokenBuilder } from './parser/token-builder.js';\nimport { DefaultValueConverter } from './parser/value-converter.js';\nimport { DefaultLinker } from './references/linker.js';\nimport { DefaultNameProvider } from './references/name-provider.js';\nimport { DefaultReferences } from './references/references.js';\nimport { DefaultScopeComputation } from './references/scope-computation.js';\nimport { DefaultScopeProvider } from './references/scope-provider.js';\nimport { DefaultJsonSerializer } from './serializer/json-serializer.js';\nimport { DefaultServiceRegistry } from './service-registry.js';\nimport { DefaultDocumentValidator } from './validation/document-validator.js';\nimport { ValidationRegistry } from './validation/validation-registry.js';\nimport { DefaultAstNodeDescriptionProvider, DefaultReferenceDescriptionProvider } from './workspace/ast-descriptions.js';\nimport { DefaultAstNodeLocator } from './workspace/ast-node-locator.js';\nimport { DefaultConfigurationProvider } from './workspace/configuration.js';\nimport { DefaultDocumentBuilder } from './workspace/document-builder.js';\nimport { DefaultLangiumDocumentFactory, DefaultLangiumDocuments } from './workspace/documents.js';\nimport { DefaultIndexManager } from './workspace/index-manager.js';\nimport { DefaultWorkspaceManager } from './workspace/workspace-manager.js';\nimport { DefaultLexer } from './parser/lexer.js';\nimport { JSDocDocumentationProvider } from './documentation/documentation-provider.js';\nimport { DefaultCommentProvider } from './documentation/comment-provider.js';\nimport { LangiumParserErrorMessageProvider } from './parser/langium-parser.js';\nimport { DefaultAsyncParser } from './parser/async-parser.js';\nimport { DefaultWorkspaceLock } from './workspace/workspace-lock.js';\nimport { DefaultHydrator } from './serializer/hydrator.js';\n\n/**\n * Context required for creating the default language-specific dependency injection module.\n */\nexport interface DefaultCoreModuleContext {\n    shared: LangiumSharedCoreServices;\n}\n\n/**\n * Creates a dependency injection module configuring the default core services.\n * This is a set of services that are dedicated to a specific language.\n */\nexport function createDefaultCoreModule(context: DefaultCoreModuleContext): Module<LangiumCoreServices, LangiumDefaultCoreServices> {\n    return {\n        documentation: {\n            CommentProvider: (services) => new DefaultCommentProvider(services),\n            DocumentationProvider: (services) => new JSDocDocumentationProvider(services)\n        },\n        parser: {\n            AsyncParser: (services) => new DefaultAsyncParser(services),\n            GrammarConfig: (services) => createGrammarConfig(services),\n            LangiumParser: (services) => createLangiumParser(services),\n            CompletionParser: (services) => createCompletionParser(services),\n            ValueConverter: () => new DefaultValueConverter(),\n            TokenBuilder: () => new DefaultTokenBuilder(),\n            Lexer: (services) => new DefaultLexer(services),\n            ParserErrorMessageProvider: () => new LangiumParserErrorMessageProvider()\n        },\n        workspace: {\n            AstNodeLocator: () => new DefaultAstNodeLocator(),\n            AstNodeDescriptionProvider: (services) => new DefaultAstNodeDescriptionProvider(services),\n            ReferenceDescriptionProvider: (services) => new DefaultReferenceDescriptionProvider(services)\n        },\n        references: {\n            Linker: (services) => new DefaultLinker(services),\n            NameProvider: () => new DefaultNameProvider(),\n            ScopeProvider: (services) => new DefaultScopeProvider(services),\n            ScopeComputation: (services) => new DefaultScopeComputation(services),\n            References: (services) => new DefaultReferences(services)\n        },\n        serializer: {\n            Hydrator: (services) => new DefaultHydrator(services),\n            JsonSerializer: (services) => new DefaultJsonSerializer(services)\n        },\n        validation: {\n            DocumentValidator: (services) => new DefaultDocumentValidator(services),\n            ValidationRegistry: (services) => new ValidationRegistry(services)\n        },\n        shared: () => context.shared\n    };\n}\n\n/**\n * Context required for creating the default shared dependency injection module.\n */\nexport interface DefaultSharedCoreModuleContext {\n    /**\n     * Factory function to create a {@link FileSystemProvider}.\n     *\n     * Langium exposes an `EmptyFileSystem` and `NodeFileSystem`, exported through `langium/node`.\n     * When running Langium as part of a vscode language server or a Node.js app, using the `NodeFileSystem` is recommended,\n     * the `EmptyFileSystem` in every other use case.\n     */\n    fileSystemProvider: (services: LangiumSharedCoreServices) => FileSystemProvider;\n}\n\n/**\n * Creates a dependency injection module configuring the default shared core services.\n * This is the set of services that are shared between multiple languages.\n */\nexport function createDefaultSharedCoreModule(context: DefaultSharedCoreModuleContext): Module<LangiumSharedCoreServices, LangiumDefaultSharedCoreServices> {\n    return {\n        ServiceRegistry: () => new DefaultServiceRegistry(),\n        workspace: {\n            LangiumDocuments: (services) => new DefaultLangiumDocuments(services),\n            LangiumDocumentFactory: (services) => new DefaultLangiumDocumentFactory(services),\n            DocumentBuilder: (services) => new DefaultDocumentBuilder(services),\n            IndexManager: (services) => new DefaultIndexManager(services),\n            WorkspaceManager: (services) => new DefaultWorkspaceManager(services),\n            FileSystemProvider: (services) => context.fileSystemProvider(services),\n            WorkspaceLock: () => new DefaultWorkspaceLock(),\n            ConfigurationProvider: (services) => new DefaultConfigurationProvider(services)\n        }\n    };\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { LangiumCoreServices } from '../services.js';\nimport { DefaultNameRegexp } from '../utils/cst-utils.js';\nimport { isCommentTerminal, terminalRegex } from '../utils/grammar-utils.js';\nimport { isMultilineComment } from '../utils/regexp-utils.js';\nimport { isTerminalRule } from './generated/ast.js';\n\nexport interface GrammarConfig {\n    /**\n     * Lists all rule names which are classified as multiline comment rules\n     */\n    multilineCommentRules: string[]\n    /**\n     * A regular expression which matches characters of names\n     */\n    nameRegexp: RegExp\n}\n\n/**\n * Create the default grammar configuration (used by `createDefaultModule`). This can be overridden in a\n * language-specific module.\n */\nexport function createGrammarConfig(services: LangiumCoreServices): GrammarConfig {\n    const rules: string[] = [];\n    const grammar = services.Grammar;\n    for (const rule of grammar.rules) {\n        if (isTerminalRule(rule) && isCommentTerminal(rule) && isMultilineComment(terminalRegex(rule))) {\n            rules.push(rule.name);\n        }\n    }\n    return {\n        multilineCommentRules: rules,\n        nameRegexp: DefaultNameRegexp\n    };\n}\n","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { LangiumCoreServices } from '../services.js';\nimport { LangiumCompletionParser } from './langium-parser.js';\nimport { createParser } from './parser-builder-base.js';\n\nexport function createCompletionParser(services: LangiumCoreServices): LangiumCompletionParser {\n    const grammar = services.Grammar;\n    const lexer = services.parser.Lexer;\n    const parser = new LangiumCompletionParser(services);\n    createParser(grammar, parser, lexer.definition);\n    parser.finalize();\n    return parser;\n}\n","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport type { URI } from '../utils/uri-utils.js';\n\nexport interface FileSystemNode {\n    readonly isFile: boolean;\n    readonly isDirectory: boolean;\n    readonly uri: URI;\n}\n\nexport type FileSystemFilter = (node: FileSystemNode) => boolean;\n\n/**\n * Provides methods to interact with an abstract file system. The default implementation is based on the node.js `fs` API.\n */\nexport interface FileSystemProvider {\n    /**\n     * Reads a document asynchronously from a given URI.\n     * @returns The string content of the file with the specified URI.\n     */\n    readFile(uri: URI): Promise<string>;\n    /**\n     * Reads the directory information for the given URI.\n     * @returns The list of file system entries that are contained within the specified directory.\n     */\n    readDirectory(uri: URI): Promise<FileSystemNode[]>;\n}\n\nexport class EmptyFileSystemProvider implements FileSystemProvider {\n\n    readFile(): Promise<string> {\n        throw new Error('No file system is available.');\n    }\n\n    async readDirectory(): Promise<FileSystemNode[]> {\n        return [];\n    }\n\n}\n\nexport const EmptyFileSystem = {\n    fileSystemProvider: () => new EmptyFileSystemProvider()\n};\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n\nimport { createDefaultCoreModule, createDefaultSharedCoreModule } from '../default-module.js';\nimport type { Module } from '../dependency-injection.js';\nimport { inject } from '../dependency-injection.js';\nimport * as ast from '../languages/generated/ast.js';\nimport type { LangiumCoreServices, LangiumSharedCoreServices, PartialLangiumCoreServices, PartialLangiumSharedCoreServices } from '../services.js';\nimport type { Mutable } from '../syntax-tree.js';\nimport { EmptyFileSystem } from '../workspace/file-system-provider.js';\nimport { URI } from './uri-utils.js';\n\nconst minimalGrammarModule: Module<LangiumCoreServices, PartialLangiumCoreServices> = {\n    Grammar: () => undefined as unknown as ast.Grammar,\n    LanguageMetaData: () => ({\n        caseInsensitive: false,\n        fileExtensions: ['.langium'],\n        languageId: 'langium'\n    })\n};\n\nconst minimalSharedGrammarModule: Module<LangiumSharedCoreServices, PartialLangiumSharedCoreServices> = {\n    AstReflection: () => new ast.LangiumGrammarAstReflection()\n};\n\nfunction createMinimalGrammarServices(): LangiumCoreServices {\n    const shared = inject(\n        createDefaultSharedCoreModule(EmptyFileSystem),\n        minimalSharedGrammarModule\n    );\n    const grammar = inject(\n        createDefaultCoreModule({ shared }),\n        minimalGrammarModule\n    );\n    shared.ServiceRegistry.register(grammar);\n    return grammar;\n}\n\n/**\n * Load a Langium grammar for your language from a JSON string. This is used by several services,\n * most notably the parser builder which interprets the grammar to create a parser.\n */\nexport function loadGrammarFromJson(json: string): ast.Grammar {\n    const services = createMinimalGrammarServices();\n    const astNode = services.serializer.JsonSerializer.deserialize(json) as Mutable<ast.Grammar>;\n    services.shared.workspace.LangiumDocumentFactory.fromModel(astNode, URI.parse(`memory://${astNode.name ?? 'grammar'}.langium`));\n    return astNode;\n}\n","import isSymbol from './isSymbol.js';\n\n/**\n * The base implementation of methods like `_.max` and `_.min` which accepts a\n * `comparator` to determine the extremum value.\n *\n * @private\n * @param {Array} array The array to iterate over.\n * @param {Function} iteratee The iteratee invoked per iteration.\n * @param {Function} comparator The comparator used to compare values.\n * @returns {*} Returns the extremum value.\n */\nfunction baseExtremum(array, iteratee, comparator) {\n  var index = -1,\n      length = array.length;\n\n  while (++index < length) {\n    var value = array[index],\n        current = iteratee(value);\n\n    if (current != null && (computed === undefined\n          ? (current === current && !isSymbol(current))\n          : comparator(current, computed)\n        )) {\n      var computed = current,\n          result = value;\n    }\n  }\n  return result;\n}\n\nexport default baseExtremum;\n","/**\n * The base implementation of `_.lt` which doesn't coerce arguments.\n *\n * @private\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if `value` is less than `other`,\n *  else `false`.\n */\nfunction baseLt(value, other) {\n  return value < other;\n}\n\nexport default baseLt;\n","import baseEach from './_baseEach.js';\nimport isArrayLike from './isArrayLike.js';\n\n/**\n * The base implementation of `_.map` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n */\nfunction baseMap(collection, iteratee) {\n  var index = -1,\n      result = isArrayLike(collection) ? Array(collection.length) : [];\n\n  baseEach(collection, function(value, key, collection) {\n    result[++index] = iteratee(value, key, collection);\n  });\n  return result;\n}\n\nexport default baseMap;\n","import assignValue from './_assignValue.js';\nimport castPath from './_castPath.js';\nimport isIndex from './_isIndex.js';\nimport isObject from './isObject.js';\nimport toKey from './_toKey.js';\n\n/**\n * The base implementation of `_.set`.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {Array|string} path The path of the property to set.\n * @param {*} value The value to set.\n * @param {Function} [customizer] The function to customize path creation.\n * @returns {Object} Returns `object`.\n */\nfunction baseSet(object, path, value, customizer) {\n  if (!isObject(object)) {\n    return object;\n  }\n  path = castPath(path, object);\n\n  var index = -1,\n      length = path.length,\n      lastIndex = length - 1,\n      nested = object;\n\n  while (nested != null && ++index < length) {\n    var key = toKey(path[index]),\n        newValue = value;\n\n    if (key === '__proto__' || key === 'constructor' || key === 'prototype') {\n      return object;\n    }\n\n    if (index != lastIndex) {\n      var objValue = nested[key];\n      newValue = customizer ? customizer(objValue, key, nested) : undefined;\n      if (newValue === undefined) {\n        newValue = isObject(objValue)\n          ? objValue\n          : (isIndex(path[index + 1]) ? [] : {});\n      }\n    }\n    assignValue(nested, key, newValue);\n    nested = nested[key];\n  }\n  return object;\n}\n\nexport default baseSet;\n","import baseGet from './_baseGet.js';\nimport baseSet from './_baseSet.js';\nimport castPath from './_castPath.js';\n\n/**\n * The base implementation of  `_.pickBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Object} object The source object.\n * @param {string[]} paths The property paths to pick.\n * @param {Function} predicate The function invoked per property.\n * @returns {Object} Returns the new object.\n */\nfunction basePickBy(object, paths, predicate) {\n  var index = -1,\n      length = paths.length,\n      result = {};\n\n  while (++index < length) {\n    var path = paths[index],\n        value = baseGet(object, path);\n\n    if (predicate(value, path)) {\n      baseSet(result, castPath(path, object), value);\n    }\n  }\n  return result;\n}\n\nexport default basePickBy;\n","import baseClone from './_baseClone.js';\n\n/** Used to compose bitmasks for cloning. */\nvar CLONE_SYMBOLS_FLAG = 4;\n\n/**\n * Creates a shallow clone of `value`.\n *\n * **Note:** This method is loosely based on the\n * [structured clone algorithm](https://mdn.io/Structured_clone_algorithm)\n * and supports cloning arrays, array buffers, booleans, date objects, maps,\n * numbers, `Object` objects, regexes, sets, strings, symbols, and typed\n * arrays. The own enumerable properties of `arguments` objects are cloned\n * as plain objects. An empty object is returned for uncloneable values such\n * as error objects, functions, DOM nodes, and WeakMaps.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to clone.\n * @returns {*} Returns the cloned value.\n * @see _.cloneDeep\n * @example\n *\n * var objects = [{ 'a': 1 }, { 'b': 2 }];\n *\n * var shallow = _.clone(objects);\n * console.log(shallow[0] === objects[0]);\n * // => true\n */\nfunction clone(value) {\n  return baseClone(value, CLONE_SYMBOLS_FLAG);\n}\n\nexport default clone;\n","import baseRest from './_baseRest.js';\nimport eq from './eq.js';\nimport isIterateeCall from './_isIterateeCall.js';\nimport keysIn from './keysIn.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own and inherited enumerable string keyed properties of source\n * objects to the destination object for all destination properties that\n * resolve to `undefined`. Source objects are applied from left to right.\n * Once a property is set, additional values of the same property are ignored.\n *\n * **Note:** This method mutates `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.defaultsDeep\n * @example\n *\n * _.defaults({ 'a': 1 }, { 'b': 2 }, { 'a': 3 });\n * // => { 'a': 1, 'b': 2 }\n */\nvar defaults = baseRest(function(object, sources) {\n  object = Object(object);\n\n  var index = -1;\n  var length = sources.length;\n  var guard = length > 2 ? sources[2] : undefined;\n\n  if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n    length = 1;\n  }\n\n  while (++index < length) {\n    var source = sources[index];\n    var props = keysIn(source);\n    var propsIndex = -1;\n    var propsLength = props.length;\n\n    while (++propsIndex < propsLength) {\n      var key = props[propsIndex];\n      var value = object[key];\n\n      if (value === undefined ||\n          (eq(value, objectProto[key]) && !hasOwnProperty.call(object, key))) {\n        object[key] = source[key];\n      }\n    }\n  }\n\n  return object;\n});\n\nexport default defaults;\n","import baseIteratee from './_baseIteratee.js';\nimport isArrayLike from './isArrayLike.js';\nimport keys from './keys.js';\n\n/**\n * Creates a `_.find` or `_.findLast` function.\n *\n * @private\n * @param {Function} findIndexFunc The function to find the collection index.\n * @returns {Function} Returns the new find function.\n */\nfunction createFind(findIndexFunc) {\n  return function(collection, predicate, fromIndex) {\n    var iterable = Object(collection);\n    if (!isArrayLike(collection)) {\n      var iteratee = baseIteratee(predicate, 3);\n      collection = keys(collection);\n      predicate = function(key) { return iteratee(iterable[key], key, iterable); };\n    }\n    var index = findIndexFunc(collection, predicate, fromIndex);\n    return index > -1 ? iterable[iteratee ? collection[index] : index] : undefined;\n  };\n}\n\nexport default createFind;\n","import baseFindIndex from './_baseFindIndex.js';\nimport baseIteratee from './_baseIteratee.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * This method is like `_.find` except that it returns the index of the first\n * element `predicate` returns truthy for instead of the element itself.\n *\n * @static\n * @memberOf _\n * @since 1.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the found element, else `-1`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'active': false },\n *   { 'user': 'fred',    'active': false },\n *   { 'user': 'pebbles', 'active': true }\n * ];\n *\n * _.findIndex(users, function(o) { return o.user == 'barney'; });\n * // => 0\n *\n * // The `_.matches` iteratee shorthand.\n * _.findIndex(users, { 'user': 'fred', 'active': false });\n * // => 1\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.findIndex(users, ['active', false]);\n * // => 0\n *\n * // The `_.property` iteratee shorthand.\n * _.findIndex(users, 'active');\n * // => 2\n */\nfunction findIndex(array, predicate, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseFindIndex(array, baseIteratee(predicate, 3), index);\n}\n\nexport default findIndex;\n","import createFind from './_createFind.js';\nimport findIndex from './findIndex.js';\n\n/**\n * Iterates over elements of `collection`, returning the first element\n * `predicate` returns truthy for. The predicate is invoked with three\n * arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {*} Returns the matched element, else `undefined`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'age': 36, 'active': true },\n *   { 'user': 'fred',    'age': 40, 'active': false },\n *   { 'user': 'pebbles', 'age': 1,  'active': true }\n * ];\n *\n * _.find(users, function(o) { return o.age < 40; });\n * // => object for 'barney'\n *\n * // The `_.matches` iteratee shorthand.\n * _.find(users, { 'age': 1, 'active': true });\n * // => object for 'pebbles'\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.find(users, ['active', false]);\n * // => object for 'fred'\n *\n * // The `_.property` iteratee shorthand.\n * _.find(users, 'active');\n * // => object for 'barney'\n */\nvar find = createFind(findIndex);\n\nexport default find;\n","import baseFlatten from './_baseFlatten.js';\n\n/**\n * Flattens `array` a single level deep.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to flatten.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * _.flatten([1, [2, [3, [4]], 5]]);\n * // => [1, 2, [3, [4]], 5]\n */\nfunction flatten(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? baseFlatten(array, 1) : [];\n}\n\nexport default flatten;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.has` without support for deep paths.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {Array|string} key The key to check.\n * @returns {boolean} Returns `true` if `key` exists, else `false`.\n */\nfunction baseHas(object, key) {\n  return object != null && hasOwnProperty.call(object, key);\n}\n\nexport default baseHas;\n","import baseHas from './_baseHas.js';\nimport hasPath from './_hasPath.js';\n\n/**\n * Checks if `path` is a direct property of `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @param {Array|string} path The path to check.\n * @returns {boolean} Returns `true` if `path` exists, else `false`.\n * @example\n *\n * var object = { 'a': { 'b': 2 } };\n * var other = _.create({ 'a': _.create({ 'b': 2 }) });\n *\n * _.has(object, 'a');\n * // => true\n *\n * _.has(object, 'a.b');\n * // => true\n *\n * _.has(object, ['a', 'b']);\n * // => true\n *\n * _.has(other, 'a');\n * // => false\n */\nfunction has(object, path) {\n  return object != null && hasPath(object, path, baseHas);\n}\n\nexport default has;\n","import baseGetTag from './_baseGetTag.js';\nimport isArray from './isArray.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar stringTag = '[object String]';\n\n/**\n * Checks if `value` is classified as a `String` primitive or object.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a string, else `false`.\n * @example\n *\n * _.isString('abc');\n * // => true\n *\n * _.isString(1);\n * // => false\n */\nfunction isString(value) {\n  return typeof value == 'string' ||\n    (!isArray(value) && isObjectLike(value) && baseGetTag(value) == stringTag);\n}\n\nexport default isString;\n","/**\n * Gets the last element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the last element of `array`.\n * @example\n *\n * _.last([1, 2, 3]);\n * // => 3\n */\nfunction last(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? array[length - 1] : undefined;\n}\n\nexport default last;\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseMap from './_baseMap.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates an array of values by running each element in `collection` thru\n * `iteratee`. The iteratee is invoked with three arguments:\n * (value, index|key, collection).\n *\n * Many lodash methods are guarded to work as iteratees for methods like\n * `_.every`, `_.filter`, `_.map`, `_.mapValues`, `_.reject`, and `_.some`.\n *\n * The guarded methods are:\n * `ary`, `chunk`, `curry`, `curryRight`, `drop`, `dropRight`, `every`,\n * `fill`, `invert`, `parseInt`, `random`, `range`, `rangeRight`, `repeat`,\n * `sampleSize`, `slice`, `some`, `sortBy`, `split`, `take`, `takeRight`,\n * `template`, `trim`, `trimEnd`, `trimStart`, and `words`\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n * @example\n *\n * function square(n) {\n *   return n * n;\n * }\n *\n * _.map([4, 8], square);\n * // => [16, 64]\n *\n * _.map({ 'a': 4, 'b': 8 }, square);\n * // => [16, 64] (iteration order is not guaranteed)\n *\n * var users = [\n *   { 'user': 'barney' },\n *   { 'user': 'fred' }\n * ];\n *\n * // The `_.property` iteratee shorthand.\n * _.map(users, 'user');\n * // => ['barney', 'fred']\n */\nfunction map(collection, iteratee) {\n  var func = isArray(collection) ? arrayMap : baseMap;\n  return func(collection, baseIteratee(iteratee, 3));\n}\n\nexport default map;\n","import baseExtremum from './_baseExtremum.js';\nimport baseLt from './_baseLt.js';\nimport identity from './identity.js';\n\n/**\n * Computes the minimum value of `array`. If `array` is empty or falsey,\n * `undefined` is returned.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Math\n * @param {Array} array The array to iterate over.\n * @returns {*} Returns the minimum value.\n * @example\n *\n * _.min([4, 2, 8, 6]);\n * // => 2\n *\n * _.min([]);\n * // => undefined\n */\nfunction min(array) {\n  return (array && array.length)\n    ? baseExtremum(array, identity, baseLt)\n    : undefined;\n}\n\nexport default min;\n","/** Used to match a single whitespace character. */\nvar reWhitespace = /\\s/;\n\n/**\n * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\n * character of `string`.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {number} Returns the index of the last non-whitespace character.\n */\nfunction trimmedEndIndex(string) {\n  var index = string.length;\n\n  while (index-- && reWhitespace.test(string.charAt(index))) {}\n  return index;\n}\n\nexport default trimmedEndIndex;\n","import trimmedEndIndex from './_trimmedEndIndex.js';\n\n/** Used to match leading whitespace. */\nvar reTrimStart = /^\\s+/;\n\n/**\n * The base implementation of `_.trim`.\n *\n * @private\n * @param {string} string The string to trim.\n * @returns {string} Returns the trimmed string.\n */\nfunction baseTrim(string) {\n  return string\n    ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\n    : string;\n}\n\nexport default baseTrim;\n","import baseTrim from './_baseTrim.js';\nimport isObject from './isObject.js';\nimport isSymbol from './isSymbol.js';\n\n/** Used as references for various `Number` constants. */\nvar NAN = 0 / 0;\n\n/** Used to detect bad signed hexadecimal string values. */\nvar reIsBadHex = /^[-+]0x[0-9a-f]+$/i;\n\n/** Used to detect binary string values. */\nvar reIsBinary = /^0b[01]+$/i;\n\n/** Used to detect octal string values. */\nvar reIsOctal = /^0o[0-7]+$/i;\n\n/** Built-in method references without a dependency on `root`. */\nvar freeParseInt = parseInt;\n\n/**\n * Converts `value` to a number.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {number} Returns the number.\n * @example\n *\n * _.toNumber(3.2);\n * // => 3.2\n *\n * _.toNumber(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toNumber(Infinity);\n * // => Infinity\n *\n * _.toNumber('3.2');\n * // => 3.2\n */\nfunction toNumber(value) {\n  if (typeof value == 'number') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return NAN;\n  }\n  if (isObject(value)) {\n    var other = typeof value.valueOf == 'function' ? value.valueOf() : value;\n    value = isObject(other) ? (other + '') : other;\n  }\n  if (typeof value != 'string') {\n    return value === 0 ? value : +value;\n  }\n  value = baseTrim(value);\n  var isBinary = reIsBinary.test(value);\n  return (isBinary || reIsOctal.test(value))\n    ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\n    : (reIsBadHex.test(value) ? NAN : +value);\n}\n\nexport default toNumber;\n","import toNumber from './toNumber.js';\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0,\n    MAX_INTEGER = 1.7976931348623157e+308;\n\n/**\n * Converts `value` to a finite number.\n *\n * @static\n * @memberOf _\n * @since 4.12.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted number.\n * @example\n *\n * _.toFinite(3.2);\n * // => 3.2\n *\n * _.toFinite(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toFinite(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toFinite('3.2');\n * // => 3.2\n */\nfunction toFinite(value) {\n  if (!value) {\n    return value === 0 ? value : 0;\n  }\n  value = toNumber(value);\n  if (value === INFINITY || value === -INFINITY) {\n    var sign = (value < 0 ? -1 : 1);\n    return sign * MAX_INTEGER;\n  }\n  return value === value ? value : 0;\n}\n\nexport default toFinite;\n","import toFinite from './toFinite.js';\n\n/**\n * Converts `value` to an integer.\n *\n * **Note:** This method is loosely based on\n * [`ToInteger`](http://www.ecma-international.org/ecma-262/7.0/#sec-tointeger).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted integer.\n * @example\n *\n * _.toInteger(3.2);\n * // => 3\n *\n * _.toInteger(Number.MIN_VALUE);\n * // => 0\n *\n * _.toInteger(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toInteger('3.2');\n * // => 3\n */\nfunction toInteger(value) {\n  var result = toFinite(value),\n      remainder = result % 1;\n\n  return result === result ? (remainder ? result - remainder : result) : 0;\n}\n\nexport default toInteger;\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.CancellationTokenSource = exports.CancellationToken = void 0;\nconst ral_1 = require(\"./ral\");\nconst Is = require(\"./is\");\nconst events_1 = require(\"./events\");\nvar CancellationToken;\n(function (CancellationToken) {\n    CancellationToken.None = Object.freeze({\n        isCancellationRequested: false,\n        onCancellationRequested: events_1.Event.None\n    });\n    CancellationToken.Cancelled = Object.freeze({\n        isCancellationRequested: true,\n        onCancellationRequested: events_1.Event.None\n    });\n    function is(value) {\n        const candidate = value;\n        return candidate && (candidate === CancellationToken.None\n            || candidate === CancellationToken.Cancelled\n            || (Is.boolean(candidate.isCancellationRequested) && !!candidate.onCancellationRequested));\n    }\n    CancellationToken.is = is;\n})(CancellationToken || (exports.CancellationToken = CancellationToken = {}));\nconst shortcutEvent = Object.freeze(function (callback, context) {\n    const handle = (0, ral_1.default)().timer.setTimeout(callback.bind(context), 0);\n    return { dispose() { handle.dispose(); } };\n});\nclass MutableToken {\n    constructor() {\n        this._isCancelled = false;\n    }\n    cancel() {\n        if (!this._isCancelled) {\n            this._isCancelled = true;\n            if (this._emitter) {\n                this._emitter.fire(undefined);\n                this.dispose();\n            }\n        }\n    }\n    get isCancellationRequested() {\n        return this._isCancelled;\n    }\n    get onCancellationRequested() {\n        if (this._isCancelled) {\n            return shortcutEvent;\n        }\n        if (!this._emitter) {\n            this._emitter = new events_1.Emitter();\n        }\n        return this._emitter.event;\n    }\n    dispose() {\n        if (this._emitter) {\n            this._emitter.dispose();\n            this._emitter = undefined;\n        }\n    }\n}\nclass CancellationTokenSource {\n    get token() {\n        if (!this._token) {\n            // be lazy and create the token only when\n            // actually needed\n            this._token = new MutableToken();\n        }\n        return this._token;\n    }\n    cancel() {\n        if (!this._token) {\n            // save an object by returning the default\n            // cancelled token when cancellation happens\n            // before someone asks for the token\n            this._token = CancellationToken.Cancelled;\n        }\n        else {\n            this._token.cancel();\n        }\n    }\n    dispose() {\n        if (!this._token) {\n            // ensure to initialize with an empty token if we had none\n            this._token = CancellationToken.None;\n        }\n        else if (this._token instanceof MutableToken) {\n            // actually dispose\n            this._token.dispose();\n        }\n    }\n}\nexports.CancellationTokenSource = CancellationTokenSource;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Emitter = exports.Event = void 0;\nconst ral_1 = require(\"./ral\");\nvar Event;\n(function (Event) {\n    const _disposable = { dispose() { } };\n    Event.None = function () { return _disposable; };\n})(Event || (exports.Event = Event = {}));\nclass CallbackList {\n    add(callback, context = null, bucket) {\n        if (!this._callbacks) {\n            this._callbacks = [];\n            this._contexts = [];\n        }\n        this._callbacks.push(callback);\n        this._contexts.push(context);\n        if (Array.isArray(bucket)) {\n            bucket.push({ dispose: () => this.remove(callback, context) });\n        }\n    }\n    remove(callback, context = null) {\n        if (!this._callbacks) {\n            return;\n        }\n        let foundCallbackWithDifferentContext = false;\n        for (let i = 0, len = this._callbacks.length; i < len; i++) {\n            if (this._callbacks[i] === callback) {\n                if (this._contexts[i] === context) {\n                    // callback & context match => remove it\n                    this._callbacks.splice(i, 1);\n                    this._contexts.splice(i, 1);\n                    return;\n                }\n                else {\n                    foundCallbackWithDifferentContext = true;\n                }\n            }\n        }\n        if (foundCallbackWithDifferentContext) {\n            throw new Error('When adding a listener with a context, you should remove it with the same context');\n        }\n    }\n    invoke(...args) {\n        if (!this._callbacks) {\n            return [];\n        }\n        const ret = [], callbacks = this._callbacks.slice(0), contexts = this._contexts.slice(0);\n        for (let i = 0, len = callbacks.length; i < len; i++) {\n            try {\n                ret.push(callbacks[i].apply(contexts[i], args));\n            }\n            catch (e) {\n                // eslint-disable-next-line no-console\n                (0, ral_1.default)().console.error(e);\n            }\n        }\n        return ret;\n    }\n    isEmpty() {\n        return !this._callbacks || this._callbacks.length === 0;\n    }\n    dispose() {\n        this._callbacks = undefined;\n        this._contexts = undefined;\n    }\n}\nclass Emitter {\n    constructor(_options) {\n        this._options = _options;\n    }\n    /**\n     * For the public to allow to subscribe\n     * to events from this Emitter\n     */\n    get event() {\n        if (!this._event) {\n            this._event = (listener, thisArgs, disposables) => {\n                if (!this._callbacks) {\n                    this._callbacks = new CallbackList();\n                }\n                if (this._options && this._options.onFirstListenerAdd && this._callbacks.isEmpty()) {\n                    this._options.onFirstListenerAdd(this);\n                }\n                this._callbacks.add(listener, thisArgs);\n                const result = {\n                    dispose: () => {\n                        if (!this._callbacks) {\n                            // disposable is disposed after emitter is disposed.\n                            return;\n                        }\n                        this._callbacks.remove(listener, thisArgs);\n                        result.dispose = Emitter._noop;\n                        if (this._options && this._options.onLastListenerRemove && this._callbacks.isEmpty()) {\n                            this._options.onLastListenerRemove(this);\n                        }\n                    }\n                };\n                if (Array.isArray(disposables)) {\n                    disposables.push(result);\n                }\n                return result;\n            };\n        }\n        return this._event;\n    }\n    /**\n     * To be kept private to fire an event to\n     * subscribers\n     */\n    fire(event) {\n        if (this._callbacks) {\n            this._callbacks.invoke.call(this._callbacks, event);\n        }\n    }\n    dispose() {\n        if (this._callbacks) {\n            this._callbacks.dispose();\n            this._callbacks = undefined;\n        }\n    }\n}\nexports.Emitter = Emitter;\nEmitter._noop = function () { };\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.stringArray = exports.array = exports.func = exports.error = exports.number = exports.string = exports.boolean = void 0;\nfunction boolean(value) {\n    return value === true || value === false;\n}\nexports.boolean = boolean;\nfunction string(value) {\n    return typeof value === 'string' || value instanceof String;\n}\nexports.string = string;\nfunction number(value) {\n    return typeof value === 'number' || value instanceof Number;\n}\nexports.number = number;\nfunction error(value) {\n    return value instanceof Error;\n}\nexports.error = error;\nfunction func(value) {\n    return typeof value === 'function';\n}\nexports.func = func;\nfunction array(value) {\n    return Array.isArray(value);\n}\nexports.array = array;\nfunction stringArray(value) {\n    return array(value) && value.every(elem => string(elem));\n}\nexports.stringArray = stringArray;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nlet _ral;\nfunction RAL() {\n    if (_ral === undefined) {\n        throw new Error(`No runtime abstraction layer installed`);\n    }\n    return _ral;\n}\n(function (RAL) {\n    function install(ral) {\n        if (ral === undefined) {\n            throw new Error(`No runtime abstraction layer provided`);\n        }\n        _ral = ral;\n    }\n    RAL.install = install;\n})(RAL || (RAL = {}));\nexports.default = RAL;\n"],"names":["InfoTokenBuilder","_Class","AbstractMermaidTokenBuilder","constructor","super","__name","InfoModule","parser","TokenBuilder","ValueConverter","CommonValueConverter","createInfoServices","context","arguments","length","undefined","EmptyFileSystem","shared","inject","createDefaultSharedCoreModule","MermaidGeneratedSharedModule","Info","createDefaultCoreModule","InfoGeneratedModule","ServiceRegistry","register","PieTokenBuilder","PieValueConverter","_Class2","AbstractMermaidValueConverter","runCustomConverter","rule","input","_cstNode","name","replace","trim","PieModule","createPieServices","Pie","PieGeneratedModule","PacketTokenBuilder","PacketModule","createPacketServices","Packet","PacketGeneratedModule","ArchitectureTokenBuilder","ArchitectureValueConverter","ArchitectureModule","createArchitectureServices","Architecture","ArchitectureGeneratedModule","GitGraphTokenBuilder","GitGraphModule","createGitGraphServices","GitGraph","GitGraphGeneratedModule","__defProp","Object","defineProperty","target","value","configurable","item","reflection","isInstance","Branch","Commit","Merge","loadedInfoGrammar","loadedPacketGrammar","loadedPieGrammar","loadedArchitectureGrammar","loadedGitGraphGrammar","MermaidAstReflection","AbstractAstReflection","getAllTypes","computeIsSubtype","subtype","supertype","this","isSubtype","getReferenceType","refInfo","referenceId","concat","container","$type","property","Error","getTypeMetaData","type","properties","defaultValue","InfoGrammar","_loadedInfoGrammar","loadGrammarFromJson","PacketGrammar","_loadedPacketGrammar","PieGrammar","_loadedPieGrammar","ArchitectureGrammar","_loadedArchitectureGr","GitGraphGrammar","_loadedGitGraphGramma","InfoLanguageMetaData","languageId","fileExtensions","caseInsensitive","PacketLanguageMetaData","PieLanguageMetaData","ArchitectureLanguageMetaData","GitGraphLanguageMetaData","AstReflection","Grammar","LanguageMetaData","rulesRegexes","ACC_DESCR","ACC_TITLE","TITLE","DefaultValueConverter","runConverter","cstNode","runCommonConverter","regex","match","exec","_Class3","_rule","_input","_Class4","DefaultTokenBuilder","keywords","Set","buildKeywordTokens","rules","terminalTokens","options","tokenTypes","forEach","tokenType","has","PATTERN","RegExp","toString","_Class5","parsers","initializers","info","async","createInfoServices2","LangiumParser","packet","createPacketServices2","pie","createPieServices2","architecture","createArchitectureServices2","gitGraph","createGitGraphServices2","parse","diagramType","text","initializer","result","lexerErrors","parserErrors","MermaidParseError","map","err","message","join","isAstNode","obj","isReference","$refText","isLinkingError","reference","subtypes","allSubtypes","node","nested","existing","getAllSubTypes","allTypes","types","possibleSubType","push","isCompositeCstNode","Array","isArray","content","isLeafCstNode","isRootCstNode","fullText","StreamImpl","startFn","nextFn","iterator","state","next","Symbol","isEmpty","Boolean","done","count","toArray","toSet","toMap","keyFn","valueFn","entryStream","element","Map","other","first","firstDone","DONE_RESULT","separator","addSeparator","indexOf","searchElement","fromIndex","index","every","predicate","some","callbackfn","filter","nonNullable","e","reduce","initialValue","previousValue","reduceRight","recursiveReduce","find","findIndex","includes","flatMap","mapped","isIterable","flat","depth","stream","head","tail","skipCount","i","limit","maxSize","size","distinct","by","set","add","exclude","key","otherKeySet","ownKey","prototype","call","EMPTY_STREAM","freeze","_len","collections","_key","collection","collIndex","arrIndex","array","TreeStreamImpl","root","children","iterators","includeRoot","pruned","pop","prune","Reduction","RangeComparison","streamCst","tokenToRange","token","start","character","startColumn","line","startLine","end","endColumn","endLine","toDocumentSegment","offset","range","inRange","to","comparison","Before","After","startInside","endInside","Inside","OverlapBack","OverlapFront","compareRange","sum","a","b","product","min","Math","max","DefaultNameRegexp","findCommentNode","commentNames","previous","hidden","parent","getPreviousNode","isCommentNode","child","ErrorWithLocation","assertUnreachable","_","AbstractRule","AbstractType","Condition","TypeDefinition","ValueLiteral","AbstractElement","ArrayLiteral","ArrayType","BooleanLiteral","Conjunction","Disjunction","InferredType","isInferredType","Interface","isInterface","Negation","NumberLiteral","Parameter","ParameterReference","ParserRule","isParserRule","ReferenceType","ReturnType","SimpleType","StringLiteral","TerminalRule","isTerminalRule","Type","isType","UnionType","Action","isAction","Alternatives","isAlternatives","Assignment","isAssignment","CharacterRange","CrossReference","isCrossReference","EndOfFile","Group","isGroup","Keyword","isKeyword","NegatedToken","RegexToken","RuleCall","isRuleCall","TerminalAlternatives","TerminalGroup","TerminalRuleCall","isTerminalRuleCall","UnorderedGroup","isUnorderedGroup","UntilToken","Wildcard","LangiumGrammarAstReflection","linkContentToContainer","entries","startsWith","$container","$containerProperty","$containerIndex","getContainerOfType","typePredicate","getDocument","rootNode","findRootNode","$document","streamContents","keys","keyIndex","arrayIndex","isAstNodeInRange","streamAllContents","streamAst","astNode","nodeRange","_a","$cstNode","streamReferences","copyDefaultValue","propertyType","cc","char","charCodeAt","insertToSet","subItem","addFlag","flagObj","flagKey","ASSERT_EXISTS","ASSERT_NEVER_REACH_HERE","isCharacter","digitsCharCodes","wordCharCodes","whitespaceCodes","hexDigitPattern","decimalPattern","decimalPatternNoZero","RegExpParser","idx","groupIdx","saveState","restoreState","newState","pattern","consumeChar","disjunction","flags","loc","begin","global","ignoreCase","multiLine","unicode","sticky","isRegExpFlag","popChar","substring","alts","alternative","peekChar","terms","isTerm","term","isAssertion","assertion","atom","quantifier","isBacktracking","atLeast","atMost","Infinity","integerIncludingZero","isDigit","greedy","dotAll","atomEscape","characterClass","group","isPatternCharacter","patternCharacter","isQuantifier","complement","decimalEscapeAtom","characterClassEscape","controlEscapeAtom","controlLetterEscapeAtom","nulCharacterAtom","hexEscapeSequenceAtom","regExpUnicodeEscapeSequenceAtom","identityEscapeAtom","positiveInteger","escapeCode","letter","test","toUpperCase","parseHexDigits","classPatternCharacterAtom","isClassAtom","from","classAtom","isRangeDash","classEscape","capturing","groupAst","number","parseInt","nextChar","howMuch","isAtom","prevState","howMany","hexString","hexChar","BaseRegExpVisitor","visitChildren","hasOwnProperty","visit","subChild","visitPattern","visitFlags","visitDisjunction","visitAlternative","visitStartAnchor","visitEndAnchor","visitWordBoundary","visitNonWordBoundary","visitLookahead","visitNegativeLookahead","visitCharacter","visitSet","visitGroup","visitGroupBackReference","visitQuantifier","NEWLINE_REGEXP","regexpParser","visitor","isStarting","endRegexpStack","multiline","endRegex","reset","startRegexp","String","fromCharCode","escapedChar","escapeRegExp","isMultilineComment","regexp","isWhitespace","partialMatches","partial","re","source","process","tmp","appendRaw","nbChars","substr","appendOptional","lastIndex","partialRegExp","getAllReachableRules","grammar","allTerminals","ruleNames","entryRule","ast","entry","getEntryRule","topMostRules","getHiddenRules","ruleDfs","visitedSet","refRule","ref","findNodeForProperty","nodes","findNodesForPropertyInternal","nodeFeature","grammarSource","feature","findNodesForKeywordInternal","keyword","treeIterator","keywordNodes","childNode","findNameAssignment","startNode","findNameAssignmentInternal","cache","go","refType","childAssignment","get","toLowerCase","typeRef","isDataTypeRule","isDataTypeRuleInternal","visited","definition","getExplicitRuleType","inferredType","dataType","returnType","getTypeName","actionType","action","getActionType","terminalRegex","terminalRule","s","u","abstractElementToRegex","flagText","_ref","_ref2","WILDCARD","withCardinality","alternatives","elements","cardinality","lookahead","right","keywordToRegex","left","wrap","characterRangeToRegex","negate","terminal","negateTokenToRegex","until","lastSlash","lastIndexOf","regexFlags","toFastProperties","toBecomeFast","FakeConstructor","fakeInstance","fakeAccess","bar","n","guard","toInteger","baseSlice","createAssigner","object","isPrototype","isArrayLike","copyObject","assignValue","props","arrayMap","getAllKeysIn","prop","baseIteratee","basePickBy","path","isObjectLike","baseGetTag","nodeIsRegExp","nodeUtil","isRegExp","baseUnary","baseIsRegExp","tokenLabel","tokType","isString","LABEL","AbstractProduction","_definition","accept","prod","NonTerminal","assign","pickBy","v","referencedRule","Rule","orgText","Alternative","ignoreAmbiguities","Option","RepetitionMandatory","RepetitionMandatoryWithSeparator","Repetition","RepetitionWithSeparator","Alternation","hasPredicates","Terminal","serializeProduction","convertDefinition","serializedNonTerminal","nonTerminalName","label","terminalType","serializedTerminal","terminalLabel","GAstVisitor","nodeAny","visitNonTerminal","visitOption","visitRepetitionMandatory","visitRepetitionMandatoryWithSeparator","visitRepetitionWithSeparator","visitRepetition","visitAlternation","visitTerminal","visitRule","baseEach","func","arraySome","baseSome","isIterateeCall","nativeMax","values","baseIndexOf","arrayEvery","baseEvery","isOptionalProd","alreadyVisited","subProd","getProductionDslName","RestWalker","walk","prevRest","currRest","drop","walkProdRef","walkTerminal","walkFlat","walkOption","walkAtLeastOne","walkAtLeastOneSep","walkManySep","walkMany","walkOr","refProd","flatProd","fullOrRest","optionProd","atLeastOneProd","fullAtLeastOneRest","atLeastOneSepProd","fullAtLeastOneSepRest","restForRepetitionWithSeparator","manyProd","fullManyRest","manySepProd","fullManySepRest","orProd","alt","prodWrapper","repSepProd","baseUniq","isSequenceProd","firstSet","seq","currSubProd","nextSubProdIdx","hasInnerProdsRemaining","isLastInnerProdOptional","uniq","firstForSequence","isBranchingProd","allAlternativesFirsts","innerProd","flatten","firstForBranching","IN","ResyncFollowsWalker","topProd","follows","startWalking","followName","inner","occurenceInParent","fullRest","t_in_topProd_follows","TypeError","args","apply","arrayFilter","baseFilter","iteratee","comparator","arrayIncludes","isCommon","valuesLength","arrayIncludesWith","cacheHas","SetCache","outer","computed","valuesIndex","baseRest","isArrayLikeObject","baseDifference","baseFlatten","resIndex","PRINT_ERROR","msg","console","error","PRINT_WARNING","warn","regExpAstCache","regExpParser","getRegExpAst","regExp","regExpStr","regExpAst","complementErrorMessage","failedOptimizationPrefixMsg","getOptimizedStartCodesIndices","ensureOptimizations","firstCharOptimizedIndices","msgSuffix","addOptimizedIdxToResult","code","rangeCode","minOptimizationVal","minUnOptVal","maxUnOptVal","minOptIdx","charCodeToOptimizedIndex","maxOptIdx","currOptIdx","isOptionalQuantifier","isWholeOptional","optimizedCharIdx","upperChar","lowerChar","handleIgnoreCase","findCode","setNode","targetCharCodes","codeOrRange","targetCode","CharCodeFinder","found","canMatchCharCode","charCodes","charCodeFinder","DEFAULT_MODE","MODES","SUPPORT_STICKY","analyzeTokenTypes","tracer","defaults","useSticky","debug","safeMode","positionTracking","lineTerminatorCharacters","onlyRelevantTypes","charCodeToOptimizedIdxMap","initCharCodeToOptimizedIndexMap","reject","currType","Lexer","NA","allTransformedPatterns","patternIdxToType","patternIdxToGroup","patternIdxToLongerAltIdxArr","patternIdxToPushMode","patternIdxToPopMode","patternIdxToCanLineTerminator","patternIdxToIsCustom","patternIdxToShort","emptyGroups","patternIdxToConfig","hasCustom","currPattern","regExpSource","addStickyFlag","addStartOfInput","isFunction","escapedRegExpString","wrappedRegExp","tokenTypeIdx","clazz","groupName","GROUP","SKIPPED","isUndefined","longerAltType","LONGER_ALT","PUSH_MODE","lineTerminatorCharCodes","getCharCodes","LINE_BREAKS","checkLineBreaksIssues","isCustomPattern","isShortPattern","acc","x","longerAlt","canLineTerminator","isCustom","short","canBeOptimized","charCodeToPatternIdxToConfig","currTokType","optimizedIdx","addToMapOfArrays","START_CHARS_HINT","lastOptimizedIdx","charOrInt","currOptimizedIdx","optimizedCodes","validatePatterns","validModesNames","errors","missingResult","tokenTypesWithMissingPattern","LexerDefinitionErrorType","MISSING_PATTERN","valid","difference","findMissingPatterns","invalidResult","tokenTypesWithInvalidPattern","INVALID_PATTERN","findInvalidPatterns","validTokenTypes","withRegExpPatterns","EndAnchorFinder","invalidRegex","regexpAst","endAnchorVisitor","end_of_input","EOI_ANCHOR_FOUND","findEndOfInputAnchor","StartAnchorFinder","startAnchorVisitor","start_of_input","SOI_ANCHOR_FOUND","findStartOfInputAnchor","invalidFlags","UNSUPPORTED_FLAGS_FOUND","findUnsupportedFlags","identicalPatterns","outerType","innerType","compact","duplicatePatterns","currIdenticalSet","setOfIdentical","tokenTypeNames","dupPatternSrc","DUPLICATE_PATTERNS_FOUND","findDuplicatePatterns","matchesEmptyString","EMPTY_MATCH_PATTERN","findEmptyMatchRegExps","validateRegExpPattern","invalidTypes","INVALID_GROUP_TYPE_FOUND","findInvalidGroupType","validModes","invalidModes","PUSH_MODE_DOES_NOT_EXIST","findModesThatDoNotExist","canBeTested","str","metaChars","noMetaChar","testIdx","regExpArray","testTokenType","UNREACHABLE_PATTERN","findUnreachablePatterns","performWarningRuntimeChecks","lexerDefinition","trackLines","warnings","hasAnyLineBreak","allTokenTypes","modes","concreteTokenTypes","terminatorCharCodes","currIssue","details","issue","IDENTIFY_TERMINATOR","errMsg","CUSTOM_LINE_BREAK","buildLineBreakIssueMessage","warningDescriptor","NO_LINE_BREAKS_FLAGS","LineTerminatorOptimizedTester","len","c","charsOrCodes","numOrString","charCode","timer","Date","getTime","val","time","tokenStructuredMatcher","tokInstance","tokConstructor","instanceType","isParent","categoryMatchesMap","tokenStructuredMatcherNoCategories","tokenShortNameIdx","tokenIdxToClass","augmentTokenTypes","tokenTypesAndParents","clone","categories","searching","CATEGORIES","newCategories","expandCategories","hasShortKeyProperty","hasCategoriesProperty","categoryMatches","hasExtendingTokensTypesMapProperty","assignTokenDefaultProps","singleAssignCategoriesToksMap","assignCategoriesMapProp","assignCategoriesTokensProp","nextNode","pathNode","nextCategory","newPath","isTokenType","defaultLexerErrorProvider","buildUnableToPopLexerModeMessage","image","buildUnexpectedCharactersMessage","startOffset","column","charAt","DEFAULT_LEXER_CONFIG","deferDefinitionErrorsHandling","lineTerminatorsPattern","errorMessageProvider","traceInitPerf","skipValidations","recoveryEnabled","config","lexerDefinitionErrors","lexerDefinitionWarning","trackStartLines","trackEndLines","canModeBeOptimized","TRACE_INIT","phaseDesc","phaseImpl","traceInitIndent","indent","traceInitMaxIdent","log","traceMethod","traceInitVal","actualDefinition","hasOnlySingleMode","defaultMode","MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE","MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY","MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST","currModeValue","currModeName","currIdx","LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED","currLongerAlt","MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE","performRuntimeChecks","allModeNames","currModDef","currModName","currAnalyzeResult","allErrMessagesString","chopInput","identity","matchWithTest","updateLastIndex","noop","matchWithExec","handleModes","computeNewColumn","updateTokenEndLineColumnLocation","createTokenInstance","createFullToken","createStartOnlyToken","createOffsetOnlyToken","addToken","addTokenUsingPush","handlePayload","handlePayloadWithCustom","addTokenUsingMemberAccess","handlePayloadNoCustom","unOptimizedModes","cannotBeOptimized","modeName","tokenize","initialMode","tokenizeInternal","j","k","matchAltImage","matchedImage","payload","altPayload","imageLength","newToken","errLength","orgLength","matchedTokensIndex","guessedNumberOfTokens","floor","matchedTokens","groups","clonedResult","groupKeys","currKey","currGroupValue","cloneEmptyGroups","lineTerminatorPattern","currModePatternsLength","currCharCodeToPatternIdxToConfig","modeStack","emptyArray","getPossiblePatterns","getPossiblePatternsSlow","getPossiblePatternsOptimized","possiblePatterns","pop_mode","popToken","newMode","last","modeCanBeOptimized","push_mode","currConfig","nextCharCode","chosenPatternIdxToConfig","chosenPatternsLength","singleCharCode","longerAltLength","longerAltConfig","longerAltPattern","foundTerminator","lastLTEndOffset","numOfLTsInMatch","errorStartOffset","errorLine","errorColumn","foundResyncPoint","tokens","pushMode","newLastIndex","lastLTIdx","lastCharIsLT","fixForEndingInLT","oldColumn","endOffset","tokenVector","tokenToAdd","hasTokenLabel","PARENT","POP_MODE","createToken","createTokenInternal","EOF","tokenMatcher","defaultParserErrorProvider","buildMismatchTokenMessage","expected","actual","ruleName","expectedMsg","buildNotAllInputParsedMessage","firstRedundant","buildNoViableAltMessage","_ref3","expectedPathsPerAlt","customUserDescription","errPrefix","errSuffix","allLookAheadPaths","currAltPaths","nextValidTokenSequences","currPath","currTokenType","nextValidSequenceItems","itemMsg","buildEarlyExitMessage","_ref4","expectedIterationPaths","defaultGrammarResolverErrorProvider","buildRuleNotFoundError","topLevelRule","undefinedRule","defaultGrammarValidatorErrorProvider","buildDuplicateFoundError","duplicateProds","topLevelName","duplicateProd","dslName","extraArgument","hasExplicitIndex","buildNamespaceConflictError","buildAlternationPrefixAmbiguityError","pathMsg","prefixPath","currTok","occurrence","alternation","ambiguityIndices","buildAlternationAmbiguityError","currtok","currMessage","buildEmptyRepetitionError","repetition","buildTokenNameError","buildEmptyAlternationError","emptyChoiceIdx","buildTooManyAlternativesError","buildLeftRecursionError","pathNames","leftRecursionPath","currRule","leftRecursivePath","buildInvalidRuleNameError","buildDuplicateRuleNameError","grammarName","GastRefResolverVisitor","nameToTopRule","errMsgProvider","resolveRefs","currTopLevel","ParserDefinitionErrorType","UNRESOLVED_SUBRULE_REF","unresolvedRefName","setter","accumulator","arrayAggregator","baseAggregator","createAggregator","baseAssignValue","AbstractNextPossibleTokensWalker","possibleTokTypes","nextProductionName","nextProductionOccurrence","isAtEndOfPath","ruleStack","reverse","occurrenceStack","updateExpectedNext","NextAfterTokenWalker","nextTerminalName","nextTerminalOccurrence","lastTok","lastTokOccurrence","restProd","AbstractNextTerminalAfterProductionWalker","topRule","isEndOfRule","NextTerminalAfterManyWalker","firstAfterMany","_first","NextTerminalAfterManySepWalker","firstAfterManySep","NextTerminalAfterAtLeastOneWalker","firstAfterAtLeastOne","NextTerminalAfterAtLeastOneSepWalker","atleastOneSepProd","firstAfterfirstAfterAtLeastOneSep","possiblePathsFrom","targetDef","maxLength","getAlternativesForProd","newDef","currAlt","partialPath","suffixDef","nextPossibleTokensAfter","initialDef","tokMatcher","maxLookAhead","EXIT_NON_TERMINAL","EXIT_NON_TERMINAL_ARR","EXIT_ALTERNATIVE","foundCompletePath","tokenVectorLength","minimalAlternativesIndex","possiblePaths","def","currDef","currRuleStack","currOccurrenceStack","nextPath","dropRight","nextIdx","nextTokenType","nextTokenOccurrence","newRuleStack","newOccurrenceStack","nextPathWithout","nextPathWith","secondIteration","separatorGast","nthRepetition","currAltPath","expandTopLevelRule","newCurrOccurrenceStack","PROD_TYPE","getProdType","OPTION","REPETITION","REPETITION_MANDATORY","REPETITION_MANDATORY_WITH_SEPARATOR","REPETITION_WITH_SEPARATOR","ALTERNATION","getLookaheadPaths","prodType","maxLookahead","getLookaheadPathsForOr","getLookaheadPathsForOptionalProd","buildAlternativesLookAheadFunc","dynamicTokensEnabled","numOfAlts","areAllOneTokenLookahead","orAlts","predicates","GATE","t","currNumOfPaths","currPredicate","currPathLength","nextToken","LA","singleTokenAlts","choiceToAlt","currExtendingType","buildSingleAlternativeLookaheadFunction","numOfPaths","singleTokensTypes","expectedTokenUniqueKey","RestDefinitionFinderWalker","targetOccurrence","targetProdType","restDef","checkIsTarget","expectedProdType","InsideDefinitionFinderVisitor","targetRef","expectedProdName","initializeArrayOfArrays","pathToHashKeys","longerKeys","currShorterKey","categoriesKeySuffix","isUniquePrefixHash","altKnownPathsKeys","searchPathKeys","currAltIdx","otherAltKnownPathsKeys","searchIdx","lookAheadSequenceFromAlternatives","altsDefs","partialAlts","finalResult","altsHashes","dict","newData","pathLength","currDataset","altIdx","currAltPathsAndSuffixes","currPathIdx","currPathPrefix","prefixKeys","currAltResult","containsPath","newPartialPathsAndSuffixes","ruleGrammar","insideDefVisitor","insideDef","afterDef","AlternativeGAST","searchPath","compareOtherPath","otherPath","searchTok","otherTok","areTokenCategoriesNotUsed","lookAheadPaths","singleAltPaths","singlePath","validateGrammar","topLevels","duplicateErrors","collectorVisitor","OccurrenceValidationCollector","allRuleProductions","allProductions","productionGroups","groupBy","identifyProductionForDuplicates","duplicates","currGroup","currDuplicates","firstProd","defError","DUPLICATE_PRODUCTIONS","param","getExtraProductionArgument","parameter","validateDuplicateProductions","termsNamespaceConflictErrors","tokenNames","currToken","currRuleName","CONFLICT_TOKENS_RULES_NAMESPACE","checkTerminalAndNoneTerminalsNameSpace","tooManyAltsErrors","curRule","orCollector","OrCollector","ors","alternations","currOr","TOO_MANY_ALTS","validateTooManyAlts","duplicateRulesError","allRules","className","occurrences","DUPLICATE_RULE_NAME","validateRuleDoesNotAlreadyExist","subrule","option","manySep","atLeastOne","atLeastOneSep","many","or","validateNoLeftRecursion","nextNonTerminals","getFirstNoneTerminal","LEFT_RECURSION","validNextSteps","errorsFromNextSteps","currRefRule","currSubDef","isFirstOptional","hasMore","rest","validateAmbiguousAlternationAlternatives","globalMaxLookahead","currOccurrence","actualMaxLookahead","altsAmbiguityErrors","foundAmbiguousPaths","identicalAmbiguities","altsCurrPathAppearsIn","currOtherAlt","currOtherAltIdx","currErrors","currAmbDescriptor","ambgIndices","AMBIGUOUS_ALTS","checkAlternativesAmbiguities","altsPrefixAmbiguityErrors","pathsAndIndices","currPathsAndIdx","currPathAndIdx","targetIdx","targetPath","prefixAmbiguitiesPathsAndIndices","searchPathAndIdx","prefix","otherTokType","currAmbPathAndIdx","AMBIGUOUS_PREFIX_ALTS","checkPrefixAlternativesAmbiguities","RepetitionCollector","resolveGrammar","actualOptions","topRulesTable","refResolver","orgResolveGrammar","MISMATCHED_TOKEN_EXCEPTION","NO_VIABLE_ALT_EXCEPTION","EARLY_EXIT_EXCEPTION","NOT_ALL_INPUT_PARSED_EXCEPTION","RECOGNITION_EXCEPTION_NAMES","isRecognitionException","RecognitionException","resyncedTokens","setPrototypeOf","captureStackTrace","MismatchedTokenException","previousToken","NoViableAltException","NotAllInputParsedException","EarlyExitException","EOF_FOLLOW_KEY","IN_RULE_RECOVERY_EXCEPTION","InRuleRecoveryException","attemptInRepetitionRecovery","prodFunc","lookaheadFunc","dslMethodIdx","prodOccurrence","nextToksWalker","notStuck","getKeyForAutomaticLookahead","firstAfterRepInfo","firstAfterRepMap","getCurrRuleFullName","getGAstProductions","expectTokAfterLastMatch","nextTokIdx","RULE_STACK","shouldInRepetitionRecoveryBeTried","tryInRepetitionRecovery","AT_LEAST_ONE_IDX","MANY_SEP_IDX","AT_LEAST_ONE_SEP_IDX","ruleIdx","LLkLookaheadStrategy","DEFAULT_PARSER_CONFIG","validate","leftRecursionErrors","emptyAltErrors","validateEmptyOrAlternatives","ambiguousAltsErrors","emptyRepetitionErrors","validateSomeNonEmptyLookaheadPath","currTopRule","exceptLast","currAlternative","possibleFirstInAlt","NONE_LAST_EMPTY_ALT","validateEmptyOrAlternative","topLevelRules","currProd","pathsInsideProduction","NO_NON_EMPTY_LOOKAHEAD","buildLookaheadForAlternation","laFuncBuilder","buildLookaheadFuncForOr","buildLookaheadForOptional","lookaheadBuilder","buildLookaheadFuncForOptionalProd","dslMethods","repetitionWithSeparator","repetitionMandatory","repetitionMandatoryWithSeparator","setNodeLocationOnlyOffset","currNodeLocation","newLocationInfo","isNaN","setNodeLocationFull","defineNameProp","nameValue","enumerable","writable","defaultVisit","ctx","childrenNames","childrenNamesLength","currChildArray","currChildArrayLength","currChild","createBaseSemanticVisitorConstructor","derivedConstructor","semanticProto","validateVisitor","semanticDefinitionErrors","visitorInstance","missingErrors","missingRuleNames","CstVisitorDefinitionError","MISSING_METHOD","methodName","validateMissingCstMethods","errorMessages","currDefError","_RULE_NAMES","RECORDING_NULL_OBJECT","description","HANDLE_SEPARATOR","MAX_METHOD_IDX","pow","RFT","RECORDING_PHASE_TOKEN","RECORDING_PHASE_CSTNODE","recordProd","prodConstructor","mainProdArg","handleSep","assertMethodIdxIsValid","prevProd","peek","recordingProdStack","grammarAction","DEF","newProd","SEP","MAX_LOOKAHEAD","recordOrProd","hasOptions","newOrProd","IGNORE_AMBIGUITIES","currAltFlat","ALT","getIdxSuffix","KNOWN_RECORDER_ERROR","END_OF_FILE","NaN","outputCst","nodeLocationTracking","DEFAULT_RULE_CONFIG","recoveryValueFunc","resyncEnabled","derivedCtor","baseCtors","EMPTY_ALT","Parser","performSelfAnalysis","parserInstance","defErrorsMsgs","selfAnalysisDone","enableRecording","definedRulesNames","originalGrammarAction","recordedRuleGast","topLevelRuleRecord","gastProductionsCache","disableRecording","resolverErrors","definitionErrors","validationErrors","tokensMap","orgValidateGrammar","lookaheadValidationErrors","lookaheadValidationErrorMessages","lookaheadStrategy","errorMessage","CUSTOM_LOOKAHEAD_VALIDATION","validateLookahead","allFollows","topProductions","reSyncFollows","currRefsFollow","computeAllProdsFollows","resyncFollows","_b","initialize","preComputeLookaheadFunctions","DEFER_DEFINITION_ERRORS_HANDLING","tokenVocabulary","that","initErrorHandler","initLexerAdapter","initLooksAhead","initRecognizerEngine","initRecoverable","initTreeBuilder","initContentAssist","initGastRecorder","initPerformanceTracer","getTokenToInsert","tokToInsert","isInsertedInRecovery","canTokenTypeBeInsertedInRecovery","canTokenTypeBeDeletedInRecovery","grammarRule","grammarRuleArgs","lookAheadFunc","expectedTokType","reSyncTokType","findReSyncTokenType","savedLexerState","exportLexerState","passedResyncPoint","nextTokenWithoutResync","generateErrorMessage","SAVE_ERROR","SKIP_TOKEN","addToResyncTokens","importLexerState","isBackTracking","canPerformInRuleRecovery","getFollowsForInRuleRecovery","tokIdxInRule","grammarPath","getCurrentGrammarPath","getNextPossibleTokenTypes","tryInRuleRecovery","canRecoverWithSingleTokenInsertion","canRecoverWithSingleTokenDeletion","nextTok","consumeToken","expectedToken","mismatchedTok","possibleFollowsTokType","isInCurrentRuleReSyncSet","followKey","getCurrFollowKey","currentRuleReSyncSet","getFollowSetFromFollowKey","allPossibleReSyncTokTypes","flattenFollowSet","foundMatch","resyncTokType","currRuleShortName","getLastExplicitRuleShortName","currRuleIdx","getLastExplicitRuleOccurrenceIndex","prevRuleShortName","getPreviousExplicitRuleShortName","shortRuleNameToFullName","idxInCallingRule","inRule","buildFullFollowKeyStack","explicitRuleStack","explicitOccurrenceStack","RULE_OCCURRENCE_STACK","followStack","resyncTokens","reSyncTo","getHumanReadableRuleStack","currShortName","lookAheadFuncsCache","collectMethods","prodIdx","laFunc","fullRuleNameToShort","setLaFuncCache","computeLookaheadFunc","prodKey","prodMaxLookahead","dslMethodName","getLaFuncFromCache","CST_STACK","setNodeLocationFromToken","setNodeLocationFromNode","cstPostRule","setInitialNodeLocation","setInitialNodeLocationFullRecovery","cstPostRuleFull","setInitialNodeLocationFullRegular","setInitialNodeLocationOnlyOffsetRecovery","cstPostRuleOnlyOffset","setInitialNodeLocationOnlyOffsetRegular","cstInvocationStateUpdate","cstFinallyStateUpdate","cstPostTerminal","cstPostNonTerminal","location","fullRuleName","create","ruleCstNode","prevToken","consumedToken","rootCst","tokenTypeName","ruleCstResult","preCstNode","ruleResult","addNoneTerminalToCst","getBaseCstVisitorConstructor","baseCstVisitorConstructor","newBaseCstVisitorConstructor","getBaseCstVisitorConstructorWithDefaults","baseCstVisitorWithDefaultsConstructor","newConstructor","baseConstructor","withDefaultsProto","createBaseVisitorConstructorWithDefaults","tokVector","tokVectorLength","newInput","soughtIdx","resetLexerState","moveToTerminatedState","getLexerPosition","shortRuleNameToFull","ruleShortNameIdx","subruleIdx","isBackTrackingStack","uniqueTokens","isObject","noTokenCategoriesUsed","tokenConstructor","defineRule","impl","shortName","BITS_FOR_METHOD_TYPE","invokeRuleWithTry","ruleInvocationStateUpdate","cst","invokeRuleCatch","ruleFinallyStateUpdate","_len2","_key2","resyncEnabledConfig","isFirstInvokedRule","reSyncEnabled","recogError","partialCstResult","recoveredNode","optionInternal","actionORMethodDef","optionInternalLogic","orgLookaheadFunction","atLeastOneInternal","laKey","atLeastOneInternalLogic","raiseEarlyExitException","ERR_MSG","doSingleRepetition","atLeastOneSepFirstInternal","atLeastOneSepFirstInternalLogic","separatorLookAheadFunc","CONSUME","repetitionSepSecondInternal","manyInternal","manyInternalLogic","lookaheadFunction","manySepFirstInternal","manySepFirstInternalLogic","nextTerminalAfterWalker","beforeIteration","orInternal","altsOrOpts","altIdxToTake","raiseNoAltException","isAtEndOfInput","firstRedundantTok","subruleInternal","ruleToCall","ARGS","subruleInternalError","consumeInternal","consumeInternalError","eFromConsumption","consumeInternalRecovery","eFromInRuleRecovery","saveRecogState","savedErrors","savedRuleStack","lexerState","reloadRecogState","fullName","ACTION","consume","CONSUME1","CONSUME2","CONSUME3","CONSUME4","CONSUME5","CONSUME6","CONSUME7","CONSUME8","CONSUME9","SUBRULE","SUBRULE1","SUBRULE2","SUBRULE3","SUBRULE4","SUBRULE5","SUBRULE6","SUBRULE7","SUBRULE8","SUBRULE9","OPTION1","OPTION2","OPTION3","OPTION4","OPTION5","OPTION6","OPTION7","OPTION8","OPTION9","OR","OR1","OR2","OR3","OR4","OR5","OR6","OR7","OR8","OR9","MANY","MANY1","MANY2","MANY3","MANY4","MANY5","MANY6","MANY7","MANY8","MANY9","MANY_SEP","MANY_SEP1","MANY_SEP2","MANY_SEP3","MANY_SEP4","MANY_SEP5","MANY_SEP6","MANY_SEP7","MANY_SEP8","MANY_SEP9","AT_LEAST_ONE","AT_LEAST_ONE1","AT_LEAST_ONE2","AT_LEAST_ONE3","AT_LEAST_ONE4","AT_LEAST_ONE5","AT_LEAST_ONE6","AT_LEAST_ONE7","AT_LEAST_ONE8","AT_LEAST_ONE9","AT_LEAST_ONE_SEP","AT_LEAST_ONE_SEP1","AT_LEAST_ONE_SEP2","AT_LEAST_ONE_SEP3","AT_LEAST_ONE_SEP4","AT_LEAST_ONE_SEP5","AT_LEAST_ONE_SEP6","AT_LEAST_ONE_SEP7","AT_LEAST_ONE_SEP8","AT_LEAST_ONE_SEP9","RULE","implementation","ruleImplementation","OVERRIDE_RULE","ruleErrors","INVALID_RULE_OVERRIDE","validateRuleIsOverridden","BACKTRACK","orgState","getSerializedGastProductions","topRules","_errors","ruleOccurrenceStack","newErrors","userDefinedErrMsg","insideProdPaths","actualTokens","errMsgTypes","lookAheadPathsPerAlternative","computeContentAssist","startRuleName","precedingInput","startRuleGast","topRuleName","topProduction","RECORDING_PHASE","arg1","arg2","consumeInternalRecord","subruleInternalRecord","optionInternalRecord","orInternalRecord","manyInternalRecord","manySepFirstInternalRecord","atLeastOneInternalRecord","atLeastOneSepFirstInternalRecord","ACTION_RECORD","BACKTRACK_RECORD","LA_RECORD","newTopLevelRule","originalError","mutabilityError","JSON","stringify","newNoneTerminal","userTraceInitPerf","traceIsNumber","baseCtor","baseProto","getOwnPropertyNames","propName","basePropDescriptor","getOwnPropertyDescriptor","EmbeddedActionsParser","configClone","buildATNKey","AbstractTransition","isEpsilon","AtomTransition","EpsilonTransition","RuleTransition","ruleStart","followState","createATN","atn","decisionMap","decisionStates","ruleToStartState","ruleToStopState","states","ruleLength","stop","createRuleStartAndStopATNStates","ruleBlock","block","buildRuleHandle","production","tokenRef","currentRule","nonTerminal","addTransition","ruleRef","defineDecisionState","handle","makeAlts","optional","epsilon","starState","star","sep","repetitionSep","plusState","plus","repetitionMandatorySep","handles","altsLength","transition","transitions","isRuleTransition","ruleTransition","removeState","makeBlock","blkStart","blkEnd","loop","loopback","loopEnd","decision","epsilonOnlyTransitions","nextTokenWithinRule","stateNumber","splice","DFA_ERROR","ATNConfigSet","configs","finalize","getATNConfigKey","stack","createDFACache","startState","predicateSet","atnStartState","PredicateSet","is","EMPTY_PREDICATES","LLStarLookaheadStrategy","logging","dfas","decisionLength","decisionToDFA","initATNSimulator","decisionIndex","isLL1Sequence","prediction","gate","adaptivePredict","g","sequences","allowEmpty","fullSet","altSet","indices","dfaCaches","dfa","addDFAState","newDFAState","computeStartState","performLookahead","s0","previousD","d","edges","computeLookaheadTarget","buildAdaptivePredictError","isAcceptState","reach","intermediate","skippedStopStates","transitionLength","getReachableTarget","closure","hasConfigInRuleStopState","computeReachSet","addDFAEdge","predictedAlt","getUniqueAlt","uniqueAlt","allConfigsInRuleStopStates","altSets","configToAlts","getConflictingAltSets","hasConflictingAltSet","hasStateAssociatedWithOneAlt","hasConflictTerminatingPrediction","reportLookaheadAmbiguity","atnState","buildAmbiguityError","current","nextTransitions","actualToken","possibleTokenTypes","uniqBy","tokenPath","mapKey","numberOfTransitions","p","atnStack","getEpsilonTarget","DocumentUri","URI","integer","uinteger","Position","Range","Location","LocationLink","Color","ColorInformation","ColorPresentation","FoldingRangeKind","FoldingRange","DiagnosticRelatedInformation","DiagnosticSeverity","DiagnosticTag","CodeDescription","Diagnostic","Command","TextEdit","ChangeAnnotation","ChangeAnnotationIdentifier","AnnotatedTextEdit","TextDocumentEdit","CreateFile","RenameFile","DeleteFile","WorkspaceEdit","TextDocumentIdentifier","VersionedTextDocumentIdentifier","OptionalVersionedTextDocumentIdentifier","TextDocumentItem","MarkupKind","MarkupContent","CompletionItemKind","InsertTextFormat","CompletionItemTag","InsertReplaceEdit","InsertTextMode","CompletionItemLabelDetails","CompletionItem","CompletionList","MarkedString","Hover","ParameterInformation","SignatureInformation","DocumentHighlightKind","DocumentHighlight","SymbolKind","SymbolTag","SymbolInformation","WorkspaceSymbol","DocumentSymbol","CodeActionKind","CodeActionTriggerKind","CodeActionContext","CodeAction","CodeLens","FormattingOptions","DocumentLink","SelectionRange","SemanticTokenTypes","SemanticTokenModifiers","SemanticTokens","InlineValueText","InlineValueVariableLookup","InlineValueEvaluatableExpression","InlineValueContext","InlayHintKind","InlayHintLabelPart","InlayHint","StringValue","InlineCompletionItem","InlineCompletionList","InlineCompletionTriggerKind","SelectedCompletionInfo","InlineCompletionContext","WorkspaceFolder","MIN_VALUE","MAX_VALUE","Number","candidate","Is","objectLiteral","one","two","three","four","uri","string","targetUri","targetRange","targetSelectionRange","originSelectionRange","red","green","blue","alpha","numberRange","color","textEdit","additionalTextEdits","typedArray","Comment","Imports","Region","startCharacter","endCharacter","kind","collapsedText","defined","Warning","Information","Hint","Unnecessary","Deprecated","href","severity","relatedInformation","codeDescription","title","command","newText","insert","position","del","needsConfirmation","boolean","annotation","annotationId","textDocument","edits","overwrite","ignoreIfExists","oldUri","newUri","recursive","ignoreIfNotExists","changes","documentChanges","change","version","PlainText","Markdown","Text","Method","Function","Constructor","Field","Variable","Class","Module","Property","Unit","Value","Enum","Snippet","File","Reference","Folder","EnumMember","Constant","Struct","Event","Operator","TypeParameter","asIs","adjustIndentation","detail","items","isIncomplete","fromPlainText","plainText","language","contents","documentation","parameters","Read","Write","Namespace","Package","Key","Null","containerName","selectionRange","deprecated","tags","Empty","QuickFix","Refactor","RefactorExtract","RefactorInline","RefactorRewrite","Source","SourceOrganizeImports","SourceFixAll","Invoked","Automatic","diagnostics","only","triggerKind","kindOrCommandOrEdit","checkKind","edit","isPreferred","data","tabSize","insertSpaces","resultId","variableName","caseSensitiveLookup","expression","frameId","stoppedLocation","tooltip","textEdits","paddingLeft","paddingRight","createSnippet","insertText","filterText","selectedCompletionInfo","TextDocument","mergeSort","compare","slice","leftIdx","rightIdx","ret","FullTextDocument","lineCount","getText","positionAt","offsetAt","applyEdits","document","sortedEdits","diff","lastModifiedOffset","_uri","_languageId","_version","_content","_lineOffsets","update","event","getLineOffsets","lineOffsets","isLineStart","ch","low","high","mid","lineOffset","nextLineOffset","check","CstNodeBuilder","nodeStack","buildRootNode","RootCstNodeImpl","buildCompositeNode","compositeNode","CompositeCstNodeImpl","buildLeafNode","leafNode","LeafCstNodeImpl","removeNode","construct","addHiddenTokens","hiddenTokens","hiddenNode","addHiddenToken","tokenStart","tokenEnd","childStart","childEnd","AbstractCstNode","_astNode","_offset","_length","_hidden","_tokenType","_range","CstNodeContainer","firstNonHiddenNode","lastNonHiddenNode","firstNode","lastNode","_rangeCache","firstRange","lastRange","addParents","unshift","_len3","_key3","_text","DatatypeSymbol","isDataTypeNode","withRuleSuffix","endsWith","AbstractLangiumParser","services","_unorderedGroups","lexer","wrapper","ChevrotainWrapper","ParserConfig","ParserErrorMessageProvider","choices","wrapOr","callback","wrapOption","wrapMany","wrapAtLeastOne","isRecording","IS_RECORDING","unorderedGroups","getRuleStack","wrapSelfAnalysis","nodeBuilder","assignmentMap","linker","references","Linker","converter","astReflection","fragment","ruleMethod","DEFINE_RULE","startImplementation","bind","mainRule","lexerResult","clear","wrapConsume","isValidToken","assignment","isCrossRef","getAssignment","convertedValue","convert","operator","subruleResult","wrapSubrule","performSubruleAssignment","resultKind","assignWithoutOverride","newItem","typeMetaData","genericNode","assignMandatoryProperties","buildReference","existingValue","newValue","AbstractParserErrorMessageProvider","LangiumParserErrorMessageProvider","LangiumCompletionParser","elementStack","lastElementStack","nextTokenIndex","stackSize","resetState","tokenIndex","keepStackSize","resetStackSize","removeUnexpectedElements","before","after","defaultConfig","useDefaultLookahead","createParser","parserContext","reachable","parserRules","buildElement","buildRules","method","ignoreGuard","buildKeyword","buildAction","buildCrossReference","ruleCall","namedArgs","buildPredicate","ruleArgs","ruleTarget","buildRuleCallPredicate","getRule","getToken","buildRuleCall","methods","predicatedMethod","getGuardCondition","buildAlternatives","orIdx","idFunc","lParser","stackId","groupState","trackedAlternatives","wrapped","delete","buildUnorderedGroup","buildGroup","condition","isConjunction","isNegation","isParameterReference","isBooleanLiteral","true","guardCondition","crossRef","assignTerminal","getRuleName","createLangiumParser","prepareLangiumParser","buildTokens","reachableRules","buildTerminalTokens","terminalToken","buildTerminalToken","requiresCustomPattern","regexPatternFunction","stickyRegex","sort","buildKeywordToken","buildKeywordPattern","findLongerAlt","getCaseInsensitivePattern","longerAlts","nameAssigment","getCrossReferenceTerminal","convertInt","convertString","convertID","_c","getRuleType","convertNumber","convertBoolean","convertBigint","convertDate","convertEscapeCharacter","BigInt","lastTick","globalInterruptionPeriod","OperationCancelled","isOperationCancelled","interruptAndCheck","CancellationToken","None","now","Promise","resolve","setImmediate","setTimeout","isCancellationRequested","Deferred","promise","arg","isIncremental","getWellformedRange","addedLineOffsets","computeLineOffsets","isFull","ensureBeforeEOL","isEOL","rangeLength","isAtLineStart","textOffset","getWellformedEdit","spans","r","o","h","cwd","normalize","isAbsolute","relative","f","l","_makeLong","dirname","basename","extname","format","dir","base","ext","delimiter","win32","posix","exports","toStringTag","platform","navigator","userAgent","scheme","authority","query","isUri","fsPath","with","_defineProperty","m","C","file","y","toJSON","revive","_formatted","external","_fsPath","_sep","$mid","encodeURIComponent","decodeURIComponent","_unused","w","A","P","joinPath","resolvePath","UriUtils","DocumentState","Utils","equals","fromPath","toPath","fromParts","split","toParts","repeat","DefaultLangiumDocumentFactory","serviceRegistry","textDocuments","workspace","TextDocuments","fileSystemProvider","FileSystemProvider","fromUri","cancellationToken","readFile","createAsync","fromTextDocument","fromString","fromModel","model","$model","parseResult","createLangiumDocument","cancelToken","parseAsync","Parsed","textDocumentGetter","createTextDocumentGetter","oldText","getServices","AsyncParser","textDoc","DefaultLangiumDocuments","documentMap","langiumDocumentFactory","LangiumDocumentFactory","all","addDocument","uriString","getOrCreateDocument","createDocument","then","hasDocument","invalidateDocument","langiumDoc","Changed","precomputedScopes","deleteDocument","DefaultLinker","langiumDocuments","LangiumDocuments","scopeProvider","ScopeProvider","astNodeLocator","AstNodeLocator","link","doLink","getCandidate","_nodeDescription","documentUri","linkedNode","loadAstNode","createLinkingError","unlink","getScope","getElement","refNode","refText","$refNode","refData","getLinkedNode","ComputedScopes","descr","$nodeDescription","nodeDescription","doc","getAstNode","targetDescription","referenceType","DefaultNameProvider","getName","isNamed","getNameNode","DefaultReferences","nameProvider","NameProvider","IndexManager","nodeLocator","findDeclaration","sourceCstNode","findAssignment","nodeElem","nameNode","isChildNode","findDeclarationNode","targetNode","findReferences","refs","includeDeclaration","getReferenceToSelf","indexReferences","findAllReferences","getAstNodePath","sourceUri","sourcePath","segment","local","MultiMap","addAll","entriesGroupedByKey","BiMap","inverse","getKey","DefaultScopeComputation","descriptions","AstNodeDescriptionProvider","computeExports","computeExportsForNode","parentNode","exportNode","createDescription","computeLocalScopes","scopes","processNode","StreamScope","outerScope","getAllElements","MapScope","localName","elementStream","DisposableCache","toDispose","isDisposed","onDispose","disposable","dispose","throwIfDisposed","SimpleCache","provider","ContextCache","contextKey","cacheForContext","contextCache","documentCache","WorkspaceCache","sharedServices","DocumentBuilder","onUpdate","DefaultScopeProvider","indexManager","globalScopeCache","precomputed","currentNode","allDescriptions","desc","getGlobalScope","createScope","createScopeForNodes","_context","allElements","isIntermediateReference","DefaultJsonSerializer","ignoreProperties","commentProvider","CommentProvider","serialize","specificReplacer","replacer","defaultReplacer","currentDocument","space","deserialize","linkNode","sourceText","textRegions","comments","uriConverter","refValue","targetDocument","$ref","$error","addAstNodeRegionWithAssignmentsTo","$textRegion","documentURI","$sourceText","_d","comment","getComment","$comment","createDocumentSegment","assignments","propertyAssignments","findNodesForProperty","containerProperty","containerIndex","propertyName","reviveReference","mutable","getRefNode","fragmentIndex","DefaultServiceRegistry","singleton","diagnosticData","ValidationCategory","DocumentValidator","Disposable","ValidationRegistry","checksRecord","thisObj","category","callbacks","wrapValidationException","addEntry","getChecks","checks","DefaultDocumentValidator","validationRegistry","validation","metadata","validateDocument","processLexingErrors","stopAfterLexingErrors","LexingError","processParsingErrors","stopAfterParsingErrors","ParsingError","processLinkingErrors","stopAfterLinkingErrors","LinkingError","validateAst","_options","lexerError","diagnostic","toDiagnosticSeverity","getSource","parserError","linkingError","containerType","toDiagnostic","validationItems","acceptor","getDiagnosticRange","findNodeForKeyword","DefaultAstNodeDescriptionProvider","nameNodeSegment","nameSegmentGetter","nameSegment","selectionSegment","DefaultReferenceDescriptionProvider","createDescriptions","targetNodeDescr","refCstNode","docUri","DefaultAstNodeLocator","segmentSeparator","indexSeparator","containerPath","newSegment","getPathSegment","currentValue","propertyIndex","DefaultConfigurationProvider","_ready","settings","workspaceConfig","ready","params","capabilities","configuration","initialized","languages","section","lang","toSectionName","fetchConfiguration","configToUpdate","conf","updateSectionConfiguration","updateConfiguration","getConfiguration","sectionName","DefaultDocumentBuilder","updateBuildOptions","updateListeners","buildPhaseListeners","buildState","documentBuildWaiters","currentState","build","documents","Validated","IndexedReferences","previousCategories","validationChecks","completed","emitUpdate","buildDocuments","changed","deleted","deletedUri","remove","changedUri","newDocument","allChangedUris","shouldRelink","rebuildDocuments","Linked","listener","changedUris","isAffected","prepareBuild","runCancelable","IndexedContent","updateContent","scopeComputation","ScopeComputation","updateReferences","toBeValidated","shouldValidate","targetState","filtered","notifyBuildPhase","onBuildPhase","waitUntil","uriOrToken","buildDisposable","cancelDisposable","onCancellationRequested","listeners","getBuildOptions","validator","validationSetting","DefaultIndexManager","symbolIndex","symbolByTypeIndex","referenceIndex","astNodePath","targetDocUri","docRefs","refDescr","nodeType","uris","documentUris","getFileDescriptions","indexData","ReferenceDescriptionProvider","DefaultWorkspaceManager","initialBuildOptions","documentBuilder","mutex","WorkspaceLock","folders","workspaceFolders","_params","write","initializeWorkspace","performStartup","collector","loadAdditionalDocuments","wf","getRootFolder","traverseFolder","_folders","_collector","workspaceFolder","folderPath","readDirectory","includeEntry","isDirectory","isFile","_workspaceFolder","DefaultLexer","toTokenTypeDictionary","lexerTokens","isTokenTypeDictionary","chevrotainLexer","ChevrotainLexer","chevrotainResult","isIMultiModeLexerDefinition","res","isTokenTypeArray","parseJSDoc","opts","currentLine","currentCharacter","lines","lastCharacter","skipWhitespace","tagRegex","tagMatch","fullMatch","inlineTagMatches","matchAll","inlineTagRegex","buildInlineTokens","getLines","normalizeOptions","startPosition","JSDocCommentImpl","parseJSDocElement","parseJSDocComment","lineIndex","characterIndex","matchIndex","startContent","tagName","endContent","nonWhitespaceRegex","whitespaceEndRegex","parseJSDocTag","parseJSDocText","JSDocLineImpl","inlines","appendEmptyLine","firstToken","lastToken","parseJSDocInline","JSDocTextImpl","parseJSDocLine","inline","tagToken","docLine","JSDocTagImpl","normalizeOption","escaped","getTag","getAllTags","getTags","fillNewlines","toMarkdown","renderTag","toMarkdownDefault","rendered","tag","display","displayStart","renderedLink","renderLink","renderLinkDefault","renderInlineTag","marker","JSDocDocumentationProvider","getDocumentation","normalizedOptions","firstRegex","lastRegex","isJSDoc","documentationLinkRenderer","documentationTagRenderer","findNameInPrecomputedScopes","findNameInGlobalScope","_node","_tag","DefaultCommentProvider","grammarConfig","GrammarConfig","isAstNodeWithComment","multilineCommentRules","DefaultAsyncParser","syncParser","DefaultWorkspaceLock","previousTokenSource","CancellationTokenSource","writeQueue","readQueue","cancelWrite","tokenSource","enqueue","read","queue","deferred","performNextOperation","shift","cancel","DefaultHydrator","grammarElementIdMap","tokenTypeIdMap","dehydrate","dehydrateAstNode","createDehyrationContext","astNodes","cstNodes","dehydrateCstNode","arr","dehydrateReference","getGrammarElementId","hydrate","createHydrationContext","hydrateCstNode","hydrateAstNode","hydrateCstLeafNode","setParent","hydrateReference","num","cstNodeObj","getGrammarElement","hydrated","getTokenType","createGrammarElementIdMap","id","DocumentationProvider","nameRegexp","createGrammarConfig","CompletionParser","createCompletionParser","References","serializer","Hydrator","JsonSerializer","WorkspaceManager","ConfigurationProvider","module1","module2","module3","module4","module5","module6","module7","module8","module9","_inject","_merge","merge","m1","m2","isProxy","module","injector","proxy","Proxy","deleteProperty","_resolve","ownKeys","Reflect","__requested__","cause","value2","value1","EmptyFileSystemProvider","minimalGrammarModule","minimalSharedGrammarModule","json","createMinimalGrammarServices","isSymbol","customizer","castPath","toKey","objValue","isIndex","paths","baseGet","baseSet","baseClone","objectProto","sources","keysIn","propsIndex","propsLength","eq","findIndexFunc","iterable","createFind","baseFindIndex","hasPath","baseHas","baseMap","baseExtremum","baseLt","reWhitespace","reTrimStart","trimmedEndIndex","reIsBadHex","reIsBinary","reIsOctal","freeParseInt","valueOf","baseTrim","isBinary","INFINITY","toNumber","toFinite","remainder","ral_1","require","events_1","Cancelled","shortcutEvent","default","MutableToken","_isCancelled","_emitter","fire","Emitter","_token","_disposable","CallbackList","bucket","_callbacks","_contexts","foundCallbackWithDifferentContext","invoke","contexts","_event","thisArgs","disposables","onFirstListenerAdd","_noop","onLastListenerRemove","stringArray","elem","_ral","RAL","install","ral"],"sourceRoot":""}